{
  "pmcid": "PMC12685205",
  "source": "PMC",
  "download_date": "2025-12-09T15:16:04.240010",
  "metadata": {
    "journal_title": "PLOS One",
    "journal_nlm_ta": "PLoS One",
    "journal_iso_abbrev": "PLoS One",
    "journal": "PLOS One",
    "pmcid": "PMC12685205",
    "pmid": "41359618",
    "doi": "10.1371/journal.pone.0335141",
    "title": "Flight delay prediction: Evaluating machine learning algorithms for enhanced accuracy",
    "year": "2025",
    "month": "12",
    "day": "8",
    "pub_date": {
      "year": "2025",
      "month": "12",
      "day": "8"
    },
    "authors": [
      "AlBassam Sarah Ahmed A.",
      "AlShahrani Dhafir N."
    ],
    "abstract": "Flight delays pose substantial operational and economic challenges for airlines, directly affecting scheduling efficiency, resource allocation, and passenger satisfaction. Accurate prediction of arrival delays is therefore critical for optimizing airline operations and enhancing customer experience. This study systematically evaluates the predictive performance of six machine learning classifiers—Decision Tree, Random Forest, Support Vector Classifier (SVC), Logistic Regression, K-Nearest Neighbors (KNN), and Naive Bayes—on a comprehensive flight dataset, with particular attention to the challenges posed by class imbalance. To mitigate skewed class distributions, resampling techniques including Random Oversampling, Synthetic Minority Oversampling Technique (SMOTE), and Adaptive Synthetic Sampling (ADASYN) were applied to the training data. Model performance was rigorously assessed using stratified 10-fold cross-validation and further validated on a hold-out test set, employing multiple evaluation metrics: Accuracy, F1-score, Matthews Correlation Coefficient (MCC), and ROC-AUC. The results demonstrate that Random Forest combined with Random Oversampling and Decision Tree combined with SMOTE both achieved the highest predictive performance (accuracy 0.90, F1-score 0.90, MCC 0.73, ROC-AUC 0.87. Notably, simpler models such as Naive Bayes exhibited competitive results under balanced conditions, underscoring the continued relevance of probabilistic classifiers in certain operational contexts. These findings highlight the critical role of resampling strategies and rigorous cross-validation in developing reliable, high-performing predictive models for imbalanced flight delay datasets, offering actionable insights for both airline operations and data-driven decision-making."
  },
  "xml": "<?xml version=\"1.0\"  ?><!DOCTYPE pmc-articleset PUBLIC \"-//NLM//DTD ARTICLE SET 2.0//EN\" \"https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd\"><pmc-articleset><article xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:ali=\"http://www.niso.org/schemas/ali/1.0/\" xml:lang=\"en\" article-type=\"research-article\" dtd-version=\"1.4\"><processing-meta base-tagset=\"archiving\" mathml-version=\"3.0\" table-model=\"xhtml\" tagset-family=\"jats\"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type=\"nlm-ta\">PLoS One</journal-id><journal-id journal-id-type=\"iso-abbrev\">PLoS One</journal-id><journal-id journal-id-type=\"pmc-domain-id\">440</journal-id><journal-id journal-id-type=\"pmc-domain\">plosone</journal-id><journal-id journal-id-type=\"publisher-id\">plos</journal-id><journal-title-group><journal-title>PLOS One</journal-title></journal-title-group><issn pub-type=\"epub\">1932-6203</issn><publisher><publisher-name>PLOS</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type=\"pmcid\">PMC12685205</article-id><article-id pub-id-type=\"pmcid-ver\">PMC12685205.1</article-id><article-id pub-id-type=\"pmcaid\">12685205</article-id><article-id pub-id-type=\"pmcaiid\">12685205</article-id><article-id pub-id-type=\"pmid\">41359618</article-id><article-id pub-id-type=\"doi\">10.1371/journal.pone.0335141</article-id><article-id pub-id-type=\"publisher-id\">PONE-D-25-05607</article-id><article-version article-version-type=\"pmc-version\">1</article-version><article-categories><subj-group subj-group-type=\"heading\"><subject>Research Article</subject></subj-group><subj-group subj-group-type=\"Discipline-v3\"><subject>Computer and Information Sciences</subject><subj-group><subject>Artificial Intelligence</subject><subj-group><subject>Machine Learning</subject></subj-group></subj-group></subj-group><subj-group subj-group-type=\"Discipline-v3\"><subject>Physical Sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Applied Mathematics</subject><subj-group><subject>Algorithms</subject><subj-group><subject>Machine Learning Algorithms</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type=\"Discipline-v3\"><subject>Research and Analysis Methods</subject><subj-group><subject>Simulation and Modeling</subject><subj-group><subject>Algorithms</subject><subj-group><subject>Machine Learning Algorithms</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type=\"Discipline-v3\"><subject>Computer and Information Sciences</subject><subj-group><subject>Artificial Intelligence</subject><subj-group><subject>Machine Learning</subject><subj-group><subject>Machine Learning Algorithms</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type=\"Discipline-v3\"><subject>Engineering and Technology</subject><subj-group><subject>Civil Engineering</subject><subj-group><subject>Transportation Infrastructure</subject><subj-group><subject>Airports</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type=\"Discipline-v3\"><subject>Engineering and Technology</subject><subj-group><subject>Transportation</subject><subj-group><subject>Transportation Infrastructure</subject><subj-group><subject>Airports</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type=\"Discipline-v3\"><subject>Research and Analysis Methods</subject><subj-group><subject>Mathematical and Statistical Techniques</subject><subj-group><subject>Statistical Methods</subject><subj-group><subject>Forecasting</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type=\"Discipline-v3\"><subject>Physical Sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Statistics</subject><subj-group><subject>Statistical Methods</subject><subj-group><subject>Forecasting</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type=\"Discipline-v3\"><subject>Engineering and Technology</subject><subj-group><subject>Management Engineering</subject><subj-group><subject>Decision Analysis</subject><subj-group><subject>Decision Trees</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type=\"Discipline-v3\"><subject>Research and Analysis Methods</subject><subj-group><subject>Decision Analysis</subject><subj-group><subject>Decision Trees</subject></subj-group></subj-group></subj-group><subj-group subj-group-type=\"Discipline-v3\"><subject>Computer and Information Sciences</subject><subj-group><subject>Artificial Intelligence</subject><subj-group><subject>Machine Learning</subject><subj-group><subject>Deep Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type=\"Discipline-v3\"><subject>Computer and Information Sciences</subject><subj-group><subject>Artificial Intelligence</subject><subj-group><subject>Machine Learning</subject><subj-group><subject>Support Vector Machines</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type=\"Discipline-v3\"><subject>Biology and Life Sciences</subject><subj-group><subject>Organisms</subject><subj-group><subject>Eukaryota</subject><subj-group><subject>Plants</subject><subj-group><subject>Trees</subject></subj-group></subj-group></subj-group></subj-group></subj-group></article-categories><title-group><article-title>Flight delay prediction: Evaluating machine learning algorithms for enhanced accuracy</article-title><alt-title alt-title-type=\"running-head\">Flight delay prediction</alt-title></title-group><contrib-group><contrib contrib-type=\"author\" corresp=\"yes\"><contrib-id authenticated=\"true\" contrib-id-type=\"orcid\">https://orcid.org/0000-0001-7505-2428</contrib-id><name name-style=\"western\"><surname>AlBassam</surname><given-names initials=\"SAA\">Sarah Ahmed A.</given-names></name><role content-type=\"http://credit.niso.org/contributor-roles/conceptualization/\">Conceptualization</role><role content-type=\"http://credit.niso.org/contributor-roles/formal-analysis/\">Formal analysis</role><role content-type=\"http://credit.niso.org/contributor-roles/supervision/\">Supervision</role><role content-type=\"http://credit.niso.org/contributor-roles/writing-review-editing/\">Writing &#8211; review &amp; editing</role><xref rid=\"cor001\" ref-type=\"corresp\">*</xref><xref rid=\"aff001\" ref-type=\"aff\"/></contrib><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>AlShahrani</surname><given-names initials=\"DN\">Dhafir N.</given-names></name><role content-type=\"http://credit.niso.org/contributor-roles/conceptualization/\">Conceptualization</role><role content-type=\"http://credit.niso.org/contributor-roles/formal-analysis/\">Formal analysis</role><role content-type=\"http://credit.niso.org/contributor-roles/methodology/\">Methodology</role><role content-type=\"http://credit.niso.org/contributor-roles/software/\">Software</role><role content-type=\"http://credit.niso.org/contributor-roles/writing-original-draft/\">Writing &#8211; original draft</role><xref rid=\"aff001\" ref-type=\"aff\"/></contrib></contrib-group><aff id=\"aff001\">\n<addr-line>Department of Information Systems, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia</addr-line>\n</aff><contrib-group><contrib contrib-type=\"editor\"><name name-style=\"western\"><surname>Tajik</surname><given-names initials=\"N\">Nazanin</given-names></name><role>Editor</role><xref rid=\"edit1\" ref-type=\"aff\"/></contrib></contrib-group><aff id=\"edit1\">\n<addr-line>Mississippi State University, UNITED STATES OF AMERICA</addr-line>\n</aff><author-notes><fn fn-type=\"COI-statement\" id=\"coi001\"><p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p></fn><corresp id=\"cor001\">* E-mail: <email>salbassam@ksu.edu.sa</email></corresp></author-notes><pub-date pub-type=\"epub\"><day>8</day><month>12</month><year>2025</year></pub-date><pub-date pub-type=\"collection\"><year>2025</year></pub-date><volume>20</volume><issue>12</issue><issue-id pub-id-type=\"pmc-issue-id\">501623</issue-id><elocation-id>e0335141</elocation-id><history><date date-type=\"received\"><day>2</day><month>2</month><year>2025</year></date><date date-type=\"accepted\"><day>7</day><month>10</month><year>2025</year></date></history><pub-history><event event-type=\"pmc-release\"><date><day>08</day><month>12</month><year>2025</year></date></event><event event-type=\"pmc-live\"><date><day>09</day><month>12</month><year>2025</year></date></event><event event-type=\"pmc-last-change\"><date iso-8601-date=\"2025-12-09 14:25:12.950\"><day>09</day><month>12</month><year>2025</year></date></event></pub-history><permissions><copyright-statement>&#169; 2025 AlBassam, AlShahrani</copyright-statement><copyright-year>2025</copyright-year><copyright-holder>AlBassam, AlShahrani</copyright-holder><license><ali:license_ref specific-use=\"textmining\" content-type=\"ccbylicense\">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open access article distributed under the terms of the <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://creativecommons.org/licenses/by/4.0/\">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><self-uri xmlns:xlink=\"http://www.w3.org/1999/xlink\" content-type=\"pmc-pdf\" xlink:href=\"pone.0335141.pdf\"/><self-uri xmlns:xlink=\"http://www.w3.org/1999/xlink\" content-type=\"pdf\" xlink:href=\"pone.0335141.pdf\"/><abstract><p>Flight delays pose substantial operational and economic challenges for airlines, directly affecting scheduling efficiency, resource allocation, and passenger satisfaction. Accurate prediction of arrival delays is therefore critical for optimizing airline operations and enhancing customer experience. This study systematically evaluates the predictive performance of six machine learning classifiers&#8212;Decision Tree, Random Forest, Support Vector Classifier (SVC), Logistic Regression, K-Nearest Neighbors (KNN), and Naive Bayes&#8212;on a comprehensive flight dataset, with particular attention to the challenges posed by class imbalance. To mitigate skewed class distributions, resampling techniques including Random Oversampling, Synthetic Minority Oversampling Technique (SMOTE), and Adaptive Synthetic Sampling (ADASYN) were applied to the training data. Model performance was rigorously assessed using stratified 10-fold cross-validation and further validated on a hold-out test set, employing multiple evaluation metrics: Accuracy, F1-score, Matthews Correlation Coefficient (MCC), and ROC-AUC. The results demonstrate that Random Forest combined with Random Oversampling and Decision Tree combined with SMOTE both achieved the highest predictive performance (accuracy 0.90, F1-score 0.90, MCC 0.73, ROC-AUC 0.87. Notably, simpler models such as Naive Bayes exhibited competitive results under balanced conditions, underscoring the continued relevance of probabilistic classifiers in certain operational contexts. These findings highlight the critical role of resampling strategies and rigorous cross-validation in developing reliable, high-performing predictive models for imbalanced flight delay datasets, offering actionable insights for both airline operations and data-driven decision-making.</p></abstract><funding-group><award-group id=\"award001\"><funding-source><institution-wrap><institution-id institution-id-type=\"funder-id\">http://dx.doi.org/10.13039/501100002383</institution-id><institution>King Saud University</institution></institution-wrap></funding-source><award-id>Ongoing Research Funding program (ORF-2025-1313)</award-id><principal-award-recipient><contrib-id authenticated=\"true\" contrib-id-type=\"orcid\">https://orcid.org/0000-0001-7505-2428</contrib-id><name name-style=\"western\"><surname>AlBassam</surname><given-names>Sarah Ahmed A.</given-names></name></principal-award-recipient></award-group><funding-statement>This research was supported by the Ongoing Research Funding program (ORF-2025-1313), King Saud University, Riyadh, Saudi Arabia. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><fig-count count=\"7\"/><table-count count=\"8\"/><page-count count=\"17\"/></counts><custom-meta-group><custom-meta><meta-name>pmc-status-qastatus</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>pmc-status-live</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-status-embargo</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-status-released</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-open-access</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-olf</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-manuscript</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-legally-suppressed</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-pdf</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-supplement</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-pdf-only</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-suppress-copyright</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-real-version</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-scanned-article</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-preprint</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-in-epmc</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta id=\"data-availability\"><meta-name>Data Availability</meta-name><meta-value>The data that support the findings of this study are openly available at <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"https://www.kaggle.com/datasets/robikscube/flight-delay-dataset-20182022\" ext-link-type=\"uri\">https://www.kaggle.com/datasets/robikscube/flight-delay-dataset-20182022</ext-link>.</meta-value></custom-meta></custom-meta-group></article-meta><notes><title>Data Availability</title><p>The data that support the findings of this study are openly available at <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"https://www.kaggle.com/datasets/robikscube/flight-delay-dataset-20182022\" ext-link-type=\"uri\">https://www.kaggle.com/datasets/robikscube/flight-delay-dataset-20182022</ext-link>.</p></notes></front><body><sec sec-type=\"intro\" id=\"sec001\"><title>1. Introduction</title><p>Air Transport has become a major factor in global economic growth, allowing for more efficient communication and travel, leading to greater access to goods and services, as well as increased economic opportunities. Annually, approximately 2 billion passengers utilize air travel, representing 40% of international tourist movement, demonstrating its crucial role in fostering global connections and tourism growth [<xref rid=\"pone.0335141.ref001\" ref-type=\"bibr\">1</xref>]. This has had a positive impact on economic growth, job creation, and poverty reduction in many countries because air transport creates jobs, facilitates trade, enables tourism, and supports sustainable development around the world [<xref rid=\"pone.0335141.ref002\" ref-type=\"bibr\">2</xref>]. Over the past years, the number of flights in the airline industry has evolved significantly. According to the International Air Transport Association (IATA) in 2019 the airline industry worldwide flew approximately 102,465 flights per day. The demand for air transport has increased by 45% over the last decade, creating a large market for commercial airlines, airports, and other aviation-related businesses. In 2023, all major markets experienced a significant increase in domestic travel demand, with total domestic traffic surpassing the 2019 record. International travel also showed consistent growth globally. As 2024 commenced, the industry&#8217;s growth remained robust, despite facing economic and geopolitical challenges impacting both airlines and consumers [<xref rid=\"pone.0335141.ref003\" ref-type=\"bibr\">3</xref>]. Therefore, the risk of flight delays has also increased accordingly. It has also led to the development of new technologies: such as aircraft and air traffic control systems. Significantly, reliable flight delay prediction is critical for the air transport industry.</p><p>Machine learning methods have been proven to be accurate in predicting flight delays. This study inspects different machine learning algorithms used for flight delay prediction. The motivation for this study comes from the need to improve customer satisfaction because flight delays can be frustrating for travelers, leading to missed connections, lost luggage, and other inconveniences [<xref rid=\"pone.0335141.ref004\" ref-type=\"bibr\">4</xref>]. By accurately predicting flight delays, airlines can proactively notify passengers and offer alternative travel to increase operational efficiency. Meaning flight delays can also be costly for airlines, leading to wasted time, fuel, and other resources. Therefore, in a highly competitive industry, airlines that can consistently deliver on-time flights are more likely to attract and retain customers. By leveraging machine learning to predict and mitigate delays, airlines can gain a competitive advantage over their peers [<xref rid=\"pone.0335141.ref004\" ref-type=\"bibr\">4</xref>].</p></sec><sec id=\"sec002\"><title>2. Related work</title><p>Several studies on flight delays have been conducted. Researchers have applied machine learning algorithms to predict flight delays effectively. Kalliguddi and Leboulluec [<xref rid=\"pone.0335141.ref005\" ref-type=\"bibr\">5</xref>] developed a flight delay prediction system using multiple linear regression, decision trees, and random forest on over 1 million U.S. domestic flights. The random forest model achieved the best performance with an R-squared (R&#178;) of 0.94 and RMSE of 12.5 minutes, outperforming other models. The findings also highlighted the key factors contributing to departure delays, including late aircraft arrival, carrier delays, weather conditions, and National Air System (NAS) delays. Another study was conducted by Xu et al. [<xref rid=\"pone.0335141.ref006\" ref-type=\"bibr\">6</xref>] with a focus on analyzing the factors contributing to flight delays and developing a predictive model using statistical analysis and machine learning techniques. The authors analyzed the impact of relevant variables from the dataset, such as temperature, previous delay rate, month, and weekday. As a result, the highest accuracy achieved was 84.5% using Gradient Boosting classifier. However, neither study has resolved the issue of an imbalanced dataset.</p><p>In a study by Meel et al. [<xref rid=\"pone.0335141.ref007\" ref-type=\"bibr\">7</xref>], five regression algorithms were evaluated using 2015 U.S. domestic flight data from the Bureau of Transportation Statistics. Models were trained separately for departure and arrival delays. The Random Forest Regressor outperformed others in both cases, achieving the lowest mean square error (MSE) of 2261.8 for departure delays and 3019.3 for arrival delays. Imbalanced dataset issue was not addressed in their work. Moreover, Atl&#305;o&#287;lu et al. [<xref rid=\"pone.0335141.ref008\" ref-type=\"bibr\">8</xref>] compared the performance of eleven supervised learning algorithms in predicting flight delay. The dataset used was provided by local airline company. The findings revealed that classification and regression trees (CART) and K-nearest neighbors (KNN) achieved the highest performance at 0.816 and 0.807 F-Scores respectively. However, they did not employ feature enhancement and instead relied only on the same data acquired from the airline operations. Moreover, they did not utilize any type of data balancing techniques.</p><p>Tijil et al. [<xref rid=\"pone.0335141.ref009\" ref-type=\"bibr\">9</xref>] compared the performance of three machine learning algorithms in predicting flight delays using data from the Bureau of Transportation Statistics (BTS). The algorithms applied were Random Forest, Support Vector Machine (SVM), and Logistic Regression. The findings revealed that SVM outperformed the other two algorithms with 100% accuracy. This high level of accuracy might be attributed to the lack of addressing imbalanced data. Chen and Li [<xref rid=\"pone.0335141.ref010\" ref-type=\"bibr\">10</xref>] proposed a flight delay prediction model that integrates multi-label random forest classification with an estimated flight delay propagation model. This approach explicitly considers the propagation of delays across connected flights, leading to improved prediction accuracy. Recognizing the limitations of using all available features, the authors implemented an optimized feature selection technique, demonstrating significant performance gains. Their analysis identified departure delay and late arrival aircraft delay as the most critical factors for robust prediction, with their model achieving an accuracy of 86.72% for arrival delay and 83.05% for departure delay.</p><p>Similar to [<xref rid=\"pone.0335141.ref010\" ref-type=\"bibr\">10</xref>], Qu et al [<xref rid=\"pone.0335141.ref011\" ref-type=\"bibr\">11</xref>] work has also focused on delay propagation, where delays in one flight can affect subsequent flights. The authors examined and forecasted flight delays utilizing deep learning models. Two innovative deep learning models were introduced: CBAM-CondenseNet and SimAM-CNN-MLSTM. The research demonstrated that these models can effectively capture both spatial and temporal dependencies in flight data, achieving accuracies of 89.8% and 91.36%, respectively. While the approach effectively captures delay propagation patterns, it does not address the class imbalance issue.</p><p>Moreover, G&#252;vercin et al. [<xref rid=\"pone.0335141.ref012\" ref-type=\"bibr\">12</xref>] addressed flight delay prediction by leveraging airport network structure and delay patterns from similar airports. Using graph-based metrics like betweenness centrality and articulation points, the authors proposed Clustered Airport Modeling (CAM) to forecast arrival delays across 305 U.S. airports. Their approach improved forecasting accuracy by up to 55% MAPE over individual models. However, their focus remains on statistical time series modeling. It does not incorporate machine learning or address class imbalance, key gaps targeted in this study.</p><p>Deep learning algorithms have also been applied to predict flight delays. Ayaydin and Ak&#231;ayol [<xref rid=\"pone.0335141.ref013\" ref-type=\"bibr\">13</xref>] applied deep recurrent neural network (DRNN), long-short term memory (LSTM), and Random Forest (RF) models to classify flight delays using a real-world dataset covering 368 global airports. Among the models, LSTM achieved the highest recall (96.50%), while Random Forest led in accuracy (82.21%) and F1-score (96.20%). Although the study applied standard preprocessing and hyperparameter tuning, it did not address feature selection or class imbalance, which are core aspects this work aims to enhance. Bisandu et al. [<xref rid=\"pone.0335141.ref014\" ref-type=\"bibr\">14</xref>] proposed a flight delay prediction model that combines deep recurrent neural network (DRNN) and a social ski driver conditional autoregressive-based (SSDCA-based) deep learning algorithm. The used dataset is from the US Government Bureau of Transportation Statistics (BTS). The model achieved an accuracy of % 93.61% and % 92.52% on dataset1 and dataset2, respectively, demonstrating superior performance compared to other methods. However, its complexity and reliance on metaheuristic tuning may limit real-time deployment or scalability across diverse aviation environments. Furthermore, the data imbalanced issue was not addressed.</p><p>Zhou et al. [<xref rid=\"pone.0335141.ref015\" ref-type=\"bibr\">15</xref>] analyzed the factors influencing departure time delay. They have also proposed gated recurrent unit (GRU) model to predict actual flight departure times using operational and scheduling data from Nanjing Lukou Airport. Their findings revealed that the proposed model achieved an RMSE of 0.42 and MAE of 0.3, and outperformed LSTM, BP, and Random Forest. While the model shows high accuracy, its static nature and reliance on single-airport data limit adaptability to real-time or multi-airport environments. Cai et al. [<xref rid=\"pone.0335141.ref016\" ref-type=\"bibr\">16</xref>] proposed a graph-based deep learning framework, MSTAGCN, to predict flight delays across a multi-airport network using time-evolving graph-structured data. Using domestic flight records from several Chinese airports, the model outperformed baseline approaches such as STGCN and DCRNN in both short and long-term predictions. However, its complexity and need for high-resolution graph data may limit scalability in real-time or low-data settings.</p><p>Li et al. [<xref rid=\"pone.0335141.ref017\" ref-type=\"bibr\">17</xref>] developed a two-stage CNN-LSTM-Random Forest model for flight delay prediction, capturing spatial dependencies via CNN, temporal weather effects via LSTM, and fusing both with extrinsic flight features in a Random Forest classifier. Using U.S. domestic flight data, the model achieved 92.39% accuracy. However, its multi-stage design may add complexity for real-time implementation. Deng et al. [<xref rid=\"pone.0335141.ref018\" ref-type=\"bibr\">18</xref>] proposed a modular neural network architecture called CC-MIDNN for predicting aircraft estimated arrival time (EAT), combining k-means clustering, Bayesian optimization, and a deep neural network (DNN) ensemble to train parallel sub-networks. Evaluated on Lisbon Airport data, it reduced MAE by 5.92 minutes over baseline models. However, its multi-step integration process and computational complexity may challenge deployment in real-time operational systems.</p><p>Kim and Park [<xref rid=\"pone.0335141.ref019\" ref-type=\"bibr\">19</xref>] focused on long-term predictions of flight delays, which exceed 2 hours. The datasets were collected from three different airports: Incheon International Airport in South Korea (ICN), John F. Kennedy International Airport (JFK), and Chicago Midway International Airport (MDW) in the United States. Several machine learning models, and Long Short-Term Memory (LSTM) were applied to predict flight takeoff delays, achieving up to 85.2% accuracy with the LSTM model at JFK. The imbalance issue was solved using random under sampling technique. This approach discards valuable data and may reduce model robustness. In a recent study, Yuan et al. [<xref rid=\"pone.0335141.ref020\" ref-type=\"bibr\">20</xref>] introduced a hybrid deep learning model (3DF-DSCL) combining 3D-CNN, GCN, and LSTM to predict airport departure delays using multi-attribute data (temporal, spatial, and spatiotemporal). Utilizing flight data from Beijing Capital International Airport, the model achieved a Mean Absolute Error (MAE) of 0.26 minutes, outperforming existing approaches by 14.47%. However, the model&#8217;s dependence on detailed operational data from a single airport may limit its applicability to broader contexts.</p><p><xref rid=\"pone.0335141.t001\" ref-type=\"table\">Table 1</xref> presents a summary of previous related works. Generally, machine learning techniques have proved to be effective for predicting flight delays. However, most of the previously mentioned studies lack some important aspects. Either they did not address the imbalanced data issue, or they missed important steps that affect the findings, such as feature selection and feature engineering. Deep learning techniques show potential for flight delay prediction; however, they often require substantial computational resources and large labeled datasets for effective training.</p><table-wrap position=\"float\" id=\"pone.0335141.t001\" orientation=\"portrait\"><object-id pub-id-type=\"doi\">10.1371/journal.pone.0335141.t001</object-id><label>Table 1</label><caption><title>Summary of related work.</title></caption><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pone.0335141.t001g\" position=\"float\" orientation=\"portrait\" xlink:href=\"pone.0335141.t001.jpg\"/><table frame=\"hsides\" rules=\"groups\"><colgroup span=\"1\"><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/></colgroup><thead><tr><th align=\"left\" rowspan=\"1\" colspan=\"1\">Paper Ref.</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">ML/DL Algorithms</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">Performance<break/>Measures</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">Dataset</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">Feature Selection Methods</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">Feature Engineering</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">Sampling Techniques</th></tr></thead><tbody><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">[<xref rid=\"pone.0335141.ref005\" ref-type=\"bibr\">5</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">multiple linear regression, decision tree, and random forest</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">R-squared (R&#178;)<break/>0.94<break/>Root Mean<break/>Squared Error (RMSE) 12.5</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Bureau of Transportation Statistics (BTS)</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">no</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">no</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">No</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">[<xref rid=\"pone.0335141.ref006\" ref-type=\"bibr\">6</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Gradient Boosting<break/>Logistic Model,<break/>K-Near Neighbors<break/>Gausian NB,<break/>Support Vector Machine,<break/>Decision Tree Classifier,<break/>Random Forest Classifier</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Accuracy 84.5</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Chinese Air Traffic Control Authority</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">yes</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">yes</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">No</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">[<xref rid=\"pone.0335141.ref007\" ref-type=\"bibr\">7</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Logistic Regression, Decision Tree Regression, Bayesian Ridge, Random Forest Regression, Gradient Boosting Regression</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Mean squared error (MSE)<break/>Departure 2261.8<break/>Arrival 3019.3</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">the US Bureau of Transport Statistics 2015</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Manual feature choice</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">no</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">No</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">[<xref rid=\"pone.0335141.ref008\" ref-type=\"bibr\">8</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">K-Nearest Neighbor (KNN), Support<break/>Vector Machine (SVM), Decision Tree (CART),<break/>Gaussian Na&#239;ve Bayes (GNB), Logistic<break/>Regression (LR), Multilayer Perceptron (MLP),<break/>Random Forest (RF), Gradient Boosting (GBM),<break/>XGBoost (XGB), CatBoost (CB), and<break/>LightGBM (LGBM)</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">F score<break/>0.816 and 0.807</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Turki airline company</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">yes</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">yes</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">No</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">[<xref rid=\"pone.0335141.ref009\" ref-type=\"bibr\">9</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Random Forest,<break/>Support Vector Machine SVM,<break/>Logistic Regression</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">f-score, recall, precision, and accuracy 100% scores.</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">The Bureau of Transportation Statistics (BTS)</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">no</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">yes</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">No</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">[<xref rid=\"pone.0335141.ref010\" ref-type=\"bibr\">10</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">combined multi-label random forest classification and approximated delay propagation model</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Accuracy<break/>Arrival delay 86.72<break/>Departure delay 83.05</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Three databases:<break/>Bureau of Transportation Statistics (BTS)<break/>Local Climatologica Data (LCD)<break/>Aviation<break/>System Performance Metrics (ASPM)</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">recursive feature elimination (RFE) algorithm</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">yes</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">SMOTE</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">[<xref rid=\"pone.0335141.ref011\" ref-type=\"bibr\">11</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">CBAM-CondenseNet<break/>SimAM-CNN-MLSTM</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Accuracy<break/>89.8% and 91.36%, respectively.</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">China Air Traffic Management Bureau</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">yes</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">yes</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">No</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">[<xref rid=\"pone.0335141.ref012\" ref-type=\"bibr\">12</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">regression and time series forecasting</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Mean Absolute Percentage Error (MAPE) and<break/>Mean Absolute Error (MAE)</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Flight data from 305 us airports</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">yes</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">yes</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">No</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">[<xref rid=\"pone.0335141.ref013\" ref-type=\"bibr\">13</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">deep recurrent neural network (RNN), long-short term memory (LSTM), and random forest (RF)</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Recall 96.50%.</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">real data set covering 368 airports across the world</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">yes</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">yes</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">No</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">[<xref rid=\"pone.0335141.ref014\" ref-type=\"bibr\">14</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">deep recurrent neural network (DRNN)</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Accuracy<break/>%93.61 dataset1%92.52 dataset2</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">the US Bureau of Transport Statistics 2019&#8211;2020</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">yes</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">yes</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">No</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">[<xref rid=\"pone.0335141.ref015\" ref-type=\"bibr\">15</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">gated recurrent unit (GRU) model</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">RMSE of 0.42 and MAE of 0.3</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Nanjing Lukou Airport</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">no</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">yes</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">no</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">[<xref rid=\"pone.0335141.ref016\" ref-type=\"bibr\">16</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">a graph-based deep learning framework</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">MAE 5.884</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Chinees airports</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">no</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">yes</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">no</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">[<xref rid=\"pone.0335141.ref017\" ref-type=\"bibr\">17</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Two-stage CNN-LSTM-Random Forest model</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Accuracy<break/>92.39%</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Bureau of Transport Statistic</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">no</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">yes</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">no</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">[<xref rid=\"pone.0335141.ref018\" ref-type=\"bibr\">18</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">neural network architecture<break/>CC-MIDNN</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">MAE 5.92</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Lisbon Airport (LIS), Portugal</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">no</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">yes</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">no</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">[<xref rid=\"pone.0335141.ref019\" ref-type=\"bibr\">19</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Decision Tree, Random Forest, Support Vector Machine, K-nearest neighbors,<break/>Logistic Regression, Extreme Gradient Boosting, and Long Short-Term Memory</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Accuracy 85.2%</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">datasets were collected from three different airports</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">yes</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">yes</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Random under sampling</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">[<xref rid=\"pone.0335141.ref020\" ref-type=\"bibr\">20</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">hybrid deep learning model (3DF-DSCL)</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">MAE 0.26</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Beijing Capital International Airport</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">yes</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">yes</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">no</td></tr></tbody></table></alternatives></table-wrap><p>To overcome these limitations, we propose an improved model for predicting flight delays, which includes several techniques to improve the performance of classifiers and thus find the best model to achieve our goal. The key objective of this project is to develop a ML model that can effectively detect small (&lt; 15 mints), medium (&#8805; 15 and &lt;45 mints) and large (&#8805;45 mints) flight delays. In our study, we considered the issue of imbalanced dataset and applied feature selection and feature engineering techniques to improve the findings.</p></sec><sec id=\"sec003\"><title>3. Proposed methodology</title><p>In this study we proposed an improved flight delay prediction model. To develop the model six different supervised learning algorithms were investigated and compared to select the best classifier. Several steps of feature engineering, feature selection, data resampling, data scaling and hypermeter optimization were applied to enhance the performance. An overview of the proposed methodology is shown in <xref rid=\"pone.0335141.g001\" ref-type=\"fig\">Fig 1</xref>.</p><fig position=\"float\" id=\"pone.0335141.g001\" orientation=\"portrait\"><object-id pub-id-type=\"doi\">10.1371/journal.pone.0335141.g001</object-id><label>Fig 1</label><caption><title>Overview of the study methodology.</title></caption><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" position=\"float\" orientation=\"portrait\" xlink:href=\"pone.0335141.g001.jpg\"/></fig><sec id=\"sec004\"><title>3.1. Experiment environment</title><p>All experiments were conducted on a MacBook Pro equipped with an Intel Core i7 processor and 16 GB of RAM. The model implementation environment is Google Collaboratory (Colab), a cloud based Jupyter Notebook environment that provides seamless access to CPUs, GPUs, and TPUs without any local configuration. Python was used as the programming language, enabling the integration of a wide range of libraries essential for machine learning workflows. Specifically, Scikit-learn, NumPy, Pandas, Matplotlib and Seaborn the libraries were employed.</p></sec><sec id=\"sec005\"><title>3.2. Data source</title><p>The study leverages the publicly available &#8220;Flight Status Prediction&#8221; dataset [<xref rid=\"pone.0335141.ref021\" ref-type=\"bibr\">21</xref>] hosted on Kaggle, comprising approximately 4,078,318 records across 61 columns, totaling around 51.94 MB. The dataset spans 2018&#8211;2022 and includes comprehensive flight information such as:</p><list list-type=\"bullet\"><list-item><p>Departure and arrival airports, flight numbers, and airline codes</p></list-item><list-item><p>Scheduled and actual departure and arrival times</p></list-item><list-item><p>Arrival and departure delays, cancellations, and associated operational delays (carrier, weather, NAS, security, and late aircraft delays)</p></list-item><list-item><p>Flight origin, destination, distance, airtime, and elapsed times</p></list-item></list><p>The dataset captures a wide variety of domestic and international flights, operated by multiple carriers across different time zones.</p></sec><sec id=\"sec006\"><title>3.3. Data pre-processing</title><p>Exploratory data analysis (EDA) was conducted to understand the dataset&#8217;s characteristics and relationships between variables. Key Python libraries (NumPy, Pandas, Matplotlib, Seaborn) were used for data manipulation and visualization. Initial exploration confirmed the dataset had time-series flight information with no missing values. Descriptive statistics were obtained using df.describe() to summarize central tendencies, dispersion, and potential outliers.</p></sec><sec id=\"sec007\"><title>3.4. Feature engineering</title><p>To enhance model performance and interpretability, feature engineering was applied. This included creating meaningful features from existing data to improve model predictions [<xref rid=\"pone.0335141.ref022\" ref-type=\"bibr\">22</xref>]. Specifically, the &#8220;delay_hours&#8221; column was binned into three categories as shown in <xref rid=\"pone.0335141.t002\" ref-type=\"table\">Table 2</xref>:</p><table-wrap position=\"float\" id=\"pone.0335141.t002\" orientation=\"portrait\"><object-id pub-id-type=\"doi\">10.1371/journal.pone.0335141.t002</object-id><label>Table 2</label><caption><title>Data binning.</title></caption><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pone.0335141.t002g\" position=\"float\" orientation=\"portrait\" xlink:href=\"pone.0335141.t002.jpg\"/><table frame=\"hsides\" rules=\"groups\"><colgroup span=\"1\"><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/></colgroup><thead><tr><th align=\"left\" rowspan=\"1\" colspan=\"1\">Delay Category</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">Delay In Minutes</th></tr></thead><tbody><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">Small</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">&lt; 15</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">Medium</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">15&#8211;44</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">Large</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">&#8805; 45</td></tr></tbody></table></alternatives></table-wrap><p>This transformation converts the problem into a multiclass classification task, capturing operationally meaningful delay thresholds. Additional engineered features included time-based aggregations, such as departure hour bins, day of the week, and day of the year, which have been shown in prior studies to influence flight punctuality.</p></sec><sec id=\"sec008\"><title>3.5. Feature selection</title><p>Feature selection is a crucial step for optimizing model performance. It involves identifying and selecting the most relevant features from the dataset to improve predictive accuracy and reduce overfitting [<xref rid=\"pone.0335141.ref023\" ref-type=\"bibr\">23</xref>]. In this study, we used the SelectKBest method with K&#8201;=&#8201;25, which selects the top 25 features based on their scoring function. After preprocessing, a total of 25 features were selected based on domain knowledge and correlation analysis.</p><p>The features included are: FlightDate, DayOfWeek, Month, Carrier, FlightNumber, OriginAirport, DestAirport, ScheduledDepTime, ScheduledArrTime, Distance, ActualDepTime, ActualArrTime, DepDelay, ArrDelay, TaxiOutTime, TaxiInTime, CarrierDelay, WeatherDelay, NASDelay, SecurityDelay, LateAircraft Delay, PrevFlightDelay, DayOfYear, DepHourBin, DelayCategory.</p><p>This curated feature set balances interpretability with predictive capability and ensures that only relevant, non-redundant information is fed into the models.</p></sec><sec id=\"sec009\"><title>3.6. Data resampling</title><p>Data resampling techniques are used to solve the imbalance data classification issue, where the dataset has an unequal distribution of the instances of each class, causing the classification model to be biased towards the majority class and reducing its overall performance [<xref rid=\"pone.0335141.ref024\" ref-type=\"bibr\">24</xref>]. Flight delay datasets are inherently imbalanced, with On-time flights often dominating the data. To address this, three resampling strategies were employed:</p><list list-type=\"order\"><list-item><p>Random Oversampling (ROS): Minority classes were randomly duplicated until class balance was achieved.</p></list-item><list-item><p>Synthetic Minority Oversampling Technique (SMOTE): Synthetic samples were generated for minority classes using k-nearest neighbors in feature space.</p></list-item><list-item><p>Adaptive Synthetic Sampling (ADASYN): Focused on generating synthetic samples for minority class instances that are harder to learn, improving classifier robustness for difficult examples.</p></list-item></list><p>These methods aim to mitigate bias toward majority classes and enhance the classifier&#8217;s ability to detect all delay categories effectively.</p></sec><sec id=\"sec010\"><title>3.7. Data splitting</title><p>Data splitting is a technique for dividing the dataset into two parts: a training set and a testing set. The training set is used to train the model, and the testing set is used to evaluate the model&#8217;s performance on unseen data. The data splitting is commonly implemented using the train_test_split function, which allows the allocation of a pre-defined proportion of data for testing purposes. The test_size parameter is set to 0.2, indicating that 20% of the data will be assigned for testing purposes, while the remaining 80% will include the training set. This strategic division serves to ensure an objective evaluation of the model&#8217;s performance on unseen data, thereby mitigating the risk of overfitting.</p></sec><sec id=\"sec011\"><title>3.8. Data scaling</title><p>For machine learning algorithms, having feature values that are closer together generally improves both the speed and effectiveness of training. Conversely, when data points or feature values are spread apart, it can take longer for the model to learn, potentially reducing accuracy. To address this, scaling is used to bring data points closer together. Essentially, scaling standardizes the values, making them more comparable. Different scaling techniques, such as Min-Max Scaler, Max Abs Scaler, and Quantile Transformer Scaler, are available to accommodate various classification tasks and enhance the effectiveness of scaling [<xref rid=\"pone.0335141.ref025\" ref-type=\"bibr\">25</xref>,<xref rid=\"pone.0335141.ref026\" ref-type=\"bibr\">26</xref>]. In our model, we implemented the MinMaxScaler method. The MinMaxScaler method helped our model to normalize each feature by scaling it to a specific range, typically between 0 and 1. This can be helpful for machine learning algorithms that are sensitive to the scale of the features by calculating the minimum and maximum values for each feature.</p></sec><sec id=\"sec012\"><title>3.9. Hyperparameter tuning</title><p>To optimize model performance, hyperparameter tuning was conducted for all classifiers. Hyperparameters define key aspects of each algorithm, such as the number of neighbors in K-Nearest Neighbors, the regularization strength in Logistic Regression, or the depth of trees in Decision Tree and Random Forest classifiers.</p><p>Selecting optimal hyperparameters ensures a balance between underfitting and overfitting, improving generalization on unseen data. In this study, a grid search method was applied to each model.</p></sec><sec id=\"sec013\"><title>3.10. Model algorithms</title><p>This study evaluates six supervised learning algorithms for predicting flight delays, selected to provide a balance of diverse modeling approaches, from linear to non-linear, and from simple to ensemble methods. The rationale for including these specific algorithms is to compare their performance across different modeling strategies and identify the most effective approach for this dataset.</p><list list-type=\"order\"><list-item><p>Support Vector Classifier (SVC): A supervised learning algorithm that classifies data by finding the optimal decision boundary (hyperplane) between classes. It can handle both linear and non-linear problems using kernel functions and is highly effective in high-dimensional spaces [<xref rid=\"pone.0335141.ref027\" ref-type=\"bibr\">27</xref>].</p></list-item><list-item><p>Na&#239;ve Bayes (NB): A probabilistic classifier based on feature independence assumptions; it is simple, fast, and performs well with categorical data [<xref rid=\"pone.0335141.ref027\" ref-type=\"bibr\">27</xref>].</p></list-item><list-item><p>K-Nearest Neighbors (K-NN): A non-parametric method that classifies instances based on proximity to neighboring points, providing a simple yet flexible baseline [<xref rid=\"pone.0335141.ref027\" ref-type=\"bibr\">27</xref>].</p></list-item><list-item><p>Random Forest (RF): An ensemble of decision trees that improves accuracy and robustness, reducing overfitting common in single trees.</p></list-item><list-item><p>Decision Tree (DT): A straightforward model that recursively splits data based on information gain, offering interpretability and fast training [<xref rid=\"pone.0335141.ref028\" ref-type=\"bibr\">28</xref>].</p></list-item><list-item><p>Logistic Regression (LR): A statistical linear model that estimates the probability of categorical outcomes, serving as a benchmark for comparison with more complex models [<xref rid=\"pone.0335141.ref027\" ref-type=\"bibr\">27</xref>].</p></list-item></list></sec><sec id=\"sec014\"><title>3.11. Cross-validation</title><p>Cross-validation is a method used to assess a model&#8217;s effectiveness and evaluate its performance by training it on one subset of the data and testing it on a different, unseen subset. A single evaluation run may not provide a reliable measure of the model&#8217;s performance. To ensure a thorough assessment and enhance the model&#8217;s robustness, repeated iterations are preferred. In our study, we employed 10-fold cross-validation. The final performance scores of the models were determined by averaging the results from all ten iterations.</p></sec><sec id=\"sec015\"><title>3.12. Evaluation metrics</title><p>To evaluate the performance of the classifiers, four key metrics were employed: accuracy, F1-score, Matthews Correlation Coefficient (MCC), and ROC-AUC. These measures collectively provide both an overall performance snapshot and insights into the models&#8217; discriminative abilities.</p><p>A confusion matrix is used to summarize classification results. It presents true positives (TP), false negatives (FN), true negatives (TN), and false positives (FP) [<xref rid=\"pone.0335141.ref029\" ref-type=\"bibr\">29</xref>].</p><list list-type=\"simple\"><list-item><p>I. Accuracy is the percentage of correctly identified flights. It calculated as the ratio of correctly identified cases (delay and on time) to the total number of cases.</p></list-item></list><disp-formula id=\"pone.0335141.e001\"><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pone.0335141.e001g\" position=\"anchor\" orientation=\"portrait\" xlink:href=\"pone.0335141.e001.jpg\"/><mml:math id=\"M1\" display=\"block\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mtext>&#160;</mml:mtext><mml:mfrac><mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives><label>(1)</label></disp-formula><list list-type=\"simple\"><list-item><p>II. The F1-score depends on both precision and recall. It is calculated by the following formula.</p></list-item></list><disp-formula id=\"pone.0335141.e002\"><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pone.0335141.e002g\" position=\"anchor\" orientation=\"portrait\" xlink:href=\"pone.0335141.e002.jpg\"/><mml:math id=\"M2\" display=\"block\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mtext>1</mml:mtext></mml:mrow><mml:mo>&#8722;</mml:mo><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mtext>2</mml:mtext></mml:mrow><mml:mi>&#215;</mml:mi><mml:mfrac><mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi>&#215;</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives><label>(2)</label></disp-formula><list list-type=\"simple\"><list-item><p>III. Matthews Correlation Coefficient (MCC) provides a balanced measure even for imbalanced datasets.</p></list-item></list><disp-formula id=\"pone.0335141.e003\"><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pone.0335141.e003g\" position=\"anchor\" orientation=\"portrait\" xlink:href=\"pone.0335141.e003.jpg\"/><mml:math id=\"M3\" display=\"block\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mi>&#215;</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mo>&#8722;</mml:mo><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mi>&#215;</mml:mi><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:mo stretchy=\"false\">(</mml:mo><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mo stretchy=\"false\">)</mml:mo><mml:mo stretchy=\"false\">(</mml:mo><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mo stretchy=\"false\">)</mml:mo><mml:mo stretchy=\"false\">(</mml:mo><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mo stretchy=\"false\">)</mml:mo><mml:mo stretchy=\"false\">(</mml:mo><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mo stretchy=\"false\">)</mml:mo></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives><label>(3)</label></disp-formula><list list-type=\"simple\"><list-item><p>IV. ROC-AUC (Receiver Operating Characteristic &#8211; Area Under Curve) measures the ability of the classifier to distinguish between classes, with values closer to 1 indicating better performance.</p></list-item></list></sec></sec><sec sec-type=\"results\" id=\"sec016\"><title>4. Results</title><sec id=\"sec017\"><title>4.1. Models performance across resampling methods</title><p>The performance of six machine learning algorithms&#8212;Decision Tree (DT), Random Forest (RF), Support Vector Classifier (SVC), Logistic Regression (LR), K-Nearest Neighbors (KNN), and Naive Bayes (NB)&#8212;was evaluated across three resampling strategies: Random Oversampling, SMOTE, and ADASYN. The results, summarized in <xref rid=\"pone.0335141.t003\" ref-type=\"table\">Tables 3</xref>&#8211;<xref rid=\"pone.0335141.t008\" ref-type=\"table\">8</xref>, indicate that the choice of resampling technique substantially impacts classifier efficacy, particularly under class imbalance conditions.</p><table-wrap position=\"float\" id=\"pone.0335141.t003\" orientation=\"portrait\"><object-id pub-id-type=\"doi\">10.1371/journal.pone.0335141.t003</object-id><label>Table 3</label><caption><title>Random forest with resampling technique.</title></caption><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pone.0335141.t003g\" position=\"float\" orientation=\"portrait\" xlink:href=\"pone.0335141.t003.jpg\"/><table frame=\"hsides\" rules=\"groups\"><colgroup span=\"1\"><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/></colgroup><thead><tr><th align=\"left\" rowspan=\"1\" colspan=\"1\">Resampling Technique</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">Accuracy</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">F1-score</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">MCC</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">ROC-AUC</th></tr></thead><tbody><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">Random Oversampler</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">\n<bold>0.90</bold>\n</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">\n<bold>0.91</bold>\n</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">\n<bold>0.74</bold>\n</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">\n<bold>0.87</bold>\n</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">SMOTE</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.87</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.88</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.68</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.87</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">ADASYN</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.87</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.88</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.68</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.86</td></tr></tbody></table></alternatives></table-wrap><table-wrap position=\"float\" id=\"pone.0335141.t004\" orientation=\"portrait\"><object-id pub-id-type=\"doi\">10.1371/journal.pone.0335141.t004</object-id><label>Table 4</label><caption><title>Decision tree with resampling technique.</title></caption><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pone.0335141.t004g\" position=\"float\" orientation=\"portrait\" xlink:href=\"pone.0335141.t004.jpg\"/><table frame=\"hsides\" rules=\"groups\"><colgroup span=\"1\"><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/></colgroup><thead><tr><th align=\"left\" rowspan=\"1\" colspan=\"1\">Resampling Technique</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">Accuracy</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">F1-score</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">MCC</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">ROC-AUC</th></tr></thead><tbody><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">RandomOversampler</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.89</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.89</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.70</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.85</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">SMOTE</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">\n<bold>0.90</bold>\n</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">\n<bold>0.91</bold>\n</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">\n<bold>0.74</bold>\n</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">\n<bold>0.87</bold>\n</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">ADASYN</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.85</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.86</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.65</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.86</td></tr></tbody></table></alternatives></table-wrap><table-wrap position=\"float\" id=\"pone.0335141.t005\" orientation=\"portrait\"><object-id pub-id-type=\"doi\">10.1371/journal.pone.0335141.t005</object-id><label>Table 5</label><caption><title>NaiveBayes with resampling technique.</title></caption><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pone.0335141.t005g\" position=\"float\" orientation=\"portrait\" xlink:href=\"pone.0335141.t005.jpg\"/><table frame=\"hsides\" rules=\"groups\"><colgroup span=\"1\"><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/></colgroup><thead><tr><th align=\"left\" rowspan=\"1\" colspan=\"1\">Resampling Technique</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">Accuracy</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">F1-score</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">MCC</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">ROC-AUC</th></tr></thead><tbody><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">RandomOversampler</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.88</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.89</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.70</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.86</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">SMOTE</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">\n<bold>0.89</bold>\n</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">\n<bold>0.89</bold>\n</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">\n<bold>0.71</bold>\n</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">\n<bold>0.86</bold>\n</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">ADASYN</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.87</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.88</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.68</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.86</td></tr></tbody></table></alternatives></table-wrap><table-wrap position=\"float\" id=\"pone.0335141.t006\" orientation=\"portrait\"><object-id pub-id-type=\"doi\">10.1371/journal.pone.0335141.t006</object-id><label>Table 6</label><caption><title>K-nearest neighbors with resampling technique.</title></caption><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pone.0335141.t006g\" position=\"float\" orientation=\"portrait\" xlink:href=\"pone.0335141.t006.jpg\"/><table frame=\"hsides\" rules=\"groups\"><colgroup span=\"1\"><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/></colgroup><thead><tr><th align=\"left\" rowspan=\"1\" colspan=\"1\">Resampling Technique</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">Accuracy</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">F1-score</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">MCC</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">ROC-AUC</th></tr></thead><tbody><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">RandomOversampler</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">\n<bold>0.54</bold>\n</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">\n<bold>0.59</bold>\n</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">\n<bold>0.11</bold>\n</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">\n<bold>0.56</bold>\n</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">SMOTE</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.51</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.57</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.12</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.57</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">ADASYN</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.50</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.56</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.10</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.56</td></tr></tbody></table></alternatives></table-wrap><table-wrap position=\"float\" id=\"pone.0335141.t007\" orientation=\"portrait\"><object-id pub-id-type=\"doi\">10.1371/journal.pone.0335141.t007</object-id><label>Table 7</label><caption><title>Logistic regression with resampling technique.</title></caption><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pone.0335141.t007g\" position=\"float\" orientation=\"portrait\" xlink:href=\"pone.0335141.t007.jpg\"/><table frame=\"hsides\" rules=\"groups\"><colgroup span=\"1\"><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/></colgroup><thead><tr><th align=\"left\" rowspan=\"1\" colspan=\"1\">Resampling Technique</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">Accuracy</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">F1-score</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">MCC</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">ROC-AUC</th></tr></thead><tbody><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">RandomOversampler</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.87</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.87</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.67</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.85</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">SMOTE</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.86</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.87</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.66</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.85</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">ADASYN</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">\n<bold>0.88</bold>\n</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">\n<bold>0.88</bold>\n</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">\n<bold>0.69</bold>\n</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">\n<bold>0.86</bold>\n</td></tr></tbody></table></alternatives></table-wrap><table-wrap position=\"float\" id=\"pone.0335141.t008\" orientation=\"portrait\"><object-id pub-id-type=\"doi\">10.1371/journal.pone.0335141.t008</object-id><label>Table 8</label><caption><title>SVC with resampling technique.</title></caption><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pone.0335141.t008g\" position=\"float\" orientation=\"portrait\" xlink:href=\"pone.0335141.t008.jpg\"/><table frame=\"hsides\" rules=\"groups\"><colgroup span=\"1\"><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/></colgroup><thead><tr><th align=\"left\" rowspan=\"1\" colspan=\"1\">Resampling Technique</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">Accuracy</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">F1-score</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">MCC</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">ROC-AUC</th></tr></thead><tbody><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">RandomOversampler</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.87</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.88</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.70</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.89</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">SMOTE</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.88</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.89</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.71</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">0.87</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">ADASYN</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">\n<bold>0.89</bold>\n</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">\n<bold>0.91</bold>\n</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">\n<bold>0.73</bold>\n</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">\n<bold>0.89</bold>\n</td></tr></tbody></table></alternatives></table-wrap><p>As shown in <xref rid=\"pone.0335141.t003\" ref-type=\"table\">Table 3</xref>, Random Forest attained its highest accuracy of 0.90 using Random Oversampling, achieving an F1-score of 0.91, MCC of 0.74, and ROC-AUC of 0.87. While SMOTE and ADASYN yielded modestly lower accuracies of 0.87, Random Oversampling enabled the model to more reliably classify both delayed and on-time flights. The confusion matrix in <xref rid=\"pone.0335141.g002\" ref-type=\"fig\">Fig 2</xref> highlights this balanced performance.</p><fig position=\"float\" id=\"pone.0335141.g002\" orientation=\"portrait\"><object-id pub-id-type=\"doi\">10.1371/journal.pone.0335141.g002</object-id><label>Fig 2</label><caption><title>Random forest confusion matrix | best resampler: random oversampler.</title></caption><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" position=\"float\" orientation=\"portrait\" xlink:href=\"pone.0335141.g002.jpg\"/></fig><p><xref rid=\"pone.0335141.t004\" ref-type=\"table\">Table 4</xref> demonstrates that Decision Tree achieved maximum accuracy (0.90) with SMOTE, accompanied by an F1-score of 0.91, MCC of 0.74, and ROC-AUC of 0.87. <xref rid=\"pone.0335141.g003\" ref-type=\"fig\">Fig 3</xref> illustrates the confusion matrix under SMOTE, indicating a substantial reduction in misclassifications compared to other resampling methods. These results emphasize the capacity of SMOTE to enhance the Decision Tree&#8217;s handling of minority classes.</p><fig position=\"float\" id=\"pone.0335141.g003\" orientation=\"portrait\"><object-id pub-id-type=\"doi\">10.1371/journal.pone.0335141.g003</object-id><label>Fig 3</label><caption><title>Decision tree confusion matrix | best resampler: SMOTE.</title></caption><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" position=\"float\" orientation=\"portrait\" xlink:href=\"pone.0335141.g003.jpg\"/></fig><p><xref rid=\"pone.0335141.t005\" ref-type=\"table\">Table 5</xref> presents the performance of Na&#239;ve Bayes. Using SMOTE resampling. Na&#239;ve Bayes demonstrated relatively modest results with an accuracy 0.89, F1-score 0.89, MCC 0.71, ROC-AUC 0.86. <xref rid=\"pone.0335141.g004\" ref-type=\"fig\">Fig 4</xref> highlights the SMOTE-enhanced confusion matrix.</p><fig position=\"float\" id=\"pone.0335141.g004\" orientation=\"portrait\"><object-id pub-id-type=\"doi\">10.1371/journal.pone.0335141.g004</object-id><label>Fig 4</label><caption><title>NaiveBayes confusion matrix | best resampler: SMOTE.</title></caption><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" position=\"float\" orientation=\"portrait\" xlink:href=\"pone.0335141.g004.jpg\"/></fig><p>Among the six classifiers, K-Nearest Neighbors (KNN) exhibited the lowest performance as shown in <xref rid=\"pone.0335141.t006\" ref-type=\"table\">Table 6</xref>. Random Oversampler produced the best results (accuracy 0.54, F1-score 0.59, MCC 0.11, ROC-AUC 0.56). <xref rid=\"pone.0335141.g005\" ref-type=\"fig\">Fig 5</xref> confirms the superiority of Random Oversampler, suggesting that KNN performs better with simpler oversampling rather than synthetic data generation.</p><fig position=\"float\" id=\"pone.0335141.g005\" orientation=\"portrait\"><object-id pub-id-type=\"doi\">10.1371/journal.pone.0335141.g005</object-id><label>Fig 5</label><caption><title>K-nearest neighbors confusion matrix |best resampler: randomoversampler.</title></caption><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" position=\"float\" orientation=\"portrait\" xlink:href=\"pone.0335141.g005.jpg\"/></fig><p>Logistic Regression outcomes are summarized in <xref rid=\"pone.0335141.t007\" ref-type=\"table\">Table 7</xref>. Overall, the ADASYN performed better than Random Oversampling and SMOTE, with an accuracy of 0.88 and F1 score of 0.88. <xref rid=\"pone.0335141.g006\" ref-type=\"fig\">Fig 6</xref> displays the confusion matrix with ADASYN.</p><fig position=\"float\" id=\"pone.0335141.g006\" orientation=\"portrait\"><object-id pub-id-type=\"doi\">10.1371/journal.pone.0335141.g006</object-id><label>Fig 6</label><caption><title>Logistic regression confusion matrix |best resampler: ADASYN.</title></caption><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" position=\"float\" orientation=\"portrait\" xlink:href=\"pone.0335141.g006.jpg\"/></fig><p>SVC has also exhibited good performance with ADASYN, it attained an accuracy of 0.89, F1-score of 0.91, MCC of 0.73, and ROC-AUC of 0.89 as shown in <xref rid=\"pone.0335141.t008\" ref-type=\"table\">Table 8</xref>. Both Random Oversampling and SMOTE produced competitive results. <xref rid=\"pone.0335141.g007\" ref-type=\"fig\">Fig 7</xref> presents the ADASYN-enhanced confusion matrix, which illustrates a highly balanced classification across delay categories, indicating that SVC effectively captures complex, non-linear relationships in the flight delay dataset.</p><fig position=\"float\" id=\"pone.0335141.g007\" orientation=\"portrait\"><object-id pub-id-type=\"doi\">10.1371/journal.pone.0335141.g007</object-id><label>Fig 7</label><caption><title>SVC confusion matrix | best resampler: ADASYN.</title></caption><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" position=\"float\" orientation=\"portrait\" xlink:href=\"pone.0335141.g007.jpg\"/></fig><p>Based on the overall performance metrics, Random Forest using Random Oversampling and Decision Tree using SMOTE sampling emerged as the top performers, consistently achieving the highest accuracy and F1-scores. Their ability to correctly classify both positive and negative instances make them suitable choice for the flight delay classification task.</p></sec><sec id=\"sec018\"><title>4.2. Statistical analysis</title><p>To evaluate whether the observed differences in predictive performance were statistically significant, two complementary tests were conducted: the paired t-test and the McNemar test. These analyses provide a robust framework for determining whether differences in model performance reflect genuine distinctions or are due to random chance.</p><p>Since multiple top-performing models exhibited very similar Accuracy and other evaluation metrics, a direct comparison between the best and worst-performing models was conducted to clearly illustrate the statistical and practical differences in predictive performance. This approach ensures that the analysis highlights the maximum contrast between model capabilities, providing a more interpretable and informative evaluation. Thus, Random Forest with RandomOverSampler was compared to K-Nearest Neighbors with ADASYN.</p><sec id=\"sec019\"><title>5.2.1. Paired t-test.</title><p>The paired t-test was employed to compare the correctness of predictions for individual flights between the best-performing model (Random Forest with RandomOverSampler) and the worst-performing model (K-Nearest Neighbors with ADASYN). The resulting statistics were:</p><list list-type=\"bullet\"><list-item><p>Paired t-test between RandomForest and KNN (test set accuracy): t = 30.9884, p &lt; 0.001</p></list-item></list><p>The extremely low p-value indicates a highly significant difference in predictive performance, with Random Forest correctly classifying a substantially larger proportion of flights compared to KNN.</p></sec><sec id=\"sec020\"><title>5.2.2. McNemar test.</title><p>The McNemar test was applied to the test set predictions to evaluate whether there was a significant difference in misclassification patterns between the two models. The test produced the following results:</p><list list-type=\"simple\"><list-item><p>McNemar test statistic = 78.0, p-value &#8776; 9.02&#8201;&#215;&#8201;10&#8315;&#185;&#8310;&#8309;</p></list-item></list><p>The very low p-value confirms that Random Forest and KNN exhibit significantly different misclassification patterns. In particular, Random Forest demonstrates superior ability to correctly identify delayed flight instances, whereas KNN struggles with certain delay categories.</p></sec></sec></sec><sec sec-type=\"conclusions\" id=\"sec021\"><title>5. Discussion</title><p>Our goal is to propose an efficient ML flight delay prediction model. So, we investigated six different ML algorithms and applied feature engineering and feature selection to improve the performance of the model. We have also addressed the issue of an imbalanced dataset.</p><p>Our findings revealed that Random Forest with Random Oversampler and Decision Tree with SMOTE, outperformed other algorithms for the flight delay prediction task. This aligns with some previous works on flight delay prediction, which found that Random Forest outperformed other algorithms [<xref rid=\"pone.0335141.ref005\" ref-type=\"bibr\">5</xref>,<xref rid=\"pone.0335141.ref007\" ref-type=\"bibr\">7</xref>,<xref rid=\"pone.0335141.ref019\" ref-type=\"bibr\">19</xref>].</p><p>Some previous studies [<xref rid=\"pone.0335141.ref006\" ref-type=\"bibr\">6</xref>&#8211;<xref rid=\"pone.0335141.ref008\" ref-type=\"bibr\">8</xref>,<xref rid=\"pone.0335141.ref010\" ref-type=\"bibr\">10</xref>&#8211;<xref rid=\"pone.0335141.ref014\" ref-type=\"bibr\">14</xref>,<xref rid=\"pone.0335141.ref019\" ref-type=\"bibr\">19</xref>] have recognized the limitations of using all available features and implemented an optimized feature selection technique, demonstrating significant performance gains. Compared to those studies that applied feature selection, the performance of our model outperforms most of the previous works [<xref rid=\"pone.0335141.ref006\" ref-type=\"bibr\">6</xref>&#8211;<xref rid=\"pone.0335141.ref012\" ref-type=\"bibr\">12</xref>,<xref rid=\"pone.0335141.ref019\" ref-type=\"bibr\">19</xref>] achieving an accuracy of 0.90 and an F-score of 0.91 for both Random Forest and Decision Tree algorithms. Although the study [<xref rid=\"pone.0335141.ref014\" ref-type=\"bibr\">14</xref>] achieved higher performance measures with an accuracy of 93.61%, it did not address the data imbalance issue. The performance of classifiers is expected to decline after addressing the data imbalance issue. This decline occurred because, prior to balancing, the models were biased toward the majority class and were largely unaffected by misclassifying the minority class. However, after correcting the class distribution, the models classified both classes more equitably, leading to a decrease in performance but a more realistic and balanced approach [<xref rid=\"pone.0335141.ref030\" ref-type=\"bibr\">30</xref>].</p><p>None of the previous works cited in this paper has addressed the issue of class imbalance. In contrast to Chen et al [<xref rid=\"pone.0335141.ref010\" ref-type=\"bibr\">10</xref>], the only study that applied the same sampling technique (oversampling) to tackle the problem of imbalanced data, our model achieved better performance, with an accuracy of 90%, while they obtained an accuracy of 86.72%. Therefore, after addressing the class imbalance, our proposed model outperformed the previous studies referenced in this paper.</p><p>Despite these promising results, there are important limitations to acknowledge, particularly concerning the model&#8217;s generalizability. While our proposed model demonstrated high predictive performance for flight delays on the specific dataset used, its generalizability to broader or unseen contexts remains an open question. Our model was trained and validated on historical flight data from U.S. domestic operations, and therefore its applicability to international flights, different regulatory environments, or airlines with distinct operational patterns may be limited. In machine learning, ensuring generalization beyond the training distribution is critical for real-world deployment. Recent work by Asif et al. [<xref rid=\"pone.0335141.ref031\" ref-type=\"bibr\">31</xref>] introduced the Advanced Zero-Shot Learning (AZSL) framework to address generalization challenges in federated learning by leveraging synthetic data and Zero-Shot Learning (ZSL) techniques. Their approach demonstrated that models could effectively adapt to unseen classes and non-IID data distributions, enhancing model flexibility and robustness across heterogeneous environments. Inspired by this, future extensions of our study could explore the integration of synthetic data generation, domain adaptation techniques, or zero-shot learning approaches to improve the model&#8217;s transferability to different airports, countries, or operational conditions. This would help ensure that the flight delay prediction models remain reliable under a variety of real-world scenarios.</p></sec><sec sec-type=\"conclusions\" id=\"sec022\"><title>6. Conclusion</title><p>This study conducted a comprehensive evaluation of six machine learning classifiers for flight delay prediction under class imbalance. Performance enhancement factors, including feature engineering, feature selection, and data sampling techniques, were applied. The models were evaluated using a benchmark dataset, and their performance was assessed using various metrics.</p><p>The results of our analysis revealed that Random Forest with Random Oversampling and Decision Tree with SMOTE outperformed the other models, achieving an accuracy of 0.90 and an F1-score of 0.91. SVC also demonstrated strong performance, exhibiting balanced performance across the metrics. Overall, the study highlights the importance of careful model selection, resampling strategy, and cross-validation to achieve reliable flight delay predictions. The findings offer actionable insights for aviation stakeholders and data scientists, supporting improved operational planning, resource allocation, and decision-making. Future investigations should consider ensemble methods, domain adaptation, and deep learning frameworks to further elevate predictive accuracy while maintaining computational efficiency.</p></sec></body><back><ref-list><title>References</title><ref id=\"pone.0335141.ref001\"><label>1</label><mixed-citation publication-type=\"book\"><name name-style=\"western\"><surname>Wensveen</surname><given-names>J</given-names></name>. <source>Air transportation: a global management perspective</source>. <edition designator=\"9\">9th ed</edition>. <publisher-loc>London</publisher-loc>: <publisher-name>Routledge</publisher-name>. <year>2023</year>.</mixed-citation></ref><ref id=\"pone.0335141.ref002\"><label>2</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Nguyen</surname><given-names>C-V</given-names></name>. <article-title>Air Transport Resilience, Tourism and Its Impact on Economic Growth</article-title>. <source>Economies</source>. <year>2024</year>;<volume>12</volume>(<issue>9</issue>):<fpage>236</fpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.3390/economies12090236</pub-id></mixed-citation></ref><ref id=\"pone.0335141.ref003\"><label>3</label><mixed-citation publication-type=\"book\"><collab>International Air Transport Association</collab>. <source>IATA&#8217;s annual review 2024</source>. <publisher-loc>Montreal</publisher-loc>: <publisher-name>IATA</publisher-name>. <year>2024</year>. <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"https://www.iata.org/en/publications/annual-review/\" ext-link-type=\"uri\">https://www.iata.org/en/publications/annual-review/</ext-link></mixed-citation></ref><ref id=\"pone.0335141.ref004\"><label>4</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Song</surname><given-names>C</given-names></name>, <name name-style=\"western\"><surname>Ma</surname><given-names>X</given-names></name>, <name name-style=\"western\"><surname>Ardizzone</surname><given-names>C</given-names></name>, <name name-style=\"western\"><surname>Zhuang</surname><given-names>J</given-names></name>. <article-title>The adverse impact of flight delays on passenger satisfaction: An innovative prediction model utilizing wide &amp; deep learning</article-title>. <source>Journal of Air Transport Management</source>. <year>2024</year>;<volume>114</volume>:<fpage>102511</fpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1016/j.jairtraman.2023.102511</pub-id></mixed-citation></ref><ref id=\"pone.0335141.ref005\"><label>5</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Kalliguddi</surname><given-names>AM</given-names></name>, <name name-style=\"western\"><surname>Leboulluec</surname><given-names>AK</given-names></name>. <article-title>Predictive Modeling of Aircraft Flight Delay</article-title>. <source>ujm</source>. <year>2017</year>;<volume>5</volume>(<issue>10</issue>):<fpage>485</fpage>&#8211;<lpage>91</lpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.13189/ujm.2017.051003</pub-id></mixed-citation></ref><ref id=\"pone.0335141.ref006\"><label>6</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Xu</surname><given-names>Y</given-names></name>, <name name-style=\"western\"><surname>Liu</surname><given-names>L</given-names></name>, <name name-style=\"western\"><surname>Gao</surname><given-names>X</given-names></name>, <name name-style=\"western\"><surname>Zeng</surname><given-names>FF</given-names></name>. <article-title>Analysis of Factors in Flight Delay.</article-title> In: <source>Proceedings of the 2019 2nd International Conference on Mathematics, Modeling and Simulation Technologies and Applications (MMSTA 2019)</source>, <year>2019</year>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.2991/mmsta-19.2019.36</pub-id></mixed-citation></ref><ref id=\"pone.0335141.ref007\"><label>7</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Meel</surname><given-names>P</given-names></name>, <name name-style=\"western\"><surname>Singhal</surname><given-names>M</given-names></name>, <name name-style=\"western\"><surname>Tanwar</surname><given-names>M</given-names></name>, <name name-style=\"western\"><surname>Saini</surname><given-names>N</given-names></name>. <article-title>Predicting Flight Delays with Error Calculation using Machine Learned Classifiers.</article-title> In: <source>2020 7th International Conference on Signal Processing and Integrated Networks (SPIN)</source>, <year>2020</year>. <fpage>71</fpage>&#8211;<lpage>6</lpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1109/spin48934.2020.9071159</pub-id></mixed-citation></ref><ref id=\"pone.0335141.ref008\"><label>8</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Atlio&#287;lu</surname><given-names>Mc</given-names></name>, <name name-style=\"western\"><surname>Bolat</surname><given-names>M</given-names></name>, <name name-style=\"western\"><surname>&#350;ah&#239;n</surname><given-names>M</given-names></name>, <name name-style=\"western\"><surname>Tunali</surname><given-names>V</given-names></name>, <name name-style=\"western\"><surname>Kilin&#231;</surname><given-names>D</given-names></name>. <article-title>Supervised Learning Approaches to Flight Delay Prediction</article-title>. <source>Sakarya University Journal of Science</source>. <year>2020</year>;<volume>24</volume>(<issue>6</issue>):<fpage>1223</fpage>&#8211;<lpage>31</lpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.16984/saufenbilder.710107</pub-id></mixed-citation></ref><ref id=\"pone.0335141.ref009\"><label>9</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Tijil</surname><given-names>Y</given-names></name>, <name name-style=\"western\"><surname>Dwivedi</surname><given-names>N</given-names></name>, <name name-style=\"western\"><surname>Srivastava</surname><given-names>SK</given-names></name>, <name name-style=\"western\"><surname>Ranjan</surname><given-names>A</given-names></name>. <article-title>Flight Delay Prediction Using Machine Learning Techniques.</article-title> In: <source>2024 IEEE International Conference on Computing, Power and Communication Technologies (IC2PCT)</source>, <year>2024</year>. <fpage>1909</fpage>&#8211;<lpage>13</lpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1109/ic2pct60090.2024.10486482</pub-id></mixed-citation></ref><ref id=\"pone.0335141.ref010\"><label>10</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Chen</surname><given-names>J</given-names></name>, <name name-style=\"western\"><surname>Li</surname><given-names>M</given-names></name>. <article-title>Chained Predictions of Flight Delay Using Machine Learning.</article-title> In: <source>AIAA Scitech 2019 Forum</source>, <year>2019</year>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.2514/6.2019-1661</pub-id></mixed-citation></ref><ref id=\"pone.0335141.ref011\"><label>11</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Qu</surname><given-names>J</given-names></name>, <name name-style=\"western\"><surname>Wu</surname><given-names>S</given-names></name>, <name name-style=\"western\"><surname>Zhang</surname><given-names>J</given-names></name>. <article-title>Flight Delay Propagation Prediction Based on Deep Learning</article-title>. <source>Mathematics</source>. <year>2023</year>;<volume>11</volume>(<issue>3</issue>):<fpage>494</fpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.3390/math11030494</pub-id></mixed-citation></ref><ref id=\"pone.0335141.ref012\"><label>12</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Guvercin</surname><given-names>M</given-names></name>, <name name-style=\"western\"><surname>Ferhatosmanoglu</surname><given-names>N</given-names></name>, <name name-style=\"western\"><surname>Gedik</surname><given-names>B</given-names></name>. <article-title>Forecasting Flight Delays Using Clustered Models Based on Airport Networks</article-title>. <source>IEEE Trans Intell Transport Syst</source>. <year>2021</year>;<volume>22</volume>(<issue>5</issue>):<fpage>3179</fpage>&#8211;<lpage>89</lpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1109/tits.2020.2990960</pub-id></mixed-citation></ref><ref id=\"pone.0335141.ref013\"><label>13</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Ayaydin</surname><given-names>A</given-names></name>, <name name-style=\"western\"><surname>Akcayol</surname><given-names>Ma</given-names></name>. <article-title>Deep Learning Based Forecasting of Delay on Flights</article-title>. <source>Bili&#351;im Teknolojileri Dergisi</source>. <year>2022</year>;<volume>15</volume>(<issue>3</issue>):<fpage>239</fpage>&#8211;<lpage>49</lpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.17671/gazibtd.1060646</pub-id></mixed-citation></ref><ref id=\"pone.0335141.ref014\"><label>14</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Bisandu</surname><given-names>DB</given-names></name>, <name name-style=\"western\"><surname>Moulitsas</surname><given-names>I</given-names></name>, <name name-style=\"western\"><surname>Filippone</surname><given-names>S</given-names></name>. <article-title>Social ski driver conditional autoregressive-based deep learning classifier for flight delay prediction</article-title>. <source>Neural Comput &amp; Applic</source>. <year>2022</year>;<volume>34</volume>(<issue>11</issue>):<fpage>8777</fpage>&#8211;<lpage>802</lpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1007/s00521-022-06898-y</pub-id></mixed-citation></ref><ref id=\"pone.0335141.ref015\"><label>15</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Zhou</surname><given-names>H</given-names></name>, <name name-style=\"western\"><surname>Li</surname><given-names>W</given-names></name>, <name name-style=\"western\"><surname>Jiang</surname><given-names>Z</given-names></name>, <name name-style=\"western\"><surname>Cai</surname><given-names>F</given-names></name>, <name name-style=\"western\"><surname>Xue</surname><given-names>Y</given-names></name>. <article-title>Flight Departure Time Prediction Based on Deep Learning</article-title>. <source>Aerospace</source>. <year>2022</year>;<volume>9</volume>(<issue>7</issue>):<fpage>394</fpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.3390/aerospace9070394</pub-id></mixed-citation></ref><ref id=\"pone.0335141.ref016\"><label>16</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Cai</surname><given-names>K</given-names></name>, <name name-style=\"western\"><surname>Li</surname><given-names>Y</given-names></name>, <name name-style=\"western\"><surname>Fang</surname><given-names>Y-P</given-names></name>, <name name-style=\"western\"><surname>Zhu</surname><given-names>Y</given-names></name>. <article-title>A Deep Learning Approach for Flight Delay Prediction Through Time-Evolving Graphs</article-title>. <source>IEEE Trans Intell Transport Syst</source>. <year>2022</year>;<volume>23</volume>(<issue>8</issue>):<fpage>11397</fpage>&#8211;<lpage>407</lpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1109/tits.2021.3103502</pub-id></mixed-citation></ref><ref id=\"pone.0335141.ref017\"><label>17</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Li</surname><given-names>Q</given-names></name>, <name name-style=\"western\"><surname>Guan</surname><given-names>X</given-names></name>, <name name-style=\"western\"><surname>Liu</surname><given-names>J</given-names></name>. <article-title>A CNN-LSTM framework for flight delay prediction</article-title>. <source>Expert Systems with Applications</source>. <year>2023</year>;<volume>227</volume>:<fpage>120287</fpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1016/j.eswa.2023.120287</pub-id></mixed-citation></ref><ref id=\"pone.0335141.ref018\"><label>18</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Deng</surname><given-names>W</given-names></name>, <name name-style=\"western\"><surname>Li</surname><given-names>K</given-names></name>, <name name-style=\"western\"><surname>Zhao</surname><given-names>H</given-names></name>. <article-title>A Flight Arrival Time Prediction Method Based on Cluster Clustering-Based Modular With Deep Neural Network</article-title>. <source>IEEE Trans Intell Transport Syst</source>. <year>2024</year>;<volume>25</volume>(<issue>6</issue>):<fpage>6238</fpage>&#8211;<lpage>47</lpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1109/tits.2023.3338251</pub-id></mixed-citation></ref><ref id=\"pone.0335141.ref019\"><label>19</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Kim</surname><given-names>S</given-names></name>, <name name-style=\"western\"><surname>Park</surname><given-names>E</given-names></name>. <article-title>Prediction of flight departure delays caused by weather conditions adopting data-driven approaches</article-title>. <source>J Big Data</source>. <year>2024</year>;<volume>11</volume>(<issue>1</issue>). <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1186/s40537-023-00867-5</pub-id></mixed-citation></ref><ref id=\"pone.0335141.ref020\"><label>20</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Yuan</surname><given-names>Y</given-names></name>, <name name-style=\"western\"><surname>Wang</surname><given-names>Y</given-names></name>, <name name-style=\"western\"><surname>Lai</surname><given-names>CS</given-names></name>. <article-title>Multi-Attribute Data-Driven Flight Departure Delay Prediction for Airport System Using Deep Learning Method</article-title>. <source>Aerospace</source>. <year>2025</year>;<volume>12</volume>(<issue>3</issue>):<fpage>246</fpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.3390/aerospace12030246</pub-id></mixed-citation></ref><ref id=\"pone.0335141.ref021\"><label>21</label><mixed-citation publication-type=\"other\">Kaggle. Flight status prediction dataset. <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"https://www.kaggle.com/datasets/robikscube/flight-delay-dataset-20182022\" ext-link-type=\"uri\">https://www.kaggle.com/datasets/robikscube/flight-delay-dataset-20182022</ext-link>. Accessed 2024 December 24.</mixed-citation></ref><ref id=\"pone.0335141.ref022\"><label>22</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Verdonck</surname><given-names>T</given-names></name>, <name name-style=\"western\"><surname>Baesens</surname><given-names>B</given-names></name>, <name name-style=\"western\"><surname>&#211;skarsd&#243;ttir</surname><given-names>M</given-names></name>, <name name-style=\"western\"><surname>vanden Broucke</surname><given-names>S</given-names></name>. <article-title>Special issue on feature engineering editorial</article-title>. <source>Mach Learn</source>. <year>2021</year>;<volume>113</volume>(<issue>7</issue>):<fpage>3917</fpage>&#8211;<lpage>28</lpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1007/s10994-021-06042-2</pub-id></mixed-citation></ref><ref id=\"pone.0335141.ref023\"><label>23</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Theng</surname><given-names>D</given-names></name>, <name name-style=\"western\"><surname>Bhoyar</surname><given-names>KK</given-names></name>. <article-title>Feature selection techniques for machine learning: a survey of more than two decades of research</article-title>. <source>Knowl Inf Syst</source>. <year>2023</year>;<volume>66</volume>(<issue>3</issue>):<fpage>1575</fpage>&#8211;<lpage>637</lpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1007/s10115-023-02010-5</pub-id></mixed-citation></ref><ref id=\"pone.0335141.ref024\"><label>24</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Kraiem</surname><given-names>MS</given-names></name>, <name name-style=\"western\"><surname>S&#225;nchez-Hern&#225;ndez</surname><given-names>F</given-names></name>, <name name-style=\"western\"><surname>Moreno-Garc&#237;a</surname><given-names>MN</given-names></name>. <article-title>Selecting the Suitable Resampling Strategy for Imbalanced Data Classification Regarding Dataset Properties. An Approach Based on Association Models</article-title>. <source>Applied Sciences</source>. <year>2021</year>;<volume>11</volume>(<issue>18</issue>):<fpage>8546</fpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.3390/app11188546</pub-id></mixed-citation></ref><ref id=\"pone.0335141.ref025\"><label>25</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Sharma</surname><given-names>V</given-names></name>. <article-title>A Study on Data Scaling Methods for Machine Learning</article-title>. <source>INJGAADMIN, ftjijgasr</source>. <year>2022</year>;<volume>1</volume>(<issue>1</issue>). <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.55938/ijgasr.v1i1.4</pub-id></mixed-citation></ref><ref id=\"pone.0335141.ref026\"><label>26</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Ahsan</surname><given-names>M</given-names></name>, <name name-style=\"western\"><surname>Mahmud</surname><given-names>M</given-names></name>, <name name-style=\"western\"><surname>Saha</surname><given-names>P</given-names></name>, <name name-style=\"western\"><surname>Gupta</surname><given-names>K</given-names></name>, <name name-style=\"western\"><surname>Siddique</surname><given-names>Z</given-names></name>. <article-title>Effect of Data Scaling Methods on Machine Learning Algorithms and Model Performance</article-title>. <source>Technologies</source>. <year>2021</year>;<volume>9</volume>(<issue>3</issue>):<fpage>52</fpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.3390/technologies9030052</pub-id></mixed-citation></ref><ref id=\"pone.0335141.ref027\"><label>27</label><mixed-citation publication-type=\"book\"><name name-style=\"western\"><surname>Zaki</surname><given-names>MJ</given-names></name>, <name name-style=\"western\"><surname>Meira</surname><given-names>W</given-names><suffix>Jr</suffix></name>. <source>Data mining and machine learning: fundamental concepts and algorithms</source>. <edition designator=\"2\">2nd ed.</edition><publisher-loc>Cambridge</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>; <year>2020</year>.</mixed-citation></ref><ref id=\"pone.0335141.ref028\"><label>28</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Suthaharan</surname><given-names>S</given-names></name>. <article-title>Decision Tree Learning</article-title>. <source>Integrated Series in Information Systems. Springer US</source>. <year>2016</year>. p. <fpage>237</fpage>&#8211;<lpage>69</lpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1007/978-1-4899-7641-3_10</pub-id></mixed-citation></ref><ref id=\"pone.0335141.ref029\"><label>29</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Rainio</surname><given-names>O</given-names></name>, <name name-style=\"western\"><surname>Teuho</surname><given-names>J</given-names></name>, <name name-style=\"western\"><surname>Kl&#233;n</surname><given-names>R</given-names></name>. <article-title>Evaluation metrics and statistical tests for machine learning</article-title>. <source>Sci Rep</source>. <year>2024</year>;<volume>14</volume>(<issue>1</issue>):<fpage>6086</fpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1038/s41598-024-56706-x</pub-id><pub-id pub-id-type=\"pmid\">38480847</pub-id><pub-id pub-id-type=\"pmcid\">PMC10937649</pub-id></mixed-citation></ref><ref id=\"pone.0335141.ref030\"><label>30</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Alasmari</surname><given-names>R</given-names></name>, <name name-style=\"western\"><surname>Alhogail</surname><given-names>AA</given-names></name>. <article-title>Protecting Smart-Home IoT Devices From MQTT Attacks: An Empirical Study of ML-Based IDS</article-title>. <source>IEEE Access</source>. <year>2024</year>;<volume>12</volume>:<fpage>25993</fpage>&#8211;<lpage>6004</lpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1109/access.2024.3367113</pub-id></mixed-citation></ref><ref id=\"pone.0335141.ref031\"><label>31</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Asif</surname><given-names>M</given-names></name>, <name name-style=\"western\"><surname>Naz</surname><given-names>S</given-names></name>, <name name-style=\"western\"><surname>Ali</surname><given-names>F</given-names></name>, <name name-style=\"western\"><surname>Alabrah</surname><given-names>A</given-names></name>, <name name-style=\"western\"><surname>Salam</surname><given-names>A</given-names></name>, <name name-style=\"western\"><surname>Amin</surname><given-names>F</given-names></name>, <etal>et al</etal>. <article-title>Advanced Zero-Shot Learning (AZSL) Framework for Secure Model Generalization in Federated Learning</article-title>. <source>IEEE Access</source>. <year>2024</year>;<volume>12</volume>:<fpage>184393</fpage>&#8211;<lpage>407</lpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1109/access.2024.3510756</pub-id></mixed-citation></ref></ref-list></back></article></pmc-articleset>",
  "text": "pmc PLoS One PLoS One 440 plosone plos PLOS One 1932-6203 PLOS PMC12685205 PMC12685205.1 12685205 12685205 41359618 10.1371/journal.pone.0335141 PONE-D-25-05607 1 Research Article Computer and Information Sciences Artificial Intelligence Machine Learning Physical Sciences Mathematics Applied Mathematics Algorithms Machine Learning Algorithms Research and Analysis Methods Simulation and Modeling Algorithms Machine Learning Algorithms Computer and Information Sciences Artificial Intelligence Machine Learning Machine Learning Algorithms Engineering and Technology Civil Engineering Transportation Infrastructure Airports Engineering and Technology Transportation Transportation Infrastructure Airports Research and Analysis Methods Mathematical and Statistical Techniques Statistical Methods Forecasting Physical Sciences Mathematics Statistics Statistical Methods Forecasting Engineering and Technology Management Engineering Decision Analysis Decision Trees Research and Analysis Methods Decision Analysis Decision Trees Computer and Information Sciences Artificial Intelligence Machine Learning Deep Learning Computer and Information Sciences Artificial Intelligence Machine Learning Support Vector Machines Biology and Life Sciences Organisms Eukaryota Plants Trees Flight delay prediction: Evaluating machine learning algorithms for enhanced accuracy Flight delay prediction https://orcid.org/0000-0001-7505-2428 AlBassam Sarah Ahmed A. Conceptualization Formal analysis Supervision Writing &#8211; review &amp; editing * AlShahrani Dhafir N. Conceptualization Formal analysis Methodology Software Writing &#8211; original draft Department of Information Systems, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia Tajik Nazanin Editor Mississippi State University, UNITED STATES OF AMERICA Competing Interests: The authors have declared that no competing interests exist. * E-mail: salbassam@ksu.edu.sa 8 12 2025 2025 20 12 501623 e0335141 2 2 2025 7 10 2025 08 12 2025 09 12 2025 09 12 2025 &#169; 2025 AlBassam, AlShahrani 2025 AlBassam, AlShahrani https://creativecommons.org/licenses/by/4.0/ This is an open access article distributed under the terms of the Creative Commons Attribution License , which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited. Flight delays pose substantial operational and economic challenges for airlines, directly affecting scheduling efficiency, resource allocation, and passenger satisfaction. Accurate prediction of arrival delays is therefore critical for optimizing airline operations and enhancing customer experience. This study systematically evaluates the predictive performance of six machine learning classifiers&#8212;Decision Tree, Random Forest, Support Vector Classifier (SVC), Logistic Regression, K-Nearest Neighbors (KNN), and Naive Bayes&#8212;on a comprehensive flight dataset, with particular attention to the challenges posed by class imbalance. To mitigate skewed class distributions, resampling techniques including Random Oversampling, Synthetic Minority Oversampling Technique (SMOTE), and Adaptive Synthetic Sampling (ADASYN) were applied to the training data. Model performance was rigorously assessed using stratified 10-fold cross-validation and further validated on a hold-out test set, employing multiple evaluation metrics: Accuracy, F1-score, Matthews Correlation Coefficient (MCC), and ROC-AUC. The results demonstrate that Random Forest combined with Random Oversampling and Decision Tree combined with SMOTE both achieved the highest predictive performance (accuracy 0.90, F1-score 0.90, MCC 0.73, ROC-AUC 0.87. Notably, simpler models such as Naive Bayes exhibited competitive results under balanced conditions, underscoring the continued relevance of probabilistic classifiers in certain operational contexts. These findings highlight the critical role of resampling strategies and rigorous cross-validation in developing reliable, high-performing predictive models for imbalanced flight delay datasets, offering actionable insights for both airline operations and data-driven decision-making. http://dx.doi.org/10.13039/501100002383 King Saud University Ongoing Research Funding program (ORF-2025-1313) https://orcid.org/0000-0001-7505-2428 AlBassam Sarah Ahmed A. This research was supported by the Ongoing Research Funding program (ORF-2025-1313), King Saud University, Riyadh, Saudi Arabia. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript. pmc-status-qastatus 0 pmc-status-live yes pmc-status-embargo no pmc-status-released yes pmc-prop-open-access yes pmc-prop-olf no pmc-prop-manuscript no pmc-prop-legally-suppressed no pmc-prop-has-pdf yes pmc-prop-has-supplement no pmc-prop-pdf-only no pmc-prop-suppress-copyright no pmc-prop-is-real-version no pmc-prop-is-scanned-article no pmc-prop-preprint no pmc-prop-in-epmc yes Data Availability The data that support the findings of this study are openly available at https://www.kaggle.com/datasets/robikscube/flight-delay-dataset-20182022 . Data Availability The data that support the findings of this study are openly available at https://www.kaggle.com/datasets/robikscube/flight-delay-dataset-20182022 . 1. Introduction Air Transport has become a major factor in global economic growth, allowing for more efficient communication and travel, leading to greater access to goods and services, as well as increased economic opportunities. Annually, approximately 2 billion passengers utilize air travel, representing 40% of international tourist movement, demonstrating its crucial role in fostering global connections and tourism growth [ 1 ]. This has had a positive impact on economic growth, job creation, and poverty reduction in many countries because air transport creates jobs, facilitates trade, enables tourism, and supports sustainable development around the world [ 2 ]. Over the past years, the number of flights in the airline industry has evolved significantly. According to the International Air Transport Association (IATA) in 2019 the airline industry worldwide flew approximately 102,465 flights per day. The demand for air transport has increased by 45% over the last decade, creating a large market for commercial airlines, airports, and other aviation-related businesses. In 2023, all major markets experienced a significant increase in domestic travel demand, with total domestic traffic surpassing the 2019 record. International travel also showed consistent growth globally. As 2024 commenced, the industry&#8217;s growth remained robust, despite facing economic and geopolitical challenges impacting both airlines and consumers [ 3 ]. Therefore, the risk of flight delays has also increased accordingly. It has also led to the development of new technologies: such as aircraft and air traffic control systems. Significantly, reliable flight delay prediction is critical for the air transport industry. Machine learning methods have been proven to be accurate in predicting flight delays. This study inspects different machine learning algorithms used for flight delay prediction. The motivation for this study comes from the need to improve customer satisfaction because flight delays can be frustrating for travelers, leading to missed connections, lost luggage, and other inconveniences [ 4 ]. By accurately predicting flight delays, airlines can proactively notify passengers and offer alternative travel to increase operational efficiency. Meaning flight delays can also be costly for airlines, leading to wasted time, fuel, and other resources. Therefore, in a highly competitive industry, airlines that can consistently deliver on-time flights are more likely to attract and retain customers. By leveraging machine learning to predict and mitigate delays, airlines can gain a competitive advantage over their peers [ 4 ]. 2. Related work Several studies on flight delays have been conducted. Researchers have applied machine learning algorithms to predict flight delays effectively. Kalliguddi and Leboulluec [ 5 ] developed a flight delay prediction system using multiple linear regression, decision trees, and random forest on over 1 million U.S. domestic flights. The random forest model achieved the best performance with an R-squared (R&#178;) of 0.94 and RMSE of 12.5 minutes, outperforming other models. The findings also highlighted the key factors contributing to departure delays, including late aircraft arrival, carrier delays, weather conditions, and National Air System (NAS) delays. Another study was conducted by Xu et al. [ 6 ] with a focus on analyzing the factors contributing to flight delays and developing a predictive model using statistical analysis and machine learning techniques. The authors analyzed the impact of relevant variables from the dataset, such as temperature, previous delay rate, month, and weekday. As a result, the highest accuracy achieved was 84.5% using Gradient Boosting classifier. However, neither study has resolved the issue of an imbalanced dataset. In a study by Meel et al. [ 7 ], five regression algorithms were evaluated using 2015 U.S. domestic flight data from the Bureau of Transportation Statistics. Models were trained separately for departure and arrival delays. The Random Forest Regressor outperformed others in both cases, achieving the lowest mean square error (MSE) of 2261.8 for departure delays and 3019.3 for arrival delays. Imbalanced dataset issue was not addressed in their work. Moreover, Atl&#305;o&#287;lu et al. [ 8 ] compared the performance of eleven supervised learning algorithms in predicting flight delay. The dataset used was provided by local airline company. The findings revealed that classification and regression trees (CART) and K-nearest neighbors (KNN) achieved the highest performance at 0.816 and 0.807 F-Scores respectively. However, they did not employ feature enhancement and instead relied only on the same data acquired from the airline operations. Moreover, they did not utilize any type of data balancing techniques. Tijil et al. [ 9 ] compared the performance of three machine learning algorithms in predicting flight delays using data from the Bureau of Transportation Statistics (BTS). The algorithms applied were Random Forest, Support Vector Machine (SVM), and Logistic Regression. The findings revealed that SVM outperformed the other two algorithms with 100% accuracy. This high level of accuracy might be attributed to the lack of addressing imbalanced data. Chen and Li [ 10 ] proposed a flight delay prediction model that integrates multi-label random forest classification with an estimated flight delay propagation model. This approach explicitly considers the propagation of delays across connected flights, leading to improved prediction accuracy. Recognizing the limitations of using all available features, the authors implemented an optimized feature selection technique, demonstrating significant performance gains. Their analysis identified departure delay and late arrival aircraft delay as the most critical factors for robust prediction, with their model achieving an accuracy of 86.72% for arrival delay and 83.05% for departure delay. Similar to [ 10 ], Qu et al [ 11 ] work has also focused on delay propagation, where delays in one flight can affect subsequent flights. The authors examined and forecasted flight delays utilizing deep learning models. Two innovative deep learning models were introduced: CBAM-CondenseNet and SimAM-CNN-MLSTM. The research demonstrated that these models can effectively capture both spatial and temporal dependencies in flight data, achieving accuracies of 89.8% and 91.36%, respectively. While the approach effectively captures delay propagation patterns, it does not address the class imbalance issue. Moreover, G&#252;vercin et al. [ 12 ] addressed flight delay prediction by leveraging airport network structure and delay patterns from similar airports. Using graph-based metrics like betweenness centrality and articulation points, the authors proposed Clustered Airport Modeling (CAM) to forecast arrival delays across 305 U.S. airports. Their approach improved forecasting accuracy by up to 55% MAPE over individual models. However, their focus remains on statistical time series modeling. It does not incorporate machine learning or address class imbalance, key gaps targeted in this study. Deep learning algorithms have also been applied to predict flight delays. Ayaydin and Ak&#231;ayol [ 13 ] applied deep recurrent neural network (DRNN), long-short term memory (LSTM), and Random Forest (RF) models to classify flight delays using a real-world dataset covering 368 global airports. Among the models, LSTM achieved the highest recall (96.50%), while Random Forest led in accuracy (82.21%) and F1-score (96.20%). Although the study applied standard preprocessing and hyperparameter tuning, it did not address feature selection or class imbalance, which are core aspects this work aims to enhance. Bisandu et al. [ 14 ] proposed a flight delay prediction model that combines deep recurrent neural network (DRNN) and a social ski driver conditional autoregressive-based (SSDCA-based) deep learning algorithm. The used dataset is from the US Government Bureau of Transportation Statistics (BTS). The model achieved an accuracy of % 93.61% and % 92.52% on dataset1 and dataset2, respectively, demonstrating superior performance compared to other methods. However, its complexity and reliance on metaheuristic tuning may limit real-time deployment or scalability across diverse aviation environments. Furthermore, the data imbalanced issue was not addressed. Zhou et al. [ 15 ] analyzed the factors influencing departure time delay. They have also proposed gated recurrent unit (GRU) model to predict actual flight departure times using operational and scheduling data from Nanjing Lukou Airport. Their findings revealed that the proposed model achieved an RMSE of 0.42 and MAE of 0.3, and outperformed LSTM, BP, and Random Forest. While the model shows high accuracy, its static nature and reliance on single-airport data limit adaptability to real-time or multi-airport environments. Cai et al. [ 16 ] proposed a graph-based deep learning framework, MSTAGCN, to predict flight delays across a multi-airport network using time-evolving graph-structured data. Using domestic flight records from several Chinese airports, the model outperformed baseline approaches such as STGCN and DCRNN in both short and long-term predictions. However, its complexity and need for high-resolution graph data may limit scalability in real-time or low-data settings. Li et al. [ 17 ] developed a two-stage CNN-LSTM-Random Forest model for flight delay prediction, capturing spatial dependencies via CNN, temporal weather effects via LSTM, and fusing both with extrinsic flight features in a Random Forest classifier. Using U.S. domestic flight data, the model achieved 92.39% accuracy. However, its multi-stage design may add complexity for real-time implementation. Deng et al. [ 18 ] proposed a modular neural network architecture called CC-MIDNN for predicting aircraft estimated arrival time (EAT), combining k-means clustering, Bayesian optimization, and a deep neural network (DNN) ensemble to train parallel sub-networks. Evaluated on Lisbon Airport data, it reduced MAE by 5.92 minutes over baseline models. However, its multi-step integration process and computational complexity may challenge deployment in real-time operational systems. Kim and Park [ 19 ] focused on long-term predictions of flight delays, which exceed 2 hours. The datasets were collected from three different airports: Incheon International Airport in South Korea (ICN), John F. Kennedy International Airport (JFK), and Chicago Midway International Airport (MDW) in the United States. Several machine learning models, and Long Short-Term Memory (LSTM) were applied to predict flight takeoff delays, achieving up to 85.2% accuracy with the LSTM model at JFK. The imbalance issue was solved using random under sampling technique. This approach discards valuable data and may reduce model robustness. In a recent study, Yuan et al. [ 20 ] introduced a hybrid deep learning model (3DF-DSCL) combining 3D-CNN, GCN, and LSTM to predict airport departure delays using multi-attribute data (temporal, spatial, and spatiotemporal). Utilizing flight data from Beijing Capital International Airport, the model achieved a Mean Absolute Error (MAE) of 0.26 minutes, outperforming existing approaches by 14.47%. However, the model&#8217;s dependence on detailed operational data from a single airport may limit its applicability to broader contexts. Table 1 presents a summary of previous related works. Generally, machine learning techniques have proved to be effective for predicting flight delays. However, most of the previously mentioned studies lack some important aspects. Either they did not address the imbalanced data issue, or they missed important steps that affect the findings, such as feature selection and feature engineering. Deep learning techniques show potential for flight delay prediction; however, they often require substantial computational resources and large labeled datasets for effective training. 10.1371/journal.pone.0335141.t001 Table 1 Summary of related work. Paper Ref. ML/DL Algorithms Performance Measures Dataset Feature Selection Methods Feature Engineering Sampling Techniques [ 5 ] multiple linear regression, decision tree, and random forest R-squared (R&#178;) 0.94 Root Mean Squared Error (RMSE) 12.5 Bureau of Transportation Statistics (BTS) no no No [ 6 ] Gradient Boosting Logistic Model, K-Near Neighbors Gausian NB, Support Vector Machine, Decision Tree Classifier, Random Forest Classifier Accuracy 84.5 Chinese Air Traffic Control Authority yes yes No [ 7 ] Logistic Regression, Decision Tree Regression, Bayesian Ridge, Random Forest Regression, Gradient Boosting Regression Mean squared error (MSE) Departure 2261.8 Arrival 3019.3 the US Bureau of Transport Statistics 2015 Manual feature choice no No [ 8 ] K-Nearest Neighbor (KNN), Support Vector Machine (SVM), Decision Tree (CART), Gaussian Na&#239;ve Bayes (GNB), Logistic Regression (LR), Multilayer Perceptron (MLP), Random Forest (RF), Gradient Boosting (GBM), XGBoost (XGB), CatBoost (CB), and LightGBM (LGBM) F score 0.816 and 0.807 Turki airline company yes yes No [ 9 ] Random Forest, Support Vector Machine SVM, Logistic Regression f-score, recall, precision, and accuracy 100% scores. The Bureau of Transportation Statistics (BTS) no yes No [ 10 ] combined multi-label random forest classification and approximated delay propagation model Accuracy Arrival delay 86.72 Departure delay 83.05 Three databases: Bureau of Transportation Statistics (BTS) Local Climatologica Data (LCD) Aviation System Performance Metrics (ASPM) recursive feature elimination (RFE) algorithm yes SMOTE [ 11 ] CBAM-CondenseNet SimAM-CNN-MLSTM Accuracy 89.8% and 91.36%, respectively. China Air Traffic Management Bureau yes yes No [ 12 ] regression and time series forecasting Mean Absolute Percentage Error (MAPE) and Mean Absolute Error (MAE) Flight data from 305 us airports yes yes No [ 13 ] deep recurrent neural network (RNN), long-short term memory (LSTM), and random forest (RF) Recall 96.50%. real data set covering 368 airports across the world yes yes No [ 14 ] deep recurrent neural network (DRNN) Accuracy %93.61 dataset1%92.52 dataset2 the US Bureau of Transport Statistics 2019&#8211;2020 yes yes No [ 15 ] gated recurrent unit (GRU) model RMSE of 0.42 and MAE of 0.3 Nanjing Lukou Airport no yes no [ 16 ] a graph-based deep learning framework MAE 5.884 Chinees airports no yes no [ 17 ] Two-stage CNN-LSTM-Random Forest model Accuracy 92.39% Bureau of Transport Statistic no yes no [ 18 ] neural network architecture CC-MIDNN MAE 5.92 Lisbon Airport (LIS), Portugal no yes no [ 19 ] Decision Tree, Random Forest, Support Vector Machine, K-nearest neighbors, Logistic Regression, Extreme Gradient Boosting, and Long Short-Term Memory Accuracy 85.2% datasets were collected from three different airports yes yes Random under sampling [ 20 ] hybrid deep learning model (3DF-DSCL) MAE 0.26 Beijing Capital International Airport yes yes no To overcome these limitations, we propose an improved model for predicting flight delays, which includes several techniques to improve the performance of classifiers and thus find the best model to achieve our goal. The key objective of this project is to develop a ML model that can effectively detect small (&lt; 15 mints), medium (&#8805; 15 and &lt;45 mints) and large (&#8805;45 mints) flight delays. In our study, we considered the issue of imbalanced dataset and applied feature selection and feature engineering techniques to improve the findings. 3. Proposed methodology In this study we proposed an improved flight delay prediction model. To develop the model six different supervised learning algorithms were investigated and compared to select the best classifier. Several steps of feature engineering, feature selection, data resampling, data scaling and hypermeter optimization were applied to enhance the performance. An overview of the proposed methodology is shown in Fig 1 . 10.1371/journal.pone.0335141.g001 Fig 1 Overview of the study methodology. 3.1. Experiment environment All experiments were conducted on a MacBook Pro equipped with an Intel Core i7 processor and 16 GB of RAM. The model implementation environment is Google Collaboratory (Colab), a cloud based Jupyter Notebook environment that provides seamless access to CPUs, GPUs, and TPUs without any local configuration. Python was used as the programming language, enabling the integration of a wide range of libraries essential for machine learning workflows. Specifically, Scikit-learn, NumPy, Pandas, Matplotlib and Seaborn the libraries were employed. 3.2. Data source The study leverages the publicly available &#8220;Flight Status Prediction&#8221; dataset [ 21 ] hosted on Kaggle, comprising approximately 4,078,318 records across 61 columns, totaling around 51.94 MB. The dataset spans 2018&#8211;2022 and includes comprehensive flight information such as: Departure and arrival airports, flight numbers, and airline codes Scheduled and actual departure and arrival times Arrival and departure delays, cancellations, and associated operational delays (carrier, weather, NAS, security, and late aircraft delays) Flight origin, destination, distance, airtime, and elapsed times The dataset captures a wide variety of domestic and international flights, operated by multiple carriers across different time zones. 3.3. Data pre-processing Exploratory data analysis (EDA) was conducted to understand the dataset&#8217;s characteristics and relationships between variables. Key Python libraries (NumPy, Pandas, Matplotlib, Seaborn) were used for data manipulation and visualization. Initial exploration confirmed the dataset had time-series flight information with no missing values. Descriptive statistics were obtained using df.describe() to summarize central tendencies, dispersion, and potential outliers. 3.4. Feature engineering To enhance model performance and interpretability, feature engineering was applied. This included creating meaningful features from existing data to improve model predictions [ 22 ]. Specifically, the &#8220;delay_hours&#8221; column was binned into three categories as shown in Table 2 : 10.1371/journal.pone.0335141.t002 Table 2 Data binning. Delay Category Delay In Minutes Small &lt; 15 Medium 15&#8211;44 Large &#8805; 45 This transformation converts the problem into a multiclass classification task, capturing operationally meaningful delay thresholds. Additional engineered features included time-based aggregations, such as departure hour bins, day of the week, and day of the year, which have been shown in prior studies to influence flight punctuality. 3.5. Feature selection Feature selection is a crucial step for optimizing model performance. It involves identifying and selecting the most relevant features from the dataset to improve predictive accuracy and reduce overfitting [ 23 ]. In this study, we used the SelectKBest method with K&#8201;=&#8201;25, which selects the top 25 features based on their scoring function. After preprocessing, a total of 25 features were selected based on domain knowledge and correlation analysis. The features included are: FlightDate, DayOfWeek, Month, Carrier, FlightNumber, OriginAirport, DestAirport, ScheduledDepTime, ScheduledArrTime, Distance, ActualDepTime, ActualArrTime, DepDelay, ArrDelay, TaxiOutTime, TaxiInTime, CarrierDelay, WeatherDelay, NASDelay, SecurityDelay, LateAircraft Delay, PrevFlightDelay, DayOfYear, DepHourBin, DelayCategory. This curated feature set balances interpretability with predictive capability and ensures that only relevant, non-redundant information is fed into the models. 3.6. Data resampling Data resampling techniques are used to solve the imbalance data classification issue, where the dataset has an unequal distribution of the instances of each class, causing the classification model to be biased towards the majority class and reducing its overall performance [ 24 ]. Flight delay datasets are inherently imbalanced, with On-time flights often dominating the data. To address this, three resampling strategies were employed: Random Oversampling (ROS): Minority classes were randomly duplicated until class balance was achieved. Synthetic Minority Oversampling Technique (SMOTE): Synthetic samples were generated for minority classes using k-nearest neighbors in feature space. Adaptive Synthetic Sampling (ADASYN): Focused on generating synthetic samples for minority class instances that are harder to learn, improving classifier robustness for difficult examples. These methods aim to mitigate bias toward majority classes and enhance the classifier&#8217;s ability to detect all delay categories effectively. 3.7. Data splitting Data splitting is a technique for dividing the dataset into two parts: a training set and a testing set. The training set is used to train the model, and the testing set is used to evaluate the model&#8217;s performance on unseen data. The data splitting is commonly implemented using the train_test_split function, which allows the allocation of a pre-defined proportion of data for testing purposes. The test_size parameter is set to 0.2, indicating that 20% of the data will be assigned for testing purposes, while the remaining 80% will include the training set. This strategic division serves to ensure an objective evaluation of the model&#8217;s performance on unseen data, thereby mitigating the risk of overfitting. 3.8. Data scaling For machine learning algorithms, having feature values that are closer together generally improves both the speed and effectiveness of training. Conversely, when data points or feature values are spread apart, it can take longer for the model to learn, potentially reducing accuracy. To address this, scaling is used to bring data points closer together. Essentially, scaling standardizes the values, making them more comparable. Different scaling techniques, such as Min-Max Scaler, Max Abs Scaler, and Quantile Transformer Scaler, are available to accommodate various classification tasks and enhance the effectiveness of scaling [ 25 , 26 ]. In our model, we implemented the MinMaxScaler method. The MinMaxScaler method helped our model to normalize each feature by scaling it to a specific range, typically between 0 and 1. This can be helpful for machine learning algorithms that are sensitive to the scale of the features by calculating the minimum and maximum values for each feature. 3.9. Hyperparameter tuning To optimize model performance, hyperparameter tuning was conducted for all classifiers. Hyperparameters define key aspects of each algorithm, such as the number of neighbors in K-Nearest Neighbors, the regularization strength in Logistic Regression, or the depth of trees in Decision Tree and Random Forest classifiers. Selecting optimal hyperparameters ensures a balance between underfitting and overfitting, improving generalization on unseen data. In this study, a grid search method was applied to each model. 3.10. Model algorithms This study evaluates six supervised learning algorithms for predicting flight delays, selected to provide a balance of diverse modeling approaches, from linear to non-linear, and from simple to ensemble methods. The rationale for including these specific algorithms is to compare their performance across different modeling strategies and identify the most effective approach for this dataset. Support Vector Classifier (SVC): A supervised learning algorithm that classifies data by finding the optimal decision boundary (hyperplane) between classes. It can handle both linear and non-linear problems using kernel functions and is highly effective in high-dimensional spaces [ 27 ]. Na&#239;ve Bayes (NB): A probabilistic classifier based on feature independence assumptions; it is simple, fast, and performs well with categorical data [ 27 ]. K-Nearest Neighbors (K-NN): A non-parametric method that classifies instances based on proximity to neighboring points, providing a simple yet flexible baseline [ 27 ]. Random Forest (RF): An ensemble of decision trees that improves accuracy and robustness, reducing overfitting common in single trees. Decision Tree (DT): A straightforward model that recursively splits data based on information gain, offering interpretability and fast training [ 28 ]. Logistic Regression (LR): A statistical linear model that estimates the probability of categorical outcomes, serving as a benchmark for comparison with more complex models [ 27 ]. 3.11. Cross-validation Cross-validation is a method used to assess a model&#8217;s effectiveness and evaluate its performance by training it on one subset of the data and testing it on a different, unseen subset. A single evaluation run may not provide a reliable measure of the model&#8217;s performance. To ensure a thorough assessment and enhance the model&#8217;s robustness, repeated iterations are preferred. In our study, we employed 10-fold cross-validation. The final performance scores of the models were determined by averaging the results from all ten iterations. 3.12. Evaluation metrics To evaluate the performance of the classifiers, four key metrics were employed: accuracy, F1-score, Matthews Correlation Coefficient (MCC), and ROC-AUC. These measures collectively provide both an overall performance snapshot and insights into the models&#8217; discriminative abilities. A confusion matrix is used to summarize classification results. It presents true positives (TP), false negatives (FN), true negatives (TN), and false positives (FP) [ 29 ]. I. Accuracy is the percentage of correctly identified flights. It calculated as the ratio of correctly identified cases (delay and on time) to the total number of cases. A c c u r a c y = &#160; T P + T N T P + T N + F P + F N (1) II. The F1-score depends on both precision and recall. It is calculated by the following formula. F 1 &#8722; S c o r e = 2 &#215; P r e c i s i o n &#215; R e c a l l P r e c i s i o n + R e c a l l (2) III. Matthews Correlation Coefficient (MCC) provides a balanced measure even for imbalanced datasets. M C C = T P &#215; T N &#8722; F P &#215; F N ( T P + F P ) ( T P + F N ) ( T N + F P ) ( T N + F N ) (3) IV. ROC-AUC (Receiver Operating Characteristic &#8211; Area Under Curve) measures the ability of the classifier to distinguish between classes, with values closer to 1 indicating better performance. 4. Results 4.1. Models performance across resampling methods The performance of six machine learning algorithms&#8212;Decision Tree (DT), Random Forest (RF), Support Vector Classifier (SVC), Logistic Regression (LR), K-Nearest Neighbors (KNN), and Naive Bayes (NB)&#8212;was evaluated across three resampling strategies: Random Oversampling, SMOTE, and ADASYN. The results, summarized in Tables 3 &#8211; 8 , indicate that the choice of resampling technique substantially impacts classifier efficacy, particularly under class imbalance conditions. 10.1371/journal.pone.0335141.t003 Table 3 Random forest with resampling technique. Resampling Technique Accuracy F1-score MCC ROC-AUC Random Oversampler 0.90 0.91 0.74 0.87 SMOTE 0.87 0.88 0.68 0.87 ADASYN 0.87 0.88 0.68 0.86 10.1371/journal.pone.0335141.t004 Table 4 Decision tree with resampling technique. Resampling Technique Accuracy F1-score MCC ROC-AUC RandomOversampler 0.89 0.89 0.70 0.85 SMOTE 0.90 0.91 0.74 0.87 ADASYN 0.85 0.86 0.65 0.86 10.1371/journal.pone.0335141.t005 Table 5 NaiveBayes with resampling technique. Resampling Technique Accuracy F1-score MCC ROC-AUC RandomOversampler 0.88 0.89 0.70 0.86 SMOTE 0.89 0.89 0.71 0.86 ADASYN 0.87 0.88 0.68 0.86 10.1371/journal.pone.0335141.t006 Table 6 K-nearest neighbors with resampling technique. Resampling Technique Accuracy F1-score MCC ROC-AUC RandomOversampler 0.54 0.59 0.11 0.56 SMOTE 0.51 0.57 0.12 0.57 ADASYN 0.50 0.56 0.10 0.56 10.1371/journal.pone.0335141.t007 Table 7 Logistic regression with resampling technique. Resampling Technique Accuracy F1-score MCC ROC-AUC RandomOversampler 0.87 0.87 0.67 0.85 SMOTE 0.86 0.87 0.66 0.85 ADASYN 0.88 0.88 0.69 0.86 10.1371/journal.pone.0335141.t008 Table 8 SVC with resampling technique. Resampling Technique Accuracy F1-score MCC ROC-AUC RandomOversampler 0.87 0.88 0.70 0.89 SMOTE 0.88 0.89 0.71 0.87 ADASYN 0.89 0.91 0.73 0.89 As shown in Table 3 , Random Forest attained its highest accuracy of 0.90 using Random Oversampling, achieving an F1-score of 0.91, MCC of 0.74, and ROC-AUC of 0.87. While SMOTE and ADASYN yielded modestly lower accuracies of 0.87, Random Oversampling enabled the model to more reliably classify both delayed and on-time flights. The confusion matrix in Fig 2 highlights this balanced performance. 10.1371/journal.pone.0335141.g002 Fig 2 Random forest confusion matrix | best resampler: random oversampler. Table 4 demonstrates that Decision Tree achieved maximum accuracy (0.90) with SMOTE, accompanied by an F1-score of 0.91, MCC of 0.74, and ROC-AUC of 0.87. Fig 3 illustrates the confusion matrix under SMOTE, indicating a substantial reduction in misclassifications compared to other resampling methods. These results emphasize the capacity of SMOTE to enhance the Decision Tree&#8217;s handling of minority classes. 10.1371/journal.pone.0335141.g003 Fig 3 Decision tree confusion matrix | best resampler: SMOTE. Table 5 presents the performance of Na&#239;ve Bayes. Using SMOTE resampling. Na&#239;ve Bayes demonstrated relatively modest results with an accuracy 0.89, F1-score 0.89, MCC 0.71, ROC-AUC 0.86. Fig 4 highlights the SMOTE-enhanced confusion matrix. 10.1371/journal.pone.0335141.g004 Fig 4 NaiveBayes confusion matrix | best resampler: SMOTE. Among the six classifiers, K-Nearest Neighbors (KNN) exhibited the lowest performance as shown in Table 6 . Random Oversampler produced the best results (accuracy 0.54, F1-score 0.59, MCC 0.11, ROC-AUC 0.56). Fig 5 confirms the superiority of Random Oversampler, suggesting that KNN performs better with simpler oversampling rather than synthetic data generation. 10.1371/journal.pone.0335141.g005 Fig 5 K-nearest neighbors confusion matrix |best resampler: randomoversampler. Logistic Regression outcomes are summarized in Table 7 . Overall, the ADASYN performed better than Random Oversampling and SMOTE, with an accuracy of 0.88 and F1 score of 0.88. Fig 6 displays the confusion matrix with ADASYN. 10.1371/journal.pone.0335141.g006 Fig 6 Logistic regression confusion matrix |best resampler: ADASYN. SVC has also exhibited good performance with ADASYN, it attained an accuracy of 0.89, F1-score of 0.91, MCC of 0.73, and ROC-AUC of 0.89 as shown in Table 8 . Both Random Oversampling and SMOTE produced competitive results. Fig 7 presents the ADASYN-enhanced confusion matrix, which illustrates a highly balanced classification across delay categories, indicating that SVC effectively captures complex, non-linear relationships in the flight delay dataset. 10.1371/journal.pone.0335141.g007 Fig 7 SVC confusion matrix | best resampler: ADASYN. Based on the overall performance metrics, Random Forest using Random Oversampling and Decision Tree using SMOTE sampling emerged as the top performers, consistently achieving the highest accuracy and F1-scores. Their ability to correctly classify both positive and negative instances make them suitable choice for the flight delay classification task. 4.2. Statistical analysis To evaluate whether the observed differences in predictive performance were statistically significant, two complementary tests were conducted: the paired t-test and the McNemar test. These analyses provide a robust framework for determining whether differences in model performance reflect genuine distinctions or are due to random chance. Since multiple top-performing models exhibited very similar Accuracy and other evaluation metrics, a direct comparison between the best and worst-performing models was conducted to clearly illustrate the statistical and practical differences in predictive performance. This approach ensures that the analysis highlights the maximum contrast between model capabilities, providing a more interpretable and informative evaluation. Thus, Random Forest with RandomOverSampler was compared to K-Nearest Neighbors with ADASYN. 5.2.1. Paired t-test. The paired t-test was employed to compare the correctness of predictions for individual flights between the best-performing model (Random Forest with RandomOverSampler) and the worst-performing model (K-Nearest Neighbors with ADASYN). The resulting statistics were: Paired t-test between RandomForest and KNN (test set accuracy): t = 30.9884, p &lt; 0.001 The extremely low p-value indicates a highly significant difference in predictive performance, with Random Forest correctly classifying a substantially larger proportion of flights compared to KNN. 5.2.2. McNemar test. The McNemar test was applied to the test set predictions to evaluate whether there was a significant difference in misclassification patterns between the two models. The test produced the following results: McNemar test statistic = 78.0, p-value &#8776; 9.02&#8201;&#215;&#8201;10&#8315;&#185;&#8310;&#8309; The very low p-value confirms that Random Forest and KNN exhibit significantly different misclassification patterns. In particular, Random Forest demonstrates superior ability to correctly identify delayed flight instances, whereas KNN struggles with certain delay categories. 5. Discussion Our goal is to propose an efficient ML flight delay prediction model. So, we investigated six different ML algorithms and applied feature engineering and feature selection to improve the performance of the model. We have also addressed the issue of an imbalanced dataset. Our findings revealed that Random Forest with Random Oversampler and Decision Tree with SMOTE, outperformed other algorithms for the flight delay prediction task. This aligns with some previous works on flight delay prediction, which found that Random Forest outperformed other algorithms [ 5 , 7 , 19 ]. Some previous studies [ 6 &#8211; 8 , 10 &#8211; 14 , 19 ] have recognized the limitations of using all available features and implemented an optimized feature selection technique, demonstrating significant performance gains. Compared to those studies that applied feature selection, the performance of our model outperforms most of the previous works [ 6 &#8211; 12 , 19 ] achieving an accuracy of 0.90 and an F-score of 0.91 for both Random Forest and Decision Tree algorithms. Although the study [ 14 ] achieved higher performance measures with an accuracy of 93.61%, it did not address the data imbalance issue. The performance of classifiers is expected to decline after addressing the data imbalance issue. This decline occurred because, prior to balancing, the models were biased toward the majority class and were largely unaffected by misclassifying the minority class. However, after correcting the class distribution, the models classified both classes more equitably, leading to a decrease in performance but a more realistic and balanced approach [ 30 ]. None of the previous works cited in this paper has addressed the issue of class imbalance. In contrast to Chen et al [ 10 ], the only study that applied the same sampling technique (oversampling) to tackle the problem of imbalanced data, our model achieved better performance, with an accuracy of 90%, while they obtained an accuracy of 86.72%. Therefore, after addressing the class imbalance, our proposed model outperformed the previous studies referenced in this paper. Despite these promising results, there are important limitations to acknowledge, particularly concerning the model&#8217;s generalizability. While our proposed model demonstrated high predictive performance for flight delays on the specific dataset used, its generalizability to broader or unseen contexts remains an open question. Our model was trained and validated on historical flight data from U.S. domestic operations, and therefore its applicability to international flights, different regulatory environments, or airlines with distinct operational patterns may be limited. In machine learning, ensuring generalization beyond the training distribution is critical for real-world deployment. Recent work by Asif et al. [ 31 ] introduced the Advanced Zero-Shot Learning (AZSL) framework to address generalization challenges in federated learning by leveraging synthetic data and Zero-Shot Learning (ZSL) techniques. Their approach demonstrated that models could effectively adapt to unseen classes and non-IID data distributions, enhancing model flexibility and robustness across heterogeneous environments. Inspired by this, future extensions of our study could explore the integration of synthetic data generation, domain adaptation techniques, or zero-shot learning approaches to improve the model&#8217;s transferability to different airports, countries, or operational conditions. This would help ensure that the flight delay prediction models remain reliable under a variety of real-world scenarios. 6. Conclusion This study conducted a comprehensive evaluation of six machine learning classifiers for flight delay prediction under class imbalance. Performance enhancement factors, including feature engineering, feature selection, and data sampling techniques, were applied. The models were evaluated using a benchmark dataset, and their performance was assessed using various metrics. The results of our analysis revealed that Random Forest with Random Oversampling and Decision Tree with SMOTE outperformed the other models, achieving an accuracy of 0.90 and an F1-score of 0.91. SVC also demonstrated strong performance, exhibiting balanced performance across the metrics. Overall, the study highlights the importance of careful model selection, resampling strategy, and cross-validation to achieve reliable flight delay predictions. The findings offer actionable insights for aviation stakeholders and data scientists, supporting improved operational planning, resource allocation, and decision-making. Future investigations should consider ensemble methods, domain adaptation, and deep learning frameworks to further elevate predictive accuracy while maintaining computational efficiency. References 1 Wensveen J . Air transportation: a global management perspective . 9th ed . London : Routledge . 2023 . 2 Nguyen C-V . Air Transport Resilience, Tourism and Its Impact on Economic Growth . Economies . 2024 ; 12 ( 9 ): 236 . doi: 10.3390/economies12090236 3 International Air Transport Association . IATA&#8217;s annual review 2024 . Montreal : IATA . 2024 . https://www.iata.org/en/publications/annual-review/ 4 Song C , Ma X , Ardizzone C , Zhuang J . The adverse impact of flight delays on passenger satisfaction: An innovative prediction model utilizing wide &amp; deep learning . Journal of Air Transport Management . 2024 ; 114 : 102511 . doi: 10.1016/j.jairtraman.2023.102511 5 Kalliguddi AM , Leboulluec AK . Predictive Modeling of Aircraft Flight Delay . ujm . 2017 ; 5 ( 10 ): 485 &#8211; 91 . doi: 10.13189/ujm.2017.051003 6 Xu Y , Liu L , Gao X , Zeng FF . Analysis of Factors in Flight Delay. In: Proceedings of the 2019 2nd International Conference on Mathematics, Modeling and Simulation Technologies and Applications (MMSTA 2019) , 2019 . doi: 10.2991/mmsta-19.2019.36 7 Meel P , Singhal M , Tanwar M , Saini N . Predicting Flight Delays with Error Calculation using Machine Learned Classifiers. In: 2020 7th International Conference on Signal Processing and Integrated Networks (SPIN) , 2020 . 71 &#8211; 6 . doi: 10.1109/spin48934.2020.9071159 8 Atlio&#287;lu Mc , Bolat M , &#350;ah&#239;n M , Tunali V , Kilin&#231; D . Supervised Learning Approaches to Flight Delay Prediction . Sakarya University Journal of Science . 2020 ; 24 ( 6 ): 1223 &#8211; 31 . doi: 10.16984/saufenbilder.710107 9 Tijil Y , Dwivedi N , Srivastava SK , Ranjan A . Flight Delay Prediction Using Machine Learning Techniques. In: 2024 IEEE International Conference on Computing, Power and Communication Technologies (IC2PCT) , 2024 . 1909 &#8211; 13 . doi: 10.1109/ic2pct60090.2024.10486482 10 Chen J , Li M . Chained Predictions of Flight Delay Using Machine Learning. In: AIAA Scitech 2019 Forum , 2019 . doi: 10.2514/6.2019-1661 11 Qu J , Wu S , Zhang J . Flight Delay Propagation Prediction Based on Deep Learning . Mathematics . 2023 ; 11 ( 3 ): 494 . doi: 10.3390/math11030494 12 Guvercin M , Ferhatosmanoglu N , Gedik B . Forecasting Flight Delays Using Clustered Models Based on Airport Networks . IEEE Trans Intell Transport Syst . 2021 ; 22 ( 5 ): 3179 &#8211; 89 . doi: 10.1109/tits.2020.2990960 13 Ayaydin A , Akcayol Ma . Deep Learning Based Forecasting of Delay on Flights . Bili&#351;im Teknolojileri Dergisi . 2022 ; 15 ( 3 ): 239 &#8211; 49 . doi: 10.17671/gazibtd.1060646 14 Bisandu DB , Moulitsas I , Filippone S . Social ski driver conditional autoregressive-based deep learning classifier for flight delay prediction . Neural Comput &amp; Applic . 2022 ; 34 ( 11 ): 8777 &#8211; 802 . doi: 10.1007/s00521-022-06898-y 15 Zhou H , Li W , Jiang Z , Cai F , Xue Y . Flight Departure Time Prediction Based on Deep Learning . Aerospace . 2022 ; 9 ( 7 ): 394 . doi: 10.3390/aerospace9070394 16 Cai K , Li Y , Fang Y-P , Zhu Y . A Deep Learning Approach for Flight Delay Prediction Through Time-Evolving Graphs . IEEE Trans Intell Transport Syst . 2022 ; 23 ( 8 ): 11397 &#8211; 407 . doi: 10.1109/tits.2021.3103502 17 Li Q , Guan X , Liu J . A CNN-LSTM framework for flight delay prediction . Expert Systems with Applications . 2023 ; 227 : 120287 . doi: 10.1016/j.eswa.2023.120287 18 Deng W , Li K , Zhao H . A Flight Arrival Time Prediction Method Based on Cluster Clustering-Based Modular With Deep Neural Network . IEEE Trans Intell Transport Syst . 2024 ; 25 ( 6 ): 6238 &#8211; 47 . doi: 10.1109/tits.2023.3338251 19 Kim S , Park E . Prediction of flight departure delays caused by weather conditions adopting data-driven approaches . J Big Data . 2024 ; 11 ( 1 ). doi: 10.1186/s40537-023-00867-5 20 Yuan Y , Wang Y , Lai CS . Multi-Attribute Data-Driven Flight Departure Delay Prediction for Airport System Using Deep Learning Method . Aerospace . 2025 ; 12 ( 3 ): 246 . doi: 10.3390/aerospace12030246 21 Kaggle. Flight status prediction dataset. https://www.kaggle.com/datasets/robikscube/flight-delay-dataset-20182022 . Accessed 2024 December 24. 22 Verdonck T , Baesens B , &#211;skarsd&#243;ttir M , vanden Broucke S . Special issue on feature engineering editorial . Mach Learn . 2021 ; 113 ( 7 ): 3917 &#8211; 28 . doi: 10.1007/s10994-021-06042-2 23 Theng D , Bhoyar KK . Feature selection techniques for machine learning: a survey of more than two decades of research . Knowl Inf Syst . 2023 ; 66 ( 3 ): 1575 &#8211; 637 . doi: 10.1007/s10115-023-02010-5 24 Kraiem MS , S&#225;nchez-Hern&#225;ndez F , Moreno-Garc&#237;a MN . Selecting the Suitable Resampling Strategy for Imbalanced Data Classification Regarding Dataset Properties. An Approach Based on Association Models . Applied Sciences . 2021 ; 11 ( 18 ): 8546 . doi: 10.3390/app11188546 25 Sharma V . A Study on Data Scaling Methods for Machine Learning . INJGAADMIN, ftjijgasr . 2022 ; 1 ( 1 ). doi: 10.55938/ijgasr.v1i1.4 26 Ahsan M , Mahmud M , Saha P , Gupta K , Siddique Z . Effect of Data Scaling Methods on Machine Learning Algorithms and Model Performance . Technologies . 2021 ; 9 ( 3 ): 52 . doi: 10.3390/technologies9030052 27 Zaki MJ , Meira W Jr . Data mining and machine learning: fundamental concepts and algorithms . 2nd ed. Cambridge : Cambridge University Press ; 2020 . 28 Suthaharan S . Decision Tree Learning . Integrated Series in Information Systems. Springer US . 2016 . p. 237 &#8211; 69 . doi: 10.1007/978-1-4899-7641-3_10 29 Rainio O , Teuho J , Kl&#233;n R . Evaluation metrics and statistical tests for machine learning . Sci Rep . 2024 ; 14 ( 1 ): 6086 . doi: 10.1038/s41598-024-56706-x 38480847 PMC10937649 30 Alasmari R , Alhogail AA . Protecting Smart-Home IoT Devices From MQTT Attacks: An Empirical Study of ML-Based IDS . IEEE Access . 2024 ; 12 : 25993 &#8211; 6004 . doi: 10.1109/access.2024.3367113 31 Asif M , Naz S , Ali F , Alabrah A , Salam A , Amin F , et al . Advanced Zero-Shot Learning (AZSL) Framework for Secure Model Generalization in Federated Learning . IEEE Access . 2024 ; 12 : 184393 &#8211; 407 . doi: 10.1109/access.2024.3510756"
}