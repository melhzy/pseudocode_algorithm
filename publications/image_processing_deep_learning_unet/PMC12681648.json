{
  "pmcid": "PMC12681648",
  "source": "PMC",
  "download_date": "2025-12-09T16:11:25.710965",
  "metadata": {
    "journal_title": "MethodsX",
    "journal_nlm_ta": "MethodsX",
    "journal_iso_abbrev": "MethodsX",
    "journal": "MethodsX",
    "pmcid": "PMC12681648",
    "pmid": "41362668",
    "doi": "10.1016/j.mex.2025.103721",
    "title": "Classification of periapical dental X-ray using the YOLOv8 deep learning model",
    "year": "2025",
    "month": "11",
    "day": "13",
    "pub_date": {
      "year": "2025",
      "month": "11",
      "day": "13"
    },
    "authors": [
      "Chaudhari Archana Y.",
      "Birwadkar Prajwal",
      "Joshi Sagar",
      "Verma Yash",
      "Sindgi Rutuja"
    ],
    "abstract": "The Radiographs are essential in clinical dentistry as they provide information that is invisible during an oral inspection. These images, however suffer from excess noise, low resolution, and poor contrast which impacts diagnosis accuracy. This study presents a two‑stage pipeline combining Enhanced Super‑Resolution GAN (ESRGAN) for radiograph enhancement followed by YOLOv8 for multi‑class dental anomaly detection. The proposed method involves the application of ESRGAN (Enhanced super-resolution generative adversarial network with adaptive dual perceptual loss) that improves image detail and sharpen resolution. A customized YOLOv8 object detection model which is trained to detect object and classify into six important dental conditions. The classification is Caries, Crown, Root Canal Treated (RCT), Restoration, Normal, and Badly Decayed teeth. The ESRGAN-enhanced images demonstrated high visual fidelity, achieving a Peak Signal-to-Noise Ratio (PSNR) of 28.7 dB and a Structural Similarity Index (SSIM) of 0.91. The proposed YOLOv8 model analyzes the images after being enhanced by ESRGAN. The YOLOv8 model was evaluated on 100 test images and achieved an overall mean Average Precision (mAP@0.5) of 56.9 % and mAP@0.5:0.95 of 41.6 %. The proposed model achieved Sensitivity (Recall) 0.942 and Specificity 0.919 for Crown detection. Detection of Caries and Badly Decayed teeth remained challenging, with lower sensitivity scores of 0.174 and 0.355, respectively. Specificity across classes ranged from 0.361 (RCT) to 0.887 (Caries), indicating variable false positive rates. The proposed pipeline demonstrated clinical potential by improving subtle structural visibility and supporting automated dental assessment. Future work will explore class‑specific augmentation and explainability tools to increase clinical utility. ESRGAN significantly improved the resolution and clarity of dental X-rays, enabling better visualization of fine details for accurate diagnosis. YOLOv8 effectively identified six dental conditions, achieving high accuracy for distinct classes like crowns and restorations",
    "keywords": [
      "Dental X‑ray",
      "Object Detection",
      "YOLOv8, deep learning model, Periapical, object classification, ESRGAN"
    ]
  },
  "xml": "<?xml version=\"1.0\"  ?><!DOCTYPE pmc-articleset PUBLIC \"-//NLM//DTD ARTICLE SET 2.0//EN\" \"https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd\"><pmc-articleset><article xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:ali=\"http://www.niso.org/schemas/ali/1.0/\" article-type=\"research-article\" xml:lang=\"en\" dtd-version=\"1.4\"><processing-meta base-tagset=\"archiving\" mathml-version=\"3.0\" table-model=\"xhtml\" tagset-family=\"jats\"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type=\"nlm-ta\">MethodsX</journal-id><journal-id journal-id-type=\"iso-abbrev\">MethodsX</journal-id><journal-id journal-id-type=\"pmc-domain-id\">2748</journal-id><journal-id journal-id-type=\"pmc-domain\">mex</journal-id><journal-title-group><journal-title>MethodsX</journal-title></journal-title-group><issn pub-type=\"epub\">2215-0161</issn><publisher><publisher-name>Elsevier</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type=\"pmcid\">PMC12681648</article-id><article-id pub-id-type=\"pmcid-ver\">PMC12681648.1</article-id><article-id pub-id-type=\"pmcaid\">12681648</article-id><article-id pub-id-type=\"pmcaiid\">12681648</article-id><article-id pub-id-type=\"pmid\">41362668</article-id><article-id pub-id-type=\"doi\">10.1016/j.mex.2025.103721</article-id><article-id pub-id-type=\"pii\">S2215-0161(25)00565-5</article-id><article-id pub-id-type=\"publisher-id\">103721</article-id><article-version article-version-type=\"pmc-version\">1</article-version><article-categories><subj-group subj-group-type=\"heading\"><subject>Engineering</subject></subj-group></article-categories><title-group><article-title>Classification of periapical dental X-ray using the YOLOv8 deep learning model</article-title></title-group><contrib-group><contrib contrib-type=\"author\" id=\"au0001\"><name name-style=\"western\"><surname>Chaudhari</surname><given-names initials=\"AY\">Archana Y.</given-names></name><email>archana.chaudhari@sitpune.edu.in</email><xref rid=\"aff0001\" ref-type=\"aff\">a</xref><xref rid=\"cor0001\" ref-type=\"corresp\">&#8270;</xref></contrib><contrib contrib-type=\"author\" id=\"au0002\"><name name-style=\"western\"><surname>Birwadkar</surname><given-names initials=\"P\">Prajwal</given-names></name><xref rid=\"aff0001\" ref-type=\"aff\">a</xref></contrib><contrib contrib-type=\"author\" id=\"au0003\"><name name-style=\"western\"><surname>Joshi</surname><given-names initials=\"S\">Sagar</given-names></name><xref rid=\"aff0001\" ref-type=\"aff\">a</xref></contrib><contrib contrib-type=\"author\" id=\"au0004\"><name name-style=\"western\"><surname>Verma</surname><given-names initials=\"Y\">Yash</given-names></name><xref rid=\"aff0001\" ref-type=\"aff\">a</xref></contrib><contrib contrib-type=\"author\" id=\"au0005\"><name name-style=\"western\"><surname>Sindgi</surname><given-names initials=\"R\">Rutuja</given-names></name><xref rid=\"aff0002\" ref-type=\"aff\">b</xref></contrib><aff id=\"aff0001\"><label>a</label>Symbiosis Institute of Technology, Pune Campus, Symbiosis International (Deemed University), Pune, India</aff><aff id=\"aff0002\"><label>b</label>Symbiosis Medical College for Women &amp; Symbiosis University Hospital and Research Centre, Symbiosis International (Deemed University), Pune, India</aff></contrib-group><author-notes><corresp id=\"cor0001\"><label>&#8270;</label>Corresponding author. <email>archana.chaudhari@sitpune.edu.in</email></corresp></author-notes><pub-date pub-type=\"collection\"><month>12</month><year>2025</year></pub-date><pub-date pub-type=\"epub\"><day>13</day><month>11</month><year>2025</year></pub-date><volume>15</volume><issue-id pub-id-type=\"pmc-issue-id\">492015</issue-id><elocation-id>103721</elocation-id><history><date date-type=\"received\"><day>14</day><month>6</month><year>2025</year></date><date date-type=\"accepted\"><day>12</day><month>11</month><year>2025</year></date></history><pub-history><event event-type=\"pmc-release\"><date><day>13</day><month>11</month><year>2025</year></date></event><event event-type=\"pmc-live\"><date><day>08</day><month>12</month><year>2025</year></date></event><event event-type=\"pmc-last-change\"><date iso-8601-date=\"2025-12-09 09:25:13.687\"><day>09</day><month>12</month><year>2025</year></date></event></pub-history><permissions><copyright-statement>&#169; 2025 The Authors. Published by Elsevier B.V.</copyright-statement><copyright-year>2025</copyright-year><copyright-holder/><license><ali:license_ref specific-use=\"textmining\" content-type=\"ccbyncndlicense\">https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref><license-p>This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).</license-p></license></permissions><self-uri xmlns:xlink=\"http://www.w3.org/1999/xlink\" content-type=\"pmc-pdf\" xlink:href=\"main.pdf\"/><abstract id=\"abs0001\"><p>The Radiographs are essential in clinical dentistry as they provide information that is invisible during an oral inspection. These images, however suffer from excess noise, low resolution, and poor contrast which impacts diagnosis accuracy. This study presents a two&#8209;stage pipeline combining Enhanced Super&#8209;Resolution GAN (ESRGAN) for radiograph enhancement followed by YOLOv8 for multi&#8209;class dental anomaly detection. The proposed method involves the application of ESRGAN (Enhanced super-resolution generative adversarial network with adaptive dual perceptual loss) that improves image detail and sharpen resolution. A customized YOLOv8 object detection model which is trained to detect object and classify into six important dental conditions. The classification is Caries, Crown, Root Canal Treated (RCT), Restoration, Normal, and Badly Decayed teeth. The ESRGAN-enhanced images demonstrated high visual fidelity, achieving a Peak Signal-to-Noise Ratio (PSNR) of 28.7 dB and a Structural Similarity Index (SSIM) of 0.91. The proposed YOLOv8 model analyzes the images after being enhanced by ESRGAN. The YOLOv8 model was evaluated on 100 test images and achieved an overall mean Average Precision (mAP@0.5) of 56.9 % and mAP@0.5:0.95 of 41.6 %. The proposed model achieved Sensitivity (Recall) 0.942 and Specificity 0.919 for Crown detection. Detection of Caries and Badly Decayed teeth remained challenging, with lower sensitivity scores of 0.174 and 0.355, respectively. Specificity across classes ranged from 0.361 (RCT) to 0.887 (Caries), indicating variable false positive rates. The proposed pipeline demonstrated clinical potential by improving subtle structural visibility and supporting automated dental assessment. Future work will explore class&#8209;specific augmentation and explainability tools to increase clinical utility.</p><p>ESRGAN significantly improved the resolution and clarity of dental X-rays, enabling better visualization of fine details for accurate diagnosis.</p><p>YOLOv8 effectively identified six dental conditions, achieving high accuracy for distinct classes like crowns and restorations</p></abstract><abstract abstract-type=\"graphical\" id=\"abs0002\"><title>Graphical abstract</title><p><fig id=\"fig0005\" position=\"anchor\" orientation=\"portrait\"><alt-text id=\"alttx001\">Image, graphical abstract</alt-text><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"celink0005\" position=\"float\" orientation=\"portrait\" xlink:href=\"ga1.jpg\"/></fig></p></abstract><kwd-group id=\"keys0001\"><title>Keywords</title><kwd>Dental X&#8209;ray</kwd><kwd>Object Detection</kwd><kwd>YOLOv8, deep learning model, Periapical, object classification, ESRGAN</kwd></kwd-group><custom-meta-group><custom-meta><meta-name>pmc-status-qastatus</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>pmc-status-live</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-status-embargo</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-status-released</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-open-access</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-olf</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-manuscript</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-legally-suppressed</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-pdf</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-supplement</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-pdf-only</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-suppress-copyright</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-real-version</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-scanned-article</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-preprint</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-in-epmc</meta-name><meta-value>yes</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id=\"sec0001\"><title>Specifications table</title><p id=\"para0002\">The table provides general information on your method.<table-wrap position=\"float\" id=\"utbl0001\" orientation=\"portrait\"><table frame=\"hsides\" rules=\"groups\"><thead><tr><th valign=\"top\" colspan=\"1\" rowspan=\"1\">Subject area</th><th valign=\"top\" colspan=\"1\" rowspan=\"1\">Medicine and Dentistry</th></tr></thead><tbody><tr><td valign=\"top\" colspan=\"1\" rowspan=\"1\"><bold>More specific subject area</bold></td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Deep Learning for Automated Diagnosis in Dental Radiography</td></tr><tr><td valign=\"top\" colspan=\"1\" rowspan=\"1\"><bold>Name of your method</bold></td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Periapical dental X-ray image classification using YOLOv8</td></tr><tr><td valign=\"top\" colspan=\"1\" rowspan=\"1\"><bold>Name and reference of original method</bold></td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">None</td></tr><tr><td valign=\"top\" colspan=\"1\" rowspan=\"1\"><bold>Resource availability</bold></td><td valign=\"top\" colspan=\"1\" rowspan=\"1\"><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://github.com/prajwalBirwadkar/Dental-X-ray-Anomaly-Detection-System\" id=\"interref0001\">https://github.com/prajwalBirwadkar/Dental-X-ray-Anomaly-Detection-System</ext-link></td></tr></tbody></table></table-wrap></p></sec><sec id=\"sec0002\"><title>Background</title><p id=\"para0003\">In recent years, the sector of dental radiograph analysis has integrated deep learning and machine learning technologies, which has greatly enhanced the caries detection. Previously, the diagnosis of dental X-rays relied extensively on the interpretation of clinicians, which was prone to manual bias and inter- observer differences, no matter how reliable it was [<xref rid=\"bib0030\" ref-type=\"bibr\">1</xref>]. Attempts at computer-aided diagnosis (CAD) were focused on using Feature Extraction and Rule-based Classifiers for detection of Dental Caries to reduce biases within systems. They often faced challenges like worsened sensitivity to changes in the quality of images, the patient's anatomy, and poor generalizability [<xref rid=\"bib0021\" ref-type=\"bibr\">2</xref>].</p><p id=\"para0004\">The automation of feature extraction and comprehensive learning in dental image understanding through deep learning, and more specifically CNNs, have intensified its application. As per literature in dental imaging various techniques like CNNs for caries classification, tooth segmentation, and even periodontitis detection from panoramic and periapical X-ray images has applied. Most recently, specific dental conditions have been localized with object detection techniques using models like Faster R- CNN and YOLO. However, unprocessed, low- grade X-ray images, which hinders the models&#8217; capacity to identify subtle yet clinically significant details [<xref rid=\"bib0022\" ref-type=\"bibr\">3</xref>].</p></sec><sec id=\"sec0003\"><title>GAN-based image enhancement</title><p id=\"para0005\">Generative Adversarial Networks (GANs) have brought transformative capabilities to image generation and enhancement. In medical imaging, GANs have been successfully applied for tasks such as denoising, modality translation (e.g., from MRI to CT), and super-resolution reconstruction, offering significant improvements in the quality of low-resolution scans [<xref rid=\"bib0026\" ref-type=\"bibr\">4</xref>]. Among GAN variants, the Enhanced Super-Resolution GAN (ESRGAN) has emerged as a leading method for image upscaling and enhancement. ESRGAN builds upon the original SRGAN by incorporating Residual-in-Residual Dense Blocks (RRDB) and a more stable relativistic average discriminator, resulting in images with finer details, sharper edges, and fewer artifacts&#8212;qualities essential for medical diagnostics. Unlike traditional interpolation-based enhancement methods, which can blur or distort features, ESRGAN learns to preserve high-frequency textures and anatomical edges [<xref rid=\"bib0027\" ref-type=\"bibr\">5</xref>]. ESRGAN provides significant opportunities within dental radiography. Dental X-ray images are often marred with low resolution and poor contrast, restricting the diagnosis of tiny carious lesions or periapical infections [<xref rid=\"bib0031\" ref-type=\"bibr\">6</xref>]. Despite the exploration of ESRGAN in MRI, CT, and even retinal imaging, there is a noticeable gap in its use for dental radiographs. This research seeks to enhance the visual integrity of object detection on periapical X-rays by first using ESRGAN for preprocessing towards better usability in detecting early-stage carious lesions [<xref rid=\"bib0028\" ref-type=\"bibr\">7</xref>].</p></sec><sec id=\"sec0004\"><title>YOLO for medical object detection</title><p id=\"para0006\">Due to its real-time image processing capabilities in parallel with a high level of accuracy, the YOLO (You Only Look Once) family of algorithms has become very popular in numerous fields of computer vision. This is especially useful in medical imaging because of the intricacy of medical scans and the numerous components that need to be considered. With the COBRA framework, versions of YOLO such as YOLOv3 and YOLOv4 have been implemented for extensive image analysis through automated tumor detection in mammograms, polyp localization during endoscopies, and fracture identification in radiographs [<xref rid=\"bib0032\" ref-type=\"bibr\">8</xref>,33]. In the dental field, YOLO has demonstrated potential in the detection of dental decay, prosthetic restorations, and periodontal bone loss [<xref rid=\"bib0025\" ref-type=\"bibr\">9</xref>]. However, limited datasets and unprocessed X-rays, which may hinder the model&#8217;s ability to detect subtle lesions. The release of YOLOv8 introduces improvements in both architectural efficiency and training dynamics [<xref rid=\"bib0031\" ref-type=\"bibr\">6</xref>], making it a promising candidate for dental applications, particularly when combined with image enhancement techniques. While models like ResNet18, EfficientNet, and DenseNet121 are primarily designed for image classification, YOLOv8 is a one-stage object detector that performs both localization and classification in a single forward pass. This makes it inherently more suitable for tasks like dental pathology detection, where identifying the exact location of anomalies is crucial.</p><sec id=\"sec0005\"><title>Research gap in existing literature</title><p id=\"para0007\">Despite the progress in deep learning for medical imaging, there remains a significant gap in targeting image enhancement and object detection in a unified diagnostic framework, especially in dental radiography. Most existing studies either focus solely on enhancing images with super- resolution techniques or apply object detection to raw, unprocessed images. This separation limits the diagnostic potential of AI systems. Furthermore, although ESRGAN has proven effective in enhancing radiological images in fields like MRI and retinal imaging, its use in dental imaging has not been extensively explored. Similarly, while YOLO-based models have been evaluated in various healthcare settings, few studies have systematically assessed their performance on enhanced dental images for multi-class disease detection. This study addresses this gap by proposing a two-stage pipeline that enhances dental X-rays and then detects multiple dental conditions, providing both technical innovation and practical relevance in the field of dental diagnostics as depict in <xref rid=\"tbl0001\" ref-type=\"table\">Table 1</xref>.<table-wrap position=\"float\" id=\"tbl0001\" orientation=\"portrait\"><label>Table 1</label><caption><p>Comparative analysis of Dental X&#8209;ray detection studies.</p></caption><alt-text id=\"alt0005\">Table 1:</alt-text><table frame=\"hsides\" rules=\"groups\"><thead><tr><th valign=\"top\" colspan=\"1\" rowspan=\"1\">Sr. No.</th><th valign=\"top\" colspan=\"1\" rowspan=\"1\">Research Topic</th><th valign=\"top\" colspan=\"1\" rowspan=\"1\">Methodologies</th><th valign=\"top\" colspan=\"1\" rowspan=\"1\">Gaps Identified</th><th valign=\"top\" colspan=\"1\" rowspan=\"1\">Results Achieved</th><th valign=\"top\" colspan=\"1\" rowspan=\"1\">Future Scope</th><th valign=\"top\" colspan=\"1\" rowspan=\"1\">Dataset Used and Citation</th></tr></thead><tbody><tr><td valign=\"top\" colspan=\"1\" rowspan=\"1\">1</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Advanced AI&#8209;driven detection of interproximal caries in bitewing radiographs using YOLOv8</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">YOLOv8 on 1506 expert&#8209;annotated bitewing images</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Limited generalizability across different machines</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Precision: 96.03 % (enamel), 80.06 % (dentin); F1: 82.22 %</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Validate across multiple clinics &amp; imaging systems</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">1506 bitewing images [<xref rid=\"bib0001\" ref-type=\"bibr\">10</xref>]</td></tr><tr><td valign=\"top\" colspan=\"1\" rowspan=\"1\">2</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Dental caries classification using YOLOv8</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Customized YOLOv8 with pixel&#8209;level augmentations</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Need for broader patient demographics &amp; cross&#8209;site validation</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">mAP: 91.8 %; F1: 92.0 %; Recall: 92.6 %</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Incorporate more varied datasets (age, ethnicity)</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Karachi periapical radiographs (5 classes) [<xref rid=\"bib0002\" ref-type=\"bibr\">11</xref>]</td></tr><tr><td valign=\"top\" colspan=\"1\" rowspan=\"1\">3</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">YOLO&#8209;DentSeg: Real&#8209;time detection &amp; segmentation of oral diseases</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">YOLOv8n&#8209;seg + BiFPN &amp; EMCA attention</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Processing large panoramic images in real time</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">+3 % mAP; dice &#8593;10&#8211;15 %; low latency</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Deploy on edge devices in low&#8209;resource clinics</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">2720 annotated panoramic X&#8209;rays [<xref rid=\"bib0003\" ref-type=\"bibr\">12</xref>]</td></tr><tr><td valign=\"top\" colspan=\"1\" rowspan=\"1\">4</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">AI&#8209;driven dental radiography analysis with YOLOv8 &amp; Eigen&#8209;CAM</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">YOLOv8m + Eigen&#8209;CAM visualization</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Explainability &amp; clinician trust</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Accuracy: 90 %; Precision: 93.2 %; F1: 95.4 %</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Interactive heat&#8209;map interfaces for clinicians</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Expert&#8209;annotated bitewings [<xref rid=\"bib0004\" ref-type=\"bibr\">13</xref>]</td></tr><tr><td valign=\"top\" colspan=\"1\" rowspan=\"1\">5</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">YOLOrtho: Unified teeth enumeration &amp; disease detection</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">YOLOv8 + CoordConv + post&#8209;processing</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">No end&#8209;to&#8209;end for enumeration + detection</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Outperformed diffusion&#8209;based baselines</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Integrate with dental EHR systems</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Dentex Challenge 2023 &amp; Tufts dataset [<xref rid=\"bib0005\" ref-type=\"bibr\">14</xref>]</td></tr><tr><td valign=\"top\" colspan=\"1\" rowspan=\"1\">6</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Instance segmentation &amp; teeth classification in panoramics</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">BB&#8209;UNet (U&#8209;Net + YOLOv8)</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Simultaneous segmentation &amp; classification</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">mAP &#8593;3 %; dice &#8593;10&#8211;15 %</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Extend to CBCT &amp; other modalities</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">425 UFBA&#8209;UESC X&#8209;rays [<xref rid=\"bib0006\" ref-type=\"bibr\">15</xref>]</td></tr><tr><td valign=\"top\" colspan=\"1\" rowspan=\"1\">7</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">DENTEX: Abnormal tooth detection &amp; diagnosis benchmark</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Multi&#8209;label YOLOv8 with hierarchical annotations</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Scarcity of diverse annotated data</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Comprehensive benchmark established</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Stimulate robust model development</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">DENTEX labels (quadrant, enumeration, diagnosis) [<xref rid=\"bib0007\" ref-type=\"bibr\">16</xref>]</td></tr><tr><td valign=\"top\" colspan=\"1\" rowspan=\"1\">8</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">ESRGAN: Enhanced super&#8209;resolution for dental imaging</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">ESRGAN w/ residual&#8209;in&#8209;residual dense blocks + perceptual loss</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Occasional hallucinated artifacts</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">More realistic textures vs. SRGAN</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Preprocess low&#8209;dose X&#8209;rays</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">General SR datasets (transfer to dental) [<xref rid=\"bib0008\" ref-type=\"bibr\">17</xref>]</td></tr><tr><td valign=\"top\" colspan=\"1\" rowspan=\"1\">9</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Curated dental X&#8209;ray object detection dataset</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Roboflow with 4 classes</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Limited to 4 classes; lacks rare conditions</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Public benchmarks for evaluation</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Add rare pathologies, imaging conditions</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">1075 X&#8209;rays (4 classes) [<xref rid=\"bib0009\" ref-type=\"bibr\">18</xref>]</td></tr><tr><td valign=\"top\" colspan=\"1\" rowspan=\"1\">10</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Clean baseline dental X&#8209;ray dataset by Rabie</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Same dataset; no augmentation/preprocessing</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">No preprocessing &amp; augmentation</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Clean baseline provided</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Apply augmentation &amp; normalization</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">1075 X&#8209;rays (70/20/10 split) [<xref rid=\"bib0010\" ref-type=\"bibr\">19</xref>]</td></tr><tr><td valign=\"top\" colspan=\"1\" rowspan=\"1\">11</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Deep caries detection using deep learning: From dataset acquisition to detection</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Various CNN architectures</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Dataset acquisition &amp; annotation cost</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Demonstrated viability of DL methods</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Standardize public datasets</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">&#8211; (not specified) [<xref rid=\"bib0011\" ref-type=\"bibr\">20</xref>]</td></tr><tr><td valign=\"top\" colspan=\"1\" rowspan=\"1\">12</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Detection of caries under fixed prostheses by analyzing digital panoramic radiographs with deep learning methods</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">AI on panoramic radiographs</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Hidden caries beneath prostheses</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">AI identified sub&#8209;prosthetic lesions</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Combine tactile &amp; radiographic data</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">&#8211; (not specified) [<xref rid=\"bib0012\" ref-type=\"bibr\">21</xref>]</td></tr><tr><td valign=\"top\" colspan=\"1\" rowspan=\"1\">13</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Caries detection with tooth surface segmentation</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">U&#8209;Net + ResNet&#8209;18 + Faster R&#8209;CNN</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Lighting &amp; image quality variability</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Acc: 0.813; AUC: 0.837</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Multimodal fusion of photos &amp; X&#8209;rays</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">2348 intraoral photos [<xref rid=\"bib0013\" ref-type=\"bibr\">22</xref>]</td></tr><tr><td valign=\"top\" colspan=\"1\" rowspan=\"1\">14</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Object detection on dental X&#8209;rays using deep learning</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Mask R&#8209;CNN + contrast enhancement</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Low contrast &amp; anatomical variability</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Effective detection of teeth &amp; restorations</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Combine Mask R&#8209;CNN &amp; YOLOv8</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">&#8211; (not specified) [<xref rid=\"bib0014\" ref-type=\"bibr\">23</xref>]</td></tr><tr><td valign=\"top\" colspan=\"1\" rowspan=\"1\">15</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Enhancing caries detection in bitewing radiographs</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">YOLOv7 w/ varying IoU &amp; image sizes</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Impact of hyperparameters</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">YOLOv7 &gt; YOLOv3; precision &amp; F1 &#8593;</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Automated hyperparameter tuning</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">2575 bitewing images (7 classes) [<xref rid=\"bib0015\" ref-type=\"bibr\">24</xref>]</td></tr><tr><td valign=\"top\" colspan=\"1\" rowspan=\"1\">16</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">AI&#8209;assisted detection of multiple caries types</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">YOLOv8 classification of various caries</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Need for fine&#8209;grained annotations</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Accuracy: 97.7 %; Precision: 93.2 %; F1: 95.4 %</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Real&#8209;time smartphone deployment</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Bitewing radiographs [<xref rid=\"bib0016\" ref-type=\"bibr\">25</xref>]</td></tr><tr><td valign=\"top\" colspan=\"1\" rowspan=\"1\">17</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">YOLO&#8209;v5 for detection &amp; numbering in mixed dentition</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">YOLOv5 on 3854 labelled PRs</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Few mixed&#8209;dentition studies</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Sensitivity &amp; precision &#8776;0.99; mAP@0.5: 0.98</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Extend to other pediatric groups</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">3854 mixed&#8209;dentition PRs [<xref rid=\"bib0017\" ref-type=\"bibr\">26</xref>]</td></tr><tr><td valign=\"top\" colspan=\"1\" rowspan=\"1\">18</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Decayed&#8209;missing&#8209;filled teeth detection: YOLOv5 vs. YOLOv8</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">YOLOv5l w/ varied learning rates</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Need for early stopping &amp; generalizability</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Precision: 0.97; Recall: 0.858; mAP: 0.904</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Early&#8209;stopping &amp; robustness techniques</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">&#8211; (not specified) [<xref rid=\"bib0018\" ref-type=\"bibr\">27</xref>]</td></tr><tr><td valign=\"top\" colspan=\"1\" rowspan=\"1\">19</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Deep learning for early dental caries detection in bitewing radiographs</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">CNN&#8209;based YOLO pipeline</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Limited clinical validation</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">High accuracy &amp; speed</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Integrate with clinical workflows</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">&#8211; (not specified) [<xref rid=\"bib0019\" ref-type=\"bibr\">28</xref>]</td></tr><tr><td valign=\"top\" colspan=\"1\" rowspan=\"1\">20</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">A deep learning approach to automatic teeth detection and numbering based on object detection in dental periapical films</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">YOLO&#8209;based object detection</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Focus on permanent dentition only</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">mAP: 0.98</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Extend to mixed &amp; primary dentitions</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">&#8211; (not specified) [<xref rid=\"bib0020\" ref-type=\"bibr\">29</xref>]</td></tr></tbody></table></table-wrap></p></sec></sec><sec id=\"sec0006\"><title>Method details</title><p id=\"para0008\">The use of dental x rays has greatly contributed in the field of dentistry. X-ray photography is of various types. Periapical X rays are one of the most helpful ones. They show complete images of teeth fully alongside the bone structure supporting it. Some essential problems of dental care, such as diagnosing root canal therapy, dental caries, or assessing surrounding bone in relation to the tooth can be dealt by these X-ray images. Most modern hospitals nowadays seem to widely endorse the use of digital radiography, as commonly touted to offer much faster scanning time, ease of storage, and better compatibility with image editing devices and programs.</p><p id=\"para0009\">Even with these improvements, a big challenge for assets, such as images, still exists&#8212;many images remain low quality. Outdated machinery or unfavorable settings frequently result in poor resolution images that are rich in contrast and noise, which complicates identifying crucial diagnostic features. These compromises in image quality may result in incorrect analyses. Additionally, human interpretation is highly flexible and subjective, especially when the dental problem is nuanced or overlapping. In more commercially oriented, high-traffic practices, the sheer volume of data makes it increasingly difficult to properly evaluate each image individually. This emphasizes the necessity for software that elevates and maintains image quality while effectively identifying underlying structural abnormalities, in turn, aiding the clinicians in making informed decisions and minimizing errors.</p><p id=\"para0010\">In medical diagnostics, acquiring images of exceptional clarity is critical for providing accurate assessments. In dental radiographs, even the slightest changes in the teeth or the surrounding bone could indicate the presence of a cavity or the complications following a root canal treatment. Suboptimal images could overlook such subtle changes and result in a misdiagnosis. Enhancing image quality is important not only from the perspective of a practicing dentist but also for the AI systems that are programmed to analyze the images. The clearer the images, the more accurately the automated systems will be able to recognize and determine the existing abnormalities, particularly in cases where sophisticated imaging tools are not accessible.</p><p id=\"para0011\">This paper implements image enhancement and object recognition techniques to automate diagnosis in a two-step approach. The first step applies ESRGAN, or Enhanced Super-Resolution Generative Adversarial Networks, which is a deep learning model specializing in the enhancement of x-ray images. The algorithm reconstructs high-resolution (HR) images by employing multi-scale techniques, achieving higher clarity and trustworthiness than traditional methods.</p><p id=\"para0012\">The second part employs the state-of-the-art real-time object detection model, YOLOv8, to detect and classify the dental conditions in the enhanced images. The model is capable of concurrent detection of numerous issues, including cavities, root canal treatments, and severely decayed teeth. It is expected that combining ESRGAN with image detection capabilities of YOLOv8 will contribute to systems that allow for more accurate diagnoses, minimizing errors, and improving treatment planning for dentists.</p><p id=\"para0013\">In this study, author designed a two-stage pipeline that begins with coarse image-level classification and progresses to fine-grained object detection. The complete workflow is illustrated in <xref rid=\"fig0001\" ref-type=\"fig\">Fig. 1</xref>.<fig id=\"fig0001\" position=\"float\" orientation=\"portrait\"><label>Fig. 1</label><caption><p>Proposed methodology workflow.</p></caption><alt-text id=\"alt0001\">Fig 1:</alt-text><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"celink0001\" position=\"float\" orientation=\"portrait\" xlink:href=\"gr1.jpg\"/></fig></p><sec id=\"sec0007\"><title>Data acquisition and annotation</title><p id=\"para0014\">This study employed a publicly available dataset named Dental Periapical X-rays [<xref rid=\"bib0029\" ref-type=\"bibr\">30</xref>] on Kaggle. It is a dataset specially designed to assist research in detection of dental disease and consists of high-resolution periapical X-rays and COCO format annotations.</p><p id=\"para0015\">All images within the dataset are retained in JPEG (.jpg) format at a standard resolution of 640 &#215; 640 pixels. This is a standard image resolution that facilitates the procedures of data preprocessing and model training with the assurance that critical diagnostic details regarding the teeth and bone are retained. All images generally contain one or more teeth with focus on the periapical area, hence covering both the bone and the teeth. The dataset contains 1729 training images, 55 test images, and 100 validation images [<xref rid=\"bib0029\" ref-type=\"bibr\">30</xref>].</p><p id=\"para0016\">The information comes with COCO (Common Objects in Context) JSON annotations, which is a common format used for object detection tasks. Each JSON file includes data relevant to image ID, filename, image dimensions, and the number of detected cavities along with their locations in the form of bounding boxes [x, y, width, height]. These annotations are important for object detection model training like YOLOv8, which needs good-quality data to detect the defective areas correctly.</p><p id=\"para0017\">The data set consists of labels for six different classes of oral conditions: Caries, referring to the early stages of tooth decay; Crown, referring to artificial coverings intended for teeth and also referred to as crowns; Root Canal Treated (RCT), referring to treated teeth for root canal; Restoration, referring to tooth restoration through filling or otherwise; Normal, referring to teeth with no observable problems; and Badly Decayed, a label for teeth that are in a severe state of decay.</p><p id=\"para0018\">Based on a cursory glance, the dataset seems to show a reasonably balanced condition distribution, although some categories such as &#8220;Caries&#8221; and &#8220;Badly Decayed&#8221; are more prevalent than &#8220;Normal&#8221; or &#8220;Crown.&#8221; To address this imbalance, this research plan to use techniques like weighted sampling and data augmentation during model training.</p><p id=\"para0019\">To ensure that the annotations are accurate and reliable, we manually checked a subset of the images by overlaying the bounding boxes on the images. <xref rid=\"fig0001\" ref-type=\"fig\">Fig. 1</xref> shows examples of the ESRGAN-enhanced images next to their original counterparts, clearly highlighting dental conditions like cavities and metallic crowns. This review confirms that the dataset is well- suited for the tasks of image enhancement and object detection, providing a solid base for our diagnostic pipeline.</p></sec><sec id=\"sec0008\"><title>Super-Resolution enhancement</title><p id=\"para0020\">To address the low contrast and blurriness in many radiographs, this research employed Enhanced Super- Resolution GAN (ESRGAN) [<xref rid=\"bib0008\" ref-type=\"bibr\">17</xref>]. ESRGAN uses perceptual loss and residual-in-residual dense blocks to enhance the image quality, particularly improving enamel boundaries and interproximal regions. The ESRGAN output images are standardized to a resolution of 640 &#215; 640 pixels, which aligns with YOLOv8&#8217;s default input size. These enhanced images were used in all downstream classification and detection experiments as shown in <xref rid=\"fig0002\" ref-type=\"fig\">Fig. 2</xref>. Bounding box annotations are originally created on the low-resolution images. During ESRGAN enhancement, the spatial dimensions are preserved, and the bounding boxes are scaled proportionally to match the upsampled resolution. This is achieved by applying a fixed scaling factor to the coordinates, ensuring that the relative positions and sizes of the boxes remain accurate post-enhancement.<fig id=\"fig0002\" position=\"float\" orientation=\"portrait\"><label>Fig. 2</label><caption><p>ESRGAN on dental dataset a) Original image b) enhanced images.</p></caption><alt-text id=\"alt0002\">Fig 2:</alt-text><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"celink0002\" position=\"float\" orientation=\"portrait\" xlink:href=\"gr2.jpg\"/></fig></p><p id=\"para0021\">The proposed method used the Residual-in-Residual Dense Block (RRDB) based ESRGAN generator with 23 RRDB and 64 feature maps, trained from a publicly available ESRGAN pre-trained checkpoint. Training used paired HR/LR patches (patch size 128 &#215; 128), Adam optimizer (&#946;1=0.9, &#946;2=0.99), L1 pixel loss + perceptual loss (VGG19 feature loss) and a GAN loss (vanilla). Learning rate started at 1e-4 with a MultiStepLR schedule; total training iterations = 20,000 (we fine-tuned from the supplied pre-trained model). At inference we used tiling with tile size 512.</p></sec><sec id=\"sec0009\"><title>Preliminary classification experiments</title><p id=\"para0022\">This research initially treated the problem as a single-label classification task, where each radiograph was assigned one class. We trained four convolutional neural networks (CNNs) on the ESRGAN- enhanced images ResNet-18 [34], EfficientNet-B0, DenseNet-121, ConvNeXt-Tiny. Training was conducted using PyTorch v2.1.0 [34] for 30 epochs with batch size 16, incorporating basic augmentations such as random flips and rotations. While the models showed moderate performance, their accuracy was hindered by the presence of multi-label instances (e.g., radiographs showing both a crown and an RCT), which violated the single-label assumption.</p></sec><sec id=\"sec0010\"><title>Object detection with YOLOv8</title><p id=\"para0023\">We then reformulated the problem as object detection to handle multiple findings per image. The Ultralytics v8.1.0 YOLOv8 framework [<xref rid=\"bib0031\" ref-type=\"bibr\">6</xref>] was adopted, with the following steps:</p><p id=\"para0024\">Data Preparation: Enhanced images and YOLO-formatted labels were placed into the images/{train,val,test} and corresponding /labels folders.</p><p id=\"para9002\">\nyaml_path = \"/content/DentalXrayDetection-1/data.yaml\"\n</p><p id=\"para9003\">\nyaml_content = \"\"\"\n</p><p id=\"para9004\">\ntrain: /content/DentalXrayDetection-1/train/images\n</p><p id=\"para9005\">\nval: /content/DentalXrayDetection-1/valid/images\n</p><p id=\"para9006\">\ntest: /content/DentalXrayDetection-1/test/images\n</p><p id=\"para9007\">\nnc: 6\n</p><p id=\"para9008\">\nnames: ['Badly Decayed', 'Caries', 'Crown', 'Normal', 'RCT', 'Restoration']\n</p><p id=\"para9009\">\n\"\"\"\n</p><p id=\"para9010\">\nwith open(yaml_path, \"w\") as f:\n</p><p id=\"para9011\">\nf.write(yaml_content)\n</p><p id=\"para0026\">Model Configuration: We used the yolov8n.pt backbone pre-trained on MS COCO [<xref rid=\"bib0030\" ref-type=\"bibr\">1</xref>], adapting the head for six custom classes. The input resolution was set to 640 &#215; 640 pixels.</p><p id=\"para0027\">Training: The model was trained for 50 epochs using SGD optimizer (learning rate = 0.01, momentum = 0.937), mosaic augmentation, and early stopping based on validation <italic toggle=\"yes\">mAP@0.5</italic>.</p><p id=\"para9012\">\nmodel = YOLO(\"yolov8n.pt\")\n</p><p id=\"para9013\">\nresults = model.train(\n</p><p id=\"para9014\">\ndata=\"/content/DentalXrayDetection-1/data.yaml\",\n</p><p id=\"para9015\">\nepochs=30,\n</p><p id=\"para9016\">\nimgsz=640,\n</p><p id=\"para9017\">\nbatch=16\n</p><p id=\"para9018\">\n)\n</p><p id=\"para0029\">Evaluation: Evaluation metrics included mAP@0.5, mAP@0.5:0.95, precision, and recall for each class as shown in <xref rid=\"tbl0002\" ref-type=\"table\">Table 2</xref>.<table-wrap position=\"float\" id=\"tbl0002\" orientation=\"portrait\"><label>Table 2</label><caption><p>YOLOv8 performance on the test set.</p></caption><alt-text id=\"alt0006\">Table 2:</alt-text><table frame=\"hsides\" rules=\"groups\"><thead><tr><th valign=\"top\" colspan=\"1\" rowspan=\"1\">Class</th><th valign=\"top\" colspan=\"1\" rowspan=\"1\">Images</th><th valign=\"top\" colspan=\"1\" rowspan=\"1\">Instances</th><th valign=\"top\" colspan=\"1\" rowspan=\"1\">Precision</th><th valign=\"top\" colspan=\"1\" rowspan=\"1\">Recall</th><th valign=\"top\" colspan=\"1\" rowspan=\"1\">mAP@0.5</th><th valign=\"top\" colspan=\"1\" rowspan=\"1\">mAP@0.5:0.95</th></tr></thead><tbody><tr><td valign=\"top\" colspan=\"1\" rowspan=\"1\">All</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">100</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">157</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">0.482</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">0.595</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">0.569</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">0.416</td></tr><tr><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Badly Decayed</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">23</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">31</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">0.538</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">0.355</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">0.434</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">0.192</td></tr><tr><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Caries</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">18</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">23</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">0.315</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">0.174</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">0.174</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">0.088</td></tr><tr><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Crown</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">20</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">26</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">0.803</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">0.942</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">0.952</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">0.870</td></tr><tr><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Normal</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">21</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">26</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">0.498</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">0.538</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">0.591</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">0.398</td></tr><tr><td valign=\"top\" colspan=\"1\" rowspan=\"1\">RCT</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">13</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">18</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">0.215</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">0.833</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">0.496</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">0.317</td></tr><tr><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Restoration</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">26</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">33</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">0.526</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">0.727</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">0.767</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">0.633</td></tr></tbody></table></table-wrap></p><p id=\"para0030\">Finally, this research integrated the best-performing checkpoint into a web-based interface that allows users to upload X-rays and visualize predictions directly on the image. The pseudocode for implementation is as follows:</p></sec></sec><sec id=\"sec0011\"><title>Method validation</title><p id=\"para0031\">Training was performed on a single NVIDIA RTX 3090 GPU (24 GB VRAM), Intel i9 CPU, and 64 GB RAM. ESRGAN fine-tuning time was approx. 6.5 h and YOLOv8 training time was 2.8 h (30 epochs, batch size 16, imgesize 640). Classification Performance <xref rid=\"fig0003\" ref-type=\"fig\">Fig. 3</xref> illustrates the accuracy performance of six different deep learning models. Among them, YOLOv8 achieves the highest accuracy at 65 %, closely followed by DenseNet-121 with 64 %. ConvNext-Tiny and ResNet-18 show moderate performance, with accuracies of 59 % and 58 % respectively. EfficientNet-B0 performs slightly lower at 50 %. Faster R-CNN has the lowest accuracy, significantly trailing behind the others at just 17.56 %. Faster R-CNN first proposes regions and then classifies them. This makes less efficient for small, subtle features like dental caries. All models show improved accuracy with ESRGAN, confirming its effectiveness in enhancing diagnostic features in dental radiographs. DenseNet121 benefits the most, increasing from 58 % to 64 %. YOLOv8 and ConvNeXt also show notable improvements, reinforcing their adaptability to enhanced image inputs. This comparison highlights YOLOv8 and DenseNet-121 as the most effective models in this context, while Faster R-CNN appears to be the least suitable based on accuracy alone. Misclassification was common when multiple dental conditions appeared in a single image.<fig id=\"fig0003\" position=\"float\" orientation=\"portrait\"><label>Fig. 3</label><caption><p>Accuracy of each model with and without ESRGAN enhancement for dental X-ray analysis.</p></caption><alt-text id=\"alt0003\">Fig 3:</alt-text><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"celink0003\" position=\"float\" orientation=\"portrait\" xlink:href=\"gr3.jpg\"/></fig></p><p id=\"para0032\">As the YOLOv8 achieved highest accuracy among another model. <xref rid=\"tbl0002\" ref-type=\"table\">Table 2</xref> shows the detection metrics of YOLOv8 performance on test set. At inference, predictions were filtered using a confidence score threshold of 0.25 and Non-Maximum Suppression (NMS) IoU threshold of 0.5, as per YOLOv8 default settings. Crown detection was especially strong, with mAP@0.5 reaching 95.2 %. This may be due to the distinct high-contrast nature of metallic crowns. Caries detection, however, was the weakest, likely due to their subtle radiographic appearance and class imbalance. for medical applications, sensitivity and specificity are particularly helpful. Sensitivity (Recall) means correctly identify positive cases (e.g., actual caries) and Specificity means to correctly identify negative cases [<xref rid=\"bib0032\" ref-type=\"bibr\">8</xref>]. <xref rid=\"tbl0003\" ref-type=\"table\">Table 3</xref> depict the sensitivity (recall) and specificity for all each class. Crown detection is excellent across all metrics. Caries and Badly Decayed show low sensitivity, indicating missed detections. RCT has high sensitivity but very low specificity, suggesting over-detection and many false positives.<table-wrap position=\"float\" id=\"tbl0003\" orientation=\"portrait\"><label>Table 3</label><caption><p>sensitivity (recall) and specificity for all each class.</p></caption><alt-text id=\"alt0007\">Table 3:</alt-text><table frame=\"hsides\" rules=\"groups\"><thead><tr><th valign=\"top\" colspan=\"1\" rowspan=\"1\">Class</th><th valign=\"top\" colspan=\"1\" rowspan=\"1\">TP</th><th valign=\"top\" colspan=\"1\" rowspan=\"1\">FN</th><th valign=\"top\" colspan=\"1\" rowspan=\"1\">FP</th><th valign=\"top\" colspan=\"1\" rowspan=\"1\">TN</th><th valign=\"top\" colspan=\"1\" rowspan=\"1\">Sensitivity (Recall)</th><th valign=\"top\" colspan=\"1\" rowspan=\"1\">Specificity</th></tr></thead><tbody><tr><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Badly Decayed</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">11.01</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">19.99</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">9.49</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">59.51</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">0.355</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">0.862</td></tr><tr><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Caries</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">4.00</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">19.00</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">8.73</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">68.27</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">0.174</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">0.887</td></tr><tr><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Crown</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">24.49</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">1.51</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">6.01</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">68.00</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">0.942</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">0.919</td></tr><tr><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Normal</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">13.99</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">12.01</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">14.23</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">59.77</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">0.538</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">0.808</td></tr><tr><td valign=\"top\" colspan=\"1\" rowspan=\"1\">RCT</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">14.99</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">3.01</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">52.39</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">29.61</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">0.833</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">0.361</td></tr><tr><td valign=\"top\" colspan=\"1\" rowspan=\"1\">Restoration</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">23.99</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">9.01</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">21.76</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">45.24</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">0.727</td><td valign=\"top\" colspan=\"1\" rowspan=\"1\">0.675</td></tr></tbody></table></table-wrap></p><p id=\"para0034\"><xref rid=\"fig0004\" ref-type=\"fig\">Fig. 4</xref> shows visual results on test samples for qualitative assessment. Crowns and restorations were predicted with high confidence, while caries and badly decayed teeth were more challenging. The ESRGAN preprocessing contributed significantly to bounding box tightness and clarity of features.<fig id=\"fig0004\" position=\"float\" orientation=\"portrait\"><label>Fig. 4</label><caption><p>Classification of periapical dental X-ray by YOLOv8.</p></caption><alt-text id=\"alt0004\">Fig 4:</alt-text><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"celink0004\" position=\"float\" orientation=\"portrait\" xlink:href=\"gr4.jpg\"/></fig></p></sec><sec id=\"sec0012\"><title>Limitations</title><p id=\"para0035\">The transition from image-level classification to object-level detection enabled more accurate modeling of the inherent multi-pathology characteristics of dental X-rays. The strong performance on well-demarcated classes like Crown and Restoration is promising. However, it struggled to effectively augment and detect more subtle lesion classes like Caries, even when synthetic data was employed for training [<xref rid=\"bib0001\" ref-type=\"bibr\">10</xref>]. Additionally, the current system lacks integrated explainability mechanisms. Incorporating attention-based visualization techniques such as Eigen-CAM [<xref rid=\"bib0004\" ref-type=\"bibr\">13</xref>] could enhance interpretability and foster greater clinical trust.</p></sec><sec id=\"sec0013\"><title>Conclusion</title><p id=\"para0036\">This research presented a two&#8209;stage approach to automated dental radiograph analysis, beginning with ESRGAN-based image enhancement and progressing from coarse image&#8209;level classification to fine&#8209;grained object detection with YOLOv8. The ESRGAN preprocessing step significantly improved the clarity of subtle anatomical features, which in turn boosted the tightness and accuracy of detected bounding boxes. Our initial classification experiments highlighted the limitations of single&#8209;label CNN models on multi&#8209;pathology images, whereas the YOLOv8 detector achieved a robust mAP@0.5 of 56.9\\ % and outstanding localization of high&#8209;contrast classes such as crowns and restorations. Although detection of early caries remains challenging due to their subtle radiographic appearance and dataset imbalance, the pipeline lays a solid foundation for targeted augmentation and segmentation strategies in future work. Overall, this study demonstrates that combining super&#8209;resolution enhancement with state&#8209;of&#8209;the&#8209;art object detection can effectively address the complex, multi&#8209;label nature of dental X&#8209;rays, paving the way for more reliable, clinically useful information.</p></sec><sec id=\"sec0014\"><title>Related research article</title><p id=\"para0037\">None.</p></sec><sec id=\"sec0016\"><title>Ethics statements</title><p id=\"para0039\">In this work data collected from online platforms, confirming that participant data has been fully anonymized.</p></sec><sec id=\"sec0016a\"><title>CRediT authorship contribution statement</title><p id=\"para0039a\"><bold>Archana Y. Chaudhari:</bold> Writing &#8211; original draft, Writing &#8211; review &amp; editing, Funding acquisition. <bold>Prajwal Birwadkar:</bold> Conceptualization, Methodology, Visualization. <bold>Sagar Joshi:</bold> Data curation. <bold>Yash Verma:</bold> Data curation. <bold>Rutuja Sindgi:</bold> Data curation, Project administration.</p></sec><sec sec-type=\"COI-statement\" id=\"coi0001\"><title>Declaration of competing interest</title><p id=\"para0041\">The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.</p></sec></body><back><ref-list id=\"cebibl1\"><title>References</title><ref id=\"bib0030\"><label>1</label><element-citation publication-type=\"journal\" id=\"sbref0030\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Pinchi</surname><given-names>V.</given-names></name><name name-style=\"western\"><surname>Norelli</surname><given-names>G.A.</given-names></name><name name-style=\"western\"><surname>Caputi</surname><given-names>F.</given-names></name><name name-style=\"western\"><surname>Fassina</surname><given-names>G.</given-names></name><name name-style=\"western\"><surname>Pradella</surname><given-names>F.</given-names></name><name name-style=\"western\"><surname>Vincenti</surname><given-names>C.</given-names></name></person-group><article-title>Dental identification by comparison of antemortem and postmortem dental radiographs: influence of operator qualifications and cognitive bias</article-title><source>Forensic. Sci. Int.</source><volume>222</volume><issue>1&#8211;3</issue><year>2012</year><fpage>252</fpage><lpage>255</lpage><pub-id pub-id-type=\"pmid\">22770720</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1016/j.forsciint.2012.06.015</pub-id></element-citation></ref><ref id=\"bib0021\"><label>2</label><element-citation publication-type=\"book\" id=\"sbref0021\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Whaites</surname><given-names>D.</given-names></name><name name-style=\"western\"><surname>Drage</surname><given-names>N.</given-names></name></person-group><part-title>Essentials of Dental Radiography and Radiology</part-title><year>2013</year><publisher-name>Elsevier Health Sciences</publisher-name><comment>5th ed.</comment></element-citation></ref><ref id=\"bib0022\"><label>3</label><element-citation publication-type=\"journal\" id=\"sbref0022\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Scarfe</surname><given-names>A.M.</given-names></name><name name-style=\"western\"><surname>Farman</surname><given-names>C.M.</given-names></name></person-group><article-title>What is Cone-Beam CT and how does it work?</article-title><source>Dental. Clin.</source><volume>52</volume><issue>4</issue><year>2008</year><fpage>707</fpage><lpage>730</lpage><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1016/j.cden.2008.05.005</pub-id><pub-id pub-id-type=\"pmid\">18805225</pub-id></element-citation></ref><ref id=\"bib0026\"><label>4</label><element-citation publication-type=\"book\" id=\"sbref0026\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Ledig</surname><given-names>C.</given-names></name><name name-style=\"western\"><surname>Theis</surname><given-names>L.</given-names></name><name name-style=\"western\"><surname>Husz&#225;r</surname><given-names>F.</given-names></name><etal/></person-group><part-title>Photo-realistic single image super-resolution using a generative adversarial network</part-title><source>Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)</source><year>2017</year><fpage>105</fpage><lpage>114</lpage></element-citation></ref><ref id=\"bib0027\"><label>5</label><element-citation publication-type=\"book\" id=\"sbref0027\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Wang</surname><given-names>X.</given-names></name><name name-style=\"western\"><surname>Yu</surname><given-names>K.</given-names></name><name name-style=\"western\"><surname>Dong</surname><given-names>C.</given-names></name><etal/></person-group><part-title>ESRGAN: enhanced super-resolution generative adversarial networks</part-title><source>Proc. ECCV Workshops</source><year>2018</year></element-citation></ref><ref id=\"bib0031\"><label>6</label><element-citation publication-type=\"book\" id=\"sbref0031\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Satpathy</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Ranjan</surname><given-names>R.</given-names></name><name name-style=\"western\"><surname>Priyadarsini</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Gupta</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Mathur</surname><given-names>P.</given-names></name><name name-style=\"western\"><surname>Mishra</surname><given-names>M.</given-names></name></person-group><part-title>Diagnostic imaging techniques in oral diseases</part-title><source>Medical Imaging Methods: Recent Trends</source><year>2019</year><publisher-name>Springer Singapore</publisher-name><publisher-loc>Singapore</publisher-loc><fpage>59</fpage><lpage>95</lpage></element-citation></ref><ref id=\"bib0028\"><label>7</label><element-citation publication-type=\"book\" id=\"sbref0028\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Ben-Cohen</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Diamant</surname><given-names>I.</given-names></name><name name-style=\"western\"><surname>Klang</surname><given-names>E.</given-names></name><etal/></person-group><part-title>Virtual PET images from CT data using deep convolutional networks: initial results</part-title><source>Proc. Med. Image Comput. Comput.-Assist. Interv. (MICCAI)</source><year>2017</year><fpage>49</fpage><lpage>57</lpage></element-citation></ref><ref id=\"bib0032\"><label>8</label><element-citation publication-type=\"journal\" id=\"sbref0032\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Stookey</surname><given-names>G.K.</given-names></name><name name-style=\"western\"><surname>Jackson</surname><given-names>R.D.</given-names></name><name name-style=\"western\"><surname>Zandona</surname><given-names>A.G.</given-names></name><name name-style=\"western\"><surname>Analoui</surname><given-names>M.</given-names></name></person-group><article-title>Dental caries diagnosis</article-title><source>Dent. Clin. North Am.</source><volume>43</volume><issue>4</issue><year>1999 Oct 1</year><fpage>665</fpage><lpage>677</lpage><pub-id pub-id-type=\"pmid\">10553249</pub-id></element-citation></ref><ref id=\"bib0025\"><label>9</label><element-citation publication-type=\"journal\" id=\"sbref0025\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Muramatsu</surname><given-names>K.</given-names></name><name name-style=\"western\"><surname>Hayashi</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>Katsumata</surname><given-names>A.</given-names></name><etal/></person-group><article-title>Detection of dental caries in X-ray images using deep learning</article-title><source>Sensors</source><volume>20</volume><issue>12</issue><year>2020</year><fpage>1</fpage><lpage>14</lpage></element-citation></ref><ref id=\"bib0001\"><label>10</label><element-citation publication-type=\"journal\" id=\"sbref0001\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Bayati</surname><given-names>M.</given-names></name><name name-style=\"western\"><surname>Savareh</surname><given-names>B.A.</given-names></name><name name-style=\"western\"><surname>Ahmadinejad</surname><given-names>H.</given-names></name><name name-style=\"western\"><surname>Mosavat</surname><given-names>F.</given-names></name></person-group><article-title>Advanced AI-driven detection of interproximal caries in bitewing radiographs using YOLOv8</article-title><source>Sci. Rep.</source><volume>15</volume><issue>1</issue><year>2025</year><fpage>4641</fpage><pub-id pub-id-type=\"pmid\">39920198</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1038/s41598-024-84737-x</pub-id><pub-id pub-id-type=\"pmcid\">PMC11806056</pub-id></element-citation></ref><ref id=\"bib0002\"><label>11</label><element-citation publication-type=\"journal\" id=\"sbref0002\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Uddin</surname><given-names>S.M.Z.</given-names></name><name name-style=\"western\"><surname>Aslam</surname><given-names>M.I.</given-names></name><name name-style=\"western\"><surname>Moinuddin</surname><given-names>M.</given-names></name></person-group><article-title>Dental caries classification using YOLOv8</article-title><source>J. Popul. Ther. Clin. Pharmacol.</source><volume>31</volume><issue>6</issue><year>2024</year></element-citation></ref><ref id=\"bib0003\"><label>12</label><element-citation publication-type=\"journal\" id=\"sbref0003\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Hua</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>Chen</surname><given-names>R.</given-names></name><name name-style=\"western\"><surname>Qin</surname><given-names>H.</given-names></name></person-group><article-title>YOLO-DentSeg: a lightweight real-time model for accurate detection and segmentation of oral diseases in panoramic radiographs</article-title><source>Electronics</source><volume>14</volume><issue>4</issue><year>2025</year><fpage>805</fpage></element-citation></ref><ref id=\"bib0004\"><label>13</label><element-citation publication-type=\"journal\" id=\"sbref0004\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Aldanma</surname><given-names>&#214;.</given-names></name><name name-style=\"western\"><surname>Atarda&#287;</surname><given-names>H.B.</given-names></name><name name-style=\"western\"><surname>Y&#252;zge&#231;</surname><given-names>E.</given-names></name><name name-style=\"western\"><surname>&#214;zyurt</surname><given-names>F.</given-names></name></person-group><article-title>AI-driven dental radiography analysis: enhancing diagnosis and education through YOLOv8 and Eigen-CAM</article-title><source>Trans. Sci.</source><volume>41</volume><issue>6</issue><year>2024</year></element-citation></ref><ref id=\"bib0005\"><label>14</label><mixed-citation publication-type=\"other\" id=\"sbref0005\">Mei, S., Ma, C., Shen, F. and Wu, H., 2023. YOLOrtho&#8211;A unified framework for teeth enumeration and dental disease detection.</mixed-citation></ref><ref id=\"bib0006\"><label>15</label><mixed-citation publication-type=\"other\" id=\"sbref0006\">Budagam, D., Kumar, A., Ghosh, S., Shrivastav, A., Imanbayev, A.Z., Akhmetov, I.R., Kaplun, D., Antonov, S., Rychenkov, A., Cyganov, G. and Sinitca, A., 2024. Instance segmentation and teeth classification in panoramic X-rays.</mixed-citation></ref><ref id=\"bib0007\"><label>16</label><mixed-citation publication-type=\"other\" id=\"sbref0007\">Hamamci, I.E., Er, S., Simsar, E., Yuksel, A.E., Gultekin, S., Ozdemir, S.D., Yang, K., Li, H.B., Pati, S., Stadlinger, B. and Mehl, A., 2023. Dentex: an abnormal tooth detection with dental enumeration and diagnosis benchmark for panoramic x-rays.</mixed-citation></ref><ref id=\"bib0008\"><label>17</label><element-citation publication-type=\"book\" id=\"sbref0008\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Wang</surname><given-names>X.</given-names></name><name name-style=\"western\"><surname>Yu</surname><given-names>K.</given-names></name><name name-style=\"western\"><surname>Wu</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Gu</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>Liu</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>Dong</surname><given-names>C.</given-names></name><name name-style=\"western\"><surname>Qiao</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>Change Loy</surname><given-names>C.</given-names></name></person-group><part-title>Esrgan: enhanced super-resolution generative adversarial networks</part-title><source>Proceedings of the European conference on computer vision (ECCV) workshops</source><year>2018</year><fpage>0</fpage><comment>-0</comment></element-citation></ref><ref id=\"bib0009\"><label>18</label><element-citation publication-type=\"book\" id=\"sbref0009\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Projects</surname><given-names>Gozdes</given-names></name></person-group><part-title>Dental X-ray 1imfs</part-title><year>2023</year><publisher-name>Roboflow Universe</publisher-name></element-citation></ref><ref id=\"bib0010\"><label>19</label><element-citation publication-type=\"book\" id=\"sbref0010\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Rabie</surname><given-names>M.</given-names></name></person-group><part-title>Dental X-ray 1imfs-2ykrj</part-title><year>2023</year><publisher-name>Roboflow Universe</publisher-name></element-citation></ref><ref id=\"bib0011\"><label>20</label><element-citation publication-type=\"journal\" id=\"sbref0011\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Kaur</surname><given-names>A.</given-names></name><etal/></person-group><article-title>Deep caries detection using deep learning: from dataset acquisition to detection</article-title><source>Clin. Oral Investig.</source><volume>28</volume><issue>12</issue><year>2024</year><fpage>677</fpage><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1007/s00784-024-06068-5</pub-id><pub-id pub-id-type=\"pmid\">39621193</pub-id></element-citation></ref><ref id=\"bib0012\"><label>21</label><element-citation publication-type=\"journal\" id=\"sbref0012\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Ayhan</surname><given-names>B.</given-names></name><name name-style=\"western\"><surname>Ayan</surname><given-names>E.</given-names></name><name name-style=\"western\"><surname>Ats&#252;</surname><given-names>S.</given-names></name></person-group><article-title>Detection of dental caries under fixed prostheses by analyzing digital panoramic radiographs with deep learning methods</article-title><source>BMC Oral Health</source><volume>25</volume><issue>1</issue><year>2025</year><fpage>216</fpage><pub-id pub-id-type=\"pmid\">39930440</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1186/s12903-025-05577-3</pub-id><pub-id pub-id-type=\"pmcid\">PMC11809006</pub-id></element-citation></ref><ref id=\"bib0013\"><label>22</label><element-citation publication-type=\"journal\" id=\"sbref0013\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Park</surname><given-names>E.Y.</given-names></name><name name-style=\"western\"><surname>Cho</surname><given-names>H.</given-names></name><name name-style=\"western\"><surname>Kang</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Jeong</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Kim</surname><given-names>E.-K.</given-names></name></person-group><article-title>Caries detection with tooth surface segmentation on intraoral photographic images using deep learning</article-title><source>BMC Oral Health</source><volume>22</volume><year>2022</year><fpage>2589</fpage><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1186/s12903-022-02589-1</pub-id><pub-id pub-id-type=\"pmcid\">PMC9730679</pub-id><pub-id pub-id-type=\"pmid\">36476359</pub-id></element-citation></ref><ref id=\"bib0014\"><label>23</label><element-citation publication-type=\"journal\" id=\"sbref0014\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Suryani</surname><given-names>D.</given-names></name><name name-style=\"western\"><surname>Shoumi</surname><given-names>M.N.</given-names></name><name name-style=\"western\"><surname>Wakhidah</surname><given-names>R.</given-names></name></person-group><article-title>Object detection on dental X-ray images using deep learning method</article-title><source>IOP Conf. Ser. Mater. Sci. Eng.</source><volume>1073</volume><issue>1</issue><year>2021</year><object-id pub-id-type=\"publisher-id\">012058</object-id></element-citation></ref><ref id=\"bib0015\"><label>24</label><element-citation publication-type=\"journal\" id=\"sbref0015\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Wannakamon</surname><given-names>P.</given-names></name><etal/></person-group><article-title>Enhancing caries detection in bitewing radiographs using YOLOv7</article-title><source>J. Digit. Imaging</source><volume>36</volume><issue>6</issue><year>2023</year><fpage>2635</fpage><lpage>2647</lpage><pub-id pub-id-type=\"pmid\">37640971</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1007/s10278-023-00871-4</pub-id><pub-id pub-id-type=\"pmcid\">PMC10584768</pub-id></element-citation></ref><ref id=\"bib0016\"><label>25</label><element-citation publication-type=\"journal\" id=\"sbref0016\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Karaku&#351;</surname><given-names>R.</given-names></name><name name-style=\"western\"><surname>&#214;zi&#231;</surname><given-names>M.&#220;.</given-names></name><name name-style=\"western\"><surname>Tassoker</surname><given-names>M.</given-names></name></person-group><article-title>AI-assisted detection of interproximal, occlusal, and secondary caries on bite-wing radiographs: a single-shot deep learning approach</article-title><source>J. Imaging Inform. Med.</source><volume>37</volume><issue>6</issue><year>2024</year><fpage>3146</fpage><lpage>3159</lpage><pub-id pub-id-type=\"pmid\">38743125</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1007/s10278-024-01113-x</pub-id><pub-id pub-id-type=\"pmcid\">PMC11612078</pub-id></element-citation></ref><ref id=\"bib0017\"><label>26</label><element-citation publication-type=\"journal\" id=\"sbref0017\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Beser</surname><given-names>B.</given-names></name><etal/></person-group><article-title>YOLO-V5 based deep learning approach for tooth detection and segmentation on pediatric panoramic radiographs in mixed dentition</article-title><source>BMC Med. Imaging</source><volume>24</volume><issue>1</issue><year>2024</year><fpage>224</fpage><pub-id pub-id-type=\"pmid\">39198729</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1186/s12880-024-01410-5</pub-id><pub-id pub-id-type=\"pmcid\">PMC11351085</pub-id></element-citation></ref><ref id=\"bib0018\"><label>27</label><element-citation publication-type=\"journal\" id=\"sbref0018\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Fitria</surname><given-names>M.</given-names></name><etal/></person-group><article-title>The deep learning model for decayed-missing-filled teeth detection: a comparison between YOLOv5 and YOLOv8</article-title><source>Jordan. J. Comput. Inf. Technol.</source><volume>10</volume><issue>3</issue><year>2024</year><fpage>335</fpage><lpage>349</lpage></element-citation></ref><ref id=\"bib0019\"><label>28</label><element-citation publication-type=\"journal\" id=\"sbref0019\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Lee</surname><given-names>S.</given-names></name><etal/></person-group><article-title>Deep learning for early dental caries detection in bitewing radiographs</article-title><source>Sci. Rep.</source><volume>11</volume><year>2021</year><object-id pub-id-type=\"publisher-id\">16807</object-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1038/s41598-021-96368-7</pub-id><pub-id pub-id-type=\"pmcid\">PMC8376948</pub-id><pub-id pub-id-type=\"pmid\">34413414</pub-id></element-citation></ref><ref id=\"bib0020\"><label>29</label><element-citation publication-type=\"journal\" id=\"sbref0020\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Chen</surname><given-names>H.</given-names></name><etal/></person-group><article-title>A deep learning approach to automatic teeth detection and numbering based on object detection in dental periapical films</article-title><source>Sci. Rep.</source><volume>9</volume><year>2019</year><fpage>3840</fpage><pub-id pub-id-type=\"pmid\">30846758</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1038/s41598-019-40414-y</pub-id><pub-id pub-id-type=\"pmcid\">PMC6405755</pub-id></element-citation></ref><ref id=\"bib0029\"><label>30</label><element-citation publication-type=\"journal\" id=\"sbref0029\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Aglan</surname><given-names>N.</given-names></name></person-group><article-title>Dental periapical X-rays dataset</article-title><source>Kaggle</source><year>2022</year><comment>Available at</comment><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://www.kaggle.com/datasets/nadaaglan/dental-periapical-x-ray\" id=\"interref0002\">https://www.kaggle.com/datasets/nadaaglan/dental-periapical-x-ray</ext-link></element-citation></ref></ref-list><sec sec-type=\"data-availability\" id=\"refdata001\"><title>Data availability</title><p id=\"para9001\">Data will be made available on request.</p></sec><ack id=\"ack0001\"><title>Acknowledgments</title><p id=\"para0042\">This research did not receive any specific grant from funding agencies in the public, commercial, or not-for-profit sectors.</p></ack></back></article></pmc-articleset>",
  "text": "pmc MethodsX MethodsX 2748 mex MethodsX 2215-0161 Elsevier PMC12681648 PMC12681648.1 12681648 12681648 41362668 10.1016/j.mex.2025.103721 S2215-0161(25)00565-5 103721 1 Engineering Classification of periapical dental X-ray using the YOLOv8 deep learning model Chaudhari Archana Y. archana.chaudhari@sitpune.edu.in a &#8270; Birwadkar Prajwal a Joshi Sagar a Verma Yash a Sindgi Rutuja b a Symbiosis Institute of Technology, Pune Campus, Symbiosis International (Deemed University), Pune, India b Symbiosis Medical College for Women &amp; Symbiosis University Hospital and Research Centre, Symbiosis International (Deemed University), Pune, India &#8270; Corresponding author. archana.chaudhari@sitpune.edu.in 12 2025 13 11 2025 15 492015 103721 14 6 2025 12 11 2025 13 11 2025 08 12 2025 09 12 2025 &#169; 2025 The Authors. Published by Elsevier B.V. 2025 https://creativecommons.org/licenses/by-nc-nd/4.0/ This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/). The Radiographs are essential in clinical dentistry as they provide information that is invisible during an oral inspection. These images, however suffer from excess noise, low resolution, and poor contrast which impacts diagnosis accuracy. This study presents a two&#8209;stage pipeline combining Enhanced Super&#8209;Resolution GAN (ESRGAN) for radiograph enhancement followed by YOLOv8 for multi&#8209;class dental anomaly detection. The proposed method involves the application of ESRGAN (Enhanced super-resolution generative adversarial network with adaptive dual perceptual loss) that improves image detail and sharpen resolution. A customized YOLOv8 object detection model which is trained to detect object and classify into six important dental conditions. The classification is Caries, Crown, Root Canal Treated (RCT), Restoration, Normal, and Badly Decayed teeth. The ESRGAN-enhanced images demonstrated high visual fidelity, achieving a Peak Signal-to-Noise Ratio (PSNR) of 28.7 dB and a Structural Similarity Index (SSIM) of 0.91. The proposed YOLOv8 model analyzes the images after being enhanced by ESRGAN. The YOLOv8 model was evaluated on 100 test images and achieved an overall mean Average Precision (mAP@0.5) of 56.9 % and mAP@0.5:0.95 of 41.6 %. The proposed model achieved Sensitivity (Recall) 0.942 and Specificity 0.919 for Crown detection. Detection of Caries and Badly Decayed teeth remained challenging, with lower sensitivity scores of 0.174 and 0.355, respectively. Specificity across classes ranged from 0.361 (RCT) to 0.887 (Caries), indicating variable false positive rates. The proposed pipeline demonstrated clinical potential by improving subtle structural visibility and supporting automated dental assessment. Future work will explore class&#8209;specific augmentation and explainability tools to increase clinical utility. ESRGAN significantly improved the resolution and clarity of dental X-rays, enabling better visualization of fine details for accurate diagnosis. YOLOv8 effectively identified six dental conditions, achieving high accuracy for distinct classes like crowns and restorations Graphical abstract Image, graphical abstract Keywords Dental X&#8209;ray Object Detection YOLOv8, deep learning model, Periapical, object classification, ESRGAN pmc-status-qastatus 0 pmc-status-live yes pmc-status-embargo no pmc-status-released yes pmc-prop-open-access yes pmc-prop-olf no pmc-prop-manuscript no pmc-prop-legally-suppressed no pmc-prop-has-pdf yes pmc-prop-has-supplement no pmc-prop-pdf-only no pmc-prop-suppress-copyright no pmc-prop-is-real-version no pmc-prop-is-scanned-article no pmc-prop-preprint no pmc-prop-in-epmc yes Specifications table The table provides general information on your method. Subject area Medicine and Dentistry More specific subject area Deep Learning for Automated Diagnosis in Dental Radiography Name of your method Periapical dental X-ray image classification using YOLOv8 Name and reference of original method None Resource availability https://github.com/prajwalBirwadkar/Dental-X-ray-Anomaly-Detection-System Background In recent years, the sector of dental radiograph analysis has integrated deep learning and machine learning technologies, which has greatly enhanced the caries detection. Previously, the diagnosis of dental X-rays relied extensively on the interpretation of clinicians, which was prone to manual bias and inter- observer differences, no matter how reliable it was [ 1 ]. Attempts at computer-aided diagnosis (CAD) were focused on using Feature Extraction and Rule-based Classifiers for detection of Dental Caries to reduce biases within systems. They often faced challenges like worsened sensitivity to changes in the quality of images, the patient's anatomy, and poor generalizability [ 2 ]. The automation of feature extraction and comprehensive learning in dental image understanding through deep learning, and more specifically CNNs, have intensified its application. As per literature in dental imaging various techniques like CNNs for caries classification, tooth segmentation, and even periodontitis detection from panoramic and periapical X-ray images has applied. Most recently, specific dental conditions have been localized with object detection techniques using models like Faster R- CNN and YOLO. However, unprocessed, low- grade X-ray images, which hinders the models&#8217; capacity to identify subtle yet clinically significant details [ 3 ]. GAN-based image enhancement Generative Adversarial Networks (GANs) have brought transformative capabilities to image generation and enhancement. In medical imaging, GANs have been successfully applied for tasks such as denoising, modality translation (e.g., from MRI to CT), and super-resolution reconstruction, offering significant improvements in the quality of low-resolution scans [ 4 ]. Among GAN variants, the Enhanced Super-Resolution GAN (ESRGAN) has emerged as a leading method for image upscaling and enhancement. ESRGAN builds upon the original SRGAN by incorporating Residual-in-Residual Dense Blocks (RRDB) and a more stable relativistic average discriminator, resulting in images with finer details, sharper edges, and fewer artifacts&#8212;qualities essential for medical diagnostics. Unlike traditional interpolation-based enhancement methods, which can blur or distort features, ESRGAN learns to preserve high-frequency textures and anatomical edges [ 5 ]. ESRGAN provides significant opportunities within dental radiography. Dental X-ray images are often marred with low resolution and poor contrast, restricting the diagnosis of tiny carious lesions or periapical infections [ 6 ]. Despite the exploration of ESRGAN in MRI, CT, and even retinal imaging, there is a noticeable gap in its use for dental radiographs. This research seeks to enhance the visual integrity of object detection on periapical X-rays by first using ESRGAN for preprocessing towards better usability in detecting early-stage carious lesions [ 7 ]. YOLO for medical object detection Due to its real-time image processing capabilities in parallel with a high level of accuracy, the YOLO (You Only Look Once) family of algorithms has become very popular in numerous fields of computer vision. This is especially useful in medical imaging because of the intricacy of medical scans and the numerous components that need to be considered. With the COBRA framework, versions of YOLO such as YOLOv3 and YOLOv4 have been implemented for extensive image analysis through automated tumor detection in mammograms, polyp localization during endoscopies, and fracture identification in radiographs [ 8 ,33]. In the dental field, YOLO has demonstrated potential in the detection of dental decay, prosthetic restorations, and periodontal bone loss [ 9 ]. However, limited datasets and unprocessed X-rays, which may hinder the model&#8217;s ability to detect subtle lesions. The release of YOLOv8 introduces improvements in both architectural efficiency and training dynamics [ 6 ], making it a promising candidate for dental applications, particularly when combined with image enhancement techniques. While models like ResNet18, EfficientNet, and DenseNet121 are primarily designed for image classification, YOLOv8 is a one-stage object detector that performs both localization and classification in a single forward pass. This makes it inherently more suitable for tasks like dental pathology detection, where identifying the exact location of anomalies is crucial. Research gap in existing literature Despite the progress in deep learning for medical imaging, there remains a significant gap in targeting image enhancement and object detection in a unified diagnostic framework, especially in dental radiography. Most existing studies either focus solely on enhancing images with super- resolution techniques or apply object detection to raw, unprocessed images. This separation limits the diagnostic potential of AI systems. Furthermore, although ESRGAN has proven effective in enhancing radiological images in fields like MRI and retinal imaging, its use in dental imaging has not been extensively explored. Similarly, while YOLO-based models have been evaluated in various healthcare settings, few studies have systematically assessed their performance on enhanced dental images for multi-class disease detection. This study addresses this gap by proposing a two-stage pipeline that enhances dental X-rays and then detects multiple dental conditions, providing both technical innovation and practical relevance in the field of dental diagnostics as depict in Table 1 . Table 1 Comparative analysis of Dental X&#8209;ray detection studies. Table 1: Sr. No. Research Topic Methodologies Gaps Identified Results Achieved Future Scope Dataset Used and Citation 1 Advanced AI&#8209;driven detection of interproximal caries in bitewing radiographs using YOLOv8 YOLOv8 on 1506 expert&#8209;annotated bitewing images Limited generalizability across different machines Precision: 96.03 % (enamel), 80.06 % (dentin); F1: 82.22 % Validate across multiple clinics &amp; imaging systems 1506 bitewing images [ 10 ] 2 Dental caries classification using YOLOv8 Customized YOLOv8 with pixel&#8209;level augmentations Need for broader patient demographics &amp; cross&#8209;site validation mAP: 91.8 %; F1: 92.0 %; Recall: 92.6 % Incorporate more varied datasets (age, ethnicity) Karachi periapical radiographs (5 classes) [ 11 ] 3 YOLO&#8209;DentSeg: Real&#8209;time detection &amp; segmentation of oral diseases YOLOv8n&#8209;seg + BiFPN &amp; EMCA attention Processing large panoramic images in real time +3 % mAP; dice &#8593;10&#8211;15 %; low latency Deploy on edge devices in low&#8209;resource clinics 2720 annotated panoramic X&#8209;rays [ 12 ] 4 AI&#8209;driven dental radiography analysis with YOLOv8 &amp; Eigen&#8209;CAM YOLOv8m + Eigen&#8209;CAM visualization Explainability &amp; clinician trust Accuracy: 90 %; Precision: 93.2 %; F1: 95.4 % Interactive heat&#8209;map interfaces for clinicians Expert&#8209;annotated bitewings [ 13 ] 5 YOLOrtho: Unified teeth enumeration &amp; disease detection YOLOv8 + CoordConv + post&#8209;processing No end&#8209;to&#8209;end for enumeration + detection Outperformed diffusion&#8209;based baselines Integrate with dental EHR systems Dentex Challenge 2023 &amp; Tufts dataset [ 14 ] 6 Instance segmentation &amp; teeth classification in panoramics BB&#8209;UNet (U&#8209;Net + YOLOv8) Simultaneous segmentation &amp; classification mAP &#8593;3 %; dice &#8593;10&#8211;15 % Extend to CBCT &amp; other modalities 425 UFBA&#8209;UESC X&#8209;rays [ 15 ] 7 DENTEX: Abnormal tooth detection &amp; diagnosis benchmark Multi&#8209;label YOLOv8 with hierarchical annotations Scarcity of diverse annotated data Comprehensive benchmark established Stimulate robust model development DENTEX labels (quadrant, enumeration, diagnosis) [ 16 ] 8 ESRGAN: Enhanced super&#8209;resolution for dental imaging ESRGAN w/ residual&#8209;in&#8209;residual dense blocks + perceptual loss Occasional hallucinated artifacts More realistic textures vs. SRGAN Preprocess low&#8209;dose X&#8209;rays General SR datasets (transfer to dental) [ 17 ] 9 Curated dental X&#8209;ray object detection dataset Roboflow with 4 classes Limited to 4 classes; lacks rare conditions Public benchmarks for evaluation Add rare pathologies, imaging conditions 1075 X&#8209;rays (4 classes) [ 18 ] 10 Clean baseline dental X&#8209;ray dataset by Rabie Same dataset; no augmentation/preprocessing No preprocessing &amp; augmentation Clean baseline provided Apply augmentation &amp; normalization 1075 X&#8209;rays (70/20/10 split) [ 19 ] 11 Deep caries detection using deep learning: From dataset acquisition to detection Various CNN architectures Dataset acquisition &amp; annotation cost Demonstrated viability of DL methods Standardize public datasets &#8211; (not specified) [ 20 ] 12 Detection of caries under fixed prostheses by analyzing digital panoramic radiographs with deep learning methods AI on panoramic radiographs Hidden caries beneath prostheses AI identified sub&#8209;prosthetic lesions Combine tactile &amp; radiographic data &#8211; (not specified) [ 21 ] 13 Caries detection with tooth surface segmentation U&#8209;Net + ResNet&#8209;18 + Faster R&#8209;CNN Lighting &amp; image quality variability Acc: 0.813; AUC: 0.837 Multimodal fusion of photos &amp; X&#8209;rays 2348 intraoral photos [ 22 ] 14 Object detection on dental X&#8209;rays using deep learning Mask R&#8209;CNN + contrast enhancement Low contrast &amp; anatomical variability Effective detection of teeth &amp; restorations Combine Mask R&#8209;CNN &amp; YOLOv8 &#8211; (not specified) [ 23 ] 15 Enhancing caries detection in bitewing radiographs YOLOv7 w/ varying IoU &amp; image sizes Impact of hyperparameters YOLOv7 &gt; YOLOv3; precision &amp; F1 &#8593; Automated hyperparameter tuning 2575 bitewing images (7 classes) [ 24 ] 16 AI&#8209;assisted detection of multiple caries types YOLOv8 classification of various caries Need for fine&#8209;grained annotations Accuracy: 97.7 %; Precision: 93.2 %; F1: 95.4 % Real&#8209;time smartphone deployment Bitewing radiographs [ 25 ] 17 YOLO&#8209;v5 for detection &amp; numbering in mixed dentition YOLOv5 on 3854 labelled PRs Few mixed&#8209;dentition studies Sensitivity &amp; precision &#8776;0.99; mAP@0.5: 0.98 Extend to other pediatric groups 3854 mixed&#8209;dentition PRs [ 26 ] 18 Decayed&#8209;missing&#8209;filled teeth detection: YOLOv5 vs. YOLOv8 YOLOv5l w/ varied learning rates Need for early stopping &amp; generalizability Precision: 0.97; Recall: 0.858; mAP: 0.904 Early&#8209;stopping &amp; robustness techniques &#8211; (not specified) [ 27 ] 19 Deep learning for early dental caries detection in bitewing radiographs CNN&#8209;based YOLO pipeline Limited clinical validation High accuracy &amp; speed Integrate with clinical workflows &#8211; (not specified) [ 28 ] 20 A deep learning approach to automatic teeth detection and numbering based on object detection in dental periapical films YOLO&#8209;based object detection Focus on permanent dentition only mAP: 0.98 Extend to mixed &amp; primary dentitions &#8211; (not specified) [ 29 ] Method details The use of dental x rays has greatly contributed in the field of dentistry. X-ray photography is of various types. Periapical X rays are one of the most helpful ones. They show complete images of teeth fully alongside the bone structure supporting it. Some essential problems of dental care, such as diagnosing root canal therapy, dental caries, or assessing surrounding bone in relation to the tooth can be dealt by these X-ray images. Most modern hospitals nowadays seem to widely endorse the use of digital radiography, as commonly touted to offer much faster scanning time, ease of storage, and better compatibility with image editing devices and programs. Even with these improvements, a big challenge for assets, such as images, still exists&#8212;many images remain low quality. Outdated machinery or unfavorable settings frequently result in poor resolution images that are rich in contrast and noise, which complicates identifying crucial diagnostic features. These compromises in image quality may result in incorrect analyses. Additionally, human interpretation is highly flexible and subjective, especially when the dental problem is nuanced or overlapping. In more commercially oriented, high-traffic practices, the sheer volume of data makes it increasingly difficult to properly evaluate each image individually. This emphasizes the necessity for software that elevates and maintains image quality while effectively identifying underlying structural abnormalities, in turn, aiding the clinicians in making informed decisions and minimizing errors. In medical diagnostics, acquiring images of exceptional clarity is critical for providing accurate assessments. In dental radiographs, even the slightest changes in the teeth or the surrounding bone could indicate the presence of a cavity or the complications following a root canal treatment. Suboptimal images could overlook such subtle changes and result in a misdiagnosis. Enhancing image quality is important not only from the perspective of a practicing dentist but also for the AI systems that are programmed to analyze the images. The clearer the images, the more accurately the automated systems will be able to recognize and determine the existing abnormalities, particularly in cases where sophisticated imaging tools are not accessible. This paper implements image enhancement and object recognition techniques to automate diagnosis in a two-step approach. The first step applies ESRGAN, or Enhanced Super-Resolution Generative Adversarial Networks, which is a deep learning model specializing in the enhancement of x-ray images. The algorithm reconstructs high-resolution (HR) images by employing multi-scale techniques, achieving higher clarity and trustworthiness than traditional methods. The second part employs the state-of-the-art real-time object detection model, YOLOv8, to detect and classify the dental conditions in the enhanced images. The model is capable of concurrent detection of numerous issues, including cavities, root canal treatments, and severely decayed teeth. It is expected that combining ESRGAN with image detection capabilities of YOLOv8 will contribute to systems that allow for more accurate diagnoses, minimizing errors, and improving treatment planning for dentists. In this study, author designed a two-stage pipeline that begins with coarse image-level classification and progresses to fine-grained object detection. The complete workflow is illustrated in Fig. 1 . Fig. 1 Proposed methodology workflow. Fig 1: Data acquisition and annotation This study employed a publicly available dataset named Dental Periapical X-rays [ 30 ] on Kaggle. It is a dataset specially designed to assist research in detection of dental disease and consists of high-resolution periapical X-rays and COCO format annotations. All images within the dataset are retained in JPEG (.jpg) format at a standard resolution of 640 &#215; 640 pixels. This is a standard image resolution that facilitates the procedures of data preprocessing and model training with the assurance that critical diagnostic details regarding the teeth and bone are retained. All images generally contain one or more teeth with focus on the periapical area, hence covering both the bone and the teeth. The dataset contains 1729 training images, 55 test images, and 100 validation images [ 30 ]. The information comes with COCO (Common Objects in Context) JSON annotations, which is a common format used for object detection tasks. Each JSON file includes data relevant to image ID, filename, image dimensions, and the number of detected cavities along with their locations in the form of bounding boxes [x, y, width, height]. These annotations are important for object detection model training like YOLOv8, which needs good-quality data to detect the defective areas correctly. The data set consists of labels for six different classes of oral conditions: Caries, referring to the early stages of tooth decay; Crown, referring to artificial coverings intended for teeth and also referred to as crowns; Root Canal Treated (RCT), referring to treated teeth for root canal; Restoration, referring to tooth restoration through filling or otherwise; Normal, referring to teeth with no observable problems; and Badly Decayed, a label for teeth that are in a severe state of decay. Based on a cursory glance, the dataset seems to show a reasonably balanced condition distribution, although some categories such as &#8220;Caries&#8221; and &#8220;Badly Decayed&#8221; are more prevalent than &#8220;Normal&#8221; or &#8220;Crown.&#8221; To address this imbalance, this research plan to use techniques like weighted sampling and data augmentation during model training. To ensure that the annotations are accurate and reliable, we manually checked a subset of the images by overlaying the bounding boxes on the images. Fig. 1 shows examples of the ESRGAN-enhanced images next to their original counterparts, clearly highlighting dental conditions like cavities and metallic crowns. This review confirms that the dataset is well- suited for the tasks of image enhancement and object detection, providing a solid base for our diagnostic pipeline. Super-Resolution enhancement To address the low contrast and blurriness in many radiographs, this research employed Enhanced Super- Resolution GAN (ESRGAN) [ 17 ]. ESRGAN uses perceptual loss and residual-in-residual dense blocks to enhance the image quality, particularly improving enamel boundaries and interproximal regions. The ESRGAN output images are standardized to a resolution of 640 &#215; 640 pixels, which aligns with YOLOv8&#8217;s default input size. These enhanced images were used in all downstream classification and detection experiments as shown in Fig. 2 . Bounding box annotations are originally created on the low-resolution images. During ESRGAN enhancement, the spatial dimensions are preserved, and the bounding boxes are scaled proportionally to match the upsampled resolution. This is achieved by applying a fixed scaling factor to the coordinates, ensuring that the relative positions and sizes of the boxes remain accurate post-enhancement. Fig. 2 ESRGAN on dental dataset a) Original image b) enhanced images. Fig 2: The proposed method used the Residual-in-Residual Dense Block (RRDB) based ESRGAN generator with 23 RRDB and 64 feature maps, trained from a publicly available ESRGAN pre-trained checkpoint. Training used paired HR/LR patches (patch size 128 &#215; 128), Adam optimizer (&#946;1=0.9, &#946;2=0.99), L1 pixel loss + perceptual loss (VGG19 feature loss) and a GAN loss (vanilla). Learning rate started at 1e-4 with a MultiStepLR schedule; total training iterations = 20,000 (we fine-tuned from the supplied pre-trained model). At inference we used tiling with tile size 512. Preliminary classification experiments This research initially treated the problem as a single-label classification task, where each radiograph was assigned one class. We trained four convolutional neural networks (CNNs) on the ESRGAN- enhanced images ResNet-18 [34], EfficientNet-B0, DenseNet-121, ConvNeXt-Tiny. Training was conducted using PyTorch v2.1.0 [34] for 30 epochs with batch size 16, incorporating basic augmentations such as random flips and rotations. While the models showed moderate performance, their accuracy was hindered by the presence of multi-label instances (e.g., radiographs showing both a crown and an RCT), which violated the single-label assumption. Object detection with YOLOv8 We then reformulated the problem as object detection to handle multiple findings per image. The Ultralytics v8.1.0 YOLOv8 framework [ 6 ] was adopted, with the following steps: Data Preparation: Enhanced images and YOLO-formatted labels were placed into the images/{train,val,test} and corresponding /labels folders. yaml_path = \"/content/DentalXrayDetection-1/data.yaml\" yaml_content = \"\"\" train: /content/DentalXrayDetection-1/train/images val: /content/DentalXrayDetection-1/valid/images test: /content/DentalXrayDetection-1/test/images nc: 6 names: ['Badly Decayed', 'Caries', 'Crown', 'Normal', 'RCT', 'Restoration'] \"\"\" with open(yaml_path, \"w\") as f: f.write(yaml_content) Model Configuration: We used the yolov8n.pt backbone pre-trained on MS COCO [ 1 ], adapting the head for six custom classes. The input resolution was set to 640 &#215; 640 pixels. Training: The model was trained for 50 epochs using SGD optimizer (learning rate = 0.01, momentum = 0.937), mosaic augmentation, and early stopping based on validation mAP@0.5 . model = YOLO(\"yolov8n.pt\") results = model.train( data=\"/content/DentalXrayDetection-1/data.yaml\", epochs=30, imgsz=640, batch=16 ) Evaluation: Evaluation metrics included mAP@0.5, mAP@0.5:0.95, precision, and recall for each class as shown in Table 2 . Table 2 YOLOv8 performance on the test set. Table 2: Class Images Instances Precision Recall mAP@0.5 mAP@0.5:0.95 All 100 157 0.482 0.595 0.569 0.416 Badly Decayed 23 31 0.538 0.355 0.434 0.192 Caries 18 23 0.315 0.174 0.174 0.088 Crown 20 26 0.803 0.942 0.952 0.870 Normal 21 26 0.498 0.538 0.591 0.398 RCT 13 18 0.215 0.833 0.496 0.317 Restoration 26 33 0.526 0.727 0.767 0.633 Finally, this research integrated the best-performing checkpoint into a web-based interface that allows users to upload X-rays and visualize predictions directly on the image. The pseudocode for implementation is as follows: Method validation Training was performed on a single NVIDIA RTX 3090 GPU (24 GB VRAM), Intel i9 CPU, and 64 GB RAM. ESRGAN fine-tuning time was approx. 6.5 h and YOLOv8 training time was 2.8 h (30 epochs, batch size 16, imgesize 640). Classification Performance Fig. 3 illustrates the accuracy performance of six different deep learning models. Among them, YOLOv8 achieves the highest accuracy at 65 %, closely followed by DenseNet-121 with 64 %. ConvNext-Tiny and ResNet-18 show moderate performance, with accuracies of 59 % and 58 % respectively. EfficientNet-B0 performs slightly lower at 50 %. Faster R-CNN has the lowest accuracy, significantly trailing behind the others at just 17.56 %. Faster R-CNN first proposes regions and then classifies them. This makes less efficient for small, subtle features like dental caries. All models show improved accuracy with ESRGAN, confirming its effectiveness in enhancing diagnostic features in dental radiographs. DenseNet121 benefits the most, increasing from 58 % to 64 %. YOLOv8 and ConvNeXt also show notable improvements, reinforcing their adaptability to enhanced image inputs. This comparison highlights YOLOv8 and DenseNet-121 as the most effective models in this context, while Faster R-CNN appears to be the least suitable based on accuracy alone. Misclassification was common when multiple dental conditions appeared in a single image. Fig. 3 Accuracy of each model with and without ESRGAN enhancement for dental X-ray analysis. Fig 3: As the YOLOv8 achieved highest accuracy among another model. Table 2 shows the detection metrics of YOLOv8 performance on test set. At inference, predictions were filtered using a confidence score threshold of 0.25 and Non-Maximum Suppression (NMS) IoU threshold of 0.5, as per YOLOv8 default settings. Crown detection was especially strong, with mAP@0.5 reaching 95.2 %. This may be due to the distinct high-contrast nature of metallic crowns. Caries detection, however, was the weakest, likely due to their subtle radiographic appearance and class imbalance. for medical applications, sensitivity and specificity are particularly helpful. Sensitivity (Recall) means correctly identify positive cases (e.g., actual caries) and Specificity means to correctly identify negative cases [ 8 ]. Table 3 depict the sensitivity (recall) and specificity for all each class. Crown detection is excellent across all metrics. Caries and Badly Decayed show low sensitivity, indicating missed detections. RCT has high sensitivity but very low specificity, suggesting over-detection and many false positives. Table 3 sensitivity (recall) and specificity for all each class. Table 3: Class TP FN FP TN Sensitivity (Recall) Specificity Badly Decayed 11.01 19.99 9.49 59.51 0.355 0.862 Caries 4.00 19.00 8.73 68.27 0.174 0.887 Crown 24.49 1.51 6.01 68.00 0.942 0.919 Normal 13.99 12.01 14.23 59.77 0.538 0.808 RCT 14.99 3.01 52.39 29.61 0.833 0.361 Restoration 23.99 9.01 21.76 45.24 0.727 0.675 Fig. 4 shows visual results on test samples for qualitative assessment. Crowns and restorations were predicted with high confidence, while caries and badly decayed teeth were more challenging. The ESRGAN preprocessing contributed significantly to bounding box tightness and clarity of features. Fig. 4 Classification of periapical dental X-ray by YOLOv8. Fig 4: Limitations The transition from image-level classification to object-level detection enabled more accurate modeling of the inherent multi-pathology characteristics of dental X-rays. The strong performance on well-demarcated classes like Crown and Restoration is promising. However, it struggled to effectively augment and detect more subtle lesion classes like Caries, even when synthetic data was employed for training [ 10 ]. Additionally, the current system lacks integrated explainability mechanisms. Incorporating attention-based visualization techniques such as Eigen-CAM [ 13 ] could enhance interpretability and foster greater clinical trust. Conclusion This research presented a two&#8209;stage approach to automated dental radiograph analysis, beginning with ESRGAN-based image enhancement and progressing from coarse image&#8209;level classification to fine&#8209;grained object detection with YOLOv8. The ESRGAN preprocessing step significantly improved the clarity of subtle anatomical features, which in turn boosted the tightness and accuracy of detected bounding boxes. Our initial classification experiments highlighted the limitations of single&#8209;label CNN models on multi&#8209;pathology images, whereas the YOLOv8 detector achieved a robust mAP@0.5 of 56.9\\ % and outstanding localization of high&#8209;contrast classes such as crowns and restorations. Although detection of early caries remains challenging due to their subtle radiographic appearance and dataset imbalance, the pipeline lays a solid foundation for targeted augmentation and segmentation strategies in future work. Overall, this study demonstrates that combining super&#8209;resolution enhancement with state&#8209;of&#8209;the&#8209;art object detection can effectively address the complex, multi&#8209;label nature of dental X&#8209;rays, paving the way for more reliable, clinically useful information. Related research article None. Ethics statements In this work data collected from online platforms, confirming that participant data has been fully anonymized. CRediT authorship contribution statement Archana Y. Chaudhari: Writing &#8211; original draft, Writing &#8211; review &amp; editing, Funding acquisition. Prajwal Birwadkar: Conceptualization, Methodology, Visualization. Sagar Joshi: Data curation. Yash Verma: Data curation. Rutuja Sindgi: Data curation, Project administration. Declaration of competing interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. References 1 Pinchi V. Norelli G.A. Caputi F. Fassina G. Pradella F. Vincenti C. Dental identification by comparison of antemortem and postmortem dental radiographs: influence of operator qualifications and cognitive bias Forensic. Sci. Int. 222 1&#8211;3 2012 252 255 22770720 10.1016/j.forsciint.2012.06.015 2 Whaites D. Drage N. Essentials of Dental Radiography and Radiology 2013 Elsevier Health Sciences 5th ed. 3 Scarfe A.M. Farman C.M. What is Cone-Beam CT and how does it work? Dental. Clin. 52 4 2008 707 730 10.1016/j.cden.2008.05.005 18805225 4 Ledig C. Theis L. Husz&#225;r F. Photo-realistic single image super-resolution using a generative adversarial network Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR) 2017 105 114 5 Wang X. Yu K. Dong C. ESRGAN: enhanced super-resolution generative adversarial networks Proc. ECCV Workshops 2018 6 Satpathy A. Ranjan R. Priyadarsini S. Gupta S. Mathur P. Mishra M. Diagnostic imaging techniques in oral diseases Medical Imaging Methods: Recent Trends 2019 Springer Singapore Singapore 59 95 7 Ben-Cohen A. Diamant I. Klang E. Virtual PET images from CT data using deep convolutional networks: initial results Proc. Med. Image Comput. Comput.-Assist. Interv. (MICCAI) 2017 49 57 8 Stookey G.K. Jackson R.D. Zandona A.G. Analoui M. Dental caries diagnosis Dent. Clin. North Am. 43 4 1999 Oct 1 665 677 10553249 9 Muramatsu K. Hayashi Y. Katsumata A. Detection of dental caries in X-ray images using deep learning Sensors 20 12 2020 1 14 10 Bayati M. Savareh B.A. Ahmadinejad H. Mosavat F. Advanced AI-driven detection of interproximal caries in bitewing radiographs using YOLOv8 Sci. Rep. 15 1 2025 4641 39920198 10.1038/s41598-024-84737-x PMC11806056 11 Uddin S.M.Z. Aslam M.I. Moinuddin M. Dental caries classification using YOLOv8 J. Popul. Ther. Clin. Pharmacol. 31 6 2024 12 Hua Y. Chen R. Qin H. YOLO-DentSeg: a lightweight real-time model for accurate detection and segmentation of oral diseases in panoramic radiographs Electronics 14 4 2025 805 13 Aldanma &#214;. Atarda&#287; H.B. Y&#252;zge&#231; E. &#214;zyurt F. AI-driven dental radiography analysis: enhancing diagnosis and education through YOLOv8 and Eigen-CAM Trans. Sci. 41 6 2024 14 Mei, S., Ma, C., Shen, F. and Wu, H., 2023. YOLOrtho&#8211;A unified framework for teeth enumeration and dental disease detection. 15 Budagam, D., Kumar, A., Ghosh, S., Shrivastav, A., Imanbayev, A.Z., Akhmetov, I.R., Kaplun, D., Antonov, S., Rychenkov, A., Cyganov, G. and Sinitca, A., 2024. Instance segmentation and teeth classification in panoramic X-rays. 16 Hamamci, I.E., Er, S., Simsar, E., Yuksel, A.E., Gultekin, S., Ozdemir, S.D., Yang, K., Li, H.B., Pati, S., Stadlinger, B. and Mehl, A., 2023. Dentex: an abnormal tooth detection with dental enumeration and diagnosis benchmark for panoramic x-rays. 17 Wang X. Yu K. Wu S. Gu J. Liu Y. Dong C. Qiao Y. Change Loy C. Esrgan: enhanced super-resolution generative adversarial networks Proceedings of the European conference on computer vision (ECCV) workshops 2018 0 -0 18 Projects Gozdes Dental X-ray 1imfs 2023 Roboflow Universe 19 Rabie M. Dental X-ray 1imfs-2ykrj 2023 Roboflow Universe 20 Kaur A. Deep caries detection using deep learning: from dataset acquisition to detection Clin. Oral Investig. 28 12 2024 677 10.1007/s00784-024-06068-5 39621193 21 Ayhan B. Ayan E. Ats&#252; S. Detection of dental caries under fixed prostheses by analyzing digital panoramic radiographs with deep learning methods BMC Oral Health 25 1 2025 216 39930440 10.1186/s12903-025-05577-3 PMC11809006 22 Park E.Y. Cho H. Kang S. Jeong S. Kim E.-K. Caries detection with tooth surface segmentation on intraoral photographic images using deep learning BMC Oral Health 22 2022 2589 10.1186/s12903-022-02589-1 PMC9730679 36476359 23 Suryani D. Shoumi M.N. Wakhidah R. Object detection on dental X-ray images using deep learning method IOP Conf. Ser. Mater. Sci. Eng. 1073 1 2021 012058 24 Wannakamon P. Enhancing caries detection in bitewing radiographs using YOLOv7 J. Digit. Imaging 36 6 2023 2635 2647 37640971 10.1007/s10278-023-00871-4 PMC10584768 25 Karaku&#351; R. &#214;zi&#231; M.&#220;. Tassoker M. AI-assisted detection of interproximal, occlusal, and secondary caries on bite-wing radiographs: a single-shot deep learning approach J. Imaging Inform. Med. 37 6 2024 3146 3159 38743125 10.1007/s10278-024-01113-x PMC11612078 26 Beser B. YOLO-V5 based deep learning approach for tooth detection and segmentation on pediatric panoramic radiographs in mixed dentition BMC Med. Imaging 24 1 2024 224 39198729 10.1186/s12880-024-01410-5 PMC11351085 27 Fitria M. The deep learning model for decayed-missing-filled teeth detection: a comparison between YOLOv5 and YOLOv8 Jordan. J. Comput. Inf. Technol. 10 3 2024 335 349 28 Lee S. Deep learning for early dental caries detection in bitewing radiographs Sci. Rep. 11 2021 16807 10.1038/s41598-021-96368-7 PMC8376948 34413414 29 Chen H. A deep learning approach to automatic teeth detection and numbering based on object detection in dental periapical films Sci. Rep. 9 2019 3840 30846758 10.1038/s41598-019-40414-y PMC6405755 30 Aglan N. Dental periapical X-rays dataset Kaggle 2022 Available at https://www.kaggle.com/datasets/nadaaglan/dental-periapical-x-ray Data availability Data will be made available on request. Acknowledgments This research did not receive any specific grant from funding agencies in the public, commercial, or not-for-profit sectors."
}