{
  "pmcid": "PMC12657348",
  "source": "PMC",
  "download_date": "2025-12-09T16:11:30.639643",
  "metadata": {
    "journal_title": "Frontiers in Cardiovascular Medicine",
    "journal_nlm_ta": "Front Cardiovasc Med",
    "journal_iso_abbrev": "Front Cardiovasc Med",
    "journal": "Frontiers in Cardiovascular Medicine",
    "pmcid": "PMC12657348",
    "pmid": "41322494",
    "doi": "10.3389/fcvm.2025.1602780",
    "title": "Optimized aortic root segmentation during transcatheter aortic valve implantation",
    "authors": [
      "Laptev Nikita V.",
      "Gerget Olga M.",
      "Belova Julia K.",
      "Vasilchenko Evgeny E.",
      "Chernyavskiy Mikhail A.",
      "Danilov Viacheslav V."
    ],
    "abstract": "Transcatheter aortic valve implantation (TAVI) is a highly effective treatment for patients with severe aortic stenosis. Accurate valve positioning is critical for successful TAVI, and highly accurate real-time visualization—with minimal use of contrast—is especially important for patients with chronic kidney disease. Under fluoroscopic conditions, which often suffer from low contrast, high noise and artifacts, automatic segmentation of anatomical structures using convolutional neural networks (CNNs) can significantly improve the accuracy of valve positioning. This paper presents a comparative analysis of various CNN architectures for automatic aortic root segmentation on angiographic images, with the aim of optimizing the TAVI process. The experimental evaluation included models such as FPN, U-Net++, DeepLabV3+, LinkNet, MA-Net, and PSPNet, all trained and tested with optimally tuned hyperparameters. During training dynamics, DeepLabV3+ and U-Net++ showed stable convergence with median Dice scores around 0.88. However, when evaluated at the patient level, MA-Net and PSPNet outperformed all other models, achieving Dice coefficients of 0.942 and 0.936, and an average symmetric surface distance of 4.1 mm. The findings underscore the potential of incorporating automatic segmentation methods into decision-support systems for cardiac surgery—reducing contrast agent use, minimizing surgical risks, and improving valve positioning accuracy. Future work will focus on expanding the dataset, exploring additional architectures, and adapting the models for real-time application.",
    "keywords": [
      "automatic segmentation",
      "aortic root",
      "angiographic images",
      "TAVI",
      "convolutional neural networks"
    ]
  },
  "xml": "<?xml version=\"1.0\"  ?><!DOCTYPE pmc-articleset PUBLIC \"-//NLM//DTD ARTICLE SET 2.0//EN\" \"https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd\"><pmc-articleset><article xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:ali=\"http://www.niso.org/schemas/ali/1.0/\" xml:lang=\"en\" article-type=\"brief-report\" dtd-version=\"1.4\"><processing-meta base-tagset=\"archiving\" mathml-version=\"3.0\" table-model=\"xhtml\" tagset-family=\"jats\"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type=\"nlm-ta\">Front Cardiovasc Med</journal-id><journal-id journal-id-type=\"iso-abbrev\">Front Cardiovasc Med</journal-id><journal-id journal-id-type=\"pmc-domain-id\">2863</journal-id><journal-id journal-id-type=\"pmc-domain\">fcvm</journal-id><journal-id journal-id-type=\"publisher-id\">Front. Cardiovasc. Med.</journal-id><journal-title-group><journal-title>Frontiers in Cardiovascular Medicine</journal-title></journal-title-group><issn pub-type=\"epub\">2297-055X</issn><publisher><publisher-name>Frontiers Media SA</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type=\"pmcid\">PMC12657348</article-id><article-id pub-id-type=\"pmcid-ver\">PMC12657348.1</article-id><article-id pub-id-type=\"pmcaid\">12657348</article-id><article-id pub-id-type=\"pmcaiid\">12657348</article-id><article-id pub-id-type=\"pmid\">41322494</article-id><article-id pub-id-type=\"doi\">10.3389/fcvm.2025.1602780</article-id><article-version-alternatives><article-version article-version-type=\"pmc-version\">1</article-version><article-version article-version-type=\"Version of Record\" vocab=\"NISO-RP-8-2008\"/></article-version-alternatives><article-categories><subj-group subj-group-type=\"heading\"><subject>Brief Research Report</subject></subj-group></article-categories><title-group><article-title>Optimized aortic root segmentation during transcatheter aortic valve implantation</article-title></title-group><contrib-group><contrib contrib-type=\"author\" corresp=\"yes\"><name name-style=\"western\"><surname>Laptev</surname><given-names initials=\"NV\">Nikita V.</given-names></name><xref rid=\"aff1\" ref-type=\"aff\">\n<sup>1</sup>\n</xref><xref rid=\"cor1\" ref-type=\"corresp\">*</xref><uri xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"https://loop.frontiersin.org/people/2991741/overview\"/><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"software\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/software/\">Software</role><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"visualization\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/visualization/\">Visualization</role><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Writing &#x2013; original draft\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/writing-original-draft/\">Writing &#8211; original draft</role><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Writing &#x2013; review &amp; editing\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/writing-review-editing/\">Writing &#8211; review &amp; editing</role><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Data curation\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/data-curation/\">Data curation</role><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"investigation\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/investigation/\">Investigation</role><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"methodology\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/methodology/\">Methodology</role></contrib><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Gerget</surname><given-names initials=\"OM\">Olga M.</given-names></name><xref rid=\"aff2\" ref-type=\"aff\">\n<sup>2</sup>\n</xref><xref rid=\"cor1\" ref-type=\"corresp\">*</xref><uri xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"https://loop.frontiersin.org/people/1381314/overview\"/><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Formal analysis\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/formal-analysis/\">Formal analysis</role><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"methodology\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/methodology/\">Methodology</role><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"validation\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/validation/\">Validation</role><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Writing &#x2013; review &amp; editing\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/writing-review-editing/\">Writing &#8211; review &amp; editing</role></contrib><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Belova</surname><given-names initials=\"JK\">Julia K.</given-names></name><xref rid=\"aff3\" ref-type=\"aff\">\n<sup>3</sup>\n</xref><uri xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"https://loop.frontiersin.org/people/1402340/overview\"/><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Data curation\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/data-curation/\">Data curation</role><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Writing &#x2013; review &amp; editing\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/writing-review-editing/\">Writing &#8211; review &amp; editing</role></contrib><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Vasilchenko</surname><given-names initials=\"EE\">Evgeny E.</given-names></name><xref rid=\"aff1\" ref-type=\"aff\">\n<sup>1</sup>\n</xref><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"resources\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/resources/\">Resources</role><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Data curation\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/data-curation/\">Data curation</role><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"validation\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/validation/\">Validation</role><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Writing &#x2013; review &amp; editing\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/writing-review-editing/\">Writing &#8211; review &amp; editing</role></contrib><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Chernyavskiy</surname><given-names initials=\"MA\">Mikhail A.</given-names></name><xref rid=\"aff3\" ref-type=\"aff\">\n<sup>3</sup>\n</xref><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"resources\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/resources/\">Resources</role><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Data curation\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/data-curation/\">Data curation</role><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"validation\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/validation/\">Validation</role><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Writing &#x2013; review &amp; editing\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/writing-review-editing/\">Writing &#8211; review &amp; editing</role></contrib><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Danilov</surname><given-names initials=\"VV\">Viacheslav V.</given-names></name><xref rid=\"aff4\" ref-type=\"aff\">\n<sup>4</sup>\n</xref><xref rid=\"cor1\" ref-type=\"corresp\">*</xref><uri xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"https://loop.frontiersin.org/people/1306472/overview\"/><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"resources\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/resources/\">Resources</role><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"validation\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/validation/\">Validation</role><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Writing &#x2013; review &amp; editing\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/writing-review-editing/\">Writing &#8211; review &amp; editing</role><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"supervision\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/supervision/\">Supervision</role><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"methodology\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/methodology/\">Methodology</role></contrib></contrib-group><aff id=\"aff1\"><label>1</label><institution>Siberian State Medical University</institution>, <city>Tomsk</city>, <country country=\"ru\">Russia</country></aff><aff id=\"aff2\"><label>2</label><institution>Institute of Control Sciences of Russian Academy of Sciences</institution>, <city>Moscow</city>, <country country=\"ru\">Russia</country></aff><aff id=\"aff3\"><label>3</label><institution>Almazov National Medical Research Center</institution>, <city>Saint Petersburg</city>, <country country=\"ru\">Russia</country></aff><aff id=\"aff4\"><label>4</label><institution>Pompeu Fabra University</institution>, <city>Barcelona</city>, <country country=\"es\">Spain</country></aff><author-notes><corresp id=\"cor1\"><label>*</label><bold>Correspondence:</bold> Nikita V. Laptev <email xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"mailto:nikitalaptev77@gmail.com\">nikitalaptev77@gmail.com</email> Olga M. Gerget<email xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"mailto:olgagerget@mail.ru\">olgagerget@mail.ru</email>Viacheslav V. Danilov <email xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"mailto:viacheslav.v.danilov@gmail.com\">viacheslav.v.danilov@gmail.com</email></corresp></author-notes><pub-date publication-format=\"electronic\" date-type=\"pub\" iso-8601-date=\"2025-11-13\"><day>13</day><month>11</month><year>2025</year></pub-date><pub-date publication-format=\"electronic\" date-type=\"collection\"><year>2025</year></pub-date><volume>12</volume><issue-id pub-id-type=\"pmc-issue-id\">480653</issue-id><elocation-id>1602780</elocation-id><history><date date-type=\"received\"><day>30</day><month>3</month><year>2025</year></date><date date-type=\"accepted\"><day>14</day><month>10</month><year>2025</year></date></history><pub-history><event event-type=\"pmc-release\"><date><day>13</day><month>11</month><year>2025</year></date></event><event event-type=\"pmc-live\"><date><day>28</day><month>11</month><year>2025</year></date></event><event event-type=\"pmc-last-change\"><date iso-8601-date=\"2025-12-01 15:25:13.087\"><day>01</day><month>12</month><year>2025</year></date></event></pub-history><permissions><copyright-statement>&#169; 2025 Laptev, Gerget, Belova, Vasilchenko, Chernyavskiy and Danilov.</copyright-statement><copyright-year>2025</copyright-year><copyright-holder>Laptev, Gerget, Belova, Vasilchenko, Chernyavskiy and Danilov</copyright-holder><license><ali:license_ref specific-use=\"textmining\" content-type=\"ccbylicense\" start_date=\"2025-11-13\">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open-access article distributed under the terms of the <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://creativecommons.org/licenses/by/4.0/\">Creative Commons Attribution License (CC BY)</ext-link>. The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p></license></permissions><self-uri xmlns:xlink=\"http://www.w3.org/1999/xlink\" content-type=\"pmc-pdf\" xlink:href=\"fcvm-12-1602780.pdf\"/><abstract><p>Transcatheter aortic valve implantation (TAVI) is a highly effective treatment for patients with severe aortic stenosis. Accurate valve positioning is critical for successful TAVI, and highly accurate real-time visualization&#8212;with minimal use of contrast&#8212;is especially important for patients with chronic kidney disease. Under fluoroscopic conditions, which often suffer from low contrast, high noise and artifacts, automatic segmentation of anatomical structures using convolutional neural networks (CNNs) can significantly improve the accuracy of valve positioning. This paper presents a comparative analysis of various CNN architectures for automatic aortic root segmentation on angiographic images, with the aim of optimizing the TAVI process. The experimental evaluation included models such as FPN, U-Net++, DeepLabV3+, LinkNet, MA-Net, and PSPNet, all trained and tested with optimally tuned hyperparameters. During training dynamics, DeepLabV3+ and U-Net++ showed stable convergence with median Dice scores around 0.88. However, when evaluated at the patient level, MA-Net and PSPNet outperformed all other models, achieving Dice coefficients of 0.942 and 0.936, and an average symmetric surface distance of 4.1&#8201;mm. The findings underscore the potential of incorporating automatic segmentation methods into decision-support systems for cardiac surgery&#8212;reducing contrast agent use, minimizing surgical risks, and improving valve positioning accuracy. Future work will focus on expanding the dataset, exploring additional architectures, and adapting the models for real-time application.</p></abstract><kwd-group><kwd>automatic segmentation</kwd><kwd>aortic root</kwd><kwd>angiographic images</kwd><kwd>TAVI</kwd><kwd>convolutional neural networks</kwd></kwd-group><funding-group><funding-statement>The author(s) declare that financial support was received for the research and/or publication of this article. This study was supported by the Russian Science Foundation under Grant No. 24-19-00084, titled &#8220;Robotic System for Medical Instrument Delivery with Integrated Intelligent Information Processing.&#8221; For more information, please visit <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"https://rscf.ru/project/24-19-00084/\" ext-link-type=\"uri\">https://rscf.ru/project/24-19-00084/</ext-link>.</funding-statement></funding-group><counts><fig-count count=\"1\"/><table-count count=\"3\"/><equation-count count=\"22\"/><ref-count count=\"47\"/><page-count count=\"10\"/><word-count count=\"21321321\"/></counts><custom-meta-group><custom-meta><meta-name>pmc-status-qastatus</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>pmc-status-live</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-status-embargo</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-status-released</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-open-access</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-olf</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-manuscript</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-legally-suppressed</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-pdf</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-supplement</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-pdf-only</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-suppress-copyright</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-real-version</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-scanned-article</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-preprint</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-in-epmc</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>section-at-acceptance</meta-name><meta-value>Cardiovascular Imaging</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec sec-type=\"intro\" id=\"s1\"><label>1</label><title>Introduction</title><p>TAVI represents a vital alternative to conventional surgical aortic valve replacement, especially for patients with symptomatic severe aortic stenosis who are at high risk for open-heart surgery. The increasing prevalence of TAVI has broadened its indications (<xref rid=\"B1\" ref-type=\"bibr\">1</xref>). However, complications&#8212;often stemming from a mismatch between prosthesis size and the fibrous aortic ring (<xref rid=\"B2\" ref-type=\"bibr\">2</xref>, <xref rid=\"B3\" ref-type=\"bibr\">3</xref>) or from improper device deployment (<xref rid=\"B4\" ref-type=\"bibr\">4</xref>)&#8212;remain a significant concern. Many post-operative complications are closely related to the experience of the operating surgeon. In addition, patient motion (e.g., chest excursion during respiration and cardiac activity) further complicates device implantation (<xref rid=\"B5\" ref-type=\"bibr\">5</xref>, <xref rid=\"B6\" ref-type=\"bibr\">6</xref>). In addition, the development of complications largely depends on the quality of intraoperative imaging required for accurate valve placement (<xref rid=\"B2\" ref-type=\"bibr\">2</xref>).</p><p>Accurate intraoperative imaging is crucial for precise valve placement; yet, conventional methods impose limitations due to increased radiation exposure and the need for repeated contrast injections, which elevate the risk of renal complications. Consequently, developing systems that reliably identify key anatomical landmarks while minimizing contrast agent use and radiation exposure is of paramount importance.</p><p>Recent advances in visual support systems allow the integration of preoperative three-dimensional computed tomography (CT) models with intraoperative X-ray images (<xref rid=\"B7\" ref-type=\"bibr\">7</xref>, <xref rid=\"B8\" ref-type=\"bibr\">8</xref>). Nonetheless, challenges such as patient movement, deformation of anatomical structures by rigid instruments, and low image contrast complicate direct comparisons between preoperative and intraoperative images (<xref rid=\"B9\" ref-type=\"bibr\">9</xref>&#8211;<xref rid=\"B13\" ref-type=\"bibr\">13</xref>).</p><p>To address these challenges, our approach integrates several strategies: multi-scale CNN architectures (e.g., U-Net++, DeepLabV3+) enhance boundary detection under low-contrast and noisy conditions; extensive data augmentation (random shifts, rotations, noise addition, perspective distortions) improves robustness against artifacts and patient motion; and the inclusion of lightweight yet accurate models (e.g., LinkNet, MA-Net) ensures computational efficiency suitable for intraoperative use. These design choices directly respond to the difficulties inherent in real-time angiographic segmentation.</p><p>Unlike prior studies, our work focuses on the automatic segmentation of the aortic root directly from individual fluoroscopic images captured during TAVI. This approach provides a rapid and accurate method for segmenting the aortic root, thereby simplifying procedural navigation and increasing safety. By combining state-of-the-art deep learning techniques with adaptations tailored to intraoperative imaging conditions, our method opens new avenues for optimizing TAVI procedures and improving clinical outcomes.</p><p>This paper provides a comparative analysis of six deep neural network architectures&#8212;FPN, U-Net++, DeepLabV3+, LinkNet, MA-Net, and PSPNet&#8212;for automatic aortic root segmentation from intraoperative angiographic images. The primary objective is to identify the model that delivers high segmentation accuracy with minimal contrast media use while maintaining computational efficiency. We also discuss hyperparameter tuning strategies and model optimization for deployment under constrained computing resources.</p></sec><sec sec-type=\"methods\" id=\"s2\"><label>2</label><title>Materials and methods</title><p>The development of our segmentation system for aortic root segmentation followed a two-stage process:</p><p>\n<list list-type=\"bullet\"><list-item><p><bold>Stage 1: Data preparation</bold>\n<list list-type=\"simple\"><list-item><label>&#9675;</label><p>Data labeling and creation of training and verification sets.</p></list-item><list-item><label>&#9675;</label><p>Each fluoroscopic image was annotated independently by two experienced vascular surgeons. All annotations were then reviewed by the Head of the Department of Vascular and Interventional Surgery. In cases of disagreement or particularly complex anatomy, the final segmentation was established by consensus in a joint meeting of the annotators. This multi-observer approach ensured a high-quality ground truth segmentation for training and evaluation.</p></list-item></list></p></list-item><list-item><p><bold>Stage 2: Training and evaluation</bold>\n<list list-type=\"simple\"><list-item><label>&#9675;</label><p>Selection of CNN architectures, loss functions, and evaluation metrics.</p></list-item><list-item><label>&#9675;</label><p>Systematic evaluation of qualitative and quantitative parameters from training and validation datasets.</p></list-item></list></p></list-item></list></p><sec id=\"s2a\"><label>2.1</label><title>Data collection</title><p>During endovascular surgeries, including TAVI, angiography via fluoroscopy serves as the reference method for dynamic intraoperative imaging. Data were collected from intraoperative angiographs obtained between 2018 and 2024 during implantation procedures in 80 patients with severe aortic valve stenosis (<xref rid=\"s12\" ref-type=\"sec\">Supplementary Table S1</xref>). The resulting dataset comprises 2,854 images (<inline-formula><mml:math id=\"IM1\" overflow=\"scroll\"><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>000</mml:mn><mml:mo>&#215;</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>000</mml:mn></mml:math></inline-formula> pixels, 8-bit grayscale). For the five-fold patient-level cross-validation, approximately 86%&#8211;88% of patients were assigned to the training set and 12%&#8211;14% to the validation/test set in each fold. Because the number of frames per patient varied, the exact ratio of training vs. test images fluctuated slightly across folds.</p><p>As part of the TAVI procedures, a series of anonymized images were obtained, illustrating four main procedural stages: (i) overview angiography (<xref rid=\"s12\" ref-type=\"sec\">Supplementary Figure S1A</xref>), (ii) positioning of the catheter and delivery system (<xref rid=\"s12\" ref-type=\"sec\">Supplementary Figure S1B</xref>), (iii) initiation of retraction of the delivery system and valve exposure (<xref rid=\"s12\" ref-type=\"sec\">Supplementary Figure S1C</xref>), and (iv) control angiography after valve implantation (<xref rid=\"s12\" ref-type=\"sec\">Supplementary Figure S1D</xref>). These images provide a comprehensive representation of procedural steps, aiding in the accurate assessment of device placement and function.</p><p>The dataset includes representative images of key procedural stages, such as valve positioning, initiation of device retraction with valve exposure, and complete valve deployment. Notably, some images depict the implantation of the <italic toggle=\"yes\">ACURATE neo valve</italic> (<xref rid=\"B14\" ref-type=\"bibr\">14</xref>), while others show the <italic toggle=\"yes\">CoreValve Evolut R</italic> (<xref rid=\"B15\" ref-type=\"bibr\">15</xref>)&#8212;both self-expanding, supra-annular valves with porcine pericardium leaflets.</p><p>Since precise TAVI device positioning requires tracking anatomical landmarks relative to the native valve plane, the dataset was further annotated during contrast agent injections using the Supervisely web-based computer vision platform (<xref rid=\"B16\" ref-type=\"bibr\">16</xref>).</p></sec><sec id=\"s2b\"><label>2.2</label><title>Model selection</title><p>In this study, we evaluated six CNNs for aortic root segmentation in angiography images: U-Net++ (<xref rid=\"B17\" ref-type=\"bibr\">17</xref>), LinkNet (<xref rid=\"B18\" ref-type=\"bibr\">18</xref>), FPN (<xref rid=\"B19\" ref-type=\"bibr\">19</xref>), PSPNet (<xref rid=\"B20\" ref-type=\"bibr\">20</xref>), DeepLabV3+ (<xref rid=\"B21\" ref-type=\"bibr\">21</xref>), and MA-Net (<xref rid=\"B22\" ref-type=\"bibr\">22</xref>). These models were selected based on their proven performance in analyzing complex biomedical images.</p><p>U-Net++ is an advanced version of the U-Net architecture tailored for medical image segmentation. It employs a deeply controlled encoder-decoder structure with nested dense transitions between the encoder and decoder, enabling the capture of fine details. Its effectiveness has been demonstrated in numerous studies, including the semantic segmentation of coronary vessel X-ray images (<xref rid=\"B23\" ref-type=\"bibr\">23</xref>).</p><p>In addition to U-Net++, we employed LinkNet and FPN. LinkNet is a lightweight network that uses skip connections to efficiently recombine fine details from the encoder to the decoder. FPN, characterized by its top-down architecture and lateral connections, creates a feature pyramid that enhances the segmentation process.</p><p>PSPNet and DeepLabV3+ were chosen for their ability to process features at multiple scales and improve contextual awareness-qualities essential for accurately segmenting complex intravascular images, where distinguishing foreground from background is challenging (<xref rid=\"B24\" ref-type=\"bibr\">24</xref>).</p><p>Finally, MA-Net, the most modern CNN in our selection, integrates attention mechanisms to focus on the most salient features of the image, thereby increasing segmentation accuracy. This model effectively exploits the strengths of conventional CNN architectures while optimizing feature extraction and presentation.</p><p>Although not included in our evaluation, we acknowledge the emergence of transformer-based segmentation models such as TransUNet, Swin-Unet, and SegFormer (<xref rid=\"B25\" ref-type=\"bibr\">25</xref>&#8211;<xref rid=\"B27\" ref-type=\"bibr\">27</xref>). These architectures leverage global self-attention and have demonstrated promising results on various segmentation tasks. However, we opted not to include them in this study due to several practical considerations. First, the self-attention mechanism in transformers has quadratic complexity (O(<inline-formula><mml:math id=\"IM2\" overflow=\"scroll\"><mml:msup><mml:mrow><mml:mi mathvariant=\"normal\">N</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula>)) with respect to the number of image pixels, making it computationally prohibitive for our high-resolution angiographic images (approximately 1,000 <inline-formula><mml:math id=\"IM3\" overflow=\"scroll\"><mml:mo>&#215;</mml:mo></mml:math></inline-formula> 1,000 pixels). Second, our dataset of 2,854 images (from 81 patients) is relatively small&#8212;transformer networks, which lack the strong spatial inductive biases of CNNs, generally require much larger training datasets to avoid overfitting. Third, in an intraoperative clinical setting like TAVI, the need for efficient, near-real-time inference favors using lightweight CNN architectures that can run quickly on available hardware. Moreover, the six CNN models we selected already achieve excellent segmentation accuracy in our experiments (Dice coefficient up to 0.88), indicating that our performance requirements can be met without the added complexity of transformers. For these reasons, we focused on CNN-based models in this comparative analysis. The exploration of transformer-based segmentation approaches is deferred to future work when larger datasets and greater computational resources become available.</p></sec><sec id=\"s2c\"><label>2.3</label><title>Hyperparameter tuning strategy</title><p>For aortic root segmentation, we carefully configured six segmentation networks&#8212;U-Net++, LinkNet, FPN, PSPNet, DeepLabV3+, and MA-Net. Achieving the optimal training settings for these models required a rigorous hyperparameter tuning process, during which each model underwent over 200 configuration tests to ensure optimal performance.</p><p>Our tuning process aimed to maximize the segmentation score, specifically focusing on the Dice Similarity Coefficient (DSC). To this end, we employed the DSC loss function (<xref rid=\"disp-formula1\" ref-type=\"disp-formula\">Equation 1</xref>), defined as follows:<disp-formula id=\"disp-formula1\"><mml:math id=\"DM1\" overflow=\"scroll\"><mml:mtext>Loss</mml:mtext><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>&#8722;</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mtext>true</mml:mtext></mml:msub><mml:mo>&#215;</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mtext>\\,pred</mml:mtext></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>&#1013;</mml:mi></mml:mrow><mml:mrow><mml:mo>&#8721;</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mtext>true</mml:mtext></mml:msub><mml:mo>+</mml:mo><mml:mo>&#8721;</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mtext>\\,pred</mml:mtext></mml:msub><mml:mo>+</mml:mo><mml:mi>&#1013;</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><label>(1)</label></disp-formula>where, <inline-formula><mml:math id=\"IM4\" overflow=\"scroll\"><mml:msub><mml:mi>y</mml:mi><mml:mtext>true</mml:mtext></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id=\"IM5\" overflow=\"scroll\"><mml:msub><mml:mi>y</mml:mi><mml:mtext>\\,pred</mml:mtext></mml:msub></mml:math></inline-formula> denote the true and predicted label values, respectively, and <inline-formula><mml:math id=\"IM6\" overflow=\"scroll\"><mml:mi>&#1013;</mml:mi></mml:math></inline-formula> is a small constant (set to <inline-formula><mml:math id=\"IM7\" overflow=\"scroll\"><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>7</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula>) for numerical stability to prevent division by zero.</p><p>Recognizing that not all hyperparameters impact model performance equally (<xref rid=\"B28\" ref-type=\"bibr\">28</xref>), our focus was on optimizing the most critical parameters: the encoder architecture, input image size, optimizer selection, and learning rate. Parameters such as batch size, activation functions, optimizer parameters, and convolution kernel sizes were kept constant. <xref rid=\"T1\" ref-type=\"table\">Table&#160;1</xref> provides a detailed summary of the hyperparameters studied and their corresponding values during model tuning.</p><table-wrap position=\"float\" id=\"T1\" orientation=\"portrait\"><label>Table&#160;1</label><caption><p>Hyperparameters used in network optimization.</p></caption><table frame=\"hsides\" rules=\"groups\"><thead><tr><th valign=\"top\" align=\"left\" rowspan=\"1\" colspan=\"1\">Hyperparameter</th><th valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Value</th><th valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Count</th></tr></thead><tbody><tr><td valign=\"top\" align=\"left\" rowspan=\"1\" colspan=\"1\">Architecture</td><td valign=\"top\" align=\"left\" rowspan=\"1\" colspan=\"1\">Unet++, LinkNet, FPN, PSPNet, DeepLabV3+, MA-Net</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">6</td></tr><tr><td valign=\"top\" align=\"left\" rowspan=\"1\" colspan=\"1\">Encoder</td><td valign=\"top\" align=\"left\" rowspan=\"1\" colspan=\"1\">EfficientNet-B0, EfficientNet-B4, EfficientNet-B0, SE-ResNeXt50, ResNet-50, ResNet-101, SE-ResNeXt101, RegNetX-120</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">8</td></tr><tr><td valign=\"top\" align=\"left\" rowspan=\"1\" colspan=\"1\">Input size</td><td valign=\"top\" align=\"left\" rowspan=\"1\" colspan=\"1\"><inline-formula><mml:math id=\"IM8\" overflow=\"scroll\"><mml:mn>512</mml:mn><mml:mo>&#215;</mml:mo><mml:mn>512</mml:mn></mml:math></inline-formula>, <inline-formula><mml:math id=\"IM9\" overflow=\"scroll\"><mml:mn>624</mml:mn><mml:mo>&#215;</mml:mo><mml:mn>624</mml:mn></mml:math></inline-formula>, <inline-formula><mml:math id=\"IM10\" overflow=\"scroll\"><mml:mn>896</mml:mn><mml:mo>&#215;</mml:mo><mml:mn>896</mml:mn></mml:math></inline-formula></td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">3</td></tr><tr><td valign=\"top\" align=\"left\" rowspan=\"1\" colspan=\"1\">Optimizer</td><td valign=\"top\" align=\"left\" rowspan=\"1\" colspan=\"1\">Adam, Radam, RMSprop</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">3</td></tr><tr><td valign=\"top\" align=\"left\" rowspan=\"1\" colspan=\"1\">Learning rate</td><td valign=\"top\" align=\"left\" rowspan=\"1\" colspan=\"1\"><inline-formula><mml:math id=\"IM11\" overflow=\"scroll\"><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula>, <inline-formula><mml:math id=\"IM12\" overflow=\"scroll\"><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula>, <inline-formula><mml:math id=\"IM13\" overflow=\"scroll\"><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula></td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">3</td></tr></tbody></table></table-wrap><p>Hyperparameter optimization was conducted using a combination of Bayesian optimization and an early termination strategy. Instead of traditional random or grid search methods, we utilized the Optuna (<xref rid=\"B29\" ref-type=\"bibr\">29</xref>) library with the Tree-structured Parzen Estimator algorithm, which builds a probabilistic model of the hyperparameters to identify the most promising combinations for further testing. Additionally, early termination of unpromising configurations was implemented using Hyperband Pruner (<xref rid=\"B30\" ref-type=\"bibr\">30</xref>). This combination of methods, corresponding to the BOHB approach (<xref rid=\"B31\" ref-type=\"bibr\">31</xref>), provided enhanced computational efficiency and reliability compared to conventional hyperparameter optimization techniques.</p></sec><sec id=\"s2d\"><label>2.4</label><title>Model training strategy</title><p>After determining the optimal hyperparameters, we trained and tested our models on the entire dataset. Due to the limited number of subjects (80 patients), we employed a 5-fold cross-validation approach. In each fold, data from 65 patients were used for training and 15 patients for testing (<xref rid=\"s12\" ref-type=\"sec\">Supplementary Table S2</xref>). This partitioning scheme ensured that the subject groups in each subset remained mutually exclusive, thereby preventing any data leakage between training and testing sets.</p><p>During the setup and training stages, a series of augmentation transformations was applied using the <italic toggle=\"yes\">Albumentations</italic> library (<xref rid=\"B32\" ref-type=\"bibr\">32</xref>). These transformations not only expanded the dataset but also served as a regularization method to mitigate overfitting. The augmentation workflow included:</p><p>\n<list list-type=\"bullet\"><list-item><p><bold>Horizontal flip</bold> with a 50% probability.</p></list-item><list-item><p><bold>Shift, scale, and rotate</bold> with a 50% probability: random shifts, scaling, and rotations within specified limits (shift limit = 0.0625, zoom limit = 0.1, rotation limit = 15).</p></list-item><list-item><p><bold>Conditional filling</bold>: padding images to ensure a consistent size for processing.</p></list-item><list-item><p><bold>Gaussian noise</bold> with a 20% probability: adding random noise with a variance range of 3&#8211;10.</p></list-item><list-item><p><bold>Perspective distortion</bold> with a 50% probability: applying random perspective transformations with a scale of 0.05&#8211;0.1.</p></list-item><list-item><p><bold>Random brightness and contrast adjustment</bold> with a 90% probability: adjusting brightness and contrast within limits (brightness limit = 0.2, contrast limit = 0.2).</p></list-item><list-item><p><bold>Hue, saturation, and value adjustment</bold> with a 90% probability: shifting hue, saturation, and value within specified limits (hue shift limit = 20, saturation shift limit = 30, value shift limit = 20).</p></list-item></list>Since the models vary in complexity, they require different amounts of GPU memory when using a fixed batch size. To ensure fair learning conditions, we adjusted the batch size so that each model utilized approximately 70%&#8211;90% of the available GPU memory.</p><p>All training, tuning, and testing were conducted on server hardware comprising a 40-core Intel(R) Xeon(R) Gold 5218R CPU @ 2.10&#8201;GHz, 512&#8201;GB of RAM, and an Nvidia A6000 GPU with 48&#8201;GB of video memory. The models were developed using PyTorch v2.1 and Python v3.11.</p></sec></sec><sec sec-type=\"results\" id=\"s3\"><label>3</label><title>Results</title><sec id=\"s3a\"><label>3.1</label><title>Tuning hyperparameters</title><p>Each model underwent a rigorous hyperparameter tuning process as described in the <xref rid=\"s2c\" ref-type=\"sec\">Section 2.3</xref>, with over 200 configurations tested per model. The results obtained at the tuning stage are summarized below and detailed in <xref rid=\"T2\" ref-type=\"table\">Table&#160;2</xref>:</p><table-wrap position=\"float\" id=\"T2\" orientation=\"portrait\"><label>Table&#160;2</label><caption><p>Optimal hyperparameters for the studied networks.</p></caption><table frame=\"hsides\" rules=\"groups\"><thead><tr><th valign=\"top\" align=\"left\" rowspan=\"1\" colspan=\"1\">Architecture</th><th valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Encoder</th><th valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Input size</th><th valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Optimizer</th><th valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">LR</th><th valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Parameters, M</th><th valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">FLOPs, G</th><th valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Config checked</th></tr></thead><tbody><tr><td valign=\"top\" align=\"left\" rowspan=\"1\" colspan=\"1\">U-Net++</td><td valign=\"top\" align=\"left\" rowspan=\"1\" colspan=\"1\">EfficientNet-B4</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">896</td><td valign=\"top\" align=\"left\" rowspan=\"1\" colspan=\"1\">RMSprop</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">0.0001&#8201;&#215;&#8201;10<sup>&#8722;4</sup></td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">72.4</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">502.1</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">216</td></tr><tr><td valign=\"top\" align=\"left\" rowspan=\"1\" colspan=\"1\">LinkNet</td><td valign=\"top\" align=\"left\" rowspan=\"1\" colspan=\"1\">SE-ResNeXt101</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">512</td><td valign=\"top\" align=\"left\" rowspan=\"1\" colspan=\"1\">RMSprop</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">0.001&#8201;&#215;&#8201;10<sup>&#8722;3</sup></td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">17.9</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">53.2</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">215</td></tr><tr><td valign=\"top\" align=\"left\" rowspan=\"1\" colspan=\"1\">FPN</td><td valign=\"top\" align=\"left\" rowspan=\"1\" colspan=\"1\">SE-ResNeXt101</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">512</td><td valign=\"top\" align=\"left\" rowspan=\"1\" colspan=\"1\">RMSprop</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">0.001&#8201;&#215;&#8201;10<sup>&#8722;3</sup></td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">19.4</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">99.2</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">216</td></tr><tr><td valign=\"top\" align=\"left\" rowspan=\"1\" colspan=\"1\">PSPNet</td><td valign=\"top\" align=\"left\" rowspan=\"1\" colspan=\"1\">SE-ResNeXt101</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">512</td><td valign=\"top\" align=\"left\" rowspan=\"1\" colspan=\"1\">Adam</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">0.001&#8201;&#215;&#8201;10<sup>&#8722;3</sup></td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">47.7</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">24.2</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">216</td></tr><tr><td valign=\"top\" align=\"left\" rowspan=\"1\" colspan=\"1\">DeepLabV3+</td><td valign=\"top\" align=\"left\" rowspan=\"1\" colspan=\"1\">SE-ResNeXt101</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">512</td><td valign=\"top\" align=\"left\" rowspan=\"1\" colspan=\"1\">RMSprop</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">0.0001&#8201;&#215;&#8201;10<sup>&#8722;4</sup></td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">18.6</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">113.6</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">189</td></tr><tr><td valign=\"top\" align=\"left\" rowspan=\"1\" colspan=\"1\">MA-Net</td><td valign=\"top\" align=\"left\" rowspan=\"1\" colspan=\"1\">EfficientNet-B4</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">896</td><td valign=\"top\" align=\"left\" rowspan=\"1\" colspan=\"1\">RMSprop</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">0.001&#8201;&#215;&#8201;10<sup>&#8722;3</sup></td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">25.6</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">39.1</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">216</td></tr></tbody></table></table-wrap><p>\n<list list-type=\"bullet\"><list-item><p><bold>Encoder:</bold> EfficientNet-B4 and SE-ResNeXt101 were the most commonly used encoders across the architectures. Specifically, U-Net++ and MA-Net employed EfficientNet-B4, while LinkNet, FPN, PSPNet, and DeepLabV3+ were based on SE-ResNeXt101.</p></list-item><list-item><p><bold>Input data size:</bold> Input dimensions were adapted for each model, ranging from <inline-formula><mml:math id=\"IM14\" overflow=\"scroll\"><mml:mn>512</mml:mn><mml:mo>&#215;</mml:mo><mml:mn>512</mml:mn></mml:math></inline-formula> to <inline-formula><mml:math id=\"IM15\" overflow=\"scroll\"><mml:mn>896</mml:mn><mml:mo>&#215;</mml:mo><mml:mn>896</mml:mn></mml:math></inline-formula> pixels. This variation reflects a trade-off between computational efficiency and the level of detail required for accurate segmentation.</p></list-item><list-item><p><bold>Optimizer and learning rate:</bold> Optimizer and Learning Rate: RMSprop was primarily used as the optimizer, with the exception of PSPNet, which employed Adam.</p></list-item><list-item><p><bold>Learning rate:</bold> The optimal learning rate depended on the model architecture, parameter count, and computational complexity. For more complex, resource-intensive models (e.g., U-Net++, DeepLabV3+), a lower learning rate (0.0001) was preferable to maintain training stability. For models with fewer parameters and moderate complexity (e.g., FPN, LinkNet, PSPNet, MA-Net), a learning rate of 0.001 allowed for faster training without degrading performance.</p></list-item><list-item><p><bold>Accuracy:</bold> Model performance was evaluated using the DSC on the validation subset, which measures the overlap between the model prediction and the true segmentation. DSC scores ranged from 0.906 (PSPNet) to 0.916 (FPN), indicating that FPN achieved the highest segmentation accuracy during the tuning phase.</p></list-item><list-item><p><bold>Complexity:</bold> The number of parameters and the floating-point operations per second (FLOPs) indicate each model&#8217;s computational requirements. FPN (19.35 million parameters, 99.2 G FLOPs), DeepLabV3+ (18.62 million, 113.52 G FLOPs), and LinkNet (17.86 million, 53.18 G FLOPs) have a relatively similar (and generally smaller) parameter count, though FPN and DeepLabV3+ require higher FLOPs compared to LinkNet due to their architectural features. U-Net++ exhibited the highest complexity, with 72.38 million parameters and 502.097 billion FLOPs, making it the most computationally intensive. PSPNet (47.69 million parameters, 24.19 G FLOPs) and MA-Net (25.63 million parameters, 39.06 G FLOPs) showed average resource consumption.</p></list-item><list-item><p><bold>Stability and training time:</bold> During hyperparameter tuning, DeepLabV3+ experienced 27 crashes, while LinkNet encountered only one. The remaining models completed all configurations without failures. Tuning times ranged from 177&#8201;h (LinkNet) to 499&#8201;h (DeepLabV3+), reflecting differences in model complexity, input size, and the number of configurations tested.</p></list-item></list>The hyperparameter tuning results indicate that FPN achieved the highest DSC scores, suggesting that it is the most suitable model for aortic root segmentation on the tuning verification subset. DeepLabV3+ followed closely, with DSC scores of 0.916 and 0.915, respectively, while U-Net++ and MA-Net exhibited comparable results at 0.913, albeit with a slightly higher computational load. Meanwhile, LinkNet and PSPNet provide a favorable accuracy-to-complexity ratio, making them particularly viable in scenarios with limited computing power or stricter processing time requirements.</p></sec><sec id=\"s3b\"><label>3.2</label><title>Model training</title><p>The study conducted a comprehensive assessment of the performance and convergence characteristics of six deep learning models: U-Net++, LinkNet, FPN, PSPNet, DeepLabV3+ and MA-Net. The models were trained over 35 epochs with an analysis of the dynamics of the loss function and the DSC coefficient (<xref rid=\"s12\" ref-type=\"sec\">Supplementary Figure S2</xref>). The research results revealed a consistent pattern in all models, demonstrating a gradual decrease in losses and a corresponding increase in the DSC coefficient throughout the learning process. These trends indicate the ability of models to learn and improve their segmentation capabilities as they learn.</p><p>Convergence was determined by the stabilization of both metrics (<xref rid=\"s12\" ref-type=\"sec\">Supplementary Table S3</xref>). DeepLabV3+ demonstrated consistent loss reduction and DSC improvement, reaching convergence between epochs 10 and 15. MA-Net and U-Net++ also converged rapidly, though with minor fluctuations that suggest more complex optimization dynamics. In contrast, LinkNet converged at a slower pace, ultimately achieving a DSC close to 0.877, while PSPNet showed the slowest convergence with a lower median DSC of 0.854. FPN exhibited the least stable behavior&#8212;likely due to its architectural design or hyperparameter configuration.</p><p>A detailed performance analysis using DSC metrics revealed notable differences in model stability (<xref rid=\"s12\" ref-type=\"sec\">Supplementary Figure S3</xref>). The lower bounds, defined by the 1.5<inline-formula><mml:math id=\"IM16\" overflow=\"scroll\"><mml:mo>&#8901;</mml:mo></mml:math></inline-formula>IQR whiskers, ranged from 0.754 for PSPNet to 0.817 for DeepLabV3+, with PSPNet displaying the widest spread (0.754&#8211;0.901) and the lowest central tendency. DeepLabV3+ and U-Net++ showed more consistent behavior, with DSC values spanning from 0.817 to 0.913 and 0.826 to 0.913, respectively, indicating stable optimization trajectories. Median DSC scores clustered closely for the stronger models: U-Net++ (0.882) and DeepLabV3+ (0.881) achieved the highest central performance, followed by MA-Net (0.878) and LinkNet (0.877). Although FPN reached a similar maximum (0.913), its wider interval (0.794&#8211;0.913) reflects reduced stability compared to these models. PSPNet, with the lowest median DSC (0.854) and the broadest range, demonstrated the least reliable segmentation outcomes. Maximum DSC values, defined by the upper whisker, ranged from 0.901 (PSPNet) to 0.913 (U-Net++, FPN, DeepLabV3+, MA-Net), with LinkNet peaking at 0.909.</p><p>In summary, DeepLabV3+, U-Net++, and MA-Net emerged as the most balanced models in terms of accuracy and stability, while PSPNet and FPN may require further optimization to reduce variability. However, epoch-wise training analysis does not directly reflect patient-level robustness. To address this, we performed a separate evaluation across patients at the best epoch for each fold.</p></sec><sec id=\"s3c\"><label>3.3</label><title>Patient-level evaluation</title><p>In addition to epoch-wise training dynamics, we performed a patient-level evaluation at the best-performing epoch for each fold (<xref rid=\"T3\" ref-type=\"table\">Table&#160;3</xref>). This analysis provides a clinically oriented estimate of segmentation robustness. Median DSC values across patients ranged from 0.926 (U-Net++) to 0.942 (MA-Net), while ASSD values spanned 4.05&#8211;4.89&#8201;mm. Reported ASSD values are given in millimeters, using a fixed PixelSpacing of 0.390625&#8201;mm/pixel derived from the DICOM headers of the fluoroscopy system, which remained constant across all cases.</p><table-wrap position=\"float\" id=\"T3\" orientation=\"portrait\"><label>Table&#160;3</label><caption><p>Patient-level evaluation results with 95% bootstrap confidence intervals.</p></caption><table frame=\"hsides\" rules=\"groups\"><thead><tr><th valign=\"top\" align=\"left\" rowspan=\"1\" colspan=\"1\">Model</th><th valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">DSC median</th><th valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">DSC 95% CI</th><th valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">ASSD median (mm)</th><th valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">ASSD 95% CI (mm)</th></tr></thead><tbody><tr><td valign=\"top\" align=\"left\" rowspan=\"1\" colspan=\"1\">DeepLabV3+</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">0.929</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">[0.915, 0.938]</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">4.619</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">[4.034, 5.578]</td></tr><tr><td valign=\"top\" align=\"left\" rowspan=\"1\" colspan=\"1\">FPN</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">0.933</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">[0.924, 0.941]</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">4.371</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">[3.985, 5.469]</td></tr><tr><td valign=\"top\" align=\"left\" rowspan=\"1\" colspan=\"1\">LinkNet</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">0.934</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">[0.920, 0.939]</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">4.567</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">[3.848, 5.420]</td></tr><tr><td valign=\"top\" align=\"left\" rowspan=\"1\" colspan=\"1\">MA-Net</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">0.942</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">[0.934, 0.951]</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">4.067</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">[3.384, 4.387]</td></tr><tr><td valign=\"top\" align=\"left\" rowspan=\"1\" colspan=\"1\">PSPNet</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">0.936</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">[0.929, 0.943]</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">4.051</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">[3.742, 4.910]</td></tr><tr><td valign=\"top\" align=\"left\" rowspan=\"1\" colspan=\"1\">U-Net++</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">0.926</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">[0.917, 0.939]</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">4.894</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">[4.961, 5.511]</td></tr></tbody></table></table-wrap><p>MA-Net (EfficientNet-B4) achieved the highest median DSC (0.942, 95% CI: 0.934&#8211;0.951) and one of the lowest ASSD scores (4.07&#8201;mm, 95% CI: 3.384&#8211;4.387). PSPNet (SE-ResNeXt101) produced a nearly comparable DSC (0.936, 95% CI: 0.93&#8211;0.94) and the lowest ASSD overall (4.05&#8201;mm, 95% CI: 3.742&#8211;4.910). LinkNet, FPN, and DeepLabV3+ achieved intermediate results (median DSC <inline-formula><mml:math id=\"IM17\" overflow=\"scroll\"><mml:mo>&#8776;</mml:mo></mml:math></inline-formula> 0.93, ASSD 4.3&#8211;4.6&#8201;mm). U-Net++ ranked lowest with a median DSC of 0.926 (95% CI: 0.917&#8211;0.939) and the highest boundary error (ASSD 4.89&#8201;mm, 95% CI: 3.962&#8211;5.511). To compare model performance, we performed paired Wilcoxon signed-rank tests on the per-patient Dice scores with Holm correction for multiple comparisons. This analysis confirmed statistically significant differences between several model pairs, most notably between MA-Net and U-Net++, MA-Net and LinkNet, and PSPNet and U-Net++ (<xref rid=\"s12\" ref-type=\"sec\">Supplementary Table S4</xref>). These results reinforce the superiority of MA-Net and PSPNet, not only during training dynamics but also when evaluated per patient, underscoring their clinical robustness. <xref rid=\"F1\" ref-type=\"fig\">Figure&#160;1</xref> illustrates representative segmentation overlays produced by the MA-Net model, highlighting its promising performance.</p><fig position=\"float\" id=\"F1\" orientation=\"portrait\"><label>Figure&#160;1</label><caption><p>Aortic root segmentation results: <bold>(A, C, E, G)</bold> segmentation mask labeling by an interventional cardiologist; <bold>(B, D, F, H)</bold> segmentation mask labeling by the MA-Net model.</p></caption><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" position=\"float\" orientation=\"portrait\" xlink:href=\"fcvm-12-1602780-g001.jpg\"><alt-text content-type=\"machine-generated\">Series of eight black and white medical X-ray images labeled A through H, showing a highlighted green area on a section of anatomy, suggesting a progression or change over time. Thin surgical tools or tubes are visible in several images, indicating an interventional procedure.</alt-text></graphic></fig></sec></sec><sec sec-type=\"discussion\" id=\"s4\"><label>4</label><title>Discussion</title><sec id=\"s4a\"><label>4.1</label><title>Segmentation performance and robustness</title><p>This study systematically benchmarks six modern CNN architectures for aortic root segmentation on intraoperative angiographic frames acquired during TAVI. In a low-contrast, artifact-prone setting, U-Net++ and DeepLabV3+ achieved the most favorable balance of accuracy and stability (median DSC <inline-formula><mml:math id=\"IM18\" overflow=\"scroll\"><mml:mo>&#8776;</mml:mo><mml:mn>0.88</mml:mn></mml:math></inline-formula>), with MA-Net and LinkNet offering competitive performance at lower computational cost. These findings align with broader medical-imaging evidence that (i) densely connected U-Net variants better preserve small structures through multi-scale skip paths and deep supervision, and (ii) atrous-convolution backbones with pyramid pooling (as in DeepLabV3/+) improve context aggregation under limited contrast and variable object scales (<xref rid=\"B33\" ref-type=\"bibr\">33</xref>&#8211;<xref rid=\"B35\" ref-type=\"bibr\">35</xref>). While PSPNet and FPN reached high best-case scores during tuning, their wider DSC dispersion in cross-validation suggests sensitivity to hyperparameters and image quality fluctuations, a known challenge in fluoroscopic segmentation where noise, motion and overlapping devices degrade local gradients. At the patient level, MA-Net and PSPNet emerged as the most robust models, combining high overlap (Dice <inline-formula><mml:math id=\"IM19\" overflow=\"scroll\"><mml:mo>&#8805;</mml:mo></mml:math></inline-formula> 0.936) with low boundary error (ASSD <inline-formula><mml:math id=\"IM20\" overflow=\"scroll\"><mml:mo>&#8804;</mml:mo></mml:math></inline-formula> 4.1&#8201;mm). LinkNet, FPN, and DeepLabV3+ performed moderately, with Dice around 0.93 and ASSD between 4.3 and 4.6&#8201;mm. U-Net++ lagged behind, showing the lowest Dice (0.926) and highest ASSD (4.89&#8201;mm). In addition, statistical testing using paired Wilcoxon signed-rank tests with Holm correction demonstrated that differences between several models were statistically significant, reinforcing the robustness of MA-Net and PSPNet compared to others (<xref rid=\"s12\" ref-type=\"sec\">Supplementary Table S4</xref>). Importantly, the patient-level evaluation highlighted that overlap-based and boundary-based metrics are not always aligned: while MA-Net maximized Dice, PSPNet minimized ASSD, pointing to complementary strengths in overlap accuracy vs. boundary precision. Together, these findings suggest that MA-Net and PSPNet are the most balanced and clinically reliable among the tested models, whereas U-Net++&#8212;despite strong performance during training-proved less consistent at the patient level.</p></sec><sec id=\"s4b\"><label>4.2</label><title>Positioning within existing solutions</title><p>Most automation in TAVI image guidance has focused on pre-procedural CT: fully automatic 3D aortic-root (AR) segmentation, landmark detection (annulus, STJ), and measurement extraction can now reach Dice <inline-formula><mml:math id=\"IM21\" overflow=\"scroll\"><mml:mo>&#8776;</mml:mo></mml:math></inline-formula> 0.90&#8211;0.93 and millimetric agreement to expert annotations, enabling accurate sizing and prediction of optimal C-arm angulation for implantation (<xref rid=\"B36\" ref-type=\"bibr\">36</xref>&#8211;<xref rid=\"B38\" ref-type=\"bibr\">38</xref>). Parallel clinical lines of work register these CT models to live fluoroscopy (CT-XR fusion) to overlay the annular plane and coronary ostia and to guide device trajectories; feasibility and workflow utility have been repeatedly demonstrated, including improved projection selection and targeted catheterization (and, in related structural cases, PVL closure guidance) (<xref rid=\"B39\" ref-type=\"bibr\">39</xref>, <xref rid=\"B40\" ref-type=\"bibr\">40</xref>).</p><p>By contrast, purely fluoroscopy-based automation remains less explored. Prior angiographic deep-learning has concentrated on prosthesis or coronary vessel segmentation (often with DeepLabV3+-type decoders or custom pre-processing), rather than segmenting native aortic-root anatomy during valve deployment (<xref rid=\"B24\" ref-type=\"bibr\">24</xref>, <xref rid=\"B41\" ref-type=\"bibr\">41</xref>, <xref rid=\"B42\" ref-type=\"bibr\">42</xref>). Our results therefore complement CT-centric pipelines and fusion systems: they show that, even without CT, single-frame fluoroscopic segmentation of the aortic root is technically feasible at clinically meaningful overlap, and can be computed fast enough for intraoperative decision support when lightweight backbones are chosen.</p></sec><sec id=\"s4c\"><label>4.3</label><title>Clinical relevance and potential impact</title><p>From a clinical perspective, accurate delineation of the aortic root on live angiography has three immediate implications:\n<list list-type=\"order\"><list-item><p><bold>Projection and deployment control.</bold> When the annular plane and sinuses are well segmented, operators can cross-check depth and coaxiality against the prosthesis in real time, particularly during rapid pacing or partial release. This complements CT-predicted C-arm angles and reduces reliance on repeated contrast runs to &#8220;re-find&#8221; the annulus in challenging anatomies (e.g., heavy calcification, horizontal aortas) (<xref rid=\"B43\" ref-type=\"bibr\">43</xref>).</p></list-item><list-item><p><bold>Complication mitigation.</bold> Better intraoperative landmarking is mechanistically linked to less malpositioning-which in turn is a major driver of paravalvular leak, conduction disturbances and reintervention. While our study did not test clinical outcomes, CT-fluoro fusion literature already shows that improved landmark visualization facilitates device manipulation; by analogy, robust fluoro-native segmentation could offer similar intraoperative guardrails without the prerequisites of CT registration (<xref rid=\"B39\" ref-type=\"bibr\">39</xref>, <xref rid=\"B40\" ref-type=\"bibr\">40</xref>).</p></list-item><list-item><p><bold>Contrast stewardship.</bold> Repeated contrast injections for annulus re-identification contribute to Acute Kidney Injury risk (AKI), which is associated with worse short-term outcomes after TAVI. Multiple studies emphasize the importance of minimizing contrast volume and/or scaling it to renal function (e.g., contrast-to-eGFR ratios) to reduce AKI and mortality risk; tools that stabilize visualization at lower contrast loads are therefore clinically attractive (<xref rid=\"B44\" ref-type=\"bibr\">44</xref>&#8211;<xref rid=\"B47\" ref-type=\"bibr\">47</xref>).</p></list-item></list></p></sec><sec id=\"s4d\"><label>4.4</label><title>Architectural trade-offs</title><p>Across architectures, two patterns emerged. First, multi-scale, dilation-based decoders (DeepLabV3+) and densely nested U-Net++ variants were consistently resilient to low SNR and background clutter-mirroring their documented strengths in other angiographic tasks that require long-range context with local boundary fidelity. Second, efficiency matters: LinkNet and MA-Net delivered respectable median DSC with markedly fewer FLOPs/parameters, which is relevant for real-time intraoperative deployment on commodity GPUs. These observations are congruent with the broader literature where tailored Deeplab/U-Net derivatives, sometimes preceded by contrast-normalization and denoising subnets, top benchmarks on X-ray angiography datasets.</p></sec><sec id=\"s4e\"><label>4.5</label><title>Beyond CNNs: transformer and hybrid designs</title><p>Emerging transformer-based and hybrid models (e.g., Swin-DeepLab, TransDeepLab) may further enhance robustness to long-range dependencies and out-of-distribution artifact patterns. Early medical imaging studies suggest superiority over pure CNNs in heterogeneous datasets. Given dataset size and intraoperative latency constraints, CNNs were prioritized here; however, future work should evaluate compact transformer-CNN hybrids for potential deployment.</p></sec><sec id=\"s4f\"><label>4.6</label><title>Validation strategy and next steps</title><p>Beyond cross-validated DSC, three axes of validation are critical:\n<list list-type=\"bullet\"><list-item><p><bold>Generalization and reproducibility.</bold> External, multi-center testing across vendors and acquisition protocols, with reader-study assessment of anatomical plausibility (annular plane, coronary ostia proximity) and inter-observer agreement.</p></list-item><list-item><p><bold>Task-linked endpoints.</bold> Prospective studies that randomize or compare standard care vs. &#8220;segmentation-assisted&#8221; guidance should track projection changes, number of contrast runs, contrast-to-eGFR ratio, pacing time, device depth variance, and early outcomes (PVL grade, PPM implantation, 30-day AKI). Such endpoints have precedent in CT-fluoro fusion and AKI literature and can ground the technical metric in clinical effect size (<xref rid=\"B40\" ref-type=\"bibr\">40</xref>, <xref rid=\"B45\" ref-type=\"bibr\">45</xref>).</p></list-item><list-item><p><bold>Workflow integration.</bold> Latency profiling and fail-safe design (confidence estimates with automatic fallback to manual workflow) are essential for OR adoption. In parallel, combining our fluoro-native segmentation with optional pre-procedural CT (when available) could offer a hybrid path: our mask stabilizes the annulus in noisy frames, while CT supplies pre-computed angles and 3D context (<xref rid=\"B38\" ref-type=\"bibr\">38</xref>).</p></list-item></list></p></sec><sec id=\"s4g\"><label>4.7</label><title>Limitations</title><p>This study is limited by its single-center dataset and evaluation restricted to contrast-enhanced fluoroscopy frames. Non-contrast frames, extreme motion, and heavy device overlap remain challenging. Transformer hybrids were not benchmarked, and real-time performance was not tested under continuous cine acquisition. Most importantly, prospective outcome studies are required to establish clinical benefits beyond segmentation accuracy. The obtained results remain preliminary and should be considered as hypotheses awaiting confirmation in future multicenter studies based on the results.</p></sec></sec><sec sec-type=\"conclusions\" id=\"s5\"><label>5</label><title>Conclusion</title><p>This study demonstrates that U-Net++ and DeepLabV3+ achieve accurate, reliable aortic root segmentation during training, with stable convergence and consistent DSC performance. However, when evaluated on a patient-level basis, MA-Net and PSPNet outperformed all other models, combining the highest Dice values with the lowest ASSD errors. These results emphasize that patient-level evaluation provides a stricter and more clinically relevant measure of segmentation reliability.</p><p>By enabling reliable visualization under low-contrast and noisy imaging conditions, our approach aligns with clinical needs to minimize contrast exposure, especially important given the well-recognized association between contrast volume and post-TAVI renal injury. Our publicly released dataset, models, and code establish a reproducible foundation for fluoroscopy-based decision-support in TAVI.</p><p>Next steps include multicenter clinical validation, integration into real-time operating-room workflows, and quantitative assessment of procedural benefits, such as reduced contrast use, shorter procedural times, improved deployment accuracy, and better patient safety outcomes.</p></sec></body><back><fn-group><fn id=\"n1\" fn-type=\"edited-by\"><p>Edited by: <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"https://loop.frontiersin.org/people/3068825/overview\" ext-link-type=\"uri\">Vladimir Tadic</ext-link>, Technical College of Applied Sciences, Serbia</p></fn><fn id=\"n2\" fn-type=\"reviewed-by\"><p>Reviewed by: <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"https://loop.frontiersin.org/people/2142300/overview\" ext-link-type=\"uri\">Sampad Sengupta</ext-link>, The University of Manchester, United Kingdom</p><p><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"https://loop.frontiersin.org/people/3142558/overview\" ext-link-type=\"uri\">Gabor Orosz</ext-link>, Semmelweis University, Hungary</p></fn></fn-group><sec sec-type=\"data-availability\" id=\"s6\"><title>Data availability statement</title><p>The data supporting the key findings of this study are presented within the article/Supplementary material. All essential components of the study, including curated source code, data, and trained models, have been made publicly available: Source code: <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"https://github.com/Nikita75699/segmentation_tavi\" ext-link-type=\"uri\">https://github.com/Nikita75699/segmentation_tavi</ext-link>. Dataset: <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"https://doi.org/10.5281/zenodo.10838384\" ext-link-type=\"uri\">https://doi.org/10.5281/zenodo.10838384</ext-link>. Models: <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"https://doi.org/10.5281/zenodo.15106413\" ext-link-type=\"uri\">https://doi.org/10.5281/zenodo.15106413</ext-link>.</p></sec><sec sec-type=\"ethics-statement\" id=\"s7\"><title>Ethics statement</title><p>Ethical approval was not required for the study involving humans in accordance with the local legislation and institutional requirements. Written informed consent to participate in this study was not required from the participants or the participants&#8217; legal guardians/next of kin in accordance with the national legislation and the institutional requirements.</p></sec><sec sec-type=\"author-contributions\" id=\"s8\"><title>Author contributions</title><p>NVL: Software, Visualization, Writing &#8211; original draft, Writing &#8211; review &amp; editing, Data curation, Investigation, Methodology. OMG: Formal analysis, Methodology, Validation, Writing &#8211; review &amp; editing. JKB: Data curation, Writing &#8211; review &amp; editing. EEV: Resources, Data curation, Validation, Writing &#8211; review &amp; editing. MAC: Resources, Data curation, Validation, Writing &#8211; review &amp; editing. VVD: Resources, Validation, Writing &#8211; review &amp; editing, Supervision, Methodology.</p></sec><sec sec-type=\"COI-statement\" id=\"s10\"><title>Conflict of interest</title><p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p></sec><sec sec-type=\"ai-statement\" id=\"s11\"><title>Generative AI statement</title><p>The author(s) declare that no Generative AI was used in the creation of this manuscript.</p><p>Any alternative text (alt text) provided alongside figures in this article has been generated by Frontiers with the support of artificial intelligence and reasonable efforts have been made to ensure accuracy, including review by the authors wherever possible. If you identify any issues, please contact us.</p></sec><sec sec-type=\"disclaimer\" id=\"s13\"><title>Publisher's note</title><p>All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.</p></sec><sec sec-type=\"supplementary-material\" id=\"s12\"><title>Supplementary material</title><p>The Supplementary Material for this article can be found online at: <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"https://www.frontiersin.org/articles/10.3389/fcvm.2025.1602780/full#supplementary-material\" ext-link-type=\"uri\">https://www.frontiersin.org/articles/10.3389/fcvm.2025.1602780/full#supplementary-material</ext-link></p><supplementary-material id=\"SM1\" position=\"float\" content-type=\"local-data\" orientation=\"portrait\"><media xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"Datasheet1.pdf\" position=\"float\" orientation=\"portrait\"/></supplementary-material></sec><ref-list><title>References</title><ref id=\"B1\"><label>1.</label><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Eggebrecht</surname><given-names>H</given-names></name><name name-style=\"western\"><surname>Mehta</surname><given-names>RH</given-names></name></person-group>. <article-title>Transcatheter aortic valve implantation (TAVI) in Germany 2008&#8211;2014: on its way to standard therapy for aortic valve stenosis in the elderly</article-title>. <source>EuroIntervention</source>. (<year>2016</year>) <volume>11</volume>:<fpage>1029</fpage>&#8211;<lpage>33</lpage>. <pub-id pub-id-type=\"doi\">10.4244/EIJY15M09_11</pub-id><pub-id pub-id-type=\"pmid\">26384006</pub-id></mixed-citation></ref><ref id=\"B2\"><label>2.</label><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Chourdakis</surname><given-names>E</given-names></name><name name-style=\"western\"><surname>Koniari</surname><given-names>I</given-names></name><name name-style=\"western\"><surname>Kounis</surname><given-names>NG</given-names></name><name name-style=\"western\"><surname>Velissaris</surname><given-names>D</given-names></name><name name-style=\"western\"><surname>Koutsogiannis</surname><given-names>N</given-names></name><name name-style=\"western\"><surname>Tsigkas</surname><given-names>G</given-names></name><etal/></person-group><article-title>The role of echocardiography and CT angiography in transcatheter aortic valve implantation patients</article-title>. <source>J Geriatr Cardiol</source>. (<year>2018</year>) <volume>15</volume>:<fpage>86</fpage>. <pub-id pub-id-type=\"doi\">10.11909/j.issn.1671-5411.2018.01.006</pub-id><pub-id pub-id-type=\"pmid\">29434630</pub-id><pub-id pub-id-type=\"pmcid\">PMC5803542</pub-id></mixed-citation></ref><ref id=\"B3\"><label>3.</label><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Scarsini</surname><given-names>R</given-names></name><name name-style=\"western\"><surname>De Maria</surname><given-names>GL</given-names></name><name name-style=\"western\"><surname>Joseph</surname><given-names>J</given-names></name><name name-style=\"western\"><surname>Fan</surname><given-names>L</given-names></name><name name-style=\"western\"><surname>Cahill</surname><given-names>TJ</given-names></name><name name-style=\"western\"><surname>Kotronias</surname><given-names>RA</given-names></name><etal/></person-group><article-title>Impact of complications during transfemoral transcatheter aortic valve replacement: how can they be avoided and managed?</article-title><source>J Am Heart Assoc</source>. (<year>2019</year>) <volume>8</volume>:<fpage>e013801</fpage>. <pub-id pub-id-type=\"doi\">10.1161/JAHA.119.013801</pub-id><pub-id pub-id-type=\"pmid\">31522627</pub-id><pub-id pub-id-type=\"pmcid\">PMC6818016</pub-id></mixed-citation></ref><ref id=\"B4\"><label>4.</label><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Veulemans</surname><given-names>V</given-names></name><name name-style=\"western\"><surname>Mollus</surname><given-names>S</given-names></name><name name-style=\"western\"><surname>Saalbach</surname><given-names>A</given-names></name><name name-style=\"western\"><surname>Pietsch</surname><given-names>M</given-names></name><name name-style=\"western\"><surname>Hellhammer</surname><given-names>K</given-names></name><name name-style=\"western\"><surname>Zeus</surname><given-names>T</given-names></name><etal/></person-group><article-title>Optimal C-arm angulation during transcatheter aortic valve replacement: accuracy of a rotational C-arm computed tomography based three dimensional heart model</article-title>. <source>World J Cardiol</source>. (<year>2016</year>) <volume>8</volume>:<fpage>606</fpage>. <pub-id pub-id-type=\"doi\">10.4330/wjc.v8.i10.606</pub-id><pub-id pub-id-type=\"pmid\">27847562</pub-id><pub-id pub-id-type=\"pmcid\">PMC5088367</pub-id></mixed-citation></ref><ref id=\"B5\"><label>5.</label><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Kappetein</surname><given-names>AP</given-names></name><name name-style=\"western\"><surname>Head</surname><given-names>SJ</given-names></name><name name-style=\"western\"><surname>G&#233;n&#233;reux</surname><given-names>P</given-names></name><name name-style=\"western\"><surname>Piazza</surname><given-names>N</given-names></name><name name-style=\"western\"><surname>Van Mieghem</surname><given-names>NM</given-names></name><name name-style=\"western\"><surname>Blackstone</surname><given-names>EH</given-names></name><etal/></person-group><article-title>Updated standardized endpoint definitions for transcatheter aortic valve implantation: the valve academic research consortium-2 consensus document</article-title>. <source>J Am Coll Cardiol</source>. (<year>2012</year>) <volume>60</volume>:<fpage>1438</fpage>&#8211;<lpage>54</lpage>. <pub-id pub-id-type=\"doi\">10.1016/j.jacc.2012.09.001</pub-id><pub-id pub-id-type=\"pmid\">23036636</pub-id></mixed-citation></ref><ref id=\"B6\"><label>6.</label><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Chan</surname><given-names>JL</given-names></name><name name-style=\"western\"><surname>Mazilu</surname><given-names>D</given-names></name><name name-style=\"western\"><surname>Miller</surname><given-names>JG</given-names></name><name name-style=\"western\"><surname>Hunt</surname><given-names>T</given-names></name><name name-style=\"western\"><surname>Horvath</surname><given-names>KA</given-names></name><name name-style=\"western\"><surname>Li</surname><given-names>M</given-names></name></person-group>. <article-title>Robotic-assisted real-time mri-guided tavr: from system deployment to in vivo experiment in swine model</article-title>. <source>Int J Comput Assist Radiol Surg</source>. (<year>2016</year>) <volume>11</volume>:<fpage>1905</fpage>&#8211;<lpage>18</lpage>. <pub-id pub-id-type=\"doi\">10.1007/s11548-016-1421-4</pub-id><pub-id pub-id-type=\"pmid\">27246950</pub-id><pub-id pub-id-type=\"pmcid\">PMC6524142</pub-id></mixed-citation></ref><ref id=\"B7\"><label>7.</label><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Kilic</surname><given-names>T</given-names></name><name name-style=\"western\"><surname>Yilmaz</surname><given-names>I</given-names></name></person-group>. <article-title>Transcatheter aortic valve implantation: a revolution in the therapy of elderly and high-risk patients with severe aortic stenosis</article-title>. <source>J Geriatr Cardiol</source>. (<year>2017</year>) <volume>14</volume>:<fpage>204</fpage>. <pub-id pub-id-type=\"doi\">10.11909/j.issn.1671-5411.2017.03.002</pub-id><pub-id pub-id-type=\"pmid\">28408919</pub-id><pub-id pub-id-type=\"pmcid\">PMC5387215</pub-id></mixed-citation></ref><ref id=\"B8\"><label>8.</label><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Codner</surname><given-names>P</given-names></name><name name-style=\"western\"><surname>Lavi</surname><given-names>I</given-names></name><name name-style=\"western\"><surname>Malki</surname><given-names>G</given-names></name><name name-style=\"western\"><surname>Vaknin-Assa</surname><given-names>H</given-names></name><name name-style=\"western\"><surname>Assali</surname><given-names>A</given-names></name><name name-style=\"western\"><surname>Kornowski</surname><given-names>R</given-names></name></person-group>. <article-title>C-THV measures of self-expandable valve positioning and correlation with implant outcomes</article-title>. <source>Catheter Cardiovasc Interv</source>. (<year>2014</year>) <volume>84</volume>:<fpage>877</fpage>&#8211;<lpage>84</lpage>. <pub-id pub-id-type=\"doi\">10.1002/ccd.25594</pub-id><pub-id pub-id-type=\"pmid\">25045134</pub-id></mixed-citation></ref><ref id=\"B9\"><label>9.</label><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Hertault</surname><given-names>A</given-names></name><name name-style=\"western\"><surname>Maurel</surname><given-names>B</given-names></name><name name-style=\"western\"><surname>Sobocinski</surname><given-names>J</given-names></name><name name-style=\"western\"><surname>Gonzalez</surname><given-names>TM</given-names></name><name name-style=\"western\"><surname>Le Roux</surname><given-names>M</given-names></name><name name-style=\"western\"><surname>Azzaoui</surname><given-names>R</given-names></name><etal/></person-group><article-title>Impact of hybrid rooms with image fusion on radiation exposure during endovascular aortic repair</article-title>. <source>Eur J Vasc Endovasc Surg</source>. (<year>2014</year>) <volume>48</volume>:<fpage>382</fpage>&#8211;<lpage>90</lpage>. <pub-id pub-id-type=\"doi\">10.1016/j.ejvs.2014.05.026</pub-id><pub-id pub-id-type=\"pmid\">25042331</pub-id></mixed-citation></ref><ref id=\"B10\"><label>10.</label><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Kauffmann</surname><given-names>C</given-names></name><name name-style=\"western\"><surname>Douane</surname><given-names>F</given-names></name><name name-style=\"western\"><surname>Therasse</surname><given-names>E</given-names></name><name name-style=\"western\"><surname>Lessard</surname><given-names>S</given-names></name><name name-style=\"western\"><surname>Elkouri</surname><given-names>S</given-names></name><name name-style=\"western\"><surname>Gilbert</surname><given-names>P</given-names></name><etal/></person-group><article-title>Source of errors and accuracy of a two-dimensional/three-dimensional fusion road map for endovascular aneurysm repair of abdominal aortic aneurysm</article-title>. <source>J Vasc Interv Radiol</source>. (<year>2015</year>) <volume>26</volume>:<fpage>544</fpage>&#8211;<lpage>51</lpage>. <pub-id pub-id-type=\"doi\">10.1016/j.jvir.2014.12.019</pub-id><pub-id pub-id-type=\"pmid\">25724087</pub-id></mixed-citation></ref><ref id=\"B11\"><label>11.</label><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>McNally</surname><given-names>MM</given-names></name><name name-style=\"western\"><surname>Scali</surname><given-names>ST</given-names></name><name name-style=\"western\"><surname>Feezor</surname><given-names>RJ</given-names></name><name name-style=\"western\"><surname>Neal</surname><given-names>D</given-names></name><name name-style=\"western\"><surname>Huber</surname><given-names>TS</given-names></name><name name-style=\"western\"><surname>Beck</surname><given-names>AW</given-names></name></person-group>. <article-title>Three-dimensional fusion computed tomography decreases radiation exposure, procedure time, and contrast use during fenestrated endovascular aortic repair</article-title>. <source>J Vasc Surg</source>. (<year>2015</year>) <volume>61</volume>:<fpage>309</fpage>&#8211;<lpage>16</lpage>. <pub-id pub-id-type=\"doi\">10.1016/j.jvs.2014.07.097</pub-id><pub-id pub-id-type=\"pmid\">25175634</pub-id><pub-id pub-id-type=\"pmcid\">PMC4308450</pub-id></mixed-citation></ref><ref id=\"B12\"><label>12.</label><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Panuccio</surname><given-names>G</given-names></name><name name-style=\"western\"><surname>Torsello</surname><given-names>GF</given-names></name><name name-style=\"western\"><surname>Pfister</surname><given-names>M</given-names></name><name name-style=\"western\"><surname>Bisdas</surname><given-names>T</given-names></name><name name-style=\"western\"><surname>Bosiers</surname><given-names>MJ</given-names></name><name name-style=\"western\"><surname>Torsello</surname><given-names>G</given-names></name><etal/></person-group><article-title>Computer-aided endovascular aortic repair using fully automated two-and three-dimensional fusion imaging</article-title>. <source>J Vasc Surg</source>. (<year>2016</year>) <volume>64</volume>:<fpage>1587</fpage>&#8211;<lpage>94</lpage>. <pub-id pub-id-type=\"doi\">10.1016/j.jvs.2016.05.100</pub-id><pub-id pub-id-type=\"pmid\">27575809</pub-id></mixed-citation></ref><ref id=\"B13\"><label>13.</label><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Schulz</surname><given-names>CJ</given-names></name><name name-style=\"western\"><surname>Schmitt</surname><given-names>M</given-names></name><name name-style=\"western\"><surname>B&#246;ckler</surname><given-names>D</given-names></name><name name-style=\"western\"><surname>Geisb&#252;sch</surname><given-names>P</given-names></name></person-group>. <article-title>Fusion imaging to support endovascular aneurysm repair using 3D-3D registration</article-title>. <source>J Endovasc Ther</source>. (<year>2016</year>) <volume>23</volume>:<fpage>791</fpage>&#8211;<lpage>9</lpage>. <pub-id pub-id-type=\"doi\">10.1177/1526602816660327</pub-id><pub-id pub-id-type=\"pmid\">27456083</pub-id></mixed-citation></ref><ref id=\"B14\"><label>14.</label><mixed-citation publication-type=\"other\"><collab>Boston Scientific</collab>. <article-title>Data from: ACURATE neo2 TAVI valve system (2025)</article-title>. <comment>(Accessed March 16, 2025)</comment>.</mixed-citation></ref><ref id=\"B15\"><label>15.</label><mixed-citation publication-type=\"other\"><collab>Medtronic</collab>. <article-title>Data from: Corevalve evolut R. <italic toggle=\"yes\">Medtronic Cardiovascular</italic></article-title>. (<year>2025</year>). <comment>Available online at: <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"https://medtronic-cardiovascular.ru/catalog/transkateternoe-protezirovanie-klapanov/corevalve-evolut-r/?doctor_confirm=yes\" ext-link-type=\"uri\">https://medtronic-cardiovascular.ru/catalog/transkateternoe-protezirovanie-klapanov/corevalve-evolut-r/?doctor_confirm=yes</ext-link> (Accessed February 13, 2025)</comment>.</mixed-citation></ref><ref id=\"B16\"><label>16.</label><mixed-citation publication-type=\"other\"><collab>Supervisely</collab>. <article-title>Data from: Supervisely computer vision platform</article-title>. <article-title><italic toggle=\"yes\">Supervisely ecosystem</italic>. (2023)</article-title>.</mixed-citation></ref><ref id=\"B17\"><label>17.</label><mixed-citation publication-type=\"other\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Zhou</surname><given-names>Z</given-names></name><name name-style=\"western\"><surname>Rahman Siddiquee</surname><given-names>MM</given-names></name><name name-style=\"western\"><surname>Tajbakhsh</surname><given-names>N</given-names></name><name name-style=\"western\"><surname>Liang</surname><given-names>J</given-names></name></person-group>. <article-title>Unet++: a nested U-Net architecture for medical image segmentation</article-title>. <comment>In: <italic toggle=\"yes\">Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support: 4th International Workshop, DLMIA 2018, and 8th International Workshop, ML-CDS 2018, Held in Conjunction with MICCAI 2018, Granada, Spain, September 20, 2018, Proceedings 4</italic>. Springer (2018). p. 3&#8211;11</comment>.<pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1007/978-3-030-00889-5_1</pub-id><pub-id pub-id-type=\"pmcid\">PMC7329239</pub-id><pub-id pub-id-type=\"pmid\">32613207</pub-id></mixed-citation></ref><ref id=\"B18\"><label>18.</label><mixed-citation publication-type=\"other\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Chaurasia</surname><given-names>A</given-names></name><name name-style=\"western\"><surname>Culurciello</surname><given-names>E</given-names></name></person-group>. <article-title>Linknet: exploiting encoder representations for efficient semantic segmentation</article-title>. <comment>In: <italic toggle=\"yes\">2017 IEEE Visual Communications and Image Processing (VCIP)</italic>. IEEE (2017). p. 1&#8211;4</comment>.</mixed-citation></ref><ref id=\"B19\"><label>19.</label><mixed-citation publication-type=\"other\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Lin</surname><given-names>TY</given-names></name><name name-style=\"western\"><surname>Doll&#225;r</surname><given-names>P</given-names></name><name name-style=\"western\"><surname>Girshick</surname><given-names>R</given-names></name><name name-style=\"western\"><surname>He</surname><given-names>K</given-names></name><name name-style=\"western\"><surname>Hariharan</surname><given-names>B</given-names></name><name name-style=\"western\"><surname>Belongie</surname><given-names>S</given-names></name></person-group>. <article-title>Feature pyramid networks for object detection</article-title>. <comment>In: <italic toggle=\"yes\">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</italic>. (2017). p. 2117&#8211;25</comment>.</mixed-citation></ref><ref id=\"B20\"><label>20.</label><mixed-citation publication-type=\"other\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Zhao</surname><given-names>H</given-names></name><name name-style=\"western\"><surname>Shi</surname><given-names>J</given-names></name><name name-style=\"western\"><surname>Qi</surname><given-names>X</given-names></name><name name-style=\"western\"><surname>Wang</surname><given-names>X</given-names></name><name name-style=\"western\"><surname>Jia</surname><given-names>J</given-names></name></person-group>. <article-title>Pyramid scene parsing network</article-title>. <comment>In: <italic toggle=\"yes\">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</italic>. (2017). p. 2881&#8211;90</comment>.</mixed-citation></ref><ref id=\"B21\"><label>21.</label><mixed-citation publication-type=\"other\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Chen</surname><given-names>LC</given-names></name><name name-style=\"western\"><surname>Zhu</surname><given-names>Y</given-names></name><name name-style=\"western\"><surname>Papandreou</surname><given-names>G</given-names></name><name name-style=\"western\"><surname>Schroff</surname><given-names>F</given-names></name><name name-style=\"western\"><surname>Adam</surname><given-names>H</given-names></name></person-group>. <article-title>Encoder-decoder with atrous separable convolution for semantic image segmentation</article-title>. <comment>In: <italic toggle=\"yes\">Proceedings of the European Conference on Computer Vision (ECCV)</italic>. (2018). p. 801&#8211;18</comment>.</mixed-citation></ref><ref id=\"B22\"><label>22.</label><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Fan</surname><given-names>T</given-names></name><name name-style=\"western\"><surname>Wang</surname><given-names>G</given-names></name><name name-style=\"western\"><surname>Li</surname><given-names>Y</given-names></name><name name-style=\"western\"><surname>Wang</surname><given-names>H</given-names></name></person-group>. <article-title>Ma-net: a multi-scale attention network for liver and tumor segmentation</article-title>. <source>IEEE Access</source>. (<year>2020</year>) <volume>8</volume>:<fpage>179656</fpage>&#8211;<lpage>65</lpage>. <pub-id pub-id-type=\"doi\">10.1109/ACCESS.2020.3025372</pub-id></mixed-citation></ref><ref id=\"B23\"><label>23.</label><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Jiang</surname><given-names>Z</given-names></name><name name-style=\"western\"><surname>Ou</surname><given-names>C</given-names></name><name name-style=\"western\"><surname>Qian</surname><given-names>Y</given-names></name><name name-style=\"western\"><surname>Rehan</surname><given-names>R</given-names></name><name name-style=\"western\"><surname>Yong</surname><given-names>A</given-names></name></person-group>. <article-title>Coronary vessel segmentation using multiresolution and multiscale deep learning</article-title>. <source>Inform Med Unlocked</source>. (<year>2021</year>) <volume>24</volume>:<fpage>100602</fpage>. <pub-id pub-id-type=\"doi\">10.1016/j.imu.2021.100602</pub-id></mixed-citation></ref><ref id=\"B24\"><label>24.</label><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Iyer</surname><given-names>K</given-names></name><name name-style=\"western\"><surname>Najarian</surname><given-names>CP</given-names></name><name name-style=\"western\"><surname>Fattah</surname><given-names>AA</given-names></name><name name-style=\"western\"><surname>Arthurs</surname><given-names>CJ</given-names></name><name name-style=\"western\"><surname>Soroushmehr</surname><given-names>SR</given-names></name><name name-style=\"western\"><surname>Subban</surname><given-names>V</given-names></name><etal/></person-group><article-title>Angionet: a convolutional neural network for vessel segmentation in x-ray angiography</article-title>. <source>Sci Rep</source>. (<year>2021</year>) <volume>11</volume>:<fpage>18066</fpage>. <pub-id pub-id-type=\"doi\">10.1038/s41598-021-97355-8</pub-id><pub-id pub-id-type=\"pmid\">34508124</pub-id><pub-id pub-id-type=\"pmcid\">PMC8433338</pub-id></mixed-citation></ref><ref id=\"B25\"><label>25.</label><mixed-citation publication-type=\"other\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Chen</surname><given-names>J</given-names></name><name name-style=\"western\"><surname>Lu</surname><given-names>Y</given-names></name><name name-style=\"western\"><surname>Yu</surname><given-names>Q</given-names></name><name name-style=\"western\"><surname>Luo</surname><given-names>X</given-names></name><name name-style=\"western\"><surname>Adeli</surname><given-names>E</given-names></name><name name-style=\"western\"><surname>Wang</surname><given-names>Y</given-names></name><etal/></person-group><article-title>Transunet: transformers make strong encoders for medical image segmentation</article-title>. <comment><italic toggle=\"yes\">arXiv</italic> [Preprint]. <italic toggle=\"yes\">arXiv:2102.04306</italic> (2021)</comment>.</mixed-citation></ref><ref id=\"B26\"><label>26.</label><mixed-citation publication-type=\"other\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Cao</surname><given-names>H</given-names></name><name name-style=\"western\"><surname>Wang</surname><given-names>Y</given-names></name><name name-style=\"western\"><surname>Chen</surname><given-names>J</given-names></name><name name-style=\"western\"><surname>Jiang</surname><given-names>D</given-names></name><name name-style=\"western\"><surname>Zhang</surname><given-names>X</given-names></name><name name-style=\"western\"><surname>Tian</surname><given-names>Q</given-names></name><etal/></person-group><article-title>Swin-Unet: Unet-like pure transformer for medical image segmentation</article-title>. <comment>In: <italic toggle=\"yes\">European Conference on Computer Vision</italic>. Springer (2022). p. 205&#8211;18</comment>.</mixed-citation></ref><ref id=\"B27\"><label>27.</label><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Xie</surname><given-names>E</given-names></name><name name-style=\"western\"><surname>Wang</surname><given-names>W</given-names></name><name name-style=\"western\"><surname>Yu</surname><given-names>Z</given-names></name><name name-style=\"western\"><surname>Anandkumar</surname><given-names>A</given-names></name><name name-style=\"western\"><surname>Alvarez</surname><given-names>JM</given-names></name><name name-style=\"western\"><surname>Luo</surname><given-names>P</given-names></name></person-group>. <article-title>Segformer: simple and efficient design for semantic segmentation with transformers</article-title>. <source>Adv Neural Inf Process Syst</source>. (<year>2021</year>) <volume>34</volume>:<fpage>12077</fpage>&#8211;<lpage>90</lpage>.</mixed-citation></ref><ref id=\"B28\"><label>28.</label><mixed-citation publication-type=\"other\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Tobin</surname><given-names>J</given-names></name></person-group>. <article-title>Data from: Troubleshooting deep neural networks</article-title>. (<year>2021</year>). <comment>Available online at: <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"https://fullstackdeeplearning.com/spring2021/lecture-7/\" ext-link-type=\"uri\">https://fullstackdeeplearning.com/spring2021/lecture-7/</ext-link></comment> (Accessed February 13, 2025).</mixed-citation></ref><ref id=\"B29\"><label>29.</label><mixed-citation publication-type=\"other\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Akiba</surname><given-names>T</given-names></name><name name-style=\"western\"><surname>Sano</surname><given-names>S</given-names></name><name name-style=\"western\"><surname>Yanase</surname><given-names>T</given-names></name><name name-style=\"western\"><surname>Ohta</surname><given-names>T</given-names></name><name name-style=\"western\"><surname>Koyama</surname><given-names>M</given-names></name></person-group>. <article-title>Optuna: a next-generation hyperparameter optimization framework</article-title>. <comment>In: <italic toggle=\"yes\">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</italic>. (2019)</comment>.</mixed-citation></ref><ref id=\"B30\"><label>30.</label><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Li</surname><given-names>L</given-names></name><name name-style=\"western\"><surname>Jamieson</surname><given-names>K</given-names></name><name name-style=\"western\"><surname>DeSalvo</surname><given-names>G</given-names></name><name name-style=\"western\"><surname>Rostamizadeh</surname><given-names>A</given-names></name><name name-style=\"western\"><surname>Talwalkar</surname><given-names>A</given-names></name></person-group>. <article-title>Hyperband: a novel bandit-based approach to hyperparameter optimization</article-title>. <source>J Mach Learn Res</source>. (<year>2018</year>) <volume>18</volume>:<fpage>1</fpage>&#8211;<lpage>52</lpage>.</mixed-citation></ref><ref id=\"B31\"><label>31.</label><mixed-citation publication-type=\"other\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Falkner</surname><given-names>S</given-names></name><name name-style=\"western\"><surname>Klein</surname><given-names>A</given-names></name><name name-style=\"western\"><surname>Hutter</surname><given-names>F</given-names></name></person-group>. <article-title>BOHB: robust and efficient hyperparameter optimization at scale</article-title>. <comment>In: <italic toggle=\"yes\">International Conference on Machine Learning</italic>. PMLR (2018). p. 1437&#8211;46</comment>.</mixed-citation></ref><ref id=\"B32\"><label>32.</label><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Buslaev</surname><given-names>A</given-names></name><name name-style=\"western\"><surname>Iglovikov</surname><given-names>VI</given-names></name><name name-style=\"western\"><surname>Khvedchenya</surname><given-names>E</given-names></name><name name-style=\"western\"><surname>Parinov</surname><given-names>A</given-names></name><name name-style=\"western\"><surname>Druzhinin</surname><given-names>M</given-names></name><name name-style=\"western\"><surname>Kalinin</surname><given-names>AA</given-names></name></person-group>. <article-title>Albumentations: fast and flexible image augmentations</article-title>. <source>Information</source>. (<year>2020</year>) <volume>11</volume>:<fpage>125</fpage>. <pub-id pub-id-type=\"doi\">10.3390/info11020125</pub-id></mixed-citation></ref><ref id=\"B33\"><label>33.</label><mixed-citation publication-type=\"other\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Siddique</surname><given-names>N</given-names></name><name name-style=\"western\"><surname>Sidike</surname><given-names>P</given-names></name><name name-style=\"western\"><surname>Elkin</surname><given-names>C</given-names></name><name name-style=\"western\"><surname>Devabhaktuni</surname><given-names>V</given-names></name></person-group>. <article-title>U-net and its variants for medical image segmentation: theory and applications</article-title>. <comment><italic toggle=\"yes\">arXiv</italic> [Preprint]. <italic toggle=\"yes\">arXiv:2011.01118</italic> (2020)</comment>.</mixed-citation></ref><ref id=\"B34\"><label>34.</label><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Jiangtao</surname><given-names>W</given-names></name><name name-style=\"western\"><surname>Ruhaiyem</surname><given-names>NIR</given-names></name><name name-style=\"western\"><surname>Panpan</surname><given-names>F</given-names></name></person-group>. <article-title>A comprehensive review of U-Net and its variants: advances and applications in medical image segmentation</article-title>. <source>IET Image Process</source>. (<year>2025</year>) <volume>19</volume>:<fpage>e70019</fpage>. <pub-id pub-id-type=\"doi\">10.1049/ipr2.70019</pub-id></mixed-citation></ref><ref id=\"B35\"><label>35.</label><mixed-citation publication-type=\"other\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Finello</surname><given-names>F</given-names></name></person-group>. <article-title>Data from: Deeplabv3 and medical imaging</article-title>. <source>IMAIOS Blog</source> (<year>2022</year>). <comment>Available online at</comment>: <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"https://www.imaios.com/en/resources/blog/deeplabv3-and-medical-imaging\" ext-link-type=\"uri\">https://www.imaios.com/en/resources/blog/deeplabv3-and-medical-imaging</ext-link><comment>(Accessed February 13, 2025).</comment></mixed-citation></ref><ref id=\"B36\"><label>36.</label><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Saitta</surname><given-names>S</given-names></name><name name-style=\"western\"><surname>Sturla</surname><given-names>F</given-names></name><name name-style=\"western\"><surname>Gorla</surname><given-names>R</given-names></name><name name-style=\"western\"><surname>Oliva</surname><given-names>OA</given-names></name><name name-style=\"western\"><surname>Votta</surname><given-names>E</given-names></name><name name-style=\"western\"><surname>Bedogni</surname><given-names>F</given-names></name><etal/></person-group><article-title>A CT-based deep learning system for automatic assessment of aortic root morphology for tavi planning</article-title>. <source>Comput Biol Med</source>. (<year>2023</year>) <volume>163</volume>:<fpage>107147</fpage>. <pub-id pub-id-type=\"doi\">10.1016/j.compbiomed.2023.107147</pub-id><pub-id pub-id-type=\"pmid\">37329622</pub-id></mixed-citation></ref><ref id=\"B37\"><label>37.</label><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Mao</surname><given-names>Y</given-names></name><name name-style=\"western\"><surname>Zhu</surname><given-names>G</given-names></name><name name-style=\"western\"><surname>Yang</surname><given-names>T</given-names></name><name name-style=\"western\"><surname>Lange</surname><given-names>R</given-names></name><name name-style=\"western\"><surname>Noterdaeme</surname><given-names>T</given-names></name><name name-style=\"western\"><surname>Ma</surname><given-names>C</given-names></name><etal/></person-group><article-title>Rapid segmentation of computed tomography angiography images of the aortic valve: the efficacy and clinical value of a deep learning algorithm</article-title>. <source>Front Bioeng Biotechnol</source>. (<year>2024</year>) <volume>12</volume>:<fpage>1285166</fpage>. <pub-id pub-id-type=\"doi\">10.3389/fbioe.2024.1285166</pub-id><pub-id pub-id-type=\"pmid\">38872900</pub-id><pub-id pub-id-type=\"pmcid\">PMC11169779</pub-id></mixed-citation></ref><ref id=\"B38\"><label>38.</label><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Ko&#269;ka</surname><given-names>V</given-names></name><name name-style=\"western\"><surname>B&#225;rtov&#225;</surname><given-names>L</given-names></name><name name-style=\"western\"><surname>Valo&#353;kov&#225;</surname><given-names>N</given-names></name><name name-style=\"western\"><surname>Labo&#353;</surname><given-names>M</given-names></name><name name-style=\"western\"><surname>Weichet</surname><given-names>J</given-names></name><name name-style=\"western\"><surname>Neuberg</surname><given-names>M</given-names></name><etal/></person-group><article-title>Fully automated measurement of aortic root anatomy using philips heartnavigator computed tomography software: fast, accurate, or both?</article-title><source>Eur Heart J Suppl</source>. (<year>2022</year>) <volume>24</volume>:<fpage>B36</fpage>&#8211;<lpage>B41</lpage>. <pub-id pub-id-type=\"doi\">10.1093/eurheartjsupp/suac005</pub-id><pub-id pub-id-type=\"pmid\">35370499</pub-id><pub-id pub-id-type=\"pmcid\">PMC8971741</pub-id></mixed-citation></ref><ref id=\"B39\"><label>39.</label><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Vernikouskaya</surname><given-names>I</given-names></name><name name-style=\"western\"><surname>Rottbauer</surname><given-names>W</given-names></name><name name-style=\"western\"><surname>Seeger</surname><given-names>J</given-names></name><name name-style=\"western\"><surname>Gonska</surname><given-names>B</given-names></name><name name-style=\"western\"><surname>Rasche</surname><given-names>V</given-names></name><name name-style=\"western\"><surname>W&#246;hrle</surname><given-names>J</given-names></name></person-group>. <article-title>Patient-specific registration of 3D CT angiography (CTA) with x-ray fluoroscopy for image fusion during transcatheter aortic valve implantation (TAVI) increases performance of the procedure</article-title>. <source>Clin Res Cardiol</source>. (<year>2018</year>) <volume>107</volume>:<fpage>507</fpage>&#8211;<lpage>16</lpage>. <pub-id pub-id-type=\"doi\">10.1007/s00392-018-1212-8</pub-id><pub-id pub-id-type=\"pmid\">29453592</pub-id></mixed-citation></ref><ref id=\"B40\"><label>40.</label><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Vernikouskaya</surname><given-names>I</given-names></name><name name-style=\"western\"><surname>Rottbauer</surname><given-names>W</given-names></name><name name-style=\"western\"><surname>Gonska</surname><given-names>B</given-names></name><name name-style=\"western\"><surname>Rodewald</surname><given-names>C</given-names></name><name name-style=\"western\"><surname>Seeger</surname><given-names>J</given-names></name><name name-style=\"western\"><surname>Rasche</surname><given-names>V</given-names></name><etal/></person-group><article-title>Image-guidance for transcatheter aortic valve implantation (TAVI) and cerebral embolic protection</article-title>. <source>Int J Cardiol</source>. (<year>2017</year>) <volume>249</volume>:<fpage>90</fpage>&#8211;<lpage>5</lpage>. <pub-id pub-id-type=\"doi\">10.1016/j.ijcard.2017.09.158</pub-id><pub-id pub-id-type=\"pmid\">28935463</pub-id></mixed-citation></ref><ref id=\"B41\"><label>41.</label><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Busto</surname><given-names>L</given-names></name><name name-style=\"western\"><surname>Veiga</surname><given-names>C</given-names></name><name name-style=\"western\"><surname>Gonz&#225;lez-N&#243;voa</surname><given-names>JA</given-names></name><name name-style=\"western\"><surname>Loureiro-Ga</surname><given-names>M</given-names></name><name name-style=\"western\"><surname>Jim&#233;nez</surname><given-names>V</given-names></name><name name-style=\"western\"><surname>Baz</surname><given-names>JA</given-names></name><etal/></person-group><article-title>Automatic identification of bioprostheses on x-ray angiographic sequences of transcatheter aortic valve implantation procedures using deep learning</article-title>. <source>Diagnostics</source>. (<year>2022</year>) <volume>12</volume>:<fpage>334</fpage>. <pub-id pub-id-type=\"doi\">10.3390/diagnostics12020334</pub-id><pub-id pub-id-type=\"pmid\">35204425</pub-id><pub-id pub-id-type=\"pmcid\">PMC8870761</pub-id></mixed-citation></ref><ref id=\"B42\"><label>42.</label><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Chen</surname><given-names>Y</given-names></name><name name-style=\"western\"><surname>Zhang</surname><given-names>Y</given-names></name><name name-style=\"western\"><surname>Jiang</surname><given-names>M</given-names></name><name name-style=\"western\"><surname>Li</surname><given-names>J</given-names></name><name name-style=\"western\"><surname>Han</surname><given-names>X</given-names></name><name name-style=\"western\"><surname>Sun</surname><given-names>K</given-names></name></person-group>, etal. <article-title>SFAG-deeplabv3+: An automatic segmentation approach for coronary angiography images</article-title>. <source>Neurocomputing</source>. (<year>2025</year>) <volume>650</volume>:<fpage>130781</fpage>. <pub-id pub-id-type=\"doi\">10.1016/j.neucom.2025.130781</pub-id></mixed-citation></ref><ref id=\"B43\"><label>43.</label><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Zaky</surname><given-names>M</given-names></name><name name-style=\"western\"><surname>Thalappillil</surname><given-names>R</given-names></name><name name-style=\"western\"><surname>Picone</surname><given-names>V</given-names></name><name name-style=\"western\"><surname>Zhan</surname><given-names>M</given-names></name><name name-style=\"western\"><surname>Cobey</surname><given-names>F</given-names></name><name name-style=\"western\"><surname>Resor</surname><given-names>C</given-names></name><etal/></person-group><article-title>Practical fluoroscopy projection algorithm for transcatheter aortic valve implantation to improve procedural efficiency</article-title>. <source>Am J Cardiol</source>. (<year>2022</year>) <volume>179</volume>:<fpage>131</fpage>. <pub-id pub-id-type=\"doi\">10.1016/j.amjcard.2022.06.055</pub-id><pub-id pub-id-type=\"pmid\">35902316</pub-id></mixed-citation></ref><ref id=\"B44\"><label>44.</label><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Venturi</surname><given-names>G</given-names></name><name name-style=\"western\"><surname>Pighi</surname><given-names>M</given-names></name><name name-style=\"western\"><surname>Pesarini</surname><given-names>G</given-names></name><name name-style=\"western\"><surname>Ferrero</surname><given-names>V</given-names></name><name name-style=\"western\"><surname>Lunardi</surname><given-names>M</given-names></name><name name-style=\"western\"><surname>Castaldi</surname><given-names>G</given-names></name><etal/></person-group><article-title>Contrast-induced acute kidney injury in patients undergoing TAVI compared with coronary interventions</article-title>. <source>J Am Heart Assoc</source>. (<year>2020</year>) <volume>9</volume>:<fpage>e017194</fpage>. <pub-id pub-id-type=\"doi\">10.1161/JAHA.120.017194</pub-id><pub-id pub-id-type=\"pmid\">32787652</pub-id><pub-id pub-id-type=\"pmcid\">PMC7660800</pub-id></mixed-citation></ref><ref id=\"B45\"><label>45.</label><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Chehab</surname><given-names>O</given-names></name><name name-style=\"western\"><surname>Esposito</surname><given-names>G</given-names></name><name name-style=\"western\"><surname>Long</surname><given-names>EJ</given-names></name><name name-style=\"western\"><surname>Ng Yin Ling</surname><given-names>C</given-names></name><name name-style=\"western\"><surname>Hale</surname><given-names>S</given-names></name><name name-style=\"western\"><surname>Malomo</surname><given-names>S</given-names></name><etal/></person-group><article-title>Contrast volume-to-estimated glomerular filtration rate ratio as a predictor of short-term outcomes following transcatheter aortic valve implantation</article-title>. <source>J Clin Med</source>. (<year>2024</year>) <volume>13</volume>:<fpage>2971</fpage>. <pub-id pub-id-type=\"doi\">10.3390/jcm13102971</pub-id><pub-id pub-id-type=\"pmid\">38792512</pub-id><pub-id pub-id-type=\"pmcid\">PMC11122551</pub-id></mixed-citation></ref><ref id=\"B46\"><label>46.</label><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Giannini</surname><given-names>F</given-names></name><name name-style=\"western\"><surname>Latib</surname><given-names>A</given-names></name><name name-style=\"western\"><surname>Jabbour</surname><given-names>RJ</given-names></name><name name-style=\"western\"><surname>Slavich</surname><given-names>M</given-names></name><name name-style=\"western\"><surname>Benincasa</surname><given-names>S</given-names></name><name name-style=\"western\"><surname>Chieffo</surname><given-names>A</given-names></name><etal/></person-group><article-title>The ratio of contrast volume to glomerular filtration rate predicts acute kidney injury and mortality after transcatheter aortic valve implantation</article-title>. <source>Cardiovasc Revasc Med</source>. (<year>2017</year>) <volume>18</volume>:<fpage>349</fpage>&#8211;<lpage>55</lpage>. <pub-id pub-id-type=\"doi\">10.1016/j.carrev.2017.02.011</pub-id><pub-id pub-id-type=\"pmid\">28342840</pub-id></mixed-citation></ref><ref id=\"B47\"><label>47.</label><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Chatani</surname><given-names>K</given-names></name><name name-style=\"western\"><surname>Abdel-Wahab</surname><given-names>M</given-names></name><name name-style=\"western\"><surname>W&#252;bken-Kleinfeld</surname><given-names>N</given-names></name><name name-style=\"western\"><surname>Gordian</surname><given-names>K</given-names></name><name name-style=\"western\"><surname>P&#246;tzing</surname><given-names>K</given-names></name><name name-style=\"western\"><surname>Mostafa</surname><given-names>AE</given-names></name><etal/></person-group><article-title>Acute kidney injury after transcatheter aortic valve implantation: impact of contrast agents, predictive factors, and prognostic importance in 203 patients with long-term follow-up</article-title>. <source>J Cardiol</source>. (<year>2015</year>) <volume>66</volume>:<fpage>514</fpage>&#8211;<lpage>9</lpage>. <pub-id pub-id-type=\"doi\">10.1016/j.jjcc.2015.02.007</pub-id><pub-id pub-id-type=\"pmid\">25801148</pub-id></mixed-citation></ref></ref-list></back></article></pmc-articleset>",
  "text": "pmc Front Cardiovasc Med Front Cardiovasc Med 2863 fcvm Front. Cardiovasc. Med. Frontiers in Cardiovascular Medicine 2297-055X Frontiers Media SA PMC12657348 PMC12657348.1 12657348 12657348 41322494 10.3389/fcvm.2025.1602780 1 Brief Research Report Optimized aortic root segmentation during transcatheter aortic valve implantation Laptev Nikita V. 1 * Software Visualization Writing &#8211; original draft Writing &#8211; review &amp; editing Data curation Investigation Methodology Gerget Olga M. 2 * Formal analysis Methodology Validation Writing &#8211; review &amp; editing Belova Julia K. 3 Data curation Writing &#8211; review &amp; editing Vasilchenko Evgeny E. 1 Resources Data curation Validation Writing &#8211; review &amp; editing Chernyavskiy Mikhail A. 3 Resources Data curation Validation Writing &#8211; review &amp; editing Danilov Viacheslav V. 4 * Resources Validation Writing &#8211; review &amp; editing Supervision Methodology 1 Siberian State Medical University , Tomsk , Russia 2 Institute of Control Sciences of Russian Academy of Sciences , Moscow , Russia 3 Almazov National Medical Research Center , Saint Petersburg , Russia 4 Pompeu Fabra University , Barcelona , Spain * Correspondence: Nikita V. Laptev nikitalaptev77@gmail.com Olga M. Gerget olgagerget@mail.ru Viacheslav V. Danilov viacheslav.v.danilov@gmail.com 13 11 2025 2025 12 480653 1602780 30 3 2025 14 10 2025 13 11 2025 28 11 2025 01 12 2025 &#169; 2025 Laptev, Gerget, Belova, Vasilchenko, Chernyavskiy and Danilov. 2025 Laptev, Gerget, Belova, Vasilchenko, Chernyavskiy and Danilov https://creativecommons.org/licenses/by/4.0/ This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY) . The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms. Transcatheter aortic valve implantation (TAVI) is a highly effective treatment for patients with severe aortic stenosis. Accurate valve positioning is critical for successful TAVI, and highly accurate real-time visualization&#8212;with minimal use of contrast&#8212;is especially important for patients with chronic kidney disease. Under fluoroscopic conditions, which often suffer from low contrast, high noise and artifacts, automatic segmentation of anatomical structures using convolutional neural networks (CNNs) can significantly improve the accuracy of valve positioning. This paper presents a comparative analysis of various CNN architectures for automatic aortic root segmentation on angiographic images, with the aim of optimizing the TAVI process. The experimental evaluation included models such as FPN, U-Net++, DeepLabV3+, LinkNet, MA-Net, and PSPNet, all trained and tested with optimally tuned hyperparameters. During training dynamics, DeepLabV3+ and U-Net++ showed stable convergence with median Dice scores around 0.88. However, when evaluated at the patient level, MA-Net and PSPNet outperformed all other models, achieving Dice coefficients of 0.942 and 0.936, and an average symmetric surface distance of 4.1&#8201;mm. The findings underscore the potential of incorporating automatic segmentation methods into decision-support systems for cardiac surgery&#8212;reducing contrast agent use, minimizing surgical risks, and improving valve positioning accuracy. Future work will focus on expanding the dataset, exploring additional architectures, and adapting the models for real-time application. automatic segmentation aortic root angiographic images TAVI convolutional neural networks The author(s) declare that financial support was received for the research and/or publication of this article. This study was supported by the Russian Science Foundation under Grant No. 24-19-00084, titled &#8220;Robotic System for Medical Instrument Delivery with Integrated Intelligent Information Processing.&#8221; For more information, please visit https://rscf.ru/project/24-19-00084/ . pmc-status-qastatus 0 pmc-status-live yes pmc-status-embargo no pmc-status-released yes pmc-prop-open-access yes pmc-prop-olf no pmc-prop-manuscript no pmc-prop-legally-suppressed no pmc-prop-has-pdf yes pmc-prop-has-supplement yes pmc-prop-pdf-only no pmc-prop-suppress-copyright no pmc-prop-is-real-version no pmc-prop-is-scanned-article no pmc-prop-preprint no pmc-prop-in-epmc yes section-at-acceptance Cardiovascular Imaging 1 Introduction TAVI represents a vital alternative to conventional surgical aortic valve replacement, especially for patients with symptomatic severe aortic stenosis who are at high risk for open-heart surgery. The increasing prevalence of TAVI has broadened its indications ( 1 ). However, complications&#8212;often stemming from a mismatch between prosthesis size and the fibrous aortic ring ( 2 , 3 ) or from improper device deployment ( 4 )&#8212;remain a significant concern. Many post-operative complications are closely related to the experience of the operating surgeon. In addition, patient motion (e.g., chest excursion during respiration and cardiac activity) further complicates device implantation ( 5 , 6 ). In addition, the development of complications largely depends on the quality of intraoperative imaging required for accurate valve placement ( 2 ). Accurate intraoperative imaging is crucial for precise valve placement; yet, conventional methods impose limitations due to increased radiation exposure and the need for repeated contrast injections, which elevate the risk of renal complications. Consequently, developing systems that reliably identify key anatomical landmarks while minimizing contrast agent use and radiation exposure is of paramount importance. Recent advances in visual support systems allow the integration of preoperative three-dimensional computed tomography (CT) models with intraoperative X-ray images ( 7 , 8 ). Nonetheless, challenges such as patient movement, deformation of anatomical structures by rigid instruments, and low image contrast complicate direct comparisons between preoperative and intraoperative images ( 9 &#8211; 13 ). To address these challenges, our approach integrates several strategies: multi-scale CNN architectures (e.g., U-Net++, DeepLabV3+) enhance boundary detection under low-contrast and noisy conditions; extensive data augmentation (random shifts, rotations, noise addition, perspective distortions) improves robustness against artifacts and patient motion; and the inclusion of lightweight yet accurate models (e.g., LinkNet, MA-Net) ensures computational efficiency suitable for intraoperative use. These design choices directly respond to the difficulties inherent in real-time angiographic segmentation. Unlike prior studies, our work focuses on the automatic segmentation of the aortic root directly from individual fluoroscopic images captured during TAVI. This approach provides a rapid and accurate method for segmenting the aortic root, thereby simplifying procedural navigation and increasing safety. By combining state-of-the-art deep learning techniques with adaptations tailored to intraoperative imaging conditions, our method opens new avenues for optimizing TAVI procedures and improving clinical outcomes. This paper provides a comparative analysis of six deep neural network architectures&#8212;FPN, U-Net++, DeepLabV3+, LinkNet, MA-Net, and PSPNet&#8212;for automatic aortic root segmentation from intraoperative angiographic images. The primary objective is to identify the model that delivers high segmentation accuracy with minimal contrast media use while maintaining computational efficiency. We also discuss hyperparameter tuning strategies and model optimization for deployment under constrained computing resources. 2 Materials and methods The development of our segmentation system for aortic root segmentation followed a two-stage process: Stage 1: Data preparation &#9675; Data labeling and creation of training and verification sets. &#9675; Each fluoroscopic image was annotated independently by two experienced vascular surgeons. All annotations were then reviewed by the Head of the Department of Vascular and Interventional Surgery. In cases of disagreement or particularly complex anatomy, the final segmentation was established by consensus in a joint meeting of the annotators. This multi-observer approach ensured a high-quality ground truth segmentation for training and evaluation. Stage 2: Training and evaluation &#9675; Selection of CNN architectures, loss functions, and evaluation metrics. &#9675; Systematic evaluation of qualitative and quantitative parameters from training and validation datasets. 2.1 Data collection During endovascular surgeries, including TAVI, angiography via fluoroscopy serves as the reference method for dynamic intraoperative imaging. Data were collected from intraoperative angiographs obtained between 2018 and 2024 during implantation procedures in 80 patients with severe aortic valve stenosis ( Supplementary Table S1 ). The resulting dataset comprises 2,854 images ( 1 , 000 &#215; 1 , 000 pixels, 8-bit grayscale). For the five-fold patient-level cross-validation, approximately 86%&#8211;88% of patients were assigned to the training set and 12%&#8211;14% to the validation/test set in each fold. Because the number of frames per patient varied, the exact ratio of training vs. test images fluctuated slightly across folds. As part of the TAVI procedures, a series of anonymized images were obtained, illustrating four main procedural stages: (i) overview angiography ( Supplementary Figure S1A ), (ii) positioning of the catheter and delivery system ( Supplementary Figure S1B ), (iii) initiation of retraction of the delivery system and valve exposure ( Supplementary Figure S1C ), and (iv) control angiography after valve implantation ( Supplementary Figure S1D ). These images provide a comprehensive representation of procedural steps, aiding in the accurate assessment of device placement and function. The dataset includes representative images of key procedural stages, such as valve positioning, initiation of device retraction with valve exposure, and complete valve deployment. Notably, some images depict the implantation of the ACURATE neo valve ( 14 ), while others show the CoreValve Evolut R ( 15 )&#8212;both self-expanding, supra-annular valves with porcine pericardium leaflets. Since precise TAVI device positioning requires tracking anatomical landmarks relative to the native valve plane, the dataset was further annotated during contrast agent injections using the Supervisely web-based computer vision platform ( 16 ). 2.2 Model selection In this study, we evaluated six CNNs for aortic root segmentation in angiography images: U-Net++ ( 17 ), LinkNet ( 18 ), FPN ( 19 ), PSPNet ( 20 ), DeepLabV3+ ( 21 ), and MA-Net ( 22 ). These models were selected based on their proven performance in analyzing complex biomedical images. U-Net++ is an advanced version of the U-Net architecture tailored for medical image segmentation. It employs a deeply controlled encoder-decoder structure with nested dense transitions between the encoder and decoder, enabling the capture of fine details. Its effectiveness has been demonstrated in numerous studies, including the semantic segmentation of coronary vessel X-ray images ( 23 ). In addition to U-Net++, we employed LinkNet and FPN. LinkNet is a lightweight network that uses skip connections to efficiently recombine fine details from the encoder to the decoder. FPN, characterized by its top-down architecture and lateral connections, creates a feature pyramid that enhances the segmentation process. PSPNet and DeepLabV3+ were chosen for their ability to process features at multiple scales and improve contextual awareness-qualities essential for accurately segmenting complex intravascular images, where distinguishing foreground from background is challenging ( 24 ). Finally, MA-Net, the most modern CNN in our selection, integrates attention mechanisms to focus on the most salient features of the image, thereby increasing segmentation accuracy. This model effectively exploits the strengths of conventional CNN architectures while optimizing feature extraction and presentation. Although not included in our evaluation, we acknowledge the emergence of transformer-based segmentation models such as TransUNet, Swin-Unet, and SegFormer ( 25 &#8211; 27 ). These architectures leverage global self-attention and have demonstrated promising results on various segmentation tasks. However, we opted not to include them in this study due to several practical considerations. First, the self-attention mechanism in transformers has quadratic complexity (O( N 2 )) with respect to the number of image pixels, making it computationally prohibitive for our high-resolution angiographic images (approximately 1,000 &#215; 1,000 pixels). Second, our dataset of 2,854 images (from 81 patients) is relatively small&#8212;transformer networks, which lack the strong spatial inductive biases of CNNs, generally require much larger training datasets to avoid overfitting. Third, in an intraoperative clinical setting like TAVI, the need for efficient, near-real-time inference favors using lightweight CNN architectures that can run quickly on available hardware. Moreover, the six CNN models we selected already achieve excellent segmentation accuracy in our experiments (Dice coefficient up to 0.88), indicating that our performance requirements can be met without the added complexity of transformers. For these reasons, we focused on CNN-based models in this comparative analysis. The exploration of transformer-based segmentation approaches is deferred to future work when larger datasets and greater computational resources become available. 2.3 Hyperparameter tuning strategy For aortic root segmentation, we carefully configured six segmentation networks&#8212;U-Net++, LinkNet, FPN, PSPNet, DeepLabV3+, and MA-Net. Achieving the optimal training settings for these models required a rigorous hyperparameter tuning process, during which each model underwent over 200 configuration tests to ensure optimal performance. Our tuning process aimed to maximize the segmentation score, specifically focusing on the Dice Similarity Coefficient (DSC). To this end, we employed the DSC loss function ( Equation 1 ), defined as follows: Loss = 1 &#8722; 2 &#8721; ( y true &#215; y \\,pred ) + &#1013; &#8721; y true + &#8721; y \\,pred + &#1013; (1) where, y true and y \\,pred denote the true and predicted label values, respectively, and &#1013; is a small constant (set to 10 &#8722; 7 ) for numerical stability to prevent division by zero. Recognizing that not all hyperparameters impact model performance equally ( 28 ), our focus was on optimizing the most critical parameters: the encoder architecture, input image size, optimizer selection, and learning rate. Parameters such as batch size, activation functions, optimizer parameters, and convolution kernel sizes were kept constant. Table&#160;1 provides a detailed summary of the hyperparameters studied and their corresponding values during model tuning. Table&#160;1 Hyperparameters used in network optimization. Hyperparameter Value Count Architecture Unet++, LinkNet, FPN, PSPNet, DeepLabV3+, MA-Net 6 Encoder EfficientNet-B0, EfficientNet-B4, EfficientNet-B0, SE-ResNeXt50, ResNet-50, ResNet-101, SE-ResNeXt101, RegNetX-120 8 Input size 512 &#215; 512 , 624 &#215; 624 , 896 &#215; 896 3 Optimizer Adam, Radam, RMSprop 3 Learning rate 10 &#8722; 3 , 10 &#8722; 4 , 10 &#8722; 5 3 Hyperparameter optimization was conducted using a combination of Bayesian optimization and an early termination strategy. Instead of traditional random or grid search methods, we utilized the Optuna ( 29 ) library with the Tree-structured Parzen Estimator algorithm, which builds a probabilistic model of the hyperparameters to identify the most promising combinations for further testing. Additionally, early termination of unpromising configurations was implemented using Hyperband Pruner ( 30 ). This combination of methods, corresponding to the BOHB approach ( 31 ), provided enhanced computational efficiency and reliability compared to conventional hyperparameter optimization techniques. 2.4 Model training strategy After determining the optimal hyperparameters, we trained and tested our models on the entire dataset. Due to the limited number of subjects (80 patients), we employed a 5-fold cross-validation approach. In each fold, data from 65 patients were used for training and 15 patients for testing ( Supplementary Table S2 ). This partitioning scheme ensured that the subject groups in each subset remained mutually exclusive, thereby preventing any data leakage between training and testing sets. During the setup and training stages, a series of augmentation transformations was applied using the Albumentations library ( 32 ). These transformations not only expanded the dataset but also served as a regularization method to mitigate overfitting. The augmentation workflow included: Horizontal flip with a 50% probability. Shift, scale, and rotate with a 50% probability: random shifts, scaling, and rotations within specified limits (shift limit = 0.0625, zoom limit = 0.1, rotation limit = 15). Conditional filling : padding images to ensure a consistent size for processing. Gaussian noise with a 20% probability: adding random noise with a variance range of 3&#8211;10. Perspective distortion with a 50% probability: applying random perspective transformations with a scale of 0.05&#8211;0.1. Random brightness and contrast adjustment with a 90% probability: adjusting brightness and contrast within limits (brightness limit = 0.2, contrast limit = 0.2). Hue, saturation, and value adjustment with a 90% probability: shifting hue, saturation, and value within specified limits (hue shift limit = 20, saturation shift limit = 30, value shift limit = 20). Since the models vary in complexity, they require different amounts of GPU memory when using a fixed batch size. To ensure fair learning conditions, we adjusted the batch size so that each model utilized approximately 70%&#8211;90% of the available GPU memory. All training, tuning, and testing were conducted on server hardware comprising a 40-core Intel(R) Xeon(R) Gold 5218R CPU @ 2.10&#8201;GHz, 512&#8201;GB of RAM, and an Nvidia A6000 GPU with 48&#8201;GB of video memory. The models were developed using PyTorch v2.1 and Python v3.11. 3 Results 3.1 Tuning hyperparameters Each model underwent a rigorous hyperparameter tuning process as described in the Section 2.3 , with over 200 configurations tested per model. The results obtained at the tuning stage are summarized below and detailed in Table&#160;2 : Table&#160;2 Optimal hyperparameters for the studied networks. Architecture Encoder Input size Optimizer LR Parameters, M FLOPs, G Config checked U-Net++ EfficientNet-B4 896 RMSprop 0.0001&#8201;&#215;&#8201;10 &#8722;4 72.4 502.1 216 LinkNet SE-ResNeXt101 512 RMSprop 0.001&#8201;&#215;&#8201;10 &#8722;3 17.9 53.2 215 FPN SE-ResNeXt101 512 RMSprop 0.001&#8201;&#215;&#8201;10 &#8722;3 19.4 99.2 216 PSPNet SE-ResNeXt101 512 Adam 0.001&#8201;&#215;&#8201;10 &#8722;3 47.7 24.2 216 DeepLabV3+ SE-ResNeXt101 512 RMSprop 0.0001&#8201;&#215;&#8201;10 &#8722;4 18.6 113.6 189 MA-Net EfficientNet-B4 896 RMSprop 0.001&#8201;&#215;&#8201;10 &#8722;3 25.6 39.1 216 Encoder: EfficientNet-B4 and SE-ResNeXt101 were the most commonly used encoders across the architectures. Specifically, U-Net++ and MA-Net employed EfficientNet-B4, while LinkNet, FPN, PSPNet, and DeepLabV3+ were based on SE-ResNeXt101. Input data size: Input dimensions were adapted for each model, ranging from 512 &#215; 512 to 896 &#215; 896 pixels. This variation reflects a trade-off between computational efficiency and the level of detail required for accurate segmentation. Optimizer and learning rate: Optimizer and Learning Rate: RMSprop was primarily used as the optimizer, with the exception of PSPNet, which employed Adam. Learning rate: The optimal learning rate depended on the model architecture, parameter count, and computational complexity. For more complex, resource-intensive models (e.g., U-Net++, DeepLabV3+), a lower learning rate (0.0001) was preferable to maintain training stability. For models with fewer parameters and moderate complexity (e.g., FPN, LinkNet, PSPNet, MA-Net), a learning rate of 0.001 allowed for faster training without degrading performance. Accuracy: Model performance was evaluated using the DSC on the validation subset, which measures the overlap between the model prediction and the true segmentation. DSC scores ranged from 0.906 (PSPNet) to 0.916 (FPN), indicating that FPN achieved the highest segmentation accuracy during the tuning phase. Complexity: The number of parameters and the floating-point operations per second (FLOPs) indicate each model&#8217;s computational requirements. FPN (19.35 million parameters, 99.2 G FLOPs), DeepLabV3+ (18.62 million, 113.52 G FLOPs), and LinkNet (17.86 million, 53.18 G FLOPs) have a relatively similar (and generally smaller) parameter count, though FPN and DeepLabV3+ require higher FLOPs compared to LinkNet due to their architectural features. U-Net++ exhibited the highest complexity, with 72.38 million parameters and 502.097 billion FLOPs, making it the most computationally intensive. PSPNet (47.69 million parameters, 24.19 G FLOPs) and MA-Net (25.63 million parameters, 39.06 G FLOPs) showed average resource consumption. Stability and training time: During hyperparameter tuning, DeepLabV3+ experienced 27 crashes, while LinkNet encountered only one. The remaining models completed all configurations without failures. Tuning times ranged from 177&#8201;h (LinkNet) to 499&#8201;h (DeepLabV3+), reflecting differences in model complexity, input size, and the number of configurations tested. The hyperparameter tuning results indicate that FPN achieved the highest DSC scores, suggesting that it is the most suitable model for aortic root segmentation on the tuning verification subset. DeepLabV3+ followed closely, with DSC scores of 0.916 and 0.915, respectively, while U-Net++ and MA-Net exhibited comparable results at 0.913, albeit with a slightly higher computational load. Meanwhile, LinkNet and PSPNet provide a favorable accuracy-to-complexity ratio, making them particularly viable in scenarios with limited computing power or stricter processing time requirements. 3.2 Model training The study conducted a comprehensive assessment of the performance and convergence characteristics of six deep learning models: U-Net++, LinkNet, FPN, PSPNet, DeepLabV3+ and MA-Net. The models were trained over 35 epochs with an analysis of the dynamics of the loss function and the DSC coefficient ( Supplementary Figure S2 ). The research results revealed a consistent pattern in all models, demonstrating a gradual decrease in losses and a corresponding increase in the DSC coefficient throughout the learning process. These trends indicate the ability of models to learn and improve their segmentation capabilities as they learn. Convergence was determined by the stabilization of both metrics ( Supplementary Table S3 ). DeepLabV3+ demonstrated consistent loss reduction and DSC improvement, reaching convergence between epochs 10 and 15. MA-Net and U-Net++ also converged rapidly, though with minor fluctuations that suggest more complex optimization dynamics. In contrast, LinkNet converged at a slower pace, ultimately achieving a DSC close to 0.877, while PSPNet showed the slowest convergence with a lower median DSC of 0.854. FPN exhibited the least stable behavior&#8212;likely due to its architectural design or hyperparameter configuration. A detailed performance analysis using DSC metrics revealed notable differences in model stability ( Supplementary Figure S3 ). The lower bounds, defined by the 1.5 &#8901; IQR whiskers, ranged from 0.754 for PSPNet to 0.817 for DeepLabV3+, with PSPNet displaying the widest spread (0.754&#8211;0.901) and the lowest central tendency. DeepLabV3+ and U-Net++ showed more consistent behavior, with DSC values spanning from 0.817 to 0.913 and 0.826 to 0.913, respectively, indicating stable optimization trajectories. Median DSC scores clustered closely for the stronger models: U-Net++ (0.882) and DeepLabV3+ (0.881) achieved the highest central performance, followed by MA-Net (0.878) and LinkNet (0.877). Although FPN reached a similar maximum (0.913), its wider interval (0.794&#8211;0.913) reflects reduced stability compared to these models. PSPNet, with the lowest median DSC (0.854) and the broadest range, demonstrated the least reliable segmentation outcomes. Maximum DSC values, defined by the upper whisker, ranged from 0.901 (PSPNet) to 0.913 (U-Net++, FPN, DeepLabV3+, MA-Net), with LinkNet peaking at 0.909. In summary, DeepLabV3+, U-Net++, and MA-Net emerged as the most balanced models in terms of accuracy and stability, while PSPNet and FPN may require further optimization to reduce variability. However, epoch-wise training analysis does not directly reflect patient-level robustness. To address this, we performed a separate evaluation across patients at the best epoch for each fold. 3.3 Patient-level evaluation In addition to epoch-wise training dynamics, we performed a patient-level evaluation at the best-performing epoch for each fold ( Table&#160;3 ). This analysis provides a clinically oriented estimate of segmentation robustness. Median DSC values across patients ranged from 0.926 (U-Net++) to 0.942 (MA-Net), while ASSD values spanned 4.05&#8211;4.89&#8201;mm. Reported ASSD values are given in millimeters, using a fixed PixelSpacing of 0.390625&#8201;mm/pixel derived from the DICOM headers of the fluoroscopy system, which remained constant across all cases. Table&#160;3 Patient-level evaluation results with 95% bootstrap confidence intervals. Model DSC median DSC 95% CI ASSD median (mm) ASSD 95% CI (mm) DeepLabV3+ 0.929 [0.915, 0.938] 4.619 [4.034, 5.578] FPN 0.933 [0.924, 0.941] 4.371 [3.985, 5.469] LinkNet 0.934 [0.920, 0.939] 4.567 [3.848, 5.420] MA-Net 0.942 [0.934, 0.951] 4.067 [3.384, 4.387] PSPNet 0.936 [0.929, 0.943] 4.051 [3.742, 4.910] U-Net++ 0.926 [0.917, 0.939] 4.894 [4.961, 5.511] MA-Net (EfficientNet-B4) achieved the highest median DSC (0.942, 95% CI: 0.934&#8211;0.951) and one of the lowest ASSD scores (4.07&#8201;mm, 95% CI: 3.384&#8211;4.387). PSPNet (SE-ResNeXt101) produced a nearly comparable DSC (0.936, 95% CI: 0.93&#8211;0.94) and the lowest ASSD overall (4.05&#8201;mm, 95% CI: 3.742&#8211;4.910). LinkNet, FPN, and DeepLabV3+ achieved intermediate results (median DSC &#8776; 0.93, ASSD 4.3&#8211;4.6&#8201;mm). U-Net++ ranked lowest with a median DSC of 0.926 (95% CI: 0.917&#8211;0.939) and the highest boundary error (ASSD 4.89&#8201;mm, 95% CI: 3.962&#8211;5.511). To compare model performance, we performed paired Wilcoxon signed-rank tests on the per-patient Dice scores with Holm correction for multiple comparisons. This analysis confirmed statistically significant differences between several model pairs, most notably between MA-Net and U-Net++, MA-Net and LinkNet, and PSPNet and U-Net++ ( Supplementary Table S4 ). These results reinforce the superiority of MA-Net and PSPNet, not only during training dynamics but also when evaluated per patient, underscoring their clinical robustness. Figure&#160;1 illustrates representative segmentation overlays produced by the MA-Net model, highlighting its promising performance. Figure&#160;1 Aortic root segmentation results: (A, C, E, G) segmentation mask labeling by an interventional cardiologist; (B, D, F, H) segmentation mask labeling by the MA-Net model. Series of eight black and white medical X-ray images labeled A through H, showing a highlighted green area on a section of anatomy, suggesting a progression or change over time. Thin surgical tools or tubes are visible in several images, indicating an interventional procedure. 4 Discussion 4.1 Segmentation performance and robustness This study systematically benchmarks six modern CNN architectures for aortic root segmentation on intraoperative angiographic frames acquired during TAVI. In a low-contrast, artifact-prone setting, U-Net++ and DeepLabV3+ achieved the most favorable balance of accuracy and stability (median DSC &#8776; 0.88 ), with MA-Net and LinkNet offering competitive performance at lower computational cost. These findings align with broader medical-imaging evidence that (i) densely connected U-Net variants better preserve small structures through multi-scale skip paths and deep supervision, and (ii) atrous-convolution backbones with pyramid pooling (as in DeepLabV3/+) improve context aggregation under limited contrast and variable object scales ( 33 &#8211; 35 ). While PSPNet and FPN reached high best-case scores during tuning, their wider DSC dispersion in cross-validation suggests sensitivity to hyperparameters and image quality fluctuations, a known challenge in fluoroscopic segmentation where noise, motion and overlapping devices degrade local gradients. At the patient level, MA-Net and PSPNet emerged as the most robust models, combining high overlap (Dice &#8805; 0.936) with low boundary error (ASSD &#8804; 4.1&#8201;mm). LinkNet, FPN, and DeepLabV3+ performed moderately, with Dice around 0.93 and ASSD between 4.3 and 4.6&#8201;mm. U-Net++ lagged behind, showing the lowest Dice (0.926) and highest ASSD (4.89&#8201;mm). In addition, statistical testing using paired Wilcoxon signed-rank tests with Holm correction demonstrated that differences between several models were statistically significant, reinforcing the robustness of MA-Net and PSPNet compared to others ( Supplementary Table S4 ). Importantly, the patient-level evaluation highlighted that overlap-based and boundary-based metrics are not always aligned: while MA-Net maximized Dice, PSPNet minimized ASSD, pointing to complementary strengths in overlap accuracy vs. boundary precision. Together, these findings suggest that MA-Net and PSPNet are the most balanced and clinically reliable among the tested models, whereas U-Net++&#8212;despite strong performance during training-proved less consistent at the patient level. 4.2 Positioning within existing solutions Most automation in TAVI image guidance has focused on pre-procedural CT: fully automatic 3D aortic-root (AR) segmentation, landmark detection (annulus, STJ), and measurement extraction can now reach Dice &#8776; 0.90&#8211;0.93 and millimetric agreement to expert annotations, enabling accurate sizing and prediction of optimal C-arm angulation for implantation ( 36 &#8211; 38 ). Parallel clinical lines of work register these CT models to live fluoroscopy (CT-XR fusion) to overlay the annular plane and coronary ostia and to guide device trajectories; feasibility and workflow utility have been repeatedly demonstrated, including improved projection selection and targeted catheterization (and, in related structural cases, PVL closure guidance) ( 39 , 40 ). By contrast, purely fluoroscopy-based automation remains less explored. Prior angiographic deep-learning has concentrated on prosthesis or coronary vessel segmentation (often with DeepLabV3+-type decoders or custom pre-processing), rather than segmenting native aortic-root anatomy during valve deployment ( 24 , 41 , 42 ). Our results therefore complement CT-centric pipelines and fusion systems: they show that, even without CT, single-frame fluoroscopic segmentation of the aortic root is technically feasible at clinically meaningful overlap, and can be computed fast enough for intraoperative decision support when lightweight backbones are chosen. 4.3 Clinical relevance and potential impact From a clinical perspective, accurate delineation of the aortic root on live angiography has three immediate implications: Projection and deployment control. When the annular plane and sinuses are well segmented, operators can cross-check depth and coaxiality against the prosthesis in real time, particularly during rapid pacing or partial release. This complements CT-predicted C-arm angles and reduces reliance on repeated contrast runs to &#8220;re-find&#8221; the annulus in challenging anatomies (e.g., heavy calcification, horizontal aortas) ( 43 ). Complication mitigation. Better intraoperative landmarking is mechanistically linked to less malpositioning-which in turn is a major driver of paravalvular leak, conduction disturbances and reintervention. While our study did not test clinical outcomes, CT-fluoro fusion literature already shows that improved landmark visualization facilitates device manipulation; by analogy, robust fluoro-native segmentation could offer similar intraoperative guardrails without the prerequisites of CT registration ( 39 , 40 ). Contrast stewardship. Repeated contrast injections for annulus re-identification contribute to Acute Kidney Injury risk (AKI), which is associated with worse short-term outcomes after TAVI. Multiple studies emphasize the importance of minimizing contrast volume and/or scaling it to renal function (e.g., contrast-to-eGFR ratios) to reduce AKI and mortality risk; tools that stabilize visualization at lower contrast loads are therefore clinically attractive ( 44 &#8211; 47 ). 4.4 Architectural trade-offs Across architectures, two patterns emerged. First, multi-scale, dilation-based decoders (DeepLabV3+) and densely nested U-Net++ variants were consistently resilient to low SNR and background clutter-mirroring their documented strengths in other angiographic tasks that require long-range context with local boundary fidelity. Second, efficiency matters: LinkNet and MA-Net delivered respectable median DSC with markedly fewer FLOPs/parameters, which is relevant for real-time intraoperative deployment on commodity GPUs. These observations are congruent with the broader literature where tailored Deeplab/U-Net derivatives, sometimes preceded by contrast-normalization and denoising subnets, top benchmarks on X-ray angiography datasets. 4.5 Beyond CNNs: transformer and hybrid designs Emerging transformer-based and hybrid models (e.g., Swin-DeepLab, TransDeepLab) may further enhance robustness to long-range dependencies and out-of-distribution artifact patterns. Early medical imaging studies suggest superiority over pure CNNs in heterogeneous datasets. Given dataset size and intraoperative latency constraints, CNNs were prioritized here; however, future work should evaluate compact transformer-CNN hybrids for potential deployment. 4.6 Validation strategy and next steps Beyond cross-validated DSC, three axes of validation are critical: Generalization and reproducibility. External, multi-center testing across vendors and acquisition protocols, with reader-study assessment of anatomical plausibility (annular plane, coronary ostia proximity) and inter-observer agreement. Task-linked endpoints. Prospective studies that randomize or compare standard care vs. &#8220;segmentation-assisted&#8221; guidance should track projection changes, number of contrast runs, contrast-to-eGFR ratio, pacing time, device depth variance, and early outcomes (PVL grade, PPM implantation, 30-day AKI). Such endpoints have precedent in CT-fluoro fusion and AKI literature and can ground the technical metric in clinical effect size ( 40 , 45 ). Workflow integration. Latency profiling and fail-safe design (confidence estimates with automatic fallback to manual workflow) are essential for OR adoption. In parallel, combining our fluoro-native segmentation with optional pre-procedural CT (when available) could offer a hybrid path: our mask stabilizes the annulus in noisy frames, while CT supplies pre-computed angles and 3D context ( 38 ). 4.7 Limitations This study is limited by its single-center dataset and evaluation restricted to contrast-enhanced fluoroscopy frames. Non-contrast frames, extreme motion, and heavy device overlap remain challenging. Transformer hybrids were not benchmarked, and real-time performance was not tested under continuous cine acquisition. Most importantly, prospective outcome studies are required to establish clinical benefits beyond segmentation accuracy. The obtained results remain preliminary and should be considered as hypotheses awaiting confirmation in future multicenter studies based on the results. 5 Conclusion This study demonstrates that U-Net++ and DeepLabV3+ achieve accurate, reliable aortic root segmentation during training, with stable convergence and consistent DSC performance. However, when evaluated on a patient-level basis, MA-Net and PSPNet outperformed all other models, combining the highest Dice values with the lowest ASSD errors. These results emphasize that patient-level evaluation provides a stricter and more clinically relevant measure of segmentation reliability. By enabling reliable visualization under low-contrast and noisy imaging conditions, our approach aligns with clinical needs to minimize contrast exposure, especially important given the well-recognized association between contrast volume and post-TAVI renal injury. Our publicly released dataset, models, and code establish a reproducible foundation for fluoroscopy-based decision-support in TAVI. Next steps include multicenter clinical validation, integration into real-time operating-room workflows, and quantitative assessment of procedural benefits, such as reduced contrast use, shorter procedural times, improved deployment accuracy, and better patient safety outcomes. Edited by: Vladimir Tadic , Technical College of Applied Sciences, Serbia Reviewed by: Sampad Sengupta , The University of Manchester, United Kingdom Gabor Orosz , Semmelweis University, Hungary Data availability statement The data supporting the key findings of this study are presented within the article/Supplementary material. All essential components of the study, including curated source code, data, and trained models, have been made publicly available: Source code: https://github.com/Nikita75699/segmentation_tavi . Dataset: https://doi.org/10.5281/zenodo.10838384 . Models: https://doi.org/10.5281/zenodo.15106413 . Ethics statement Ethical approval was not required for the study involving humans in accordance with the local legislation and institutional requirements. Written informed consent to participate in this study was not required from the participants or the participants&#8217; legal guardians/next of kin in accordance with the national legislation and the institutional requirements. Author contributions NVL: Software, Visualization, Writing &#8211; original draft, Writing &#8211; review &amp; editing, Data curation, Investigation, Methodology. OMG: Formal analysis, Methodology, Validation, Writing &#8211; review &amp; editing. JKB: Data curation, Writing &#8211; review &amp; editing. EEV: Resources, Data curation, Validation, Writing &#8211; review &amp; editing. MAC: Resources, Data curation, Validation, Writing &#8211; review &amp; editing. VVD: Resources, Validation, Writing &#8211; review &amp; editing, Supervision, Methodology. Conflict of interest The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest. Generative AI statement The author(s) declare that no Generative AI was used in the creation of this manuscript. Any alternative text (alt text) provided alongside figures in this article has been generated by Frontiers with the support of artificial intelligence and reasonable efforts have been made to ensure accuracy, including review by the authors wherever possible. If you identify any issues, please contact us. Publisher's note All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher. Supplementary material The Supplementary Material for this article can be found online at: https://www.frontiersin.org/articles/10.3389/fcvm.2025.1602780/full#supplementary-material References 1. Eggebrecht H Mehta RH . Transcatheter aortic valve implantation (TAVI) in Germany 2008&#8211;2014: on its way to standard therapy for aortic valve stenosis in the elderly . EuroIntervention . ( 2016 ) 11 : 1029 &#8211; 33 . 10.4244/EIJY15M09_11 26384006 2. Chourdakis E Koniari I Kounis NG Velissaris D Koutsogiannis N Tsigkas G The role of echocardiography and CT angiography in transcatheter aortic valve implantation patients . J Geriatr Cardiol . ( 2018 ) 15 : 86 . 10.11909/j.issn.1671-5411.2018.01.006 29434630 PMC5803542 3. Scarsini R De Maria GL Joseph J Fan L Cahill TJ Kotronias RA Impact of complications during transfemoral transcatheter aortic valve replacement: how can they be avoided and managed? J Am Heart Assoc . ( 2019 ) 8 : e013801 . 10.1161/JAHA.119.013801 31522627 PMC6818016 4. Veulemans V Mollus S Saalbach A Pietsch M Hellhammer K Zeus T Optimal C-arm angulation during transcatheter aortic valve replacement: accuracy of a rotational C-arm computed tomography based three dimensional heart model . World J Cardiol . ( 2016 ) 8 : 606 . 10.4330/wjc.v8.i10.606 27847562 PMC5088367 5. Kappetein AP Head SJ G&#233;n&#233;reux P Piazza N Van Mieghem NM Blackstone EH Updated standardized endpoint definitions for transcatheter aortic valve implantation: the valve academic research consortium-2 consensus document . J Am Coll Cardiol . ( 2012 ) 60 : 1438 &#8211; 54 . 10.1016/j.jacc.2012.09.001 23036636 6. Chan JL Mazilu D Miller JG Hunt T Horvath KA Li M . Robotic-assisted real-time mri-guided tavr: from system deployment to in vivo experiment in swine model . Int J Comput Assist Radiol Surg . ( 2016 ) 11 : 1905 &#8211; 18 . 10.1007/s11548-016-1421-4 27246950 PMC6524142 7. Kilic T Yilmaz I . Transcatheter aortic valve implantation: a revolution in the therapy of elderly and high-risk patients with severe aortic stenosis . J Geriatr Cardiol . ( 2017 ) 14 : 204 . 10.11909/j.issn.1671-5411.2017.03.002 28408919 PMC5387215 8. Codner P Lavi I Malki G Vaknin-Assa H Assali A Kornowski R . C-THV measures of self-expandable valve positioning and correlation with implant outcomes . Catheter Cardiovasc Interv . ( 2014 ) 84 : 877 &#8211; 84 . 10.1002/ccd.25594 25045134 9. Hertault A Maurel B Sobocinski J Gonzalez TM Le Roux M Azzaoui R Impact of hybrid rooms with image fusion on radiation exposure during endovascular aortic repair . Eur J Vasc Endovasc Surg . ( 2014 ) 48 : 382 &#8211; 90 . 10.1016/j.ejvs.2014.05.026 25042331 10. Kauffmann C Douane F Therasse E Lessard S Elkouri S Gilbert P Source of errors and accuracy of a two-dimensional/three-dimensional fusion road map for endovascular aneurysm repair of abdominal aortic aneurysm . J Vasc Interv Radiol . ( 2015 ) 26 : 544 &#8211; 51 . 10.1016/j.jvir.2014.12.019 25724087 11. McNally MM Scali ST Feezor RJ Neal D Huber TS Beck AW . Three-dimensional fusion computed tomography decreases radiation exposure, procedure time, and contrast use during fenestrated endovascular aortic repair . J Vasc Surg . ( 2015 ) 61 : 309 &#8211; 16 . 10.1016/j.jvs.2014.07.097 25175634 PMC4308450 12. Panuccio G Torsello GF Pfister M Bisdas T Bosiers MJ Torsello G Computer-aided endovascular aortic repair using fully automated two-and three-dimensional fusion imaging . J Vasc Surg . ( 2016 ) 64 : 1587 &#8211; 94 . 10.1016/j.jvs.2016.05.100 27575809 13. Schulz CJ Schmitt M B&#246;ckler D Geisb&#252;sch P . Fusion imaging to support endovascular aneurysm repair using 3D-3D registration . J Endovasc Ther . ( 2016 ) 23 : 791 &#8211; 9 . 10.1177/1526602816660327 27456083 14. Boston Scientific . Data from: ACURATE neo2 TAVI valve system (2025) . (Accessed March 16, 2025) . 15. Medtronic . Data from: Corevalve evolut R. Medtronic Cardiovascular . ( 2025 ). Available online at: https://medtronic-cardiovascular.ru/catalog/transkateternoe-protezirovanie-klapanov/corevalve-evolut-r/?doctor_confirm=yes (Accessed February 13, 2025) . 16. Supervisely . Data from: Supervisely computer vision platform . Supervisely ecosystem . (2023) . 17. Zhou Z Rahman Siddiquee MM Tajbakhsh N Liang J . Unet++: a nested U-Net architecture for medical image segmentation . In: Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support: 4th International Workshop, DLMIA 2018, and 8th International Workshop, ML-CDS 2018, Held in Conjunction with MICCAI 2018, Granada, Spain, September 20, 2018, Proceedings 4 . Springer (2018). p. 3&#8211;11 . 10.1007/978-3-030-00889-5_1 PMC7329239 32613207 18. Chaurasia A Culurciello E . Linknet: exploiting encoder representations for efficient semantic segmentation . In: 2017 IEEE Visual Communications and Image Processing (VCIP) . IEEE (2017). p. 1&#8211;4 . 19. Lin TY Doll&#225;r P Girshick R He K Hariharan B Belongie S . Feature pyramid networks for object detection . In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition . (2017). p. 2117&#8211;25 . 20. Zhao H Shi J Qi X Wang X Jia J . Pyramid scene parsing network . In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition . (2017). p. 2881&#8211;90 . 21. Chen LC Zhu Y Papandreou G Schroff F Adam H . Encoder-decoder with atrous separable convolution for semantic image segmentation . In: Proceedings of the European Conference on Computer Vision (ECCV) . (2018). p. 801&#8211;18 . 22. Fan T Wang G Li Y Wang H . Ma-net: a multi-scale attention network for liver and tumor segmentation . IEEE Access . ( 2020 ) 8 : 179656 &#8211; 65 . 10.1109/ACCESS.2020.3025372 23. Jiang Z Ou C Qian Y Rehan R Yong A . Coronary vessel segmentation using multiresolution and multiscale deep learning . Inform Med Unlocked . ( 2021 ) 24 : 100602 . 10.1016/j.imu.2021.100602 24. Iyer K Najarian CP Fattah AA Arthurs CJ Soroushmehr SR Subban V Angionet: a convolutional neural network for vessel segmentation in x-ray angiography . Sci Rep . ( 2021 ) 11 : 18066 . 10.1038/s41598-021-97355-8 34508124 PMC8433338 25. Chen J Lu Y Yu Q Luo X Adeli E Wang Y Transunet: transformers make strong encoders for medical image segmentation . arXiv [Preprint]. arXiv:2102.04306 (2021) . 26. Cao H Wang Y Chen J Jiang D Zhang X Tian Q Swin-Unet: Unet-like pure transformer for medical image segmentation . In: European Conference on Computer Vision . Springer (2022). p. 205&#8211;18 . 27. Xie E Wang W Yu Z Anandkumar A Alvarez JM Luo P . Segformer: simple and efficient design for semantic segmentation with transformers . Adv Neural Inf Process Syst . ( 2021 ) 34 : 12077 &#8211; 90 . 28. Tobin J . Data from: Troubleshooting deep neural networks . ( 2021 ). Available online at: https://fullstackdeeplearning.com/spring2021/lecture-7/ (Accessed February 13, 2025). 29. Akiba T Sano S Yanase T Ohta T Koyama M . Optuna: a next-generation hyperparameter optimization framework . In: Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining . (2019) . 30. Li L Jamieson K DeSalvo G Rostamizadeh A Talwalkar A . Hyperband: a novel bandit-based approach to hyperparameter optimization . J Mach Learn Res . ( 2018 ) 18 : 1 &#8211; 52 . 31. Falkner S Klein A Hutter F . BOHB: robust and efficient hyperparameter optimization at scale . In: International Conference on Machine Learning . PMLR (2018). p. 1437&#8211;46 . 32. Buslaev A Iglovikov VI Khvedchenya E Parinov A Druzhinin M Kalinin AA . Albumentations: fast and flexible image augmentations . Information . ( 2020 ) 11 : 125 . 10.3390/info11020125 33. Siddique N Sidike P Elkin C Devabhaktuni V . U-net and its variants for medical image segmentation: theory and applications . arXiv [Preprint]. arXiv:2011.01118 (2020) . 34. Jiangtao W Ruhaiyem NIR Panpan F . A comprehensive review of U-Net and its variants: advances and applications in medical image segmentation . IET Image Process . ( 2025 ) 19 : e70019 . 10.1049/ipr2.70019 35. Finello F . Data from: Deeplabv3 and medical imaging . IMAIOS Blog ( 2022 ). Available online at : https://www.imaios.com/en/resources/blog/deeplabv3-and-medical-imaging (Accessed February 13, 2025). 36. Saitta S Sturla F Gorla R Oliva OA Votta E Bedogni F A CT-based deep learning system for automatic assessment of aortic root morphology for tavi planning . Comput Biol Med . ( 2023 ) 163 : 107147 . 10.1016/j.compbiomed.2023.107147 37329622 37. Mao Y Zhu G Yang T Lange R Noterdaeme T Ma C Rapid segmentation of computed tomography angiography images of the aortic valve: the efficacy and clinical value of a deep learning algorithm . Front Bioeng Biotechnol . ( 2024 ) 12 : 1285166 . 10.3389/fbioe.2024.1285166 38872900 PMC11169779 38. Ko&#269;ka V B&#225;rtov&#225; L Valo&#353;kov&#225; N Labo&#353; M Weichet J Neuberg M Fully automated measurement of aortic root anatomy using philips heartnavigator computed tomography software: fast, accurate, or both? Eur Heart J Suppl . ( 2022 ) 24 : B36 &#8211; B41 . 10.1093/eurheartjsupp/suac005 35370499 PMC8971741 39. Vernikouskaya I Rottbauer W Seeger J Gonska B Rasche V W&#246;hrle J . Patient-specific registration of 3D CT angiography (CTA) with x-ray fluoroscopy for image fusion during transcatheter aortic valve implantation (TAVI) increases performance of the procedure . Clin Res Cardiol . ( 2018 ) 107 : 507 &#8211; 16 . 10.1007/s00392-018-1212-8 29453592 40. Vernikouskaya I Rottbauer W Gonska B Rodewald C Seeger J Rasche V Image-guidance for transcatheter aortic valve implantation (TAVI) and cerebral embolic protection . Int J Cardiol . ( 2017 ) 249 : 90 &#8211; 5 . 10.1016/j.ijcard.2017.09.158 28935463 41. Busto L Veiga C Gonz&#225;lez-N&#243;voa JA Loureiro-Ga M Jim&#233;nez V Baz JA Automatic identification of bioprostheses on x-ray angiographic sequences of transcatheter aortic valve implantation procedures using deep learning . Diagnostics . ( 2022 ) 12 : 334 . 10.3390/diagnostics12020334 35204425 PMC8870761 42. Chen Y Zhang Y Jiang M Li J Han X Sun K , etal. SFAG-deeplabv3+: An automatic segmentation approach for coronary angiography images . Neurocomputing . ( 2025 ) 650 : 130781 . 10.1016/j.neucom.2025.130781 43. Zaky M Thalappillil R Picone V Zhan M Cobey F Resor C Practical fluoroscopy projection algorithm for transcatheter aortic valve implantation to improve procedural efficiency . Am J Cardiol . ( 2022 ) 179 : 131 . 10.1016/j.amjcard.2022.06.055 35902316 44. Venturi G Pighi M Pesarini G Ferrero V Lunardi M Castaldi G Contrast-induced acute kidney injury in patients undergoing TAVI compared with coronary interventions . J Am Heart Assoc . ( 2020 ) 9 : e017194 . 10.1161/JAHA.120.017194 32787652 PMC7660800 45. Chehab O Esposito G Long EJ Ng Yin Ling C Hale S Malomo S Contrast volume-to-estimated glomerular filtration rate ratio as a predictor of short-term outcomes following transcatheter aortic valve implantation . J Clin Med . ( 2024 ) 13 : 2971 . 10.3390/jcm13102971 38792512 PMC11122551 46. Giannini F Latib A Jabbour RJ Slavich M Benincasa S Chieffo A The ratio of contrast volume to glomerular filtration rate predicts acute kidney injury and mortality after transcatheter aortic valve implantation . Cardiovasc Revasc Med . ( 2017 ) 18 : 349 &#8211; 55 . 10.1016/j.carrev.2017.02.011 28342840 47. Chatani K Abdel-Wahab M W&#252;bken-Kleinfeld N Gordian K P&#246;tzing K Mostafa AE Acute kidney injury after transcatheter aortic valve implantation: impact of contrast agents, predictive factors, and prognostic importance in 203 patients with long-term follow-up . J Cardiol . ( 2015 ) 66 : 514 &#8211; 9 . 10.1016/j.jjcc.2015.02.007 25801148"
}