{
  "pmcid": "PMC12681719",
  "source": "PMC",
  "download_date": "2025-12-09T16:11:25.686849",
  "metadata": {
    "journal_title": "Osteoarthritis and Cartilage Open",
    "journal_nlm_ta": "Osteoarthr Cartil Open",
    "journal_iso_abbrev": "Osteoarthr Cartil Open",
    "journal": "Osteoarthritis and Cartilage Open",
    "pmcid": "PMC12681719",
    "pmid": "41362327",
    "doi": "10.1016/j.ocarto.2025.100702",
    "title": "Advancing deep learning based knee cartilage segmentation in MRI: Innovations, challenges and applications",
    "year": "2025",
    "month": "11",
    "day": "17",
    "pub_date": {
      "year": "2025",
      "month": "11",
      "day": "17"
    },
    "authors": [
      "Khan Sheheryar",
      "Khawer Muhammad Ammar",
      "Zhong Junru",
      "Qureshi Rizwan",
      "Asim Muhammad",
      "Chen Weitian"
    ],
    "abstract": "Objective Recent advancements in deep learning (DL) have advanced knee cartilage segmentation in Magnetic Resonance Imaging (MRI), offering scalable, automated solutions that markedly reduce reader time and address the limitations of traditional manual approaches. Automated segmentation can substantially aid osteoarthritis (OA) assessment using MRI, facilitating consistent, reproducible quantification across large longitudinal cohorts, reduces inter-/intra-observer variability, capabilities that are impractical with manual workflows. Method This study presents a concise review of state-of-the-art DL-based approaches for knee cartilage segmentation, focusing on the evaluation of various architectures, techniques, and their adaptability to diverse datasets and imaging protocols. This review highlights key challenges in knee cartilage segmentation, including data scarcity, domain shifts, and imaging variability, while also discussing proposed solutions such as semi-supervised learning, domain adaptation, augmentation strategies, and foundation models. Additionally, the clinical significance of knee cartilage segmentation is underscored through its diverse applications. Results The study highlights substantial improvements against conventional methods in segmentation accuracy and efficiency using DL-based methods, given challenging scenarios of knee MRI. Solutions to key challenges are presented, and clinical applications showcase the potential of automated segmentation for cartilage thickness mapping and OA assessment. Conclusion DL-based segmentation is advancing musculoskeletal imaging by offering reliable and automated solutions. Despite persistent challenges such as data scarcity, domain shifts, and imaging variability, advancements in areas like semi-supervised learning, domain adaptation, augmentation strategies, and foundation models present significant opportunities to enhance model robustness and expand clinical applicability.",
    "keywords": [
      "Knee MRI",
      "Osteoarthritis",
      "Cartilage segmentation",
      "Deep learning",
      "Cartilage thickness mapping",
      "Foundation models"
    ]
  },
  "xml": "<?xml version=\"1.0\"  ?><!DOCTYPE pmc-articleset PUBLIC \"-//NLM//DTD ARTICLE SET 2.0//EN\" \"https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd\"><pmc-articleset><article xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:ali=\"http://www.niso.org/schemas/ali/1.0/\" article-type=\"research-article\" xml:lang=\"en\" dtd-version=\"1.4\"><processing-meta base-tagset=\"archiving\" mathml-version=\"3.0\" table-model=\"xhtml\" tagset-family=\"jats\"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type=\"nlm-ta\">Osteoarthr Cartil Open</journal-id><journal-id journal-id-type=\"iso-abbrev\">Osteoarthr Cartil Open</journal-id><journal-id journal-id-type=\"pmc-domain-id\">4341</journal-id><journal-id journal-id-type=\"pmc-domain\">ocarto</journal-id><journal-title-group><journal-title>Osteoarthritis and Cartilage Open</journal-title></journal-title-group><issn pub-type=\"epub\">2665-9131</issn><publisher><publisher-name>Elsevier</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type=\"pmcid\">PMC12681719</article-id><article-id pub-id-type=\"pmcid-ver\">PMC12681719.1</article-id><article-id pub-id-type=\"pmcaid\">12681719</article-id><article-id pub-id-type=\"pmcaiid\">12681719</article-id><article-id pub-id-type=\"pmid\">41362327</article-id><article-id pub-id-type=\"doi\">10.1016/j.ocarto.2025.100702</article-id><article-id pub-id-type=\"pii\">S2665-9131(25)00138-4</article-id><article-id pub-id-type=\"publisher-id\">100702</article-id><article-version article-version-type=\"pmc-version\">1</article-version><article-categories><subj-group subj-group-type=\"heading\"><subject>Virtual Special Issue on: Artificial intelligence in Osteoarthritis imaging; Edited by Chunyi Wen</subject></subj-group></article-categories><title-group><article-title>Advancing deep learning based knee cartilage segmentation in MRI: Innovations, challenges and applications</article-title></title-group><contrib-group><contrib contrib-type=\"author\" id=\"au1\"><name name-style=\"western\"><surname>Khan</surname><given-names initials=\"S\">Sheheryar</given-names></name><email>shkhan@cpce-polyu.edu.hk</email><xref rid=\"aff1\" ref-type=\"aff\">a</xref><xref rid=\"cor1\" ref-type=\"corresp\">&#8270;</xref></contrib><contrib contrib-type=\"author\" id=\"au2\"><name name-style=\"western\"><surname>Khawer</surname><given-names initials=\"MA\">Muhammad Ammar</given-names></name><email>ammarkhawer1@gmail.com</email><xref rid=\"aff1\" ref-type=\"aff\">a</xref></contrib><contrib contrib-type=\"author\" id=\"au3\"><name name-style=\"western\"><surname>Zhong</surname><given-names initials=\"J\">Junru</given-names></name><email>jrzhong@link.cuhk.edu.hk</email><xref rid=\"aff2\" ref-type=\"aff\">b</xref></contrib><contrib contrib-type=\"author\" id=\"au4\"><name name-style=\"western\"><surname>Qureshi</surname><given-names initials=\"R\">Rizwan</given-names></name><email>fnu.rizwan@ucf.edu</email><xref rid=\"aff3\" ref-type=\"aff\">c</xref></contrib><contrib contrib-type=\"author\" id=\"au5\"><name name-style=\"western\"><surname>Asim</surname><given-names initials=\"M\">Muhammad</given-names></name><email>muhammad.asim@cpce-polyu.edu.hk</email><xref rid=\"aff1\" ref-type=\"aff\">a</xref></contrib><contrib contrib-type=\"author\" id=\"au6\"><name name-style=\"western\"><surname>Chen</surname><given-names initials=\"W\">Weitian</given-names></name><email>wtchen@cuhk.edu.hk</email><xref rid=\"aff2\" ref-type=\"aff\">b</xref></contrib><aff id=\"aff1\"><label>a</label>Division of Science Engineering, and Health Studies (SEHS), School of Professional Education and Executive Development, The Hong Kong Polytechnic University, Hong Kong</aff><aff id=\"aff2\"><label>b</label>Department of Imaging and Interventional Radiology, CUHK Lab of AI in Radiology (CLAIR), Chinese University of Hong Kong, Shatin N.T., Hong Kong</aff><aff id=\"aff3\"><label>c</label>Center for Research in Computer Vision, University of Central Florida, Orlando, FL, USA</aff></contrib-group><author-notes><corresp id=\"cor1\"><label>&#8270;</label>Corresponding author. <email>shkhan@cpce-polyu.edu.hk</email></corresp></author-notes><pub-date pub-type=\"collection\"><month>3</month><year>2026</year></pub-date><pub-date pub-type=\"epub\"><day>17</day><month>11</month><year>2025</year></pub-date><volume>8</volume><issue>1</issue><issue-id pub-id-type=\"pmc-issue-id\">501708</issue-id><elocation-id>100702</elocation-id><history><date date-type=\"received\"><day>31</day><month>1</month><year>2025</year></date><date date-type=\"accepted\"><day>3</day><month>11</month><year>2025</year></date></history><pub-history><event event-type=\"pmc-release\"><date><day>17</day><month>11</month><year>2025</year></date></event><event event-type=\"pmc-live\"><date><day>08</day><month>12</month><year>2025</year></date></event><event event-type=\"pmc-last-change\"><date iso-8601-date=\"2025-12-09 14:25:12.950\"><day>09</day><month>12</month><year>2025</year></date></event></pub-history><permissions><copyright-statement>&#169; 2025 The Author(s)</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref specific-use=\"textmining\" content-type=\"ccbyncndlicense\">https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref><license-p>This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).</license-p></license></permissions><self-uri xmlns:xlink=\"http://www.w3.org/1999/xlink\" content-type=\"pmc-pdf\" xlink:href=\"main.pdf\"/><abstract id=\"abs0010\"><sec><title>Objective</title><p>Recent advancements in deep learning (DL) have advanced knee cartilage segmentation in Magnetic Resonance Imaging (MRI), offering scalable, automated solutions that markedly reduce reader time and address the limitations of traditional manual approaches. Automated segmentation can substantially aid osteoarthritis (OA) assessment using MRI, facilitating consistent, reproducible quantification across large longitudinal cohorts, reduces inter-/intra-observer variability, capabilities that are impractical with manual workflows.</p></sec><sec><title>Method</title><p>This study presents a concise review of state-of-the-art DL-based approaches for knee cartilage segmentation, focusing on the evaluation of various architectures, techniques, and their adaptability to diverse datasets and imaging protocols. This review highlights key challenges in knee cartilage segmentation, including data scarcity, domain shifts, and imaging variability, while also discussing proposed solutions such as semi-supervised learning, domain adaptation, augmentation strategies, and foundation models. Additionally, the clinical significance of knee cartilage segmentation is underscored through its diverse applications.</p></sec><sec><title>Results</title><p>The study highlights substantial improvements against conventional methods in segmentation accuracy and efficiency using DL-based methods, given challenging scenarios of knee MRI. Solutions to key challenges are presented, and clinical applications showcase the potential of automated segmentation for cartilage thickness mapping and OA assessment.</p></sec><sec><title>Conclusion</title><p>DL-based segmentation is advancing musculoskeletal imaging by offering reliable and automated solutions. Despite persistent challenges such as data scarcity, domain shifts, and imaging variability, advancements in areas like semi-supervised learning, domain adaptation, augmentation strategies, and foundation models present significant opportunities to enhance model robustness and expand clinical applicability.</p></sec></abstract><kwd-group id=\"kwrds0010\"><title>Keywords</title><kwd>Knee MRI</kwd><kwd>Osteoarthritis</kwd><kwd>Cartilage segmentation</kwd><kwd>Deep learning</kwd><kwd>Cartilage thickness mapping</kwd><kwd>Foundation models</kwd></kwd-group><custom-meta-group><custom-meta><meta-name>pmc-status-qastatus</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>pmc-status-live</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-status-embargo</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-status-released</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-open-access</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-olf</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-manuscript</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-legally-suppressed</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-pdf</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-supplement</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-pdf-only</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-suppress-copyright</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-real-version</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-scanned-article</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-preprint</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-in-epmc</meta-name><meta-value>yes</meta-value></custom-meta></custom-meta-group></article-meta><notes><p id=\"misc0010\">Handling Editor: Professor H Madry</p></notes></front><body><sec id=\"sec1\"><label>1</label><title>Introduction</title><p id=\"p0010\">Knee cartilage segmentation plays a critical role in the clinical management of osteoarthritis (OA), a degenerative joint disease that affects millions worldwide [<xref rid=\"bib1\" ref-type=\"bibr\">1</xref>]. Accurate segmentation of knee structures, including articular cartilage, menisci, and subchondral bone, offer significant value in developing advanced clinical applications for OA, monitoring its progression, and planning appropriate treatment strategies [<xref rid=\"bib2\" ref-type=\"bibr\">2</xref>,<xref rid=\"bib3\" ref-type=\"bibr\">3</xref>]. Magnetic Resonance Imaging (MRI) has become the preferred imaging modality due to its ability to provide high-resolution images that reveal subtle changes in cartilage morphology and composition [<xref rid=\"bib4\" ref-type=\"bibr\">4</xref>,<xref rid=\"bib5\" ref-type=\"bibr\">5</xref>].</p><p id=\"p0015\">MRI technology significantly enhances OA detection by enabling detailed imaging of joint structures, supporting early diagnosis and improved disease monitoring [<xref rid=\"bib6\" ref-type=\"bibr\">6</xref>,<xref rid=\"bib7\" ref-type=\"bibr\">7</xref>]. Traditional imaging methods like X-ray often fail to detect early changes in cartilage and other soft tissues, whereas MRI can visualize subtle alterations in joint cartilage microstructure that are indicative of early OA. Advanced MRI techniques, such as T1&#961; and T2 mapping, allow for the assessment of biochemical changes within the cartilage, which can serve as biomarkers for early degeneration [<xref rid=\"bib6\" ref-type=\"bibr\">[6]</xref>, <xref rid=\"bib7\" ref-type=\"bibr\">[7]</xref>, <xref rid=\"bib8\" ref-type=\"bibr\">[8]</xref>, <xref rid=\"bib9\" ref-type=\"bibr\">[9]</xref>]. Moreover, emerging technologies like Field-Cycling Imaging have shown promise in identifying differences in how healthy and osteoarthritic cartilage responds to varying magnetic fields, potentially marking a breakthrough in early detection [<xref rid=\"bib10\" ref-type=\"bibr\">10</xref>]. These advancements facilitate timely intervention strategies, promoting early preventive measures to delay the progression of debilitating osteoarthritis, rather than prioritizing the treatment of advanced joint damage.</p><p id=\"p0020\">The analysis of MRI images for OA assessment often involves the segmentation of knee cartilage, however, manual segmentation of knee cartilage is time-consuming. Commonly used manual tools for segmentation include software packages such as ITK-SNAP, OsiriX, and 3D Slicer [<xref rid=\"bib11\" ref-type=\"bibr\">11</xref>]. Manual segmentation, although capable of capturing fine anatomical details, is prone to variability and demands substantial expertise.</p><p id=\"p0025\">Conventional segmentation methods for knee cartilage, such as graph cuts, watershed, region growing, and shape models, rely on predefined rules and heuristics to delineate structures from MRI images [<xref rid=\"bib2\" ref-type=\"bibr\">2</xref>,<xref rid=\"bib12\" ref-type=\"bibr\">12</xref>]. These techniques often require manual tuning and can be sensitive to noise and variations in image quality. In contrast, DL algorithms, particularly those leveraging architectures like U-Net [<xref rid=\"bib13\" ref-type=\"bibr\">13</xref>], have advanced automatic cartilage segmentation [<xref rid=\"bib14\" ref-type=\"bibr\">14</xref>]. These approaches not only significantly reduce the time needed for tissue segmentation but also minimize potential human error, delivering consistent and reproducible results.</p><p id=\"p0030\">DL is highly efficient in terms of reader time per scan. Prior studies report &#8764;43&#8211;78 &#8203;min per plate or &#8764;75 &#8203;min per knee for earlier manual/semi-automated protocols, and &#8764;10&#8211;20 &#8203;min per compartment for newer local-area cartilage segmentation (LACS) implementations [<xref rid=\"bib15\" ref-type=\"bibr\">15</xref>], whereas DL inference typically completes in seconds to &#8764;1 &#8203;min with minimal reader involvement [<xref rid=\"bib16\" ref-type=\"bibr\">16</xref>]. Evidence indicates that, when properly validated, DL can match manual methods in agreement and longitudinal precision and preserve key longitudinal associations [<xref rid=\"bib17\" ref-type=\"bibr\">17</xref>]. Accordingly, DL is preferable when non-inferior precision is demonstrated on local data with appropriate quality control (QC); otherwise, a hybrid DL &#8203;+ &#8203;QC workflow can mitigate any speed-responsiveness trade-off [<xref rid=\"bib18\" ref-type=\"bibr\">18</xref>].</p><p id=\"p0035\">In this paper, we present a concise review of DL-based methods for knee cartilage segmentation using MRI. This review is not intended to be exhaustive; rather, it highlights a curated selection of studies the authors consider most relevant and illustrative of current advances.</p></sec><sec id=\"sec2\"><label>2</label><title>Overview of DL-based knee MRI cartilage segmentation</title><p id=\"p0040\">Medical image analysis has undergone significant transformations over the decades, evolving from manual tracing and simple thresholding techniques to sophisticated computational methods. In the context of MRI-based cartilage segmentation, early methods primarily depended on manually outlining cartilage boundaries, which were often subject to significant inter-observer variability [<xref rid=\"bib19\" ref-type=\"bibr\">19</xref>]. However, with technological progress, the shortcomings of manual and traditional segmentation approaches became increasingly apparent, driving the development and adoption of more robust and automated solutions.</p><sec id=\"sec2.1\"><label>2.1</label><title>Emergence of DL in knee MRI segmentation</title><p id=\"p0045\">The advent of DL has brought a transformative shift to medical image analysis [<xref rid=\"bib16\" ref-type=\"bibr\">16</xref>], significantly advancing the field of MRI-based cartilage segmentation [<xref rid=\"bib10\" ref-type=\"bibr\">10</xref>,<xref rid=\"bib13\" ref-type=\"bibr\">13</xref>,<xref rid=\"bib20\" ref-type=\"bibr\">20</xref>]. Convolutional Neural Networks (CNNs) and their variants played a pivotal role in this evolution. U-Net [<xref rid=\"bib13\" ref-type=\"bibr\">13</xref>] and its variants U-Net++ [<xref rid=\"bib21\" ref-type=\"bibr\">21</xref>], nnU-Net [<xref rid=\"bib22\" ref-type=\"bibr\">22</xref>] have emerged as powerful DL architectures for automated MRI cartilage segmentation [<xref rid=\"bib23\" ref-type=\"bibr\">23</xref>]. These methods leverage CNNs to learn features directly from image data, improving segmentation accuracy as well as consistency and reproducibility. The U-Net and its variants consist of an encoder path for feature extraction and a decoder path for upsampled predictions, connected by skip connections to preserve spatial details. To further enhance segmentation performance, attention mechanisms have been integrated into U-Net variants, addressing the challenges posed by the irregular shape and small size of cartilage within MRI images [<xref rid=\"bib24\" ref-type=\"bibr\">24</xref>]. Transfer learning techniques have also been employed, using pre-trained models to initialize the network and accelerate training with limited labelled data [<xref rid=\"bib25\" ref-type=\"bibr\">25</xref>]. Nevertheless, integrating DL models with classical shape priors, e.g., active appearance models (AAM) and statistical shape models (SSM), has further improved segmentation performance on MRI [<xref rid=\"bib26\" ref-type=\"bibr\">[26]</xref>, <xref rid=\"bib27\" ref-type=\"bibr\">[27]</xref>, <xref rid=\"bib28\" ref-type=\"bibr\">[28]</xref>].</p><p id=\"p0050\">Recent advancements in DL have introduced a diverse array of specialized techniques designed to tackle specific challenges in MRI-based cartilage segmentation [<xref rid=\"bib29\" ref-type=\"bibr\">29</xref>]. Data augmentation techniques, such as Generative Adversarial Network (GAN)-based methods [<xref rid=\"bib30\" ref-type=\"bibr\">30</xref>,<xref rid=\"bib31\" ref-type=\"bibr\">31</xref>] are used to generate synthetic MRI-like images, enriching the training dataset and mitigating data scarcity. Transformer-based models have been introduced to improve attention mechanisms [<xref rid=\"bib32\" ref-type=\"bibr\">32</xref>], enabling better focus on subtle anatomical structures. In cases where source domain data is unavailable, source-free domain adaptation methods have been applied successfully in knee MRI segmentation [<xref rid=\"bib33\" ref-type=\"bibr\">33</xref>]. Additionally, knowledge distillation and semi-supervised learning techniques [<xref rid=\"bib34\" ref-type=\"bibr\">[34]</xref>, <xref rid=\"bib35\" ref-type=\"bibr\">[35]</xref>, <xref rid=\"bib36\" ref-type=\"bibr\">[36]</xref>] are being explored to leverage unlabelled data and improve efficiency, further broadening the range of solutions for automated cartilage segmentation. These developments underscore the ongoing evolution of DL for cartilage segmentation, pushing towards more accurate and efficient automated analysis in OA assessment and other musculoskeletal imaging applications. <xref rid=\"fig1\" ref-type=\"fig\">Fig. 1</xref> illustrates a visual breakdown of these advancements, categorizing the discussed approaches into model types, methodologies, specific applications, and their associated challenges.<fig id=\"fig1\" position=\"float\" orientation=\"portrait\"><label>Fig. 1</label><caption><p>Overview of advancements in automated cartilage segmentation, highlighting model classifications, methodologies, applications, and challenges in the field.</p></caption><alt-text id=\"alttext0010\">Fig. 1</alt-text><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" position=\"float\" orientation=\"portrait\" xlink:href=\"gr1.jpg\"/></fig></p></sec><sec id=\"sec2.2\"><label>2.2</label><title>Datasets and benchmarks</title><p id=\"p0055\">The following datasets: iMorphics OAI [<xref rid=\"bib37\" ref-type=\"bibr\">37</xref>,<xref rid=\"bib38\" ref-type=\"bibr\">38</xref>], SKM-TEA [<xref rid=\"bib39\" ref-type=\"bibr\">39</xref>], and OAI-ZIB [<xref rid=\"bib40\" ref-type=\"bibr\">40</xref>], are widely used public datasets that provide comprehensive labels for training and evaluating methods in knee MRI analysis, particularly for segmentation tasks. A summarized description of these datasets is presented in <xref rid=\"tbl1\" ref-type=\"table\">Table 1</xref>, highlighting their key characteristics and relevance to knee MRI analysis.<table-wrap position=\"float\" id=\"tbl1\" orientation=\"portrait\"><label>Table 1</label><caption><p>Summarized dataset details.</p></caption><alt-text id=\"alttext0025\">Table 1</alt-text><table frame=\"hsides\" rules=\"groups\"><thead><tr><th colspan=\"1\" rowspan=\"1\">Name &amp; Reference</th><th colspan=\"1\" rowspan=\"1\">Sample Size</th><th colspan=\"1\" rowspan=\"1\">Nature of subjects</th><th colspan=\"1\" rowspan=\"1\">Labels</th><th colspan=\"1\" rowspan=\"1\">Image spacing (mm)</th><th colspan=\"1\" rowspan=\"1\">Image size (px)</th><th colspan=\"1\" rowspan=\"1\">MRI sequence</th></tr></thead><tbody><tr><td colspan=\"1\" rowspan=\"1\">OAI-iMorphics [<xref rid=\"bib37\" ref-type=\"bibr\">37</xref>,<xref rid=\"bib38\" ref-type=\"bibr\">38</xref>]</td><td colspan=\"1\" rowspan=\"1\">88 subjects, 176 images [<xref rid=\"bib71\" ref-type=\"bibr\">71</xref>]</td><td colspan=\"1\" rowspan=\"1\">Moderate &amp; severe OA patients</td><td colspan=\"1\" rowspan=\"1\">FC, MTC, LTC, PC, MM, LM</td><td colspan=\"1\" rowspan=\"1\">0.365&#8727;0.465&#8727;0.7</td><td colspan=\"1\" rowspan=\"1\">384&#8727;384&#8727;160</td><td colspan=\"1\" rowspan=\"1\">3T Siemens, Sagittal 3D DESS WE [<xref rid=\"bib72\" ref-type=\"bibr\">72</xref>]</td></tr><tr><td colspan=\"1\" rowspan=\"1\">OAI-ZIB [<xref rid=\"bib40\" ref-type=\"bibr\">40</xref>]</td><td colspan=\"1\" rowspan=\"1\">507 subjects, 507 images</td><td colspan=\"1\" rowspan=\"1\">OA patients. &#8220;full spectrum of OA grades, with a strong tendency towards severe cases&#8221; [<xref rid=\"bib26\" ref-type=\"bibr\">26</xref>]</td><td colspan=\"1\" rowspan=\"1\">FB, TB, FC, MTC, LTC</td><td colspan=\"1\" rowspan=\"1\">0.365&#8727;0.465&#8727;0.7</td><td colspan=\"1\" rowspan=\"1\">384&#8727;384&#8727;160</td><td colspan=\"1\" rowspan=\"1\">3T Siemens, Sagittal 3D DESS WE [<xref rid=\"bib72\" ref-type=\"bibr\">72</xref>]</td></tr><tr><td colspan=\"1\" rowspan=\"1\">SKI-10 [<xref rid=\"bib73\" ref-type=\"bibr\">73</xref>] (Currently not accessible)</td><td colspan=\"1\" rowspan=\"1\">100 images</td><td colspan=\"1\" rowspan=\"1\">Late-stage OA patients from a surgical planning program</td><td colspan=\"1\" rowspan=\"1\">FB, TB, FC, TC</td><td colspan=\"1\" rowspan=\"1\">0.4&#8727;0.4&#8727;1</td><td colspan=\"1\" rowspan=\"1\">290&#8727;340&#8727;110 (various sizes)</td><td colspan=\"1\" rowspan=\"1\">1.5T (&#8764;90 &#8203;%), 3T and 1T (&#8764;10 &#8203;%); T1w &amp; T2w, GRE &amp; SPGR</td></tr><tr><td colspan=\"1\" rowspan=\"1\">SKM-TEA [<xref rid=\"bib39\" ref-type=\"bibr\">39</xref>]</td><td colspan=\"1\" rowspan=\"1\">155 subjects, 155 images</td><td colspan=\"1\" rowspan=\"1\">OA patients</td><td colspan=\"1\" rowspan=\"1\">FC, MTC, LTC, PC</td><td colspan=\"1\" rowspan=\"1\">0.38&#8727;0.31</td><td colspan=\"1\" rowspan=\"1\">416&#8727;512&#8727;[80&#8211;88 slices]</td><td colspan=\"1\" rowspan=\"1\">3T GE; qDESS</td></tr></tbody></table><table-wrap-foot><fn id=\"tspara0015\"><p>FB &#8203;= &#8203;femur bone, TB &#8203;= &#8203;tibia, FC &#8203;= &#8203;femoral cartilage, TC &#8203;= &#8203;tibial cartilage (one label for two sides), MTC &#8203;= &#8203;medial tibial cartilage, LTC &#8203;= &#8203;lateral tibial cartilage, PC &#8203;= &#8203;patellar cartilage, MM &#8203;= &#8203;medial meniscus, LM &#8203;= &#8203;lateral meniscus.</p></fn><fn id=\"tspara0020\"><p>Abbreviations-OA: osteoarthritis; qDESS: quantitative double-echo steady state; 3T/1.5T/1T: magnet field strength (tesla); WE: water excitation; T1w/T2w: T1-/T2-weighted; GRE/SPGR: gradient-recalled/spoiled gradient echo.</p></fn><fn id=\"tspara0025\"><p>Anatomy/labels-FB: femoral bone; TB: tibial bone; FC: femoral cartilage; TC: tibial cartilage; MTC: medial tibial cartilage; LTC: lateral tibial cartilage; -PC: patellar cartilage; MM: medial meniscus; LM: lateral meniscus.</p></fn></table-wrap-foot></table-wrap></p><sec id=\"sec2.2.1\"><label>2.2.1</label><title>iMorphics OAI dataset</title><p id=\"p0060\">The iMorphics OAI dataset [<xref rid=\"bib37\" ref-type=\"bibr\">37</xref>,<xref rid=\"bib38\" ref-type=\"bibr\">38</xref>] includes 88 patient scans available from the public Osteoarthritis Initiative (OAI) database (<ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"http://www.oai.ucsf.edu/\" id=\"intref0010\">http://www.oai.ucsf.edu</ext-link>). Images were acquired using a 3T Siemens MAGNETOM Trio scanners with Double Echo Steady State (DESS) pulse sequence with voxel size &#8203;= &#8203;0.36 &#8203;&#215; &#8203;0.36 &#8203;&#215; &#8203;0.7 &#8203;mm, matrix size &#8203;= &#8203;384 &#8203;&#215; &#8203;384, FOV &#8203;= &#8203;140 &#8203;mm, and 160 slices. The dataset includes both baseline and 12-month follow-up scans, each with corresponding manual cartilage segmentation masks. Manual segmentation of cartilage was performed by trained musculoskeletal radiologists following the iMorphics cartilage segmentation protocol, ensuring an intra-observer variation below 3 &#8203;%, with expert review for accuracy.</p><p id=\"p0065\"><bold><italic toggle=\"yes\">OAI-ZIB dataset:</italic></bold> Both the iMorphics OAI [<xref rid=\"bib37\" ref-type=\"bibr\">37</xref>,<xref rid=\"bib38\" ref-type=\"bibr\">38</xref>] and OAI-ZIB [<xref rid=\"bib40\" ref-type=\"bibr\">40</xref>] datasets are derived from the OAI. However, they differ in terms of subject selection, OA severity distribution, OA grading, and the segmentation classes provided. The OAI-ZIB dataset includes scans from patients with OA across all severity grades, with the majority representing severe cases. This dataset focuses on the segmentation of four tissues: femur bone, femoral cartilage, tibia bone, and tibial cartilage, making it a valuable resource for studying OA-related structural changes.</p><p id=\"p0070\"><bold><italic toggle=\"yes\">SKM-TEA:</italic></bold> The SKM-TEA dataset [<xref rid=\"bib39\" ref-type=\"bibr\">39</xref>] includes 155 quantitative DESS MRI knee scans acquired at Stanford University, consisting of raw k-space data, DICOM images, manual segmentations of six tissues (including cartilage and meniscus), and three-dimensional (3D) bounding boxes for 16 pathologies. The dataset is divided into 86 training, 33 validation, and 36 testing scans. Pathology annotations and tissue segmentations were manually performed, with localization based on radiology reports. This dataset supports both segmentation and pathology detection tasks.</p></sec></sec></sec><sec id=\"sec3\"><label>3</label><title>Categorization of DL methods</title><p id=\"p0075\">DL-based knee cartilage segmentation encompasses a variety of approaches designed to address the inherent challenges of 3D knee MRI. <xref rid=\"tbl2\" ref-type=\"table\">Table 2</xref> provides a summary of DL methods applied to knee MRI cartilage segmentation. Furthermore, <xref rid=\"fig2\" ref-type=\"fig\">Fig. 2</xref> illustrates slice-wise Dice Similarity Coefficient (DSC) agreement, where DSC scores are higher in central slices and decrease towards the periphery, primarily due to the partial volume effect at curved cartilage edges and through plane blurring, this trend however can be reduced with isotropic 3D imaging [<xref rid=\"bib41\" ref-type=\"bibr\">41</xref>]. This variation underscores the necessity for DL models capable of maintaining consistent performance across the entire 3D volume. To address this, several methods, including 2D/3D architectures, attention mechanisms, knowledge distillation, adversarial learning, and data augmentation, have been proposed to improve segmentation accuracy and spatial consistency [<xref rid=\"bib2\" ref-type=\"bibr\">2</xref>].<table-wrap position=\"float\" id=\"tbl2\" orientation=\"portrait\"><label>Table 2</label><caption><p>Summarized details of deep learning methods in knee MRI cartilage segmentation.</p></caption><alt-text id=\"alttext0030\">Table 2</alt-text><table frame=\"hsides\" rules=\"groups\"><thead><tr><th colspan=\"1\" rowspan=\"1\">Reference</th><th colspan=\"1\" rowspan=\"1\">MRI</th><th colspan=\"1\" rowspan=\"1\">Dataset</th><th colspan=\"1\" rowspan=\"1\">Method</th><th colspan=\"1\" rowspan=\"1\">Task</th><th colspan=\"1\" rowspan=\"1\">Results of Task</th></tr></thead><tbody><tr><td colspan=\"1\" rowspan=\"1\">Ambellan et al.<break/>2019 [<xref rid=\"bib26\" ref-type=\"bibr\">26</xref>]</td><td colspan=\"1\" rowspan=\"1\">3D DESS,</td><td colspan=\"1\" rowspan=\"1\">SKI10, OAI Imorphics and OAI<break/>ZIB datasets</td><td colspan=\"1\" rowspan=\"1\">3D Statistical Shape Models as well as 2D and 3D CNNs</td><td colspan=\"1\" rowspan=\"1\">Cartilage Segmentation &#8203;+ &#8203;Bone</td><td colspan=\"1\" rowspan=\"1\">DSC is 98.5 &#8203;% for FB,<break/>98.5 &#8203;% for TB, 89.9 &#8203;% for FC, and 85.6 &#8203;% for TC</td></tr><tr><td colspan=\"1\" rowspan=\"1\">DOSMA 2019 [<xref rid=\"bib43\" ref-type=\"bibr\">43</xref>]</td><td colspan=\"1\" rowspan=\"1\">3D DESS</td><td colspan=\"1\" rowspan=\"1\">OAI (88/176)</td><td colspan=\"1\" rowspan=\"1\">2D U-Net</td><td colspan=\"1\" rowspan=\"1\">Cartilage Segmentation &#8203;+ &#8203;Bone</td><td colspan=\"1\" rowspan=\"1\">FC (0.90), TC(0.88) PC (0.86), Meniscus (0.8)</td></tr><tr><td colspan=\"1\" rowspan=\"1\">Desai et al. 2021 [<xref rid=\"bib74\" ref-type=\"bibr\">74</xref>]</td><td colspan=\"1\" rowspan=\"1\">3D DESS</td><td colspan=\"1\" rowspan=\"1\">OAI (88/176)</td><td colspan=\"1\" rowspan=\"1\">3D U-Net</td><td colspan=\"1\" rowspan=\"1\">Cartilage Segmentation &#8203;+ &#8203;Bone</td><td colspan=\"1\" rowspan=\"1\">FC (0.88), TC(0.87) PC (0.83), Meniscus (0.84)</td></tr><tr><td colspan=\"1\" rowspan=\"1\">Zhou et al., 2018 [<xref rid=\"bib75\" ref-type=\"bibr\">75</xref>]</td><td colspan=\"1\" rowspan=\"1\">3D FSE</td><td colspan=\"1\" rowspan=\"1\">In-house 3D-FSE knee OA cohort (20 subjects)</td><td colspan=\"1\" rowspan=\"1\">CNN (CED) &#8203;+ &#8203;3D fully connected CRF &#8203;+ &#8203;3D simplex deformable modeling</td><td colspan=\"1\" rowspan=\"1\">Multi-structure segmentation (12 tissues, including Cartilage and Bone)</td><td colspan=\"1\" rowspan=\"1\">Mean DSC &gt;0.9 for FB/TB; FC 0.806 &#8203;&#177; &#8203;0.062, TC 0.801 &#8203;&#177; &#8203;0.052; ASSD &lt;1 &#8203;mm for most tissues</td></tr><tr><td colspan=\"1\" rowspan=\"1\">Liu et al., 2018 [<xref rid=\"bib76\" ref-type=\"bibr\">76</xref>]</td><td colspan=\"1\" rowspan=\"1\">T1w SPGR (SKI10), 3D-FSE, T2 maps</td><td colspan=\"1\" rowspan=\"1\">SKI10 (100 scans; 60 train/40 test), clinical 3D-FSE (60 &#8203;pts), clinical T2 maps (100 &#8203;pts)</td><td colspan=\"1\" rowspan=\"1\">SegNet (CED) &#8203;+ &#8203;3D simplex deformable modeling</td><td colspan=\"1\" rowspan=\"1\">Cartilage Segmentation &#8203;+ &#8203;Bone</td><td colspan=\"1\" rowspan=\"1\">SKI10: Cartilage VOE/VD (%): FC 28.4/8.1, TC 33.1/-1.2<break/>3D-FSE: FC/TC/PC VOE (%): 33.1/35.9/22.0; VD (%): 11.2/6.1/-3.5</td></tr><tr><td colspan=\"1\" rowspan=\"1\">Chadoulos et al. 2022 [<xref rid=\"bib77\" ref-type=\"bibr\">77</xref>]</td><td colspan=\"1\" rowspan=\"1\">3D DESS</td><td colspan=\"1\" rowspan=\"1\">OAI (76/-)</td><td colspan=\"1\" rowspan=\"1\">SegNet, VoxelMorph</td><td colspan=\"1\" rowspan=\"1\">Cartilage Segmentation</td><td colspan=\"1\" rowspan=\"1\">DSC:88.89 &#8203;%, Precision: 89.86 &#8203;%, Recall:88.12 &#8203;%</td></tr><tr><td colspan=\"1\" rowspan=\"1\">Yang M et al.<break/>2022 [<xref rid=\"bib25\" ref-type=\"bibr\">25</xref>]</td><td colspan=\"1\" rowspan=\"1\">3D DESS</td><td colspan=\"1\" rowspan=\"1\">OAI</td><td colspan=\"1\" rowspan=\"1\">GAN &#8203;+ &#8203;Transfer Learning</td><td colspan=\"1\" rowspan=\"1\">Cartilage Segmentation</td><td colspan=\"1\" rowspan=\"1\">DSC: 0.819, HD 95 of 1.463 &#8203;mm, and an<break/>ASSD of 0.350 &#8203;mm</td></tr><tr><td colspan=\"1\" rowspan=\"1\">Peng et al.<italic toggle=\"yes\">,</italic> 2022 [<xref rid=\"bib36\" ref-type=\"bibr\">36</xref>]</td><td colspan=\"1\" rowspan=\"1\">3D DESS/3D SPGR</td><td colspan=\"1\" rowspan=\"1\">SKI-10</td><td colspan=\"1\" rowspan=\"1\">KCB-Net</td><td colspan=\"1\" rowspan=\"1\">Cartilage Segmentation &#8203;+ &#8203;Bone</td><td colspan=\"1\" rowspan=\"1\">Femur 98.41 &#8203;%, Femoral: 81.67 &#8203;%, Tibia 97.97, Tibial 78 &#8203;%</td></tr><tr><td colspan=\"1\" rowspan=\"1\">Li et al. 2024 [<xref rid=\"bib33\" ref-type=\"bibr\">33</xref>]</td><td colspan=\"1\" rowspan=\"1\">3D DESS/3D SPGR</td><td colspan=\"1\" rowspan=\"1\">SKI-10</td><td colspan=\"1\" rowspan=\"1\">Source Free DA</td><td colspan=\"1\" rowspan=\"1\">Cartilage Segmentation &#8203;+ &#8203;Bone</td><td colspan=\"1\" rowspan=\"1\">Femur: 0.92, FC: 0.69, Tibia: 0.92, TC: 0.60, Av: 0.78</td></tr><tr><td colspan=\"1\" rowspan=\"1\">Ammar et al. 2025 [<xref rid=\"bib78\" ref-type=\"bibr\">78</xref>]</td><td colspan=\"1\" rowspan=\"1\">3D DESS/3D FSE</td><td colspan=\"1\" rowspan=\"1\">OAI (88/176), Private</td><td colspan=\"1\" rowspan=\"1\">Knowledge Distillation (Successive Eigen Noise, Eigen Low-Rank Subspace</td><td colspan=\"1\" rowspan=\"1\">Cartilage Segmentation</td><td colspan=\"1\" rowspan=\"1\">FC: 0.83, LTC: 0.83, MTC: 0.83, PC: 0.81, LM: 0.85, MM: 0.87, Average: 0.84</td></tr><tr><td colspan=\"1\" rowspan=\"1\">Khan et al. 2025 [<xref rid=\"bib31\" ref-type=\"bibr\">31</xref>]</td><td colspan=\"1\" rowspan=\"1\">3D DESS/3D FSE</td><td colspan=\"1\" rowspan=\"1\">OAI Imorphics and Self</td><td colspan=\"1\" rowspan=\"1\">Efficient UNet &#8203;+ &#8203;Cycle Gan</td><td colspan=\"1\" rowspan=\"1\">Cartilage Segmentation</td><td colspan=\"1\" rowspan=\"1\">FC: 0.8, LTC: 0.8, MTC: 0.8, PC: 0.8, LM: 0.8, MM: 0.8, Av: 0.8</td></tr></tbody></table><table-wrap-foot><fn id=\"tspara0035\"><p>FC &#8203;= &#8203;femoral cartilage, TC &#8203;= &#8203;tibial cartilage, MTC &#8203;= &#8203;medial tibial cartilage, LTC &#8203;= &#8203;lateral tibial cartilage, PC &#8203;= &#8203;patellar cartilage, MM &#8203;= &#8203;medial meniscus, LM &#8203;= &#8203;lateral meniscus.</p></fn><fn id=\"tspara0040\"><p>Abbreviations and metrics: 3D DESS: three-dimensional double-echo steady state; 3D FSE: three-dimensional fast spin echo; 3D SPGR: three-dimensional spoiled gradient echo; OAI: Osteoarthritis Initiative; SSM: statistical shape model; CED: convolutional encoder-decoder; CRF: conditional random field; GAN: generative adversarial network; DA: domain adaptation; DSC: Dice similarity coefficient; ASSD: average symmetric surface distance; HD95: 95th-percentile Hausdorff distance; VOE: volumetric overlap error; VD: volume difference.</p></fn><fn id=\"tspara0045\"><p>Anatomical labels: FB: femoral bone; TB: tibial bone; FC: femoral cartilage; TC: tibial cartilage; MTC: medial tibial cartilage; LTC: lateral tibial cartilage; PC: patellar cartilage; MM: medial meniscus; LM: lateral meniscus; Av: average.</p></fn></table-wrap-foot></table-wrap><fig id=\"fig2\" position=\"float\" orientation=\"portrait\"><label>Fig. 2</label><caption><p>Slice-wise 3D knee cartilage DSC (Dice Similarity Coefficient) agreement across the sagittal stack. DSC is computed between model predictions [<xref rid=\"bib48\" ref-type=\"bibr\">48</xref>] and expert manual segmentations. Slice-wise Dice scores are higher in central slices and decrease toward the periphery, largely due to partial volume effects at curved cartilage boundaries and through-plane blurring, which increase boundary uncertainty.</p></caption><alt-text id=\"alttext0015\">Fig. 2</alt-text><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" position=\"float\" orientation=\"portrait\" xlink:href=\"gr2.jpg\"/></fig></p><sec id=\"sec3.1\"><label>3.1</label><title>2D and 3D CNN segmentation</title><p id=\"p0080\">2D CNNs, such as the original U-Net [<xref rid=\"bib13\" ref-type=\"bibr\">13</xref>], process individual MRI slices and are computationally efficient. Many studies have demonstrated their effectiveness in segmenting knee structures, making them suitable for clinical use. For example, Norman et al. [<xref rid=\"bib42\" ref-type=\"bibr\">42</xref>] reported DSC accuracy of 77.0 &#8203;%&#8211;87.8 &#8203;% for cartilage and 75.3 &#8203;%&#8211;80.9 &#8203;% for menisci, showing that 2D CNNs can provide reasonable baseline segmentation on 3D-DESS scans. However, for longitudinal assessment where cartilage changes are subtle, DSC at the lower end of this range (e.g., &#8764;0.77) may be insufficient, underscoring the need for higher-accuracy or 3D/ensemble methods for precise monitoring.</p><p id=\"p0085\">In contrast, 3D CNN-based methods [<xref rid=\"bib36\" ref-type=\"bibr\">36</xref>], such as 3D U-Net and its variants, directly incorporate volumetric spatial context by processing the entire 3D MRI volume. The prior-based 3D U-Net has been proposed [<xref rid=\"bib26\" ref-type=\"bibr\">26</xref>], enhancing the standard 3D U-Net by incorporating average shape model (ASM) and subpixel technology in a two-stage process. In the first stage, it segments the femur and tibia, and in the second stage, ASM-based constraints are applied to refine cartilage segmentation. It achieved a DSC accuracy of 74.02 &#8203;%. However, some studies [<xref rid=\"bib43\" ref-type=\"bibr\">43</xref>] on 3D DESS suggest little to no improvement of 3D CNNs over 2D methods.</p><p id=\"p0090\">Recent work by Esrafilian et al. [<xref rid=\"bib44\" ref-type=\"bibr\">44</xref>] further demonstrates the usability of CNN-based segmentation in clinical modelling pipelines. They employed both 2D and 3D versions of nnU-Net [<xref rid=\"bib22\" ref-type=\"bibr\">22</xref>] to automatically segment bones, cartilages, menisci, and ligaments from knee MRI across multiple datasets. Esrafilian et al. [<xref rid=\"bib44\" ref-type=\"bibr\">44</xref>] reported DSC against expert manual annotations, supporting the practical utility of CNN-based segmentation in downstream biomechanical simulations and personalized rehabilitation planning.</p></sec><sec id=\"sec3.2\"><label>3.2</label><title>Attention mechanism models</title><p id=\"p0095\">Laing et al. [<xref rid=\"bib45\" ref-type=\"bibr\">45</xref>] proposes a Position-prior Clustering-based Self-attention Module (PCAM) for knee cartilage segmentation using MR images. PCAM integrates position-prior, clustering, and self-attention mechanisms into a V-Net architecture to capture long-range dependencies, ensure segmentation continuity, and reduce false positives. When tested on the OAI-ZIB dataset, the model demonstrated improved segmentation accuracy, achieving a DSC of 0.893 for femoral cartilage and 0.861 for tibial cartilage, outperforming plain V-Net and nnU-net [<xref rid=\"bib22\" ref-type=\"bibr\">22</xref>].</p><p id=\"p0100\">Recently, Wang and Shi [<xref rid=\"bib46\" ref-type=\"bibr\">46</xref>] proposed PA-UNet, a novel U-Net&#8211;based architecture with patch-based attention mechanisms for knee cartilage segmentation in MRI. Integrating channel-wise and patch-wise attention blocks it targets small structure detection and spatial detail. Evaluated on OAI-ZIB and SKI10, PA-UNet [<xref rid=\"bib46\" ref-type=\"bibr\">46</xref>] achieved DSCs up to 90.2 &#8203;% (femoral) and 85.7 &#8203;% (tibial), with improvements that depended on model dimensionality (2D vs. 3D) and dataset. These gains for each pair of femoral/tibial were relative to the baselines considered such as: U-Net [<xref rid=\"bib13\" ref-type=\"bibr\">13</xref>] (OAI-ZIB: 86.7/81.3; SKI10: 77.4/71.2), SeG-Net [<xref rid=\"bib47\" ref-type=\"bibr\">47</xref>] (OAI-ZIB: 86.4/80.2), U-Net++ [<xref rid=\"bib21\" ref-type=\"bibr\">21</xref>] (3D OAI-ZIB: 88.22/84.31; 3D SKI10: 77.20/71.40), Attention U-Net [<xref rid=\"bib24\" ref-type=\"bibr\">24</xref>] (3D OAI-ZIB: 88.90/84.99; 3D SKI10: 79.93/76.01), Norman et al. [<xref rid=\"bib42\" ref-type=\"bibr\">42</xref>] (SKI10 2D: 77.8/70.6). Overall, localized patch-based attention provided consistent, incremental benefits within these settings, while absolute DSCs remain within the range of strong plain U-Nets.</p></sec><sec id=\"sec3.3\"><label>3.3</label><title>Adversarial learning and augmentation</title><p id=\"p0105\">Adversarial learning, combined with augmentation, is presented as source-independent multi-domain adaptation framework [<xref rid=\"bib31\" ref-type=\"bibr\">31</xref>] for knee MRI segmentation, aiming to overcome domain shifts in clinical imaging. The architecture features a modified U-Net [<xref rid=\"bib48\" ref-type=\"bibr\">48</xref>], with compound scaling to enhance fine tissue detail extraction. It also incorporates pseudo-label attention and a GAN-enabled generator for unidirectional domain mapping. Through iterative training across 3D DESS, 3D T1-Fast Field Echo (T1-FFE), and 3D Fast/Turbo Spin Echo (FSE/TSE) datasets, the framework attains DSC of 87.01 &#8203;% (source domain) and 79.90 &#8203;% (target domain). While these absolute values are modest, they are within the typical range for cross-domain evaluations, where train/test protocols differ and show incremental improvements over non-adapted models, with notable benefits for small tissues such as the meniscus. <xref rid=\"fig3\" ref-type=\"fig\">Fig. 3</xref> is presented from Ref. [<xref rid=\"bib31\" ref-type=\"bibr\">31</xref>] to demonstrate the impact of domain generalization in segmentation, highlighting segmentation results on a 3D FSE MRI scan of an OA subject. In this example, a network trained on 3D DESS data achieves improved segmentation accuracy by utilizing adversarial learning and augmentation.<fig id=\"fig3\" position=\"float\" orientation=\"portrait\"><label>Fig. 3</label><caption><p>The figure shows the 3D FSE MRI scan of OA subject and its derived segmentation. (a) shows the ground truth labels, (b) show the segmentation from DL method. The domain adaptation helps to achieve the better segmentation even though the network is trained on 3D DESS data. (c) shows the derived thickness map corresponding to the segmentation outcome with arrows pointing out the challenging regions where cartilage is difficult to segment as shown in (a), (b) and (c).</p></caption><alt-text id=\"alttext0020\">Fig. 3</alt-text><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" position=\"float\" orientation=\"portrait\" xlink:href=\"gr3.jpg\"/></fig></p><p id=\"p0110\">Panfilov et al. [<xref rid=\"bib49\" ref-type=\"bibr\">49</xref>] uses a U-Net-based architecture for knee MRI segmentation, enhanced with mixup and unsupervised domain adaptation (UDA) techniques. The methodology introduces mixup, which generates synthetic training samples through linear interpolation, enhancing generalization and reducing overfitting. In addition, adversarial UDA is employed to align feature distributions between different MRI acquisition settings. The approach achieved DSC of 0.819 for femoral cartilage (FC) and 0.802 for tibial cartilage (TC) on an independent test set.</p></sec><sec id=\"sec3.4\"><label>3.4</label><title>Knowledge distillation</title><p id=\"p0115\">Knowledge distillation has been explored as a method for segmentation and for addressing heterogeneity in MRI datasets from diverse sources. He et al. [<xref rid=\"bib35\" ref-type=\"bibr\">35</xref>] proposes a federated few-shot learning framework with dual knowledge distillation to segment knee cartilages from heterogeneous 3D MR images. The architecture employs a teacher-student model, where dual knowledge (response-based and feature-based) is distilled from a pre-trained teacher model (using high-resolution OAI repository data) to student models at individual clients with low-resolution data. The approach addresses annotation scarcity, imaging heterogeneity, and reduces data transfer. The method outperforms state-of-the-art federated approaches, achieving a DSC of 0.789 vs DSC of 0.746 (without using prior knowledge), with significant improvements in the segmentation of small cartilage like patellar cartilage (PC), i.e 0.690 vs 0.654.</p><p id=\"p0120\">Recent approaches in knowledge distillation, such as SEN-MTKD [<xref rid=\"bib34\" ref-type=\"bibr\">34</xref>], address domain shifts and noisy pseudo-labels in knee MRI segmentation. Using a teacher-student architecture with modules like Eigen Low-Rank Subspace (ELRS) and Successive Eigen Noise (SEN), it aligns features across domains from OAI DESS and 3D FSE datasets. This method segments knee tissues such as femoral cartilage, tibial cartilage, patellar cartilage, and meniscus, achieving a Dice accuracy of 83.52 &#8203;%, outperforming state-of-the-art methods using 25 &#8203;% of labelled data.</p></sec></sec><sec id=\"sec4\"><label>4</label><title>Challenges and solutions</title><p id=\"p0125\">The advancement of DL models for knee cartilage segmentation is promising; however, clinical adoption is primarily limited by the lack of clearly established clinical use cases and integration pathways. Additional barriers include the knee's intricate anatomy, limited annotated datasets, variability in imaging protocols, and domain shifts in knee MRI. Addressing these obstacles is essential to achieve reliable, generalizable, and clinical applicable segmentation. In this section, we outline the primary technical challenges and summarize representative solutions.</p><sec id=\"sec4.1\"><label>4.1</label><title>Label scarcity and data variability</title><p id=\"p0130\">A significant challenge in developing DL methods for knee MRI segmentation is the limited availability of training datasets with high-quality manual segmentation labels. This limitation is further compounded by variations in acquisition protocols, hardware configurations, scanner models, and vendors, which introduce inconsistencies and hinder the generalizability of these models.</p><p id=\"p0135\">Although most published knee cartilage segmentation studies rely on 3D gradient-echo MRI (e.g., DESS/SPGR), multislice two-dimensional (2D) FSE remains the standard imaging sequence in clinical knee MRI. Increasingly, 3D FSE with variable flip angle modulation achieves high scan efficiency by using long echo trains without excessive blurring caused by T2 relaxation [<xref rid=\"bib50\" ref-type=\"bibr\">50</xref>]. All major MRI vendors provide commercial implementations of such techniques. With isotropic resolution, 3D FSE reduces partial volume effects along the through-plane direction, enables reformatting to arbitrary planes, and shortens overall exam time [<xref rid=\"bib51\" ref-type=\"bibr\">51</xref>]. Other rapid 3D MRI acquisition and quantitative imaging methods have also been introduced for imaging of OA [<xref rid=\"bib50\" ref-type=\"bibr\">50</xref>,<xref rid=\"bib52\" ref-type=\"bibr\">52</xref>]. This mismatch between research datasets (often 3D gradient-echo) and clinical acquisitions (2D/3D FSE) motivates methods that transfer or generalize across sequences.</p><p id=\"p0140\">Given the prevalence of FSE contrast in knee MRI, it is important to develop DL methods that can generalize to the segmentation of FSE images. However, publicly available 3D FSE data remains limited. The OAI database provides a substantial dataset acquired using the 3D DESS pulse sequence, accompanied by manually segmented labels. However, adapting models trained on OAI data to 3D FSE remains challenging. The thin, irregular 3D structure of cartilage, combined with patient-specific variability in knee anatomy and OA severity, further complicates this task [<xref rid=\"bib36\" ref-type=\"bibr\">36</xref>,<xref rid=\"bib53\" ref-type=\"bibr\">53</xref>]. The variability in image features between the source domain (DESS) and the target domain (FSE) highlights the problem of domain shift, which is further exacerbated by differences in scanner models, vendors, and acquisition protocols.</p></sec><sec id=\"sec4.2\"><label>4.2</label><title>Domain adaptation and transfer learning</title><p id=\"p0145\">Transfer learning offers a partial solution by fine-tuning pre-trained models on specific datasets [<xref rid=\"bib14\" ref-type=\"bibr\">14</xref>]. However, this approach still depends on additional labelled data from the target domain. Several studies have applied UDA techniques to knee MRI segmentation. For instance, Liu et al. [<xref rid=\"bib30\" ref-type=\"bibr\">30</xref>] incorporated a segmentation network into an adversarial framework to achieve bone and cartilage segmentation. On PD-FSE, this method yielded femoral/tibial cartilage DSCs of 0.66 and 0.65 vs 0.77 and 0.70 for supervised U-Net; on T2-FSE, 0.81 and 0.75 vs 0.82 and 0.76. These DSCs (&#8764;0.65&#8211;0.82) reflect the difficulty of unsupervised adaptation from gradient echo acquisitions to FSE without target labels. Panfilov et al. [<xref rid=\"bib49\" ref-type=\"bibr\">49</xref>] employed UDA through cross-domain alignment to enhance cartilage segmentation performance. Specifically, segmentation accuracy improved from 0.791 to 0.819 for femoral cartilage and from 0.746 to 0.802 for tibial cartilage across datasets obtained from different scanners, while maintaining a consistent pulse sequence. Li et al. [<xref rid=\"bib33\" ref-type=\"bibr\">33</xref>] proposed a source-free UDA method for knee joint segmentation, enabling adaptation without requiring access to the source dataset and effectively addressing privacy concerns. Their approach achieved a mean DSC of 0.806 (SKI-10 to OAI-ZIB) and 0.781 (OAI-ZIB to SKI-10). In certain cases, such as bone structure segmentation, the results were comparable to those of fully supervised models. These studies demonstrated the potential of UDA in knee MRI segmentation.</p></sec><sec id=\"sec4.3\"><label>4.3</label><title>Foundation model</title><p id=\"p0150\">Foundation models are gaining attentions recently. Segment Anything (SAM) [<xref rid=\"bib54\" ref-type=\"bibr\">54</xref>] and SAM2 [<xref rid=\"bib55\" ref-type=\"bibr\">55</xref>] have been developed to improve generalizability of segmentation. These foundation models are trained using a very large dataset which includes diverse image contents. The original SAM and SAM2 were trained for segmenting natural images, and variants were created for medical data. MedSAM [<xref rid=\"bib56\" ref-type=\"bibr\">56</xref>] finetuned the SAM on multiple medical datasets. In the context of knee MRI segmentation, Hoyer et al. [<xref rid=\"bib57\" ref-type=\"bibr\">57</xref>] conducted a comprehensive evaluation of SAM, SAM2, and MedSAM on knee MRI data. The initial performance of the three models without fine-tuning was limited; however, with fine-tuning, their performance became comparable to traditional segmentation models such as U-Net. This highlights the importance of developing modality-specific foundation models tailored for knee MRI, as general-purpose models trained on natural images may face challenges in generalizing effectively to this domain without targeted adaptation.</p></sec></sec><sec id=\"sec5\"><label>5</label><title>Applications of knee MRI cartilage segmentation</title><p id=\"p0155\">Accurate segmentation of knee cartilage is crucial for a variety of research and clinical applications, particularly in the context of OA and related musculoskeletal disorders. In practice, it enables progression monitoring, assessment of treatment response (e.g., after cartilage restoration or ligament/meniscal surgery), and supports surgical planning. By providing precise cartilage thickness and other morphometrics, segmentation underpins imaging biomarkers for disease tracking, cohort studies and personalized treatment strategies [<xref rid=\"bib19\" ref-type=\"bibr\">19</xref>].</p><sec id=\"sec5.1\"><label>5.1</label><title>Cartilage thickness and morphometrics</title><p id=\"p0160\">Chaudhari et al. [<xref rid=\"bib58\" ref-type=\"bibr\">58</xref>] applied DL for both super-resolution and cartilage segmentation in knee MRI. A 3D U-Net achieved Dice accuracy of 90.2 &#8203;% (original) and 89.6 &#8203;% (super-resolved) images, outperforming interpolation-based methods (86.3 &#8203;%). This demonstrates the ability of DL-based segmentation to maintain accurate cartilage morphometry, even in enhanced lower-resolution scans, and highlights its potential for scalable, automated OA analysis.</p><p id=\"p0165\">Yao et al. introduces CartiMorph [<xref rid=\"bib59\" ref-type=\"bibr\">[59]</xref>, <xref rid=\"bib60\" ref-type=\"bibr\">[60]</xref>] an automated framework for knee articular cartilage morphometrics, aimed at improving imaging biomarker extraction for knee OA. The framework quantifies cartilage subregion metrics, including full-thickness cartilage loss (FCL), mean thickness, surface area, and volume, leveraging DL models for tissue segmentation, template construction, and image registration. The authors also developed CartiMorph Toolbox (CMT) [<xref rid=\"bib60\" ref-type=\"bibr\">60</xref>] an AI-powered framework for automated knee cartilage morphometrics, focusing on cartilage shape and lesion quantification from medical images. Compared to atlas-based methods [<xref rid=\"bib12\" ref-type=\"bibr\">12</xref>], CartiMorph consistently provide more robust and quantitative metrics, supporting a wide range of clinical applications including OA progression monitoring, biomarker development, and treatment evaluation.</p><p id=\"p0170\">Kessler et al. [<xref rid=\"bib61\" ref-type=\"bibr\">61</xref>] combined DL-based segmentations with 3D cartilage surface mapping (3D-CaSM) to assess cartilage thickness and T2 values. Their findings demonstrated that 3D U-Nets produced more accurate and region-specific thickness estimates compared to 2D U-Nets, particularly in anatomically complex regions such as the femoral condyle. These results underscore the potential of DL-based segmentation for detailed, surface-level cartilage analysis.</p><p id=\"p0175\">Khan et al. [<xref rid=\"bib48\" ref-type=\"bibr\">48</xref>] presents an automatic segmentation framework for knee tissue analysis from MRI, focusing on cartilage and meniscus. The method combines a multipath convolutional neural network (CNN) with low-rank (LR) tensor reconstruction to extract structural similarities from 3D MRI blocks, generates trimaps to identify high-confidence regions, and employs alpha matting for accurate boundary refinement. Validated on the OAI dataset, the method achieved average DSC of 0.892 across six knee tissue compartments, with femoral and tibial cartilage exceeding 0.9. The approach also demonstrated robust segmentation in thin cartilage regions and late-stage OA cases, along with thickness mapping on 3D DESS and FFET1 MRI volumes.</p><p id=\"p0180\">Iriondo et al. [<xref rid=\"bib62\" ref-type=\"bibr\">62</xref>] developed a fully automated DL pipeline using CNN ensembles for knee cartilage segmentation and thickness measurement, achieving high accuracy (DSC: femur 0.89, tibia 0.88, patella 0.85; concordance correlation coefficient (CCC) up to 0.93 vs. manual). They analyzed 8-year trajectories in 1453 knees, identifying distinct patterns of cartilage thinning and thickening. Nonstable trajectories, especially in the medial compartments, were associated with significantly higher odds of incident radiographic OA (e.g., odds ratio &#8203;= &#8203;10.1 for accelerated thinning in medial femur). This approach enables improved OA phenotyping and longitudinal assessment of cartilage degeneration.</p><p id=\"p0185\">While DL markedly reduces reader time, longitudinal utility depends on responsiveness to change. A fully automated U-Net trained on radiographic OA knees detected 24-month cartilage thickness loss with responsiveness comparable to expert manual segmentation and similar cohort discrimination, identifying a comparable proportion of individual progressors [<xref rid=\"bib63\" ref-type=\"bibr\">63</xref>]. DL model trained on healthy-reference knees showed reduced responsiveness, highlighting the need for OA-specific training.</p><p id=\"p0190\"><xref rid=\"tbl3\" ref-type=\"table\">Table 3</xref> provides a summary of the cartilage thickness mapping methods, along with their final outcomes based on thickness measurements.<table-wrap position=\"float\" id=\"tbl3\" orientation=\"portrait\"><label>Table 3</label><caption><p>Summarized details of deep learning methods in knee MRI cartilage segmentation and their applications in thickness measurement.</p></caption><alt-text id=\"alttext0035\">Table 3</alt-text><table frame=\"hsides\" rules=\"groups\"><thead><tr><th colspan=\"6\" rowspan=\"1\">Cartilage Segmentation applications in thickness<hr/></th></tr><tr><th colspan=\"1\" rowspan=\"1\">Reference</th><th colspan=\"1\" rowspan=\"1\">MRI</th><th colspan=\"1\" rowspan=\"1\">Dataset</th><th colspan=\"1\" rowspan=\"1\">Method</th><th colspan=\"1\" rowspan=\"1\">Task</th><th colspan=\"1\" rowspan=\"1\">Results of Task</th></tr></thead><tbody><tr><td colspan=\"1\" rowspan=\"1\">Chaudhari et al., 2020 [<xref rid=\"bib58\" ref-type=\"bibr\">58</xref>]</td><td colspan=\"1\" rowspan=\"1\">3D DESS</td><td colspan=\"1\" rowspan=\"1\">OAI</td><td colspan=\"1\" rowspan=\"1\">DeepResolve (3D CNN SR) &#8203;+ &#8203;3D U-Net segmentation</td><td colspan=\"1\" rowspan=\"1\">Super-resolution &#8203;+ &#8203;Cartilage segmentation &#8203;+ &#8203;Morphometry</td><td colspan=\"1\" rowspan=\"1\">DSCs: 89.6 &#8203;% (SR), 90.2 &#8203;% (HR); Overlap with HR: 97.6 &#8203;% (SR), 95.0 &#8203;% (TCI); RMS-CV% (volume): 2.8 &#8203;% (SR), 3.1 &#8203;% (HR), 4.9 &#8203;% (TCI)</td></tr><tr><td colspan=\"1\" rowspan=\"1\">Iriondo et al., 2021 [<xref rid=\"bib62\" ref-type=\"bibr\">62</xref>]</td><td colspan=\"1\" rowspan=\"1\">3D DESS,</td><td colspan=\"1\" rowspan=\"1\">OAI-ZIB Dataset</td><td colspan=\"1\" rowspan=\"1\">Ensemble of 6 CNNs (2D and 3D) &#8203;+ &#8203;Euclidean Distance Transform &#8203;+ &#8203;Skeletonization</td><td colspan=\"1\" rowspan=\"1\">Automatic segmentation &#8203;+ &#8203;Subcompartmentalization &#8203;+ &#8203;Thickness measurement &#8203;+ &#8203;Longitudinal trajectory analysis</td><td colspan=\"1\" rowspan=\"1\">MAE: 0.11&#8211;0.14 &#8203;mm (vs manual); Reproducibility: 0.04&#8211;0.07 &#8203;mm; DSCs: femoral: 0.890, tibial: 0.880, patellar: 0.850; CCC: 0.817&#8211;0.929; RMS CV%: &lt;3.5 &#8203;%;</td></tr><tr><td colspan=\"1\" rowspan=\"1\">Kessler et al.<break/>2022 [<xref rid=\"bib61\" ref-type=\"bibr\">61</xref>]</td><td colspan=\"1\" rowspan=\"1\">3D DESS, FFET1</td><td colspan=\"1\" rowspan=\"1\">OAI Imorphics</td><td colspan=\"1\" rowspan=\"1\">Surface-based cartilage analysis, thickness, T2 composition, manual segmentation, network-generated segmentation, OAI-ZIB testing images.</td><td colspan=\"1\" rowspan=\"1\">Segmentation &#8203;+ &#8203;Cartilage thickness map &#8203;+ &#8203;measurement</td><td colspan=\"1\" rowspan=\"1\">Range: 3D UNet: 0.07 to 0.14 [-0.14, 0.39] mm. For T2, mean bias: 95 &#8203;%<break/>Range: 0.16 to 1.32 [-4.71, 4.83] ms</td></tr><tr><td colspan=\"1\" rowspan=\"1\">Khan et al., 2022 [<xref rid=\"bib48\" ref-type=\"bibr\">48</xref>]</td><td colspan=\"1\" rowspan=\"1\">3D DESS, FFET1</td><td colspan=\"1\" rowspan=\"1\">OAI Imorphics and Self</td><td colspan=\"1\" rowspan=\"1\">Efficient UNet &#8203;+ &#8203;Matting &#8203;+ &#8203;Geometric norm</td><td colspan=\"1\" rowspan=\"1\">Segmentation &#8203;+ &#8203;Cartilage thickness map</td><td colspan=\"1\" rowspan=\"1\">FC (0.91),LTC (0.91), MTC (0.89), PC (0.87), LM (0.88), MM (0.87)</td></tr><tr><td colspan=\"1\" rowspan=\"1\">Yao et al., 2024 [<xref rid=\"bib59\" ref-type=\"bibr\">59</xref>]</td><td colspan=\"1\" rowspan=\"1\">3D DESS,</td><td colspan=\"1\" rowspan=\"1\">OAI-ZIB Dataset</td><td colspan=\"1\" rowspan=\"1\">Ensemble of 2D and 3D Models<break/>Surface-Normal-Based Thickness Mapping</td><td colspan=\"1\" rowspan=\"1\">Segmentation &#8203;+ &#8203;Cartilage thickness map &#8203;+ &#8203;measurement</td><td colspan=\"1\" rowspan=\"1\">RMSD: &lt;8 &#8203;%.<break/>CVRMSD: &lt;0.17<break/>Mean Thickness: 0.82&#8211;0.97<break/>Surface Area: 0.82&#8211;0.98<break/>Volume: 0.89&#8211;0.98</td></tr><tr><td colspan=\"1\" rowspan=\"1\">Jansen et al., 2025 [<xref rid=\"bib79\" ref-type=\"bibr\">79</xref>]</td><td colspan=\"1\" rowspan=\"1\">3D SPGR</td><td colspan=\"1\" rowspan=\"1\">IMI-APPROACH [<xref rid=\"bib80\" ref-type=\"bibr\">80</xref>]</td><td colspan=\"1\" rowspan=\"1\">Deep learning &#8203;+ &#8203;manual correction &#8203;+ &#8203;CaSM (3D surface mapping)</td><td colspan=\"1\" rowspan=\"1\">Cartilage segmentation &#8203;+ &#8203;Thickness mapping &#8203;+ &#8203;Statistical analysis</td><td colspan=\"1\" rowspan=\"1\">Vertex-wise thickness (min &#8764;1.5 &#8203;mm); male sex &amp; height linked to increased thickness; OA severity (KL, JSN, BMLs, osteophytes) linked to region-specific thinning or thickening (&#8722;0.35 to +0.5 &#8203;mm)</td></tr><tr><td colspan=\"1\" rowspan=\"1\">G. Hoyer et al., 2025 [<xref rid=\"bib69\" ref-type=\"bibr\">69</xref>]</td><td colspan=\"1\" rowspan=\"1\">3D DESS</td><td colspan=\"1\" rowspan=\"1\">OAI</td><td colspan=\"1\" rowspan=\"1\">Ensemble of 2D and 3D V-Nets &#8203;+ &#8203;PCA &#8203;+ &#8203;Multivariate regression analysis</td><td colspan=\"1\" rowspan=\"1\">Bone and cartilage segmentation &#8203;+ &#8203;Bone Shape &#8203;+ &#8203;Cartilage thickness</td><td colspan=\"1\" rowspan=\"1\">DSCs: Meniscus (0.87); FC (0.89); TC(0.88); PC(0.85) and Bones (0.85).<break/>Cartilage Thickness: MAE (auto vs manual): &#8804;0.15 &#8203;mm; Reproducibility (scan&#8211;rescan): &#8804;0.053 &#8203;&#177; &#8203;0.03 &#8203;mm</td></tr></tbody></table><table-wrap-foot><fn id=\"tspara0055\"><p>Abbreviations-3D DESS: three-dimensional double-echo steady state; 3D SPGR: three-dimensional spoiled gradient echo; FFE/T1: fast field echo T1; SR: super-resolution; HR: high resolution; TCI: tricubic interpolation; EDT: Euclidean distance transform; CaSM: cartilage surface mapping; PCA: principal component analysis; CCC: concordance correlation coefficient; MAE: mean absolute error; RMSD: root-mean-square difference; CVRMSD: coefficient of variation of RMSD; RMS-CV%: root-mean-square coefficient of variation; DSC: Dice similarity coefficient; KL: Kellgren-Lawrence grade; JSN: joint space narrowing; BML: bone marrow lesion.</p></fn><fn id=\"tspara0060\"><p>Anatomy-FB: femur; TB: tibia; FC: femoral cartilage; TC: tibial cartilage; MTC: medial tibial cartilage; LTC: lateral tibial cartilage; PC: patellar cartilage; MM: medial meniscus; LM: lateral meniscus. Measurements-thickness maps/values are in mm unless noted; T2 values in ms.</p></fn></table-wrap-foot></table-wrap></p></sec><sec id=\"sec5.2\"><label>5.2</label><title>MRI segmentation with biochemical imaging</title><p id=\"p0195\">Razmjoo et al. [<xref rid=\"bib64\" ref-type=\"bibr\">64</xref>] developed a 3D V-Net DL model for automatic cartilage segmentation and T2 relaxometry across the entire OAI dataset (25,729 MRIs). The model achieved DSC up to 0.75 and T2 values strongly correlated with manual measurements. Elevated T2 in medial femur and tibia was significantly associated with future OA incidence and total knee replacement. This study highlights T2 mapping as a promising early imaging biomarker for OA diagnosis and risk prediction.</p><p id=\"p0200\">Zhong et al. [<xref rid=\"bib65\" ref-type=\"bibr\">65</xref>] proposes an automated post-processing pipeline for T1&#961; imaging of knee cartilage to facilitate quantitative MRI analysis. The pipeline includes image standardization, DL-based cartilage segmentation, subregion parcellation into 20 regions, and T1&#961; quantification. Evaluated on 40 subjects (30 OA patients, 10 healthy volunteers), the method showed reliable segmentation performance (DSCs: 0.74&#8211;0.88) and T1&#961; quantification with minimal error (RMSD: 0.79 &#8203;ms for patients, 0.56 &#8203;ms for volunteers). This pipeline enables efficient subregional cartilage mapping, supporting early OA detection, prognosis, and treatment monitoring in clinical applications.</p><p id=\"p0205\">Schmidt et al. [<xref rid=\"bib53\" ref-type=\"bibr\">53</xref>] evaluated two 2D U-Net models for automated knee cartilage segmentation across diverse qDESS MRI (SKM-TEA dataset). The qDESS-trained model achieved strong performance (DSCs: 0.79&#8211;0.93; T2 CCC: 0.75&#8211;0.98) across scanners and populations without fine-tuning. Its robust accuracy in both morphology and relaxometry supports its application in large-scale, multi-site quantitative MRI studies.</p><p id=\"p0210\">Goyal et al. [<xref rid=\"bib66\" ref-type=\"bibr\">66</xref>] present an open-source, fully automated &#8220;KneePipeline&#8221; that segments knee bones, cartilage, and menisci from qDESS MRI using a 2D U-Net and derives key biochemical/morphometric biomarkers (cartilage T2, cartilage thickness, meniscus volume, femoral BScore). In a 20-subject prospective cohort with two manual annotators, cartilage segmentation achieved DSC &#8776;0.84&#8211;0.91 (higher for bone; meniscus &#8764;0.85&#8211;0.89). Automated quantitative outputs closely matched manual references (cartilage T2 ICC 0.89&#8211;0.99; thickness ICC 0.68&#8211;0.93). The pipeline enables rapid, reproducible whole-joint biochemical MRI analysis for knee osteoarthritis, with optional support for PET-based bone metabolism metrics.</p><p id=\"p0215\">Pedoia et al. [<xref rid=\"bib67\" ref-type=\"bibr\">67</xref>] used baseline OAI T2 maps to classify knees with and without radiographic OA. Using atlas-based segmentation and voxel-based relaxometry, they found widespread T2 prolongation in OA, especially in deep cartilage layers. A DenseNet trained on flattened T2 maps achieved area under the curve (AUC) 83.4 &#8203;% (95 &#8203;% CI&#8764;82.5&#8211;84.3) with Sensitivity 77.0 &#8203;% (95 &#8203;% CI&#8764;74.2&#8211;79.8), Specificity 77.9 &#8203;% (95 &#8203;% CI&#8764;75.1&#8211;80.6), outperforming a best shallow model using principal component analysis (PCA) features and demographics (AUC 77.8 &#8203;%). The difference in misclassification rates (22.83 &#8203;% vs 30.5 &#8203;%) was statistically significant (McNemar's &#967;<sup>2</sup> &#8203;= &#8203;10.33, p &#8203;= &#8203;0.0013). The study demonstrates that deep learning on T2 relaxometry captures meaningful biochemical changes and improves early OA detection over traditional approaches.</p></sec><sec id=\"sec5.3\"><label>5.3</label><title>MRI-based OA analytics and knee replacement</title><p id=\"p0220\">Qiu et al. [<xref rid=\"bib68\" ref-type=\"bibr\">68</xref>] presented cross-plane and cross-sequence attention with ResNet3D-based encoders to diagnose 12 knee abnormalities, including meniscal tears and ligament injuries, from multi-sequence MRI data (PDW, T1W, T2W across sagittal, coronal, and axial planes). Tested on 1748 patients, it achieved an area under the receiver operating characteristic curve (AUC-ROC) of 0.812, outperforming junior radiologists and enhancing diagnostic accuracy as an assistive tool for senior radiologists.</p><p id=\"p0225\">Tack et al. [<xref rid=\"bib27\" ref-type=\"bibr\">27</xref>] proposed a fully automated method combining 2D and 3D U-Net CNNs with statistical shape models for segmenting knee menisci and tibial cartilage from sagittal DESS MRI. The approach utilized segmentation, enabling extraction of quantitative biomarkers like meniscal volume, tibial coverage, and extrusion. Notably, medial meniscal extrusion predicted incident OA with an odds ratio of 1.51 (P &#8203;= &#8203;0.001), demonstrating the utility of DL-based segmentation for OA biomarker analysis in large-scale MRI studies.</p><p id=\"p0230\">G. Hoyer et al. [<xref rid=\"bib69\" ref-type=\"bibr\">69</xref>] presents a framework for creating a knee joint digital twin using quantitative MRI and machine learning to predict OA progression and knee replacement (KR) outcomes. Using OAI data with over 4700 participants, the authors identified significant imaging biomarkers across cartilage thickness, T2 relaxation time, and bone and meniscus shapes. Notably, femoral cartilage thickness principal component (PC-2) was protective in both OA incidence and KR models (e.g., odds ratio&#8776;0.95, p &#8203;&lt; &#8203;0.001), while tibial bone shape and patellar/femoral T2 modes were associated with increased KR risk (p &#8203;&lt; &#8203;0.01). The study also introduced a 3D visualization tool to help radiologists interpret biomarkers, enabling personalized knee health monitoring.</p><p id=\"p0235\">Zhong et al. [<xref rid=\"bib70\" ref-type=\"bibr\">70</xref>] proposes an automated knee OA phenotype classification along with UDA. Using a CNN encoder trained on the OAI dataset and adapted to a smaller, locally collected 3D FSE MRI dataset, the method classifies cartilage/meniscus and subchondral bone phenotypes. The integration of segmentation outputs into phenotype classification pipelines strengthens the anatomical relevance of predictions, facilitating their application in OA grading and progression tracking.</p></sec></sec><sec id=\"sec6\"><label>6</label><title>Conclusion</title><p id=\"p0240\">Automated segmentation methods, powered by DL are at least as accurate as expert manual approaches, often more consistent than traditional (non-DL, hand-crafted) pipelines. The advancements in DL methods facilitate precise identification of structural changes in cartilage and other knee tissues, enabling automatic detection of degenerative conditions and more effective clinical decision-making.</p><p id=\"p0245\">Despite significant progress, several hurdles remain. Variability in imaging protocols and patient-specific anatomical differences often lead to inconsistencies when applying models across diverse datasets. Efforts to overcome this issue, such as leveraging domain adaptation and integration of synthetic data, have shown promise but require further refinement to ensure broader applicability. Additionally, the limited availability of annotated datasets continues to constrain the development of robust models, with researchers exploring alternative solutions like semi-supervised learning and the foundation models to mitigate this bottleneck.</p></sec><sec id=\"sec8\"><title>Author contribution</title><p id=\"p0255\">Sheheryar Khan led study's conceptualization, performed the main part of the writing, data preparation, experimentation and results presentation. Muhammad Ammar Khawar contributed in writeup, focusing on DL methods, writing analysis of Knowledge distillation methods. Muhammad Asim assisted in writing the manuscript and preparing figures. Junru Zhong provided dataset information and created data tables along with editing and analysis. Rizwan Qureshi contributed to writing the section on applications in knee cartilage segmentation. Weitian Chen aided in conceptualization, overseeing the work, critical analysis on MRI pulse sequences, IRB approval, provided resources, and contributed to reviewing and editing the manuscript for submission.</p></sec><sec id=\"sec9\"><title>IRB approval</title><p id=\"p0260\">This study was conducted with IRB approval from the joint CUHK-NTEC.</p><p id=\"p0265\">Clinical Research Ethics Committee (reference number: CREC 2020.115 (Apr 15, 2020).</p></sec><sec sec-type=\"COI-statement\" id=\"coi0010\"><title>Conflict of interest</title><p id=\"p0270\">None of the authors have conflict of interest to disclose.</p></sec></body><back><ref-list id=\"cebib0010\"><title>References</title><ref id=\"bib1\"><label>1</label><element-citation publication-type=\"journal\" id=\"sref1\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Cross</surname><given-names>M.</given-names></name><etal/></person-group><article-title>The global burden of hip and knee osteoarthritis: estimates from the global burden of disease 2010 study</article-title><source>Ann. Rheum. Dis.</source><volume>73</volume><issue>7</issue><year>2014</year><fpage>1323</fpage><lpage>1330</lpage><pub-id pub-id-type=\"pmid\">24553908</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1136/annrheumdis-2013-204763</pub-id></element-citation></ref><ref id=\"bib2\"><label>2</label><element-citation publication-type=\"journal\" id=\"sref2\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Bousson</surname><given-names>V.</given-names></name><name name-style=\"western\"><surname>Benoist</surname><given-names>N.</given-names></name><name name-style=\"western\"><surname>Guetat</surname><given-names>P.</given-names></name><name name-style=\"western\"><surname>Attan&#233;</surname><given-names>G.</given-names></name><name name-style=\"western\"><surname>Salvat</surname><given-names>C.</given-names></name><name name-style=\"western\"><surname>Perronne</surname><given-names>L.</given-names></name></person-group><article-title>Application of artificial intelligence to imaging interpretations in the musculoskeletal area: where are we? Where are we going?</article-title><source>Jt. Bone Spine</source><volume>90</volume><issue>1</issue><year>2023</year><object-id pub-id-type=\"publisher-id\">105493</object-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1016/j.jbspin.2022.105493</pub-id><pub-id pub-id-type=\"pmid\">36423783</pub-id></element-citation></ref><ref id=\"bib3\"><label>3</label><element-citation publication-type=\"journal\" id=\"sref3\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Felson</surname><given-names>D.T.</given-names></name><etal/></person-group><article-title>A new approach yields high rates of radiographic progression in knee osteoarthritis</article-title><source>J. Rheumatol.</source><volume>35</volume><issue>10</issue><year>2008</year><fpage>2047</fpage><lpage>2054</lpage><pub-id pub-id-type=\"pmid\">18793000</pub-id><pub-id pub-id-type=\"pmcid\">PMC2758234</pub-id></element-citation></ref><ref id=\"bib4\"><label>4</label><element-citation publication-type=\"journal\" id=\"sref4\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Wang</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>Wluka</surname><given-names>A.E.</given-names></name><name name-style=\"western\"><surname>Jones</surname><given-names>G.</given-names></name><name name-style=\"western\"><surname>Ding</surname><given-names>C.</given-names></name><name name-style=\"western\"><surname>Cicuttini</surname><given-names>F.M.</given-names></name></person-group><article-title>Use magnetic resonance imaging to assess articular cartilage</article-title><source>Ther. Adv. Musculoskelet. Dis.</source><volume>4</volume><issue>2</issue><year>2012</year><fpage>77</fpage><lpage>97</lpage><pub-id pub-id-type=\"pmid\">22870497</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1177/1759720X11431005</pub-id><pub-id pub-id-type=\"pmcid\">PMC3383521</pub-id></element-citation></ref><ref id=\"bib5\"><label>5</label><element-citation publication-type=\"journal\" id=\"sref5\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Roemer</surname><given-names>F.W.</given-names></name><name name-style=\"western\"><surname>Crema</surname><given-names>M.D.</given-names></name><name name-style=\"western\"><surname>Trattnig</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Guermazi</surname><given-names>A.</given-names></name></person-group><article-title>Advances in imaging of osteoarthritis and cartilage</article-title><source>Radiology</source><volume>260</volume><issue>2</issue><year>2011</year><fpage>332</fpage><lpage>354</lpage><pub-id pub-id-type=\"pmid\">21778451</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1148/radiol.11101359</pub-id></element-citation></ref><ref id=\"bib6\"><label>6</label><element-citation publication-type=\"journal\" id=\"sref6\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Link</surname><given-names>T.M.</given-names></name><name name-style=\"western\"><surname>Joseph</surname><given-names>G.B.</given-names></name><name name-style=\"western\"><surname>Li</surname><given-names>X.</given-names></name></person-group><article-title>MRI-based T1rho and T2 cartilage compositional imaging in osteoarthritis: what have we learned and what is needed to apply it clinically and in a trial setting?</article-title><source>Skelet. Radiol.</source><volume>52</volume><issue>11</issue><year>Nov.2023</year><fpage>2137</fpage><lpage>2147</lpage><pub-id pub-id-type=\"doi\">10.1007/S00256-023-04310-X/METRICS</pub-id><pub-id pub-id-type=\"pmcid\">PMC11409322</pub-id><pub-id pub-id-type=\"pmid\">37000230</pub-id></element-citation></ref><ref id=\"bib7\"><label>7</label><element-citation publication-type=\"journal\" id=\"sref7\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Oei</surname><given-names>E.H.G.</given-names></name><name name-style=\"western\"><surname>Hirvasniemi</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>vanZadelhoff</surname><given-names>T.A.</given-names></name><name name-style=\"western\"><surname>van derHeijden</surname><given-names>R.A.</given-names></name></person-group><article-title>Osteoarthritis year in review 2021: imaging</article-title><source>Osteoarthr. Cartil.</source><volume>30</volume><issue>2</issue><year>Feb.2022</year><fpage>226</fpage><lpage>236</lpage><pub-id pub-id-type=\"doi\">10.1016/J.JOCA.2021.11.012</pub-id><pub-id pub-id-type=\"pmid\">34838670</pub-id></element-citation></ref><ref id=\"bib8\"><label>8</label><element-citation publication-type=\"journal\" id=\"sref8\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Atkinson</surname><given-names>H.F.</given-names></name><etal/></person-group><article-title>MRI T2 and T1&#961; relaxation in patients at risk for knee osteoarthritis: a systematic review and meta-analysis</article-title><source>BMC Musculoskelet. Disord.</source><volume>20</volume><issue>1</issue><year>2019</year><fpage>1</fpage><lpage>18</lpage><pub-id pub-id-type=\"doi\">10.1186/S12891-019-2547-7</pub-id><comment>2019 201</comment><pub-id pub-id-type=\"pmid\">31039785</pub-id><pub-id pub-id-type=\"pmcid\">PMC6492327</pub-id></element-citation></ref><ref id=\"bib9\"><label>9</label><element-citation publication-type=\"journal\" id=\"sref9\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Le</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>Peng</surname><given-names>Q.</given-names></name><name name-style=\"western\"><surname>Sperling</surname><given-names>K.</given-names></name></person-group><article-title>Biochemical magnetic resonance imaging of knee articular cartilage: T1rho and T2 mapping as cartilage degeneration biomarkers</article-title><source>Ann. N. Y. Acad. Sci.</source><volume>1383</volume><issue>1</issue><year>Nov.2016</year><fpage>34</fpage><lpage>42</lpage><pub-id pub-id-type=\"doi\">10.1111/NYAS.13189</pub-id><pub-id pub-id-type=\"pmid\">27472534</pub-id></element-citation></ref><ref id=\"bib10\"><label>10</label><element-citation publication-type=\"journal\" id=\"sref10\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Rankin</surname><given-names>I.A.</given-names></name><etal/></person-group><article-title>Fast-field cycling magnetic resonance imaging &#8211; developing a new biomarker for early osteoarthritis of the knee</article-title><source>Osteoarthr. Cartil.</source><volume>26</volume><year>Apr.2018</year><object-id pub-id-type=\"publisher-id\">S467</object-id><pub-id pub-id-type=\"doi\">10.1016/j.joca.2018.02.881</pub-id></element-citation></ref><ref id=\"bib11\"><label>11</label><element-citation publication-type=\"journal\" id=\"sref11\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Zayniddinov</surname><given-names>X.N.</given-names></name><name name-style=\"western\"><surname>Normatov</surname><given-names>R.M.</given-names></name><name name-style=\"western\"><surname>Azimov</surname><given-names>B.R.</given-names></name><name name-style=\"western\"><surname>Gafurov</surname><given-names>S.A.</given-names></name></person-group><article-title>Tools for manual 3D medical image segmentation and data preprocessing for automatic 3D medical image segmentation</article-title><source>Int. J. Sci. Res. Index.</source><volume>5</volume><issue>1</issue><year>2024</year><fpage>233</fpage><lpage>237</lpage></element-citation></ref><ref id=\"bib12\"><label>12</label><element-citation publication-type=\"journal\" id=\"sref12\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Ebrahimkhani</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Jaward</surname><given-names>M.H.</given-names></name><name name-style=\"western\"><surname>Cicuttini</surname><given-names>F.M.</given-names></name><name name-style=\"western\"><surname>Dharmaratne</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Wang</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>deHerrera</surname><given-names>A.G.S.</given-names></name></person-group><article-title>A review on segmentation of knee articular cartilage: from conventional methods towards deep learning</article-title><source>Artif. Intell. Med.</source><volume>106</volume><issue>January 2019</issue><year>2020</year><object-id pub-id-type=\"publisher-id\">101851</object-id><pub-id pub-id-type=\"doi\">10.1016/j.artmed.2020.101851</pub-id><pub-id pub-id-type=\"pmid\">32593389</pub-id></element-citation></ref><ref id=\"bib13\"><label>13</label><element-citation publication-type=\"book\" id=\"sref13\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Ronneberger</surname><given-names>O.</given-names></name><name name-style=\"western\"><surname>Fischer</surname><given-names>P.</given-names></name><name name-style=\"western\"><surname>Brox</surname><given-names>T.</given-names></name></person-group><part-title>U-net: convolutional networks for biomedical image segmentation</part-title><source>Medical Image Computing and computer-assisted intervention&#8211;MICCAI 2015: 18Th International Conference, Munich, Germany, October 5-9, 2015, Proceedings, Part III 18</source><year>2015</year><publisher-name>Springer</publisher-name><fpage>234</fpage><lpage>241</lpage></element-citation></ref><ref id=\"bib14\"><label>14</label><element-citation publication-type=\"journal\" id=\"sref14\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Mead</surname><given-names>K.</given-names></name><name name-style=\"western\"><surname>Cross</surname><given-names>T.</given-names></name><name name-style=\"western\"><surname>Roger</surname><given-names>G.</given-names></name><name name-style=\"western\"><surname>Sabharwal</surname><given-names>R.</given-names></name><name name-style=\"western\"><surname>Singh</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Giannotti</surname><given-names>N.</given-names></name></person-group><article-title>MRI deep learning models for assisted diagnosis of knee pathologies: a systematic review</article-title><source>Eur. Radiol.</source><year>2024</year><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1007/s00330-024-11105-8</pub-id><pub-id pub-id-type=\"pmcid\">PMC12021734</pub-id><pub-id pub-id-type=\"pmid\">39422725</pub-id></element-citation></ref><ref id=\"bib15\"><label>15</label><element-citation publication-type=\"journal\" id=\"sref15\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Mathiessen</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Ashbeck</surname><given-names>E.L.</given-names></name><name name-style=\"western\"><surname>Huang</surname><given-names>E.</given-names></name><name name-style=\"western\"><surname>Bedrick</surname><given-names>E.J.</given-names></name><name name-style=\"western\"><surname>Kwoh</surname><given-names>C.K.</given-names></name><name name-style=\"western\"><surname>Duryea</surname><given-names>J.</given-names></name></person-group><article-title>Cartilage topography assessment with local area cartilage segmentation (LACS) for knee MRI</article-title><source>Arthritis Care Res.</source><volume>74</volume><issue>12</issue><year>Dec.2022</year><fpage>2013</fpage><pub-id pub-id-type=\"doi\">10.1002/ACR.24745</pub-id><pub-id pub-id-type=\"pmcid\">PMC8727638</pub-id><pub-id pub-id-type=\"pmid\">34219396</pub-id></element-citation></ref><ref id=\"bib16\"><label>16</label><element-citation publication-type=\"journal\" id=\"sref16\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Latif</surname><given-names>M.H.A.</given-names></name><name name-style=\"western\"><surname>Faye</surname><given-names>I.</given-names></name></person-group><article-title>Automated tibiofemoral joint segmentation based on deeply supervised 2D-3D ensemble U-Net: data from the osteoarthritis initiative</article-title><source>Artif. Intell. Med.</source><volume>122</volume><year>2021</year><pub-id pub-id-type=\"doi\">10.1016/j.artmed.2021.102213</pub-id><pub-id pub-id-type=\"pmid\">34823835</pub-id></element-citation></ref><ref id=\"bib17\"><label>17</label><element-citation publication-type=\"journal\" id=\"sref17\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Wirth</surname><given-names>W.</given-names></name><etal/></person-group><article-title>Accuracy and longitudinal reproducibility of quantitative femorotibial cartilage measures derived from automated U-Net-based segmentation of two different MRI contrasts: data from the osteoarthritis initiative healthy reference cohort</article-title><source>Magn. Reson. Mater. Physics, Biol. Med.</source><volume>34</volume><issue>3</issue><year>Jun.2021</year><fpage>337</fpage><lpage>354</lpage><pub-id pub-id-type=\"doi\">10.1007/S10334-020-00889-7/TABLES/6</pub-id><pub-id pub-id-type=\"pmcid\">PMC8154803</pub-id><pub-id pub-id-type=\"pmid\">33025284</pub-id></element-citation></ref><ref id=\"bib18\"><label>18</label><element-citation publication-type=\"journal\" id=\"sref18\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Martel-Pelletier</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>Paiement</surname><given-names>P.</given-names></name><name name-style=\"western\"><surname>Pelletier</surname><given-names>J.P.</given-names></name></person-group><article-title>Magnetic resonance imaging assessments for knee segmentation and their use in combination with machine/deep learning as predictors of early osteoarthritis diagnosis and prognosis</article-title><source>Ther. Adv. Musculoskelet. Dis.</source><volume>15</volume><year>Jan.2023</year><pub-id pub-id-type=\"doi\">10.1177/1759720X231165560</pub-id><comment>1759720X231165560</comment><pub-id pub-id-type=\"pmcid\">PMC10155034</pub-id><pub-id pub-id-type=\"pmid\">37151912</pub-id></element-citation></ref><ref id=\"bib19\"><label>19</label><element-citation publication-type=\"journal\" id=\"sref19\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Martel-Pelletier</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>Paiement</surname><given-names>P.</given-names></name><name name-style=\"western\"><surname>Pelletier</surname><given-names>J.-P.</given-names></name></person-group><article-title>Magnetic resonance imaging assessments for knee segmentation and their use in combination with machine/deep learning as predictors of early osteoarthritis diagnosis and prognosis</article-title><source>Ther. Adv. Musculoskelet. Dis.</source><volume>15</volume><year>2023</year><comment>1759720X231165560</comment><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1177/1759720X231165560</pub-id><pub-id pub-id-type=\"pmcid\">PMC10155034</pub-id><pub-id pub-id-type=\"pmid\">37151912</pub-id></element-citation></ref><ref id=\"bib20\"><label>20</label><element-citation publication-type=\"journal\" id=\"sref20\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Avanzo</surname><given-names>M.</given-names></name><name name-style=\"western\"><surname>Stancanello</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>Pirrone</surname><given-names>G.</given-names></name><name name-style=\"western\"><surname>Drigo</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Retico</surname><given-names>A.</given-names></name></person-group><article-title>The evolution of artificial intelligence in medical imaging: from computer science to machine and deep learning</article-title><source>Cancers (Basel)</source><volume>16</volume><issue>21</issue><year>2024</year><fpage>3702</fpage><pub-id pub-id-type=\"pmid\">39518140</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.3390/cancers16213702</pub-id><pub-id pub-id-type=\"pmcid\">PMC11545079</pub-id></element-citation></ref><ref id=\"bib21\"><label>21</label><element-citation publication-type=\"book\" id=\"sref21\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Zhou</surname><given-names>Z.</given-names></name><name name-style=\"western\"><surname>Rahman Siddiquee</surname><given-names>M.M.</given-names></name><name name-style=\"western\"><surname>Tajbakhsh</surname><given-names>N.</given-names></name><name name-style=\"western\"><surname>Liang</surname><given-names>J.</given-names></name></person-group><part-title>Unet++: a nested u-net architecture for medical image segmentation</part-title><source>Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support: 4Th International Workshop, DLMIA 2018, and 8th International Workshop, ML-CDS 2018, Held in Conjunction with MICCAI 2018, Granada, Spain, September 20, 2018</source><year>2018</year><publisher-name>Springer</publisher-name><fpage>3</fpage><lpage>11</lpage><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1007/978-3-030-00889-5_1</pub-id><pub-id pub-id-type=\"pmcid\">PMC7329239</pub-id><pub-id pub-id-type=\"pmid\">32613207</pub-id></element-citation></ref><ref id=\"bib22\"><label>22</label><element-citation publication-type=\"journal\" id=\"sref22\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Isensee</surname><given-names>F.</given-names></name><name name-style=\"western\"><surname>Jaeger</surname><given-names>P.F.</given-names></name><name name-style=\"western\"><surname>Kohl</surname><given-names>S.A.A.</given-names></name><name name-style=\"western\"><surname>Petersen</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>Maier-Hein</surname><given-names>K.H.</given-names></name></person-group><article-title>nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation</article-title><source>Nat. Methods</source><volume>18</volume><issue>2</issue><year>Feb.2021</year><fpage>203</fpage><lpage>211</lpage><pub-id pub-id-type=\"doi\">10.1038/S41592-020-01008-Z</pub-id><comment>SUBJMETA=114,1564,308,575,631,692;KWRD=IMAGE+PROCESSING,TRANSLATIONAL+RESEARCH</comment><pub-id pub-id-type=\"pmid\">33288961</pub-id></element-citation></ref><ref id=\"bib23\"><label>23</label><element-citation publication-type=\"journal\" id=\"sref23\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Kumar</surname><given-names>D.</given-names></name><name name-style=\"western\"><surname>Gandhamal</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Talbar</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Hani</surname><given-names>A.F.M.</given-names></name></person-group><article-title>Knee articular cartilage segmentation from MR images: a review</article-title><source>ACM Comput. Surv.</source><volume>51</volume><issue>5</issue><year>2018</year><fpage>1</fpage><lpage>29</lpage></element-citation></ref><ref id=\"bib24\"><label>24</label><element-citation publication-type=\"journal\" id=\"sref24\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Byra</surname><given-names>M.</given-names></name><etal/></person-group><article-title>Knee menisci segmentation and relaxometry of 3D ultrashort echo time cones MR imaging using attention U-Net with transfer learning</article-title><source>Magn. Reson. Med.</source><volume>83</volume><issue>3</issue><year>2020</year><fpage>1109</fpage><lpage>1122</lpage><pub-id pub-id-type=\"pmid\">31535731</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1002/mrm.27969</pub-id><pub-id pub-id-type=\"pmcid\">PMC6879791</pub-id></element-citation></ref><ref id=\"bib25\"><label>25</label><element-citation publication-type=\"journal\" id=\"sref25\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Yang</surname><given-names>M.</given-names></name><etal/></person-group><article-title>Automated knee cartilage segmentation for heterogeneous clinical MRI using generative adversarial networks with transfer learning</article-title><source>Quant. Imag. Med. Surg.</source><volume>12</volume><issue>5</issue><year>2022</year><fpage>2620</fpage><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.21037/qims-21-459</pub-id><pub-id pub-id-type=\"pmcid\">PMC9014147</pub-id><pub-id pub-id-type=\"pmid\">35502381</pub-id></element-citation></ref><ref id=\"bib26\"><label>26</label><element-citation publication-type=\"journal\" id=\"sref26\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Ambellan</surname><given-names>F.</given-names></name><name name-style=\"western\"><surname>Tack</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Ehlke</surname><given-names>M.</given-names></name><name name-style=\"western\"><surname>Zachow</surname><given-names>S.</given-names></name></person-group><article-title>Automated segmentation of knee bone and cartilage combining statistical shape knowledge and convolutional neural networks: data from the osteoarthritis initiative</article-title><source>Med. Image Anal.</source><volume>52</volume><year>2019</year><fpage>109</fpage><lpage>118</lpage><pub-id pub-id-type=\"pmid\">30529224</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1016/j.media.2018.11.009</pub-id></element-citation></ref><ref id=\"bib27\"><label>27</label><element-citation publication-type=\"journal\" id=\"sref27\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Tack</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Mukhopadhyay</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Zachow</surname><given-names>S.</given-names></name></person-group><article-title>Knee menisci segmentation using convolutional neural networks: data from the osteoarthritis initiative</article-title><source>Osteoarthr. Cartil.</source><volume>26</volume><issue>5</issue><year>2018</year><fpage>680</fpage><lpage>688</lpage><pub-id pub-id-type=\"doi\">10.1016/J.JOCA.2018.02.907</pub-id><pub-id pub-id-type=\"pmid\">29526784</pub-id></element-citation></ref><ref id=\"bib28\"><label>28</label><element-citation publication-type=\"journal\" id=\"sref28\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Liu</surname><given-names>H.</given-names></name><name name-style=\"western\"><surname>Sun</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>Cheng</surname><given-names>X.</given-names></name><name name-style=\"western\"><surname>Jiang</surname><given-names>D.</given-names></name></person-group><article-title>Prior-based 3D U-Net: a model for knee-cartilage segmentation in MRI images</article-title><source>Comput. Graph.</source><volume>115</volume><year>Oct.2023</year><fpage>167</fpage><lpage>180</lpage><pub-id pub-id-type=\"doi\">10.1016/J.CAG.2023.07.008</pub-id></element-citation></ref><ref id=\"bib29\"><label>29</label><element-citation publication-type=\"journal\" id=\"sref29\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Yeoh</surname><given-names>P.S.Q.</given-names></name><etal/></person-group><article-title>Emergence of deep learning in knee osteoarthritis diagnosis</article-title><source>Comput. Intell. Neurosci.</source><volume>2021</volume><issue>1</issue><year>Jan.2021</year><object-id pub-id-type=\"publisher-id\">4931437</object-id><pub-id pub-id-type=\"doi\">10.1155/2021/4931437</pub-id><pub-id pub-id-type=\"pmcid\">PMC8598325</pub-id><pub-id pub-id-type=\"pmid\">34804143</pub-id></element-citation></ref><ref id=\"bib30\"><label>30</label><element-citation publication-type=\"journal\" id=\"sref30\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Liu</surname><given-names>F.</given-names></name></person-group><article-title>SUSAN: segment unannotated image structure using adversarial network</article-title><source>Magn. Reson. Med.</source><volume>81</volume><issue>5</issue><year>2019</year><fpage>3330</fpage><lpage>3345</lpage><pub-id pub-id-type=\"pmid\">30536427</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1002/mrm.27627</pub-id><pub-id pub-id-type=\"pmcid\">PMC7140982</pub-id></element-citation></ref><ref id=\"bib31\"><label>31</label><element-citation publication-type=\"journal\" id=\"sref31\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>khan</surname><given-names>S.</given-names></name><etal/></person-group><article-title>Source independent multiple-domain adaptation for knee osteoarthritis cartilage and meniscus segmentation in clinical magnetic resonance imaging</article-title><source>Intell. Med.</source><year>Jun.2025</year><pub-id pub-id-type=\"doi\">10.1016/J.IMED.2024.12.002</pub-id></element-citation></ref><ref id=\"bib32\"><label>32</label><element-citation publication-type=\"journal\" id=\"sref32\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Li</surname><given-names>X.</given-names></name><etal/></person-group><article-title>SDMT: spatial dependence multi-task transformer network for 3D knee MRI segmentation and landmark localization</article-title><source>IEEE Trans. Med. Imag.</source><volume>42</volume><issue>8</issue><year>Aug.2023</year><fpage>2274</fpage><lpage>2285</lpage><pub-id pub-id-type=\"doi\">10.1109/TMI.2023.3247543</pub-id><pub-id pub-id-type=\"pmid\">37027574</pub-id></element-citation></ref><ref id=\"bib33\"><label>33</label><element-citation publication-type=\"journal\" id=\"sref33\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Li</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Zhao</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Zhang</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>Hong</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>Chen</surname><given-names>W.</given-names></name></person-group><article-title>Source-free unsupervised adaptive segmentation for knee joint MRI</article-title><source>Biomed. Signal Process Control</source><volume>92</volume><year>Jun.2024</year><object-id pub-id-type=\"publisher-id\">106028</object-id><pub-id pub-id-type=\"doi\">10.1016/J.BSPC.2024.106028</pub-id></element-citation></ref><ref id=\"bib34\"><label>34</label><element-citation publication-type=\"journal\" id=\"sref34\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Khan</surname><given-names>S.</given-names></name><etal/></person-group><article-title>Semi-supervised knee cartilage segmentation with successive eigen noise-assisted mean teacher knowledge distillation</article-title><source>IEEE Trans. Med. Imag.</source><year>2025</year><pub-id pub-id-type=\"doi\">10.1109/TMI.2025.3556870</pub-id><pub-id pub-id-type=\"pmid\">40168230</pub-id></element-citation></ref><ref id=\"bib35\"><label>35</label><element-citation publication-type=\"journal\" id=\"sref35\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>He</surname><given-names>X.</given-names></name><etal/></person-group><article-title>Dealing with heterogeneous 3d Mr knee images: a federated few-shot learning method with dual knowledge distillation</article-title><source>Proc. Int. Symp. Biomed. Imag.</source><year>2023-April, 2023</year><pub-id pub-id-type=\"doi\">10.1109/ISBI53787.2023.10230679</pub-id></element-citation></ref><ref id=\"bib36\"><label>36</label><element-citation publication-type=\"journal\" id=\"sref36\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Peng</surname><given-names>Y.</given-names></name><etal/></person-group><article-title>KCB-Net: a 3D knee cartilage and bone segmentation network via sparse annotation</article-title><source>Med. Image Anal.</source><volume>82</volume><year>2022</year><object-id pub-id-type=\"publisher-id\">102574</object-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1016/j.media.2022.102574</pub-id><pub-id pub-id-type=\"pmcid\">PMC10515734</pub-id><pub-id pub-id-type=\"pmid\">36126403</pub-id></element-citation></ref><ref id=\"bib37\"><label>37</label><mixed-citation publication-type=\"other\" id=\"sref37\">OAI-The OSteoarthritis initiative&#8221;, Online. Available: <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://nda.nih.gov/oai\" id=\"intref0015\">https://nda.nih.gov/oai</ext-link>.</mixed-citation></ref><ref id=\"bib38\"><label>38</label><element-citation publication-type=\"journal\" id=\"sref38\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Williams</surname><given-names>T.G.</given-names></name><etal/></person-group><article-title>Measurement and visualisation of focal cartilage thickness change by MRI in a study of knee osteoarthritis using a novel image analysis tool</article-title><source>Br. J. Radiol.</source><volume>83</volume><issue>995</issue><year>2010</year><fpage>940</fpage><lpage>948</lpage><pub-id pub-id-type=\"pmid\">20223905</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1259/bjr/68875123</pub-id><pub-id pub-id-type=\"pmcid\">PMC3473735</pub-id></element-citation></ref><ref id=\"bib39\"><label>39</label><element-citation publication-type=\"journal\" id=\"sref39\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Desai</surname><given-names>A.D.</given-names></name><etal/></person-group><article-title>SKM-TEA: A dataset for accelerated mri reconstruction with dense image labels for quantitative clinical evaluation, in</article-title><source>Proc. Int. Conf. Neural Inf. Process. Syst.</source><year>2021</year><fpage>2531</fpage><lpage>2544</lpage></element-citation></ref><ref id=\"bib40\"><label>40</label><mixed-citation publication-type=\"other\" id=\"sref40\">OAI-ZIB datset.&#8221; Online. Available: <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://www.zib.de/research/projects/analysis-and-quantification-morphological-and-structural-changes-cartilage\" id=\"intref0020\">https://www.zib.de/research/projects/analysis-and-quantification-morphological-and-structural-changes-cartilage</ext-link>.</mixed-citation></ref><ref id=\"bib41\"><label>41</label><element-citation publication-type=\"journal\" id=\"sref41\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Mugler</surname><given-names>J.P.</given-names></name></person-group><article-title>Optimized three-dimensional fast-spin-echo MRI</article-title><source>J. Magn. Reson. Imag.</source><volume>39</volume><issue>4</issue><year>2014</year><fpage>745</fpage><lpage>767</lpage><pub-id pub-id-type=\"doi\">10.1002/JMRI.24542</pub-id><pub-id pub-id-type=\"pmid\">24399498</pub-id></element-citation></ref><ref id=\"bib42\"><label>42</label><element-citation publication-type=\"journal\" id=\"sref42\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Norman</surname><given-names>B.</given-names></name><name name-style=\"western\"><surname>Pedoia</surname><given-names>V.</given-names></name><name name-style=\"western\"><surname>Majumdar</surname><given-names>S.</given-names></name></person-group><article-title>Use of 2D U-Net convolutional neural networks for automated cartilage and meniscus segmentation of knee MR imaging data to determine relaxometry and morphometry</article-title><source>Radiology</source><volume>288</volume><issue>1</issue><year>Jul.2018</year><fpage>177</fpage><lpage>185</lpage><pub-id pub-id-type=\"doi\">10.1148/RADIOL.2018172322</pub-id><pub-id pub-id-type=\"pmid\">29584598</pub-id><pub-id pub-id-type=\"pmcid\">PMC6013406</pub-id></element-citation></ref><ref id=\"bib43\"><label>43</label><element-citation publication-type=\"book\" id=\"sref43\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Desai</surname><given-names>A.D.</given-names></name><etal/></person-group><part-title>DOSMA: a deep-learning, open-source framework for musculoskeletal MRI analysis</part-title><source>Proc 27th Annual Meeting</source><year>2019</year><publisher-name>ISMRM</publisher-name><publisher-loc>Montreal</publisher-loc><fpage>1135</fpage></element-citation></ref><ref id=\"bib44\"><label>44</label><element-citation publication-type=\"journal\" id=\"sref44\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Esrafilian</surname><given-names>A.</given-names></name><etal/></person-group><article-title>An automated and robust tool for musculoskeletal and finite element modeling of the knee joint</article-title><source>IEEE Trans. Biomed. Eng.</source><volume>72</volume><issue>1</issue><year>2024</year><fpage>56</fpage><lpage>69</lpage><pub-id pub-id-type=\"doi\">10.1109/TBME.2024.3438272</pub-id><pub-id pub-id-type=\"pmid\">39236141</pub-id></element-citation></ref><ref id=\"bib45\"><label>45</label><element-citation publication-type=\"journal\" id=\"sref45\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Liang</surname><given-names>D.</given-names></name><name name-style=\"western\"><surname>Liu</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>Wang</surname><given-names>K.</given-names></name><name name-style=\"western\"><surname>Luo</surname><given-names>G.</given-names></name><name name-style=\"western\"><surname>Wang</surname><given-names>W.</given-names></name><name name-style=\"western\"><surname>Li</surname><given-names>S.</given-names></name></person-group><article-title>Position-prior clustering-based self-attention module for knee cartilage segmentation</article-title><source>Lect. Notes Comput. Sci.</source><volume>13435</volume><issue>LNCS</issue><year>2022</year><fpage>193</fpage><lpage>202</lpage><pub-id pub-id-type=\"doi\">10.1007/978-3-031-16443-9_19</pub-id></element-citation></ref><ref id=\"bib46\"><label>46</label><element-citation publication-type=\"journal\" id=\"sref46\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Wang</surname><given-names>X.</given-names></name><name name-style=\"western\"><surname>Shi</surname><given-names>C.</given-names></name></person-group><article-title>Patch attention U-Net for knee cartilage segmentation in magnetic resonance images</article-title><source>Biomed. Signal Process Control</source><volume>106</volume><year>Aug.2025</year><object-id pub-id-type=\"publisher-id\">107754</object-id><pub-id pub-id-type=\"doi\">10.1016/J.BSPC.2025.107754</pub-id></element-citation></ref><ref id=\"bib47\"><label>47</label><element-citation publication-type=\"journal\" id=\"sref47\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Badrinarayanan</surname><given-names>V.</given-names></name><name name-style=\"western\"><surname>Kendall</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Cipolla</surname><given-names>R.</given-names></name></person-group><article-title>SegNet: a deep convolutional encoder-decoder architecture for image segmentation</article-title><source>IEEE Trans. Pattern Anal. Mach. Intell.</source><volume>39</volume><issue>12</issue><year>Dec.2017</year><fpage>2481</fpage><lpage>2495</lpage><pub-id pub-id-type=\"doi\">10.1109/TPAMI.2016.2644615</pub-id><pub-id pub-id-type=\"pmid\">28060704</pub-id></element-citation></ref><ref id=\"bib48\"><label>48</label><element-citation publication-type=\"journal\" id=\"sref48\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Khan</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Azam</surname><given-names>B.</given-names></name><name name-style=\"western\"><surname>Yao</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>Chen</surname><given-names>W.</given-names></name></person-group><article-title>Deep collaborative network with alpha matte for precise knee tissue segmentation from MRI</article-title><source>Comput. Methods Progr. Biomed.</source><volume>222</volume><year>Jul.2022</year><object-id pub-id-type=\"publisher-id\">106963</object-id><pub-id pub-id-type=\"doi\">10.1016/J.CMPB.2022.106963</pub-id><pub-id pub-id-type=\"pmid\">35752117</pub-id></element-citation></ref><ref id=\"bib49\"><label>49</label><element-citation publication-type=\"book\" id=\"sref49\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Panfilov</surname><given-names>E.</given-names></name><name name-style=\"western\"><surname>Tiulpin</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Klein</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Nieminen</surname><given-names>M.T.</given-names></name><name name-style=\"western\"><surname>Saarakkala</surname><given-names>S.</given-names></name></person-group><part-title>Improving Robustness of Deep Learning Based Knee MRI Segmentation: Mixup and Adversarial Domain Adaptation</part-title><year>2019</year><comment>[Online]. Available:</comment><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://github.com/facebookresearch/\" id=\"intref0025\">https://github.com/facebookresearch/</ext-link></element-citation></ref><ref id=\"bib50\"><label>50</label><element-citation publication-type=\"journal\" id=\"sref50\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Mugler</surname><given-names>J.P.</given-names></name></person-group><article-title>Optimized three-dimensional fast-spin-echo MRI</article-title><source>J. Magn. Reson. Imag.</source><volume>39</volume><issue>4</issue><year>Apr.2014</year><fpage>745</fpage><lpage>767</lpage><pub-id pub-id-type=\"doi\">10.1002/JMRI.24542</pub-id><pub-id pub-id-type=\"pmid\">24399498</pub-id></element-citation></ref><ref id=\"bib51\"><label>51</label><element-citation publication-type=\"journal\" id=\"sref51\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Gold</surname><given-names>G.E.</given-names></name><etal/></person-group><article-title>Isotropic MRI of the knee with 3D fast spin-echo extended echo-train acquisition (XETA): initial experience</article-title><source>Am. J. Roentgenol.</source><volume>188</volume><issue>5</issue><year>2007</year><fpage>1287</fpage><lpage>1293</lpage><pub-id pub-id-type=\"doi\">10.2214/AJR.06.1208/ASSET/IMAGES/06_1208_07B.JPEG</pub-id><pub-id pub-id-type=\"pmid\">17449772</pub-id></element-citation></ref><ref id=\"bib52\"><label>52</label><element-citation publication-type=\"journal\" id=\"sref52\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Kijowski</surname><given-names>R.</given-names></name></person-group><article-title>3D MRI of articular cartilage</article-title><source>Semin. Muscoskel. Radiol.</source><volume>25</volume><issue>3</issue><year>Jun.2021</year><fpage>397</fpage><lpage>408</lpage><pub-id pub-id-type=\"doi\">10.1055/S-0041-1730913</pub-id><pub-id pub-id-type=\"pmid\">34547805</pub-id></element-citation></ref><ref id=\"bib53\"><label>53</label><element-citation publication-type=\"journal\" id=\"sref53\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Schmidt</surname><given-names>A.M.</given-names></name><etal/></person-group><article-title>Generalizability of deep learning segmentation algorithms for automated assessment of cartilage morphology and MRI relaxometry</article-title><source>J. Magn. Reson. Imag.</source><volume>57</volume><issue>4</issue><year>Apr.2023</year><fpage>1029</fpage><lpage>1039</lpage><pub-id pub-id-type=\"doi\">10.1002/JMRI.28365</pub-id><pub-id pub-id-type=\"pmcid\">PMC9849481</pub-id><pub-id pub-id-type=\"pmid\">35852498</pub-id></element-citation></ref><ref id=\"bib54\"><label>54</label><element-citation publication-type=\"journal\" id=\"sref54\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Kirillov</surname><given-names>A.</given-names></name><etal/></person-group><article-title>Segment anything</article-title><source>Proc. IEEE Int. Conf. Comput. Vis.</source><year>2023</year><fpage>3992</fpage><lpage>4003</lpage><pub-id pub-id-type=\"doi\">10.1109/ICCV51070.2023.00371</pub-id></element-citation></ref><ref id=\"bib55\"><label>55</label><element-citation publication-type=\"book\" id=\"sref55\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Ravi</surname><given-names>N.</given-names></name><etal/></person-group><part-title>SAM 2: Segment anything in Images and Videos</part-title><year>Aug.2024</year><comment>[Online]. Available:</comment><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://arxiv.org/pdf/2408.00714\" id=\"intref0030\">https://arxiv.org/pdf/2408.00714</ext-link></element-citation></ref><ref id=\"bib56\"><label>56</label><element-citation publication-type=\"journal\" id=\"sref56\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Ma</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>He</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>Li</surname><given-names>F.</given-names></name><name name-style=\"western\"><surname>Han</surname><given-names>L.</given-names></name><name name-style=\"western\"><surname>You</surname><given-names>C.</given-names></name><name name-style=\"western\"><surname>Wang</surname><given-names>B.</given-names></name></person-group><article-title>Segment anything in medical images</article-title><source>Nat. Commun.</source><volume>15</volume><issue>1</issue><year>Jan.2024</year><fpage>1</fpage><lpage>9</lpage><pub-id pub-id-type=\"doi\">10.1038/s41467-024-44824-z</pub-id><comment>2024 151</comment><pub-id pub-id-type=\"pmid\">38253604</pub-id><pub-id pub-id-type=\"pmcid\">PMC10803759</pub-id></element-citation></ref><ref id=\"bib57\"><label>57</label><element-citation publication-type=\"book\" id=\"sref57\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Hoyer</surname><given-names>G.</given-names></name><name name-style=\"western\"><surname>Tong</surname><given-names>M.W.</given-names></name><name name-style=\"western\"><surname>Bhattacharjee</surname><given-names>R.</given-names></name><name name-style=\"western\"><surname>Pedoia</surname><given-names>V.</given-names></name><name name-style=\"western\"><surname>Majumdar</surname><given-names>S.</given-names></name></person-group><part-title>Scalable Evaluation Framework for Foundation Models in Musculoskeletal MRI Bridging Computational Innovation with Clinical Utility</part-title><year>Jan.2025</year><comment>[Online]. Available:</comment><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://arxiv.org/pdf/2501.13376\" id=\"intref0035\">https://arxiv.org/pdf/2501.13376</ext-link></element-citation></ref><ref id=\"bib58\"><label>58</label><element-citation publication-type=\"journal\" id=\"sref58\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Chaudhari</surname><given-names>A.S.</given-names></name><etal/></person-group><article-title>Utility of deep learning super-resolution in the context of osteoarthritis MRI biomarkers</article-title><source>J. Magn. Reson. Imag.</source><volume>51</volume><issue>3</issue><year>Mar.2020</year><fpage>768</fpage><lpage>779</lpage><pub-id pub-id-type=\"doi\">10.1002/JMRI.26872</pub-id><pub-id pub-id-type=\"pmcid\">PMC6962563</pub-id><pub-id pub-id-type=\"pmid\">31313397</pub-id></element-citation></ref><ref id=\"bib59\"><label>59</label><element-citation publication-type=\"journal\" id=\"sref59\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Yao</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>Zhong</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>Zhang</surname><given-names>L.</given-names></name><name name-style=\"western\"><surname>Khan</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Chen</surname><given-names>W.</given-names></name></person-group><article-title>CartiMorph: a framework for automated knee articular cartilage morphometrics</article-title><source>Med. Image Anal.</source><volume>91</volume><year>Jan.2024</year><object-id pub-id-type=\"publisher-id\">103035</object-id><pub-id pub-id-type=\"doi\">10.1016/J.MEDIA.2023.103035</pub-id><pub-id pub-id-type=\"pmid\">37992496</pub-id></element-citation></ref><ref id=\"bib60\"><label>60</label><element-citation publication-type=\"book\" id=\"sref60\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Yao</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>Chen</surname><given-names>W.</given-names></name></person-group><part-title>Quantifying Knee Cartilage Shape and Lesion: from Image to Metrics</part-title><year>Sep.2025</year><fpage>162</fpage><lpage>172</lpage><pub-id pub-id-type=\"doi\">10.1007/978-3-031-82007-6_16</pub-id></element-citation></ref><ref id=\"bib61\"><label>61</label><element-citation publication-type=\"journal\" id=\"sref61\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Kessler</surname><given-names>D.A.</given-names></name><etal/></person-group><article-title>Segmentation of knee MRI data with convolutional neural networks for semi-automated three-dimensional surface-based analysis of cartilage morphology and composition</article-title><source>Osteoarthr. Imag.</source><volume>2</volume><issue>2</issue><year>2022</year><object-id pub-id-type=\"publisher-id\">100010</object-id></element-citation></ref><ref id=\"bib62\"><label>62</label><element-citation publication-type=\"journal\" id=\"sref62\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Iriondo</surname><given-names>C.</given-names></name><name name-style=\"western\"><surname>Liu</surname><given-names>F.</given-names></name><name name-style=\"western\"><surname>Caliv&#224;</surname><given-names>F.</given-names></name><name name-style=\"western\"><surname>Kamat</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Majumdar</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Pedoia</surname><given-names>V.</given-names></name></person-group><article-title>Towards understanding mechanistic subgroups of osteoarthritis: 8-year cartilage thickness trajectory analysis</article-title><source>J. Orthop. Res.</source><volume>39</volume><issue>6</issue><year>Jun.2021</year><fpage>1305</fpage><lpage>1317</lpage><pub-id pub-id-type=\"doi\">10.1002/JOR.24849;SUBPAGE:STRING:FULL</pub-id><pub-id pub-id-type=\"pmid\">32897602</pub-id></element-citation></ref><ref id=\"bib63\"><label>63</label><element-citation publication-type=\"journal\" id=\"sref63\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Eckstein</surname><given-names>F.</given-names></name><etal/></person-group><article-title>Detection of differences in longitudinal cartilage thickness loss using a deep-learning automated segmentation algorithm: data from the foundation for the national institutes of health biomarkers study of the osteoarthritis initiative</article-title><source>Arthritis Care Res.</source><volume>74</volume><issue>6</issue><year>Jun.2022</year><fpage>929</fpage><lpage>936</lpage><pub-id pub-id-type=\"doi\">10.1002/ACR.24539</pub-id><pub-id pub-id-type=\"pmcid\">PMC9321555</pub-id><pub-id pub-id-type=\"pmid\">33337584</pub-id></element-citation></ref><ref id=\"bib64\"><label>64</label><element-citation publication-type=\"journal\" id=\"sref64\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Razmjoo</surname><given-names>A.</given-names></name><etal/></person-group><article-title>T2 analysis of the entire osteoarthritis initiative dataset</article-title><source>J. Orthop. Res.</source><volume>39</volume><issue>1</issue><year>Jan.2021</year><fpage>74</fpage><lpage>85</lpage><pub-id pub-id-type=\"doi\">10.1002/JOR.24811</pub-id><pub-id pub-id-type=\"pmid\">32691905</pub-id></element-citation></ref><ref id=\"bib65\"><label>65</label><element-citation publication-type=\"book\" id=\"sref65\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Zhong</surname><given-names>J.</given-names></name><etal/></person-group><part-title>A Systematic Post-processing Approach for Quantitative T1 Rho Imaging of Knee Articular Cartilage</part-title><year>Sep.2024</year><comment>[Online]. Available:</comment><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://arxiv.org/abs/2409.12600v1\" id=\"intref0040\">https://arxiv.org/abs/2409.12600v1</ext-link></element-citation></ref><ref id=\"bib66\"><label>66</label><element-citation publication-type=\"journal\" id=\"sref66\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Goyal</surname><given-names>A.</given-names></name><etal/></person-group><article-title>Automating imaging biomarker analysis for knee osteoarthritis using an open-source MRI-based deep learning pipeline</article-title><source>medRxiv</source><year>Feb.2025</year><fpage>2025</fpage><pub-id pub-id-type=\"doi\">10.1101/2025.02.21.25322094</pub-id><comment>02.21.25322094</comment></element-citation></ref><ref id=\"bib67\"><label>67</label><element-citation publication-type=\"journal\" id=\"sref67\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Pedoia</surname><given-names>V.</given-names></name><name name-style=\"western\"><surname>Lee</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>Norman</surname><given-names>B.</given-names></name><name name-style=\"western\"><surname>Link</surname><given-names>T.M.</given-names></name><name name-style=\"western\"><surname>Majumdar</surname><given-names>S.</given-names></name></person-group><article-title>Diagnosing osteoarthritis from T2 maps using deep learning: an analysis of the entire osteoarthritis initiative baseline cohort</article-title><source>Osteoarthr. Cartil.</source><volume>27</volume><issue>7</issue><year>Jul.2019</year><fpage>1002</fpage><lpage>1010</lpage><pub-id pub-id-type=\"doi\">10.1016/j.joca.2019.02.800</pub-id><pub-id pub-id-type=\"pmcid\">PMC6579664</pub-id><pub-id pub-id-type=\"pmid\">30905742</pub-id></element-citation></ref><ref id=\"bib68\"><label>68</label><element-citation publication-type=\"journal\" id=\"sref68\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Qiu</surname><given-names>Z.</given-names></name><etal/></person-group><article-title>Learning co-plane attention across MRI sequences for diagnosing twelve types of knee abnormalities</article-title><source>Nat. Commun.</source><volume>15</volume><issue>1</issue><year>Sep.2024</year><fpage>1</fpage><lpage>11</lpage><pub-id pub-id-type=\"doi\">10.1038/s41467-024-51888-4</pub-id><comment>2024 151</comment><pub-id pub-id-type=\"pmid\">39223149</pub-id><pub-id pub-id-type=\"pmcid\">PMC11368947</pub-id></element-citation></ref><ref id=\"bib69\"><label>69</label><element-citation publication-type=\"book\" id=\"sref69\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Hoyer</surname><given-names>G.</given-names></name><etal/></person-group><part-title>Foundations of a Knee Joint Digital Twin from qMRI Biomarkers for Osteoarthritis and Knee Replacement</part-title><year>Jan.2025</year><comment>[Online]. Available:</comment><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://arxiv.org/abs/2501.15396v1\" id=\"intref0045\">https://arxiv.org/abs/2501.15396v1</ext-link><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1038/s41746-025-01507-3</pub-id><pub-id pub-id-type=\"pmcid\">PMC11845592</pub-id><pub-id pub-id-type=\"pmid\">39984725</pub-id></element-citation></ref><ref id=\"bib70\"><label>70</label><element-citation publication-type=\"journal\" id=\"sref70\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Zhong</surname><given-names>J.</given-names></name><etal/></person-group><article-title>Unsupervised domain adaptation for automated knee osteoarthritis phenotype classification</article-title><source>Quant. Imag. Med. Surg.</source><volume>13</volume><issue>11</issue><year>Nov.2023</year><fpage>7444</fpage><lpage>7458</lpage><pub-id pub-id-type=\"doi\">10.21037/QIMS-23-704/COIF</pub-id><pub-id pub-id-type=\"pmcid\">PMC10644135</pub-id><pub-id pub-id-type=\"pmid\">37969620</pub-id></element-citation></ref><ref id=\"bib71\"><label>71</label><mixed-citation publication-type=\"other\" id=\"sref71\">Overview and description of central image assessments.&#8221; Online. Available: <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://s3.amazonaws.com/nda.nih.gov/cms/prod/ImageAssessmentDataOverview.pdf\" id=\"intref0050\">https://s3.amazonaws.com/nda.nih.gov/cms/prod/ImageAssessmentDataOverview.pdf</ext-link>.</mixed-citation></ref><ref id=\"bib72\"><label>72</label><element-citation publication-type=\"journal\" id=\"sref72\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Peterfy</surname><given-names>C.G.</given-names></name><name name-style=\"western\"><surname>Schneider</surname><given-names>E.</given-names></name><name name-style=\"western\"><surname>Nevitt</surname><given-names>M.</given-names></name></person-group><article-title>The osteoarthritis initiative: report on the design rationale for the magnetic resonance imaging protocol for the knee</article-title><source>Osteoarthr. Cartil.</source><volume>16</volume><issue>12</issue><year>2008</year><fpage>1433</fpage><lpage>1441</lpage><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1016/j.joca.2008.06.016</pub-id><pub-id pub-id-type=\"pmcid\">PMC3048821</pub-id><pub-id pub-id-type=\"pmid\">18786841</pub-id></element-citation></ref><ref id=\"bib73\"><label>73</label><mixed-citation publication-type=\"other\" id=\"sref73\">S. K. W. Tobias Heimann, Martin Styner, &#8220;SKi10 grand-challenge.&#8221; Online. Available: <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://ski10.grand-challenge.org/\" id=\"intref0055\">https://ski10.grand-challenge.org/</ext-link>.</mixed-citation></ref><ref id=\"bib74\"><label>74</label><element-citation publication-type=\"journal\" id=\"sref74\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Desai</surname><given-names>A.D.</given-names></name><etal/></person-group><article-title>The international workshop on osteoarthritis imaging knee MRI segmentation challenge: a multi-institute evaluation and analysis framework on a standardized dataset</article-title><source>Radiol. Artif. Intell.</source><volume>3</volume><issue>3</issue><year>2021</year><object-id pub-id-type=\"publisher-id\">e200078</object-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1148/ryai.2021200078</pub-id><pub-id pub-id-type=\"pmcid\">PMC8231759</pub-id><pub-id pub-id-type=\"pmid\">34235438</pub-id></element-citation></ref><ref id=\"bib75\"><label>75</label><element-citation publication-type=\"journal\" id=\"sref75\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Zhou</surname><given-names>Z.</given-names></name><name name-style=\"western\"><surname>Zhao</surname><given-names>G.</given-names></name><name name-style=\"western\"><surname>Kijowski</surname><given-names>R.</given-names></name><name name-style=\"western\"><surname>Liu</surname><given-names>F.</given-names></name></person-group><article-title>Deep convolutional neural network for segmentation of knee joint anatomy</article-title><source>Magn. Reson. Med.</source><volume>80</volume><issue>6</issue><year>Dec.2018</year><fpage>2759</fpage><lpage>2770</lpage><pub-id pub-id-type=\"doi\">10.1002/MRM.27229</pub-id><pub-id pub-id-type=\"pmid\">29774599</pub-id><pub-id pub-id-type=\"pmcid\">PMC6342268</pub-id></element-citation></ref><ref id=\"bib76\"><label>76</label><element-citation publication-type=\"journal\" id=\"sref76\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Liu</surname><given-names>F.</given-names></name><name name-style=\"western\"><surname>Zhou</surname><given-names>Z.</given-names></name><name name-style=\"western\"><surname>Jang</surname><given-names>H.</given-names></name><name name-style=\"western\"><surname>Samsonov</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Zhao</surname><given-names>G.</given-names></name><name name-style=\"western\"><surname>Kijowski</surname><given-names>R.</given-names></name></person-group><article-title>Deep convolutional neural network and 3D deformable approach for tissue segmentation in musculoskeletal magnetic resonance imaging</article-title><source>Magn. Reson. Med.</source><volume>79</volume><issue>4</issue><year>Apr.2018</year><fpage>2379</fpage><lpage>2391</lpage><pub-id pub-id-type=\"doi\">10.1002/MRM.26841</pub-id><pub-id pub-id-type=\"pmid\">28733975</pub-id><pub-id pub-id-type=\"pmcid\">PMC6271435</pub-id></element-citation></ref><ref id=\"bib77\"><label>77</label><element-citation publication-type=\"journal\" id=\"sref77\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Chadoulos</surname><given-names>C.G.</given-names></name><name name-style=\"western\"><surname>Tsaopoulos</surname><given-names>D.E.</given-names></name><name name-style=\"western\"><surname>Moustakidis</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Tsakiridis</surname><given-names>N.L.</given-names></name><name name-style=\"western\"><surname>Theocharis</surname><given-names>J.B.</given-names></name></person-group><article-title>A novel multi-atlas segmentation approach under the semi-supervised learning framework: application to knee cartilage segmentation</article-title><source>Comput. Methods Progr. Biomed.</source><volume>227</volume><year>2022</year><object-id pub-id-type=\"publisher-id\">107208</object-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1016/j.cmpb.2022.107208</pub-id><pub-id pub-id-type=\"pmid\">36384059</pub-id></element-citation></ref><ref id=\"bib78\"><label>78</label><element-citation publication-type=\"journal\" id=\"sref78\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Khawer</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Khan</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Qureshi</surname><given-names>R.</given-names></name><name name-style=\"western\"><surname>Awais</surname><given-names>M.</given-names></name><name name-style=\"western\"><surname>Chen</surname><given-names>W.</given-names></name><name name-style=\"western\"><surname>Wu</surname><given-names>J.</given-names></name></person-group><article-title>MTKD-LRS: semi supervised knee cartilage segmentation using eigen low rank subspace assisted mean-teacher framework</article-title><source>Proc. Int. Symp. Biomed. Imag.</source><year>2025</year><pub-id pub-id-type=\"doi\">10.1109/ISBI60581.2025.10980909</pub-id></element-citation></ref><ref id=\"bib79\"><label>79</label><element-citation publication-type=\"journal\" id=\"sref79\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Jansen</surname><given-names>M.P.</given-names></name><etal/></person-group><article-title>Cartilage thickness distribution and its dependence on demographic, radiographic, and MRI structural pathology in knee osteoarthritis-data from the IMI-APPROACH cohort</article-title><source>Skelet. Radiol.</source><volume>12</volume><year>Mar.2025</year><fpage>1</fpage><lpage>10</lpage><pub-id pub-id-type=\"doi\">10.1007/S00256-025-04907-4/FIGURES/6</pub-id><pub-id pub-id-type=\"pmcid\">PMC12361290</pub-id><pub-id pub-id-type=\"pmid\">40113602</pub-id></element-citation></ref><ref id=\"bib80\"><label>80</label><element-citation publication-type=\"journal\" id=\"sref80\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>vanHelvoort</surname><given-names>E.M.</given-names></name><etal/></person-group><article-title>Cohort profile: the applied public-private research enabling OsteoArthritis clinical headway (IMI-APPROACH) study: a 2-year, European, cohort study to describe, validate and predict phenotypes of osteoarthritis using clinical, imaging and biochemical markers</article-title><source>BMJ Open</source><volume>10</volume><issue>7</issue><year>Jul.2020</year><object-id pub-id-type=\"publisher-id\">e035101</object-id><pub-id pub-id-type=\"doi\">10.1136/BMJOPEN-2019-035101</pub-id><pub-id pub-id-type=\"pmcid\">PMC7389775</pub-id><pub-id pub-id-type=\"pmid\">32723735</pub-id></element-citation></ref></ref-list><ack id=\"ack0010\"><title>Acknowledgement</title><p id=\"p0275\">This work is supported by a grant from the Research Grants Council of the Hong Kong SAR (UGC/FDS24/E18/22), and partially supported by a grant from the Innovation and Technology Commission of the Hong Kong SAR (Project MRP/001/18X).</p></ack><fn-group><fn id=\"d36e559\"><p id=\"ntpara0010\">This article is part of a special issue entitled: Artificial intelligence in Osteoarthritis imaging published in Osteoarthritis and Cartilage Open.</p></fn></fn-group></back></article></pmc-articleset>",
  "text": "pmc Osteoarthr Cartil Open Osteoarthr Cartil Open 4341 ocarto Osteoarthritis and Cartilage Open 2665-9131 Elsevier PMC12681719 PMC12681719.1 12681719 12681719 41362327 10.1016/j.ocarto.2025.100702 S2665-9131(25)00138-4 100702 1 Virtual Special Issue on: Artificial intelligence in Osteoarthritis imaging; Edited by Chunyi Wen Advancing deep learning based knee cartilage segmentation in MRI: Innovations, challenges and applications Khan Sheheryar shkhan@cpce-polyu.edu.hk a &#8270; Khawer Muhammad Ammar ammarkhawer1@gmail.com a Zhong Junru jrzhong@link.cuhk.edu.hk b Qureshi Rizwan fnu.rizwan@ucf.edu c Asim Muhammad muhammad.asim@cpce-polyu.edu.hk a Chen Weitian wtchen@cuhk.edu.hk b a Division of Science Engineering, and Health Studies (SEHS), School of Professional Education and Executive Development, The Hong Kong Polytechnic University, Hong Kong b Department of Imaging and Interventional Radiology, CUHK Lab of AI in Radiology (CLAIR), Chinese University of Hong Kong, Shatin N.T., Hong Kong c Center for Research in Computer Vision, University of Central Florida, Orlando, FL, USA &#8270; Corresponding author. shkhan@cpce-polyu.edu.hk 3 2026 17 11 2025 8 1 501708 100702 31 1 2025 3 11 2025 17 11 2025 08 12 2025 09 12 2025 &#169; 2025 The Author(s) 2025 https://creativecommons.org/licenses/by-nc-nd/4.0/ This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/). Objective Recent advancements in deep learning (DL) have advanced knee cartilage segmentation in Magnetic Resonance Imaging (MRI), offering scalable, automated solutions that markedly reduce reader time and address the limitations of traditional manual approaches. Automated segmentation can substantially aid osteoarthritis (OA) assessment using MRI, facilitating consistent, reproducible quantification across large longitudinal cohorts, reduces inter-/intra-observer variability, capabilities that are impractical with manual workflows. Method This study presents a concise review of state-of-the-art DL-based approaches for knee cartilage segmentation, focusing on the evaluation of various architectures, techniques, and their adaptability to diverse datasets and imaging protocols. This review highlights key challenges in knee cartilage segmentation, including data scarcity, domain shifts, and imaging variability, while also discussing proposed solutions such as semi-supervised learning, domain adaptation, augmentation strategies, and foundation models. Additionally, the clinical significance of knee cartilage segmentation is underscored through its diverse applications. Results The study highlights substantial improvements against conventional methods in segmentation accuracy and efficiency using DL-based methods, given challenging scenarios of knee MRI. Solutions to key challenges are presented, and clinical applications showcase the potential of automated segmentation for cartilage thickness mapping and OA assessment. Conclusion DL-based segmentation is advancing musculoskeletal imaging by offering reliable and automated solutions. Despite persistent challenges such as data scarcity, domain shifts, and imaging variability, advancements in areas like semi-supervised learning, domain adaptation, augmentation strategies, and foundation models present significant opportunities to enhance model robustness and expand clinical applicability. Keywords Knee MRI Osteoarthritis Cartilage segmentation Deep learning Cartilage thickness mapping Foundation models pmc-status-qastatus 0 pmc-status-live yes pmc-status-embargo no pmc-status-released yes pmc-prop-open-access yes pmc-prop-olf no pmc-prop-manuscript no pmc-prop-legally-suppressed no pmc-prop-has-pdf yes pmc-prop-has-supplement no pmc-prop-pdf-only no pmc-prop-suppress-copyright no pmc-prop-is-real-version no pmc-prop-is-scanned-article no pmc-prop-preprint no pmc-prop-in-epmc yes Handling Editor: Professor H Madry 1 Introduction Knee cartilage segmentation plays a critical role in the clinical management of osteoarthritis (OA), a degenerative joint disease that affects millions worldwide [ 1 ]. Accurate segmentation of knee structures, including articular cartilage, menisci, and subchondral bone, offer significant value in developing advanced clinical applications for OA, monitoring its progression, and planning appropriate treatment strategies [ 2 , 3 ]. Magnetic Resonance Imaging (MRI) has become the preferred imaging modality due to its ability to provide high-resolution images that reveal subtle changes in cartilage morphology and composition [ 4 , 5 ]. MRI technology significantly enhances OA detection by enabling detailed imaging of joint structures, supporting early diagnosis and improved disease monitoring [ 6 , 7 ]. Traditional imaging methods like X-ray often fail to detect early changes in cartilage and other soft tissues, whereas MRI can visualize subtle alterations in joint cartilage microstructure that are indicative of early OA. Advanced MRI techniques, such as T1&#961; and T2 mapping, allow for the assessment of biochemical changes within the cartilage, which can serve as biomarkers for early degeneration [ [6] , [7] , [8] , [9] ]. Moreover, emerging technologies like Field-Cycling Imaging have shown promise in identifying differences in how healthy and osteoarthritic cartilage responds to varying magnetic fields, potentially marking a breakthrough in early detection [ 10 ]. These advancements facilitate timely intervention strategies, promoting early preventive measures to delay the progression of debilitating osteoarthritis, rather than prioritizing the treatment of advanced joint damage. The analysis of MRI images for OA assessment often involves the segmentation of knee cartilage, however, manual segmentation of knee cartilage is time-consuming. Commonly used manual tools for segmentation include software packages such as ITK-SNAP, OsiriX, and 3D Slicer [ 11 ]. Manual segmentation, although capable of capturing fine anatomical details, is prone to variability and demands substantial expertise. Conventional segmentation methods for knee cartilage, such as graph cuts, watershed, region growing, and shape models, rely on predefined rules and heuristics to delineate structures from MRI images [ 2 , 12 ]. These techniques often require manual tuning and can be sensitive to noise and variations in image quality. In contrast, DL algorithms, particularly those leveraging architectures like U-Net [ 13 ], have advanced automatic cartilage segmentation [ 14 ]. These approaches not only significantly reduce the time needed for tissue segmentation but also minimize potential human error, delivering consistent and reproducible results. DL is highly efficient in terms of reader time per scan. Prior studies report &#8764;43&#8211;78 &#8203;min per plate or &#8764;75 &#8203;min per knee for earlier manual/semi-automated protocols, and &#8764;10&#8211;20 &#8203;min per compartment for newer local-area cartilage segmentation (LACS) implementations [ 15 ], whereas DL inference typically completes in seconds to &#8764;1 &#8203;min with minimal reader involvement [ 16 ]. Evidence indicates that, when properly validated, DL can match manual methods in agreement and longitudinal precision and preserve key longitudinal associations [ 17 ]. Accordingly, DL is preferable when non-inferior precision is demonstrated on local data with appropriate quality control (QC); otherwise, a hybrid DL &#8203;+ &#8203;QC workflow can mitigate any speed-responsiveness trade-off [ 18 ]. In this paper, we present a concise review of DL-based methods for knee cartilage segmentation using MRI. This review is not intended to be exhaustive; rather, it highlights a curated selection of studies the authors consider most relevant and illustrative of current advances. 2 Overview of DL-based knee MRI cartilage segmentation Medical image analysis has undergone significant transformations over the decades, evolving from manual tracing and simple thresholding techniques to sophisticated computational methods. In the context of MRI-based cartilage segmentation, early methods primarily depended on manually outlining cartilage boundaries, which were often subject to significant inter-observer variability [ 19 ]. However, with technological progress, the shortcomings of manual and traditional segmentation approaches became increasingly apparent, driving the development and adoption of more robust and automated solutions. 2.1 Emergence of DL in knee MRI segmentation The advent of DL has brought a transformative shift to medical image analysis [ 16 ], significantly advancing the field of MRI-based cartilage segmentation [ 10 , 13 , 20 ]. Convolutional Neural Networks (CNNs) and their variants played a pivotal role in this evolution. U-Net [ 13 ] and its variants U-Net++ [ 21 ], nnU-Net [ 22 ] have emerged as powerful DL architectures for automated MRI cartilage segmentation [ 23 ]. These methods leverage CNNs to learn features directly from image data, improving segmentation accuracy as well as consistency and reproducibility. The U-Net and its variants consist of an encoder path for feature extraction and a decoder path for upsampled predictions, connected by skip connections to preserve spatial details. To further enhance segmentation performance, attention mechanisms have been integrated into U-Net variants, addressing the challenges posed by the irregular shape and small size of cartilage within MRI images [ 24 ]. Transfer learning techniques have also been employed, using pre-trained models to initialize the network and accelerate training with limited labelled data [ 25 ]. Nevertheless, integrating DL models with classical shape priors, e.g., active appearance models (AAM) and statistical shape models (SSM), has further improved segmentation performance on MRI [ [26] , [27] , [28] ]. Recent advancements in DL have introduced a diverse array of specialized techniques designed to tackle specific challenges in MRI-based cartilage segmentation [ 29 ]. Data augmentation techniques, such as Generative Adversarial Network (GAN)-based methods [ 30 , 31 ] are used to generate synthetic MRI-like images, enriching the training dataset and mitigating data scarcity. Transformer-based models have been introduced to improve attention mechanisms [ 32 ], enabling better focus on subtle anatomical structures. In cases where source domain data is unavailable, source-free domain adaptation methods have been applied successfully in knee MRI segmentation [ 33 ]. Additionally, knowledge distillation and semi-supervised learning techniques [ [34] , [35] , [36] ] are being explored to leverage unlabelled data and improve efficiency, further broadening the range of solutions for automated cartilage segmentation. These developments underscore the ongoing evolution of DL for cartilage segmentation, pushing towards more accurate and efficient automated analysis in OA assessment and other musculoskeletal imaging applications. Fig. 1 illustrates a visual breakdown of these advancements, categorizing the discussed approaches into model types, methodologies, specific applications, and their associated challenges. Fig. 1 Overview of advancements in automated cartilage segmentation, highlighting model classifications, methodologies, applications, and challenges in the field. Fig. 1 2.2 Datasets and benchmarks The following datasets: iMorphics OAI [ 37 , 38 ], SKM-TEA [ 39 ], and OAI-ZIB [ 40 ], are widely used public datasets that provide comprehensive labels for training and evaluating methods in knee MRI analysis, particularly for segmentation tasks. A summarized description of these datasets is presented in Table 1 , highlighting their key characteristics and relevance to knee MRI analysis. Table 1 Summarized dataset details. Table 1 Name &amp; Reference Sample Size Nature of subjects Labels Image spacing (mm) Image size (px) MRI sequence OAI-iMorphics [ 37 , 38 ] 88 subjects, 176 images [ 71 ] Moderate &amp; severe OA patients FC, MTC, LTC, PC, MM, LM 0.365&#8727;0.465&#8727;0.7 384&#8727;384&#8727;160 3T Siemens, Sagittal 3D DESS WE [ 72 ] OAI-ZIB [ 40 ] 507 subjects, 507 images OA patients. &#8220;full spectrum of OA grades, with a strong tendency towards severe cases&#8221; [ 26 ] FB, TB, FC, MTC, LTC 0.365&#8727;0.465&#8727;0.7 384&#8727;384&#8727;160 3T Siemens, Sagittal 3D DESS WE [ 72 ] SKI-10 [ 73 ] (Currently not accessible) 100 images Late-stage OA patients from a surgical planning program FB, TB, FC, TC 0.4&#8727;0.4&#8727;1 290&#8727;340&#8727;110 (various sizes) 1.5T (&#8764;90 &#8203;%), 3T and 1T (&#8764;10 &#8203;%); T1w &amp; T2w, GRE &amp; SPGR SKM-TEA [ 39 ] 155 subjects, 155 images OA patients FC, MTC, LTC, PC 0.38&#8727;0.31 416&#8727;512&#8727;[80&#8211;88 slices] 3T GE; qDESS FB &#8203;= &#8203;femur bone, TB &#8203;= &#8203;tibia, FC &#8203;= &#8203;femoral cartilage, TC &#8203;= &#8203;tibial cartilage (one label for two sides), MTC &#8203;= &#8203;medial tibial cartilage, LTC &#8203;= &#8203;lateral tibial cartilage, PC &#8203;= &#8203;patellar cartilage, MM &#8203;= &#8203;medial meniscus, LM &#8203;= &#8203;lateral meniscus. Abbreviations-OA: osteoarthritis; qDESS: quantitative double-echo steady state; 3T/1.5T/1T: magnet field strength (tesla); WE: water excitation; T1w/T2w: T1-/T2-weighted; GRE/SPGR: gradient-recalled/spoiled gradient echo. Anatomy/labels-FB: femoral bone; TB: tibial bone; FC: femoral cartilage; TC: tibial cartilage; MTC: medial tibial cartilage; LTC: lateral tibial cartilage; -PC: patellar cartilage; MM: medial meniscus; LM: lateral meniscus. 2.2.1 iMorphics OAI dataset The iMorphics OAI dataset [ 37 , 38 ] includes 88 patient scans available from the public Osteoarthritis Initiative (OAI) database ( http://www.oai.ucsf.edu ). Images were acquired using a 3T Siemens MAGNETOM Trio scanners with Double Echo Steady State (DESS) pulse sequence with voxel size &#8203;= &#8203;0.36 &#8203;&#215; &#8203;0.36 &#8203;&#215; &#8203;0.7 &#8203;mm, matrix size &#8203;= &#8203;384 &#8203;&#215; &#8203;384, FOV &#8203;= &#8203;140 &#8203;mm, and 160 slices. The dataset includes both baseline and 12-month follow-up scans, each with corresponding manual cartilage segmentation masks. Manual segmentation of cartilage was performed by trained musculoskeletal radiologists following the iMorphics cartilage segmentation protocol, ensuring an intra-observer variation below 3 &#8203;%, with expert review for accuracy. OAI-ZIB dataset: Both the iMorphics OAI [ 37 , 38 ] and OAI-ZIB [ 40 ] datasets are derived from the OAI. However, they differ in terms of subject selection, OA severity distribution, OA grading, and the segmentation classes provided. The OAI-ZIB dataset includes scans from patients with OA across all severity grades, with the majority representing severe cases. This dataset focuses on the segmentation of four tissues: femur bone, femoral cartilage, tibia bone, and tibial cartilage, making it a valuable resource for studying OA-related structural changes. SKM-TEA: The SKM-TEA dataset [ 39 ] includes 155 quantitative DESS MRI knee scans acquired at Stanford University, consisting of raw k-space data, DICOM images, manual segmentations of six tissues (including cartilage and meniscus), and three-dimensional (3D) bounding boxes for 16 pathologies. The dataset is divided into 86 training, 33 validation, and 36 testing scans. Pathology annotations and tissue segmentations were manually performed, with localization based on radiology reports. This dataset supports both segmentation and pathology detection tasks. 3 Categorization of DL methods DL-based knee cartilage segmentation encompasses a variety of approaches designed to address the inherent challenges of 3D knee MRI. Table 2 provides a summary of DL methods applied to knee MRI cartilage segmentation. Furthermore, Fig. 2 illustrates slice-wise Dice Similarity Coefficient (DSC) agreement, where DSC scores are higher in central slices and decrease towards the periphery, primarily due to the partial volume effect at curved cartilage edges and through plane blurring, this trend however can be reduced with isotropic 3D imaging [ 41 ]. This variation underscores the necessity for DL models capable of maintaining consistent performance across the entire 3D volume. To address this, several methods, including 2D/3D architectures, attention mechanisms, knowledge distillation, adversarial learning, and data augmentation, have been proposed to improve segmentation accuracy and spatial consistency [ 2 ]. Table 2 Summarized details of deep learning methods in knee MRI cartilage segmentation. Table 2 Reference MRI Dataset Method Task Results of Task Ambellan et al. 2019 [ 26 ] 3D DESS, SKI10, OAI Imorphics and OAI ZIB datasets 3D Statistical Shape Models as well as 2D and 3D CNNs Cartilage Segmentation &#8203;+ &#8203;Bone DSC is 98.5 &#8203;% for FB, 98.5 &#8203;% for TB, 89.9 &#8203;% for FC, and 85.6 &#8203;% for TC DOSMA 2019 [ 43 ] 3D DESS OAI (88/176) 2D U-Net Cartilage Segmentation &#8203;+ &#8203;Bone FC (0.90), TC(0.88) PC (0.86), Meniscus (0.8) Desai et al. 2021 [ 74 ] 3D DESS OAI (88/176) 3D U-Net Cartilage Segmentation &#8203;+ &#8203;Bone FC (0.88), TC(0.87) PC (0.83), Meniscus (0.84) Zhou et al., 2018 [ 75 ] 3D FSE In-house 3D-FSE knee OA cohort (20 subjects) CNN (CED) &#8203;+ &#8203;3D fully connected CRF &#8203;+ &#8203;3D simplex deformable modeling Multi-structure segmentation (12 tissues, including Cartilage and Bone) Mean DSC &gt;0.9 for FB/TB; FC 0.806 &#8203;&#177; &#8203;0.062, TC 0.801 &#8203;&#177; &#8203;0.052; ASSD &lt;1 &#8203;mm for most tissues Liu et al., 2018 [ 76 ] T1w SPGR (SKI10), 3D-FSE, T2 maps SKI10 (100 scans; 60 train/40 test), clinical 3D-FSE (60 &#8203;pts), clinical T2 maps (100 &#8203;pts) SegNet (CED) &#8203;+ &#8203;3D simplex deformable modeling Cartilage Segmentation &#8203;+ &#8203;Bone SKI10: Cartilage VOE/VD (%): FC 28.4/8.1, TC 33.1/-1.2 3D-FSE: FC/TC/PC VOE (%): 33.1/35.9/22.0; VD (%): 11.2/6.1/-3.5 Chadoulos et al. 2022 [ 77 ] 3D DESS OAI (76/-) SegNet, VoxelMorph Cartilage Segmentation DSC:88.89 &#8203;%, Precision: 89.86 &#8203;%, Recall:88.12 &#8203;% Yang M et al. 2022 [ 25 ] 3D DESS OAI GAN &#8203;+ &#8203;Transfer Learning Cartilage Segmentation DSC: 0.819, HD 95 of 1.463 &#8203;mm, and an ASSD of 0.350 &#8203;mm Peng et al. , 2022 [ 36 ] 3D DESS/3D SPGR SKI-10 KCB-Net Cartilage Segmentation &#8203;+ &#8203;Bone Femur 98.41 &#8203;%, Femoral: 81.67 &#8203;%, Tibia 97.97, Tibial 78 &#8203;% Li et al. 2024 [ 33 ] 3D DESS/3D SPGR SKI-10 Source Free DA Cartilage Segmentation &#8203;+ &#8203;Bone Femur: 0.92, FC: 0.69, Tibia: 0.92, TC: 0.60, Av: 0.78 Ammar et al. 2025 [ 78 ] 3D DESS/3D FSE OAI (88/176), Private Knowledge Distillation (Successive Eigen Noise, Eigen Low-Rank Subspace Cartilage Segmentation FC: 0.83, LTC: 0.83, MTC: 0.83, PC: 0.81, LM: 0.85, MM: 0.87, Average: 0.84 Khan et al. 2025 [ 31 ] 3D DESS/3D FSE OAI Imorphics and Self Efficient UNet &#8203;+ &#8203;Cycle Gan Cartilage Segmentation FC: 0.8, LTC: 0.8, MTC: 0.8, PC: 0.8, LM: 0.8, MM: 0.8, Av: 0.8 FC &#8203;= &#8203;femoral cartilage, TC &#8203;= &#8203;tibial cartilage, MTC &#8203;= &#8203;medial tibial cartilage, LTC &#8203;= &#8203;lateral tibial cartilage, PC &#8203;= &#8203;patellar cartilage, MM &#8203;= &#8203;medial meniscus, LM &#8203;= &#8203;lateral meniscus. Abbreviations and metrics: 3D DESS: three-dimensional double-echo steady state; 3D FSE: three-dimensional fast spin echo; 3D SPGR: three-dimensional spoiled gradient echo; OAI: Osteoarthritis Initiative; SSM: statistical shape model; CED: convolutional encoder-decoder; CRF: conditional random field; GAN: generative adversarial network; DA: domain adaptation; DSC: Dice similarity coefficient; ASSD: average symmetric surface distance; HD95: 95th-percentile Hausdorff distance; VOE: volumetric overlap error; VD: volume difference. Anatomical labels: FB: femoral bone; TB: tibial bone; FC: femoral cartilage; TC: tibial cartilage; MTC: medial tibial cartilage; LTC: lateral tibial cartilage; PC: patellar cartilage; MM: medial meniscus; LM: lateral meniscus; Av: average. Fig. 2 Slice-wise 3D knee cartilage DSC (Dice Similarity Coefficient) agreement across the sagittal stack. DSC is computed between model predictions [ 48 ] and expert manual segmentations. Slice-wise Dice scores are higher in central slices and decrease toward the periphery, largely due to partial volume effects at curved cartilage boundaries and through-plane blurring, which increase boundary uncertainty. Fig. 2 3.1 2D and 3D CNN segmentation 2D CNNs, such as the original U-Net [ 13 ], process individual MRI slices and are computationally efficient. Many studies have demonstrated their effectiveness in segmenting knee structures, making them suitable for clinical use. For example, Norman et al. [ 42 ] reported DSC accuracy of 77.0 &#8203;%&#8211;87.8 &#8203;% for cartilage and 75.3 &#8203;%&#8211;80.9 &#8203;% for menisci, showing that 2D CNNs can provide reasonable baseline segmentation on 3D-DESS scans. However, for longitudinal assessment where cartilage changes are subtle, DSC at the lower end of this range (e.g., &#8764;0.77) may be insufficient, underscoring the need for higher-accuracy or 3D/ensemble methods for precise monitoring. In contrast, 3D CNN-based methods [ 36 ], such as 3D U-Net and its variants, directly incorporate volumetric spatial context by processing the entire 3D MRI volume. The prior-based 3D U-Net has been proposed [ 26 ], enhancing the standard 3D U-Net by incorporating average shape model (ASM) and subpixel technology in a two-stage process. In the first stage, it segments the femur and tibia, and in the second stage, ASM-based constraints are applied to refine cartilage segmentation. It achieved a DSC accuracy of 74.02 &#8203;%. However, some studies [ 43 ] on 3D DESS suggest little to no improvement of 3D CNNs over 2D methods. Recent work by Esrafilian et al. [ 44 ] further demonstrates the usability of CNN-based segmentation in clinical modelling pipelines. They employed both 2D and 3D versions of nnU-Net [ 22 ] to automatically segment bones, cartilages, menisci, and ligaments from knee MRI across multiple datasets. Esrafilian et al. [ 44 ] reported DSC against expert manual annotations, supporting the practical utility of CNN-based segmentation in downstream biomechanical simulations and personalized rehabilitation planning. 3.2 Attention mechanism models Laing et al. [ 45 ] proposes a Position-prior Clustering-based Self-attention Module (PCAM) for knee cartilage segmentation using MR images. PCAM integrates position-prior, clustering, and self-attention mechanisms into a V-Net architecture to capture long-range dependencies, ensure segmentation continuity, and reduce false positives. When tested on the OAI-ZIB dataset, the model demonstrated improved segmentation accuracy, achieving a DSC of 0.893 for femoral cartilage and 0.861 for tibial cartilage, outperforming plain V-Net and nnU-net [ 22 ]. Recently, Wang and Shi [ 46 ] proposed PA-UNet, a novel U-Net&#8211;based architecture with patch-based attention mechanisms for knee cartilage segmentation in MRI. Integrating channel-wise and patch-wise attention blocks it targets small structure detection and spatial detail. Evaluated on OAI-ZIB and SKI10, PA-UNet [ 46 ] achieved DSCs up to 90.2 &#8203;% (femoral) and 85.7 &#8203;% (tibial), with improvements that depended on model dimensionality (2D vs. 3D) and dataset. These gains for each pair of femoral/tibial were relative to the baselines considered such as: U-Net [ 13 ] (OAI-ZIB: 86.7/81.3; SKI10: 77.4/71.2), SeG-Net [ 47 ] (OAI-ZIB: 86.4/80.2), U-Net++ [ 21 ] (3D OAI-ZIB: 88.22/84.31; 3D SKI10: 77.20/71.40), Attention U-Net [ 24 ] (3D OAI-ZIB: 88.90/84.99; 3D SKI10: 79.93/76.01), Norman et al. [ 42 ] (SKI10 2D: 77.8/70.6). Overall, localized patch-based attention provided consistent, incremental benefits within these settings, while absolute DSCs remain within the range of strong plain U-Nets. 3.3 Adversarial learning and augmentation Adversarial learning, combined with augmentation, is presented as source-independent multi-domain adaptation framework [ 31 ] for knee MRI segmentation, aiming to overcome domain shifts in clinical imaging. The architecture features a modified U-Net [ 48 ], with compound scaling to enhance fine tissue detail extraction. It also incorporates pseudo-label attention and a GAN-enabled generator for unidirectional domain mapping. Through iterative training across 3D DESS, 3D T1-Fast Field Echo (T1-FFE), and 3D Fast/Turbo Spin Echo (FSE/TSE) datasets, the framework attains DSC of 87.01 &#8203;% (source domain) and 79.90 &#8203;% (target domain). While these absolute values are modest, they are within the typical range for cross-domain evaluations, where train/test protocols differ and show incremental improvements over non-adapted models, with notable benefits for small tissues such as the meniscus. Fig. 3 is presented from Ref. [ 31 ] to demonstrate the impact of domain generalization in segmentation, highlighting segmentation results on a 3D FSE MRI scan of an OA subject. In this example, a network trained on 3D DESS data achieves improved segmentation accuracy by utilizing adversarial learning and augmentation. Fig. 3 The figure shows the 3D FSE MRI scan of OA subject and its derived segmentation. (a) shows the ground truth labels, (b) show the segmentation from DL method. The domain adaptation helps to achieve the better segmentation even though the network is trained on 3D DESS data. (c) shows the derived thickness map corresponding to the segmentation outcome with arrows pointing out the challenging regions where cartilage is difficult to segment as shown in (a), (b) and (c). Fig. 3 Panfilov et al. [ 49 ] uses a U-Net-based architecture for knee MRI segmentation, enhanced with mixup and unsupervised domain adaptation (UDA) techniques. The methodology introduces mixup, which generates synthetic training samples through linear interpolation, enhancing generalization and reducing overfitting. In addition, adversarial UDA is employed to align feature distributions between different MRI acquisition settings. The approach achieved DSC of 0.819 for femoral cartilage (FC) and 0.802 for tibial cartilage (TC) on an independent test set. 3.4 Knowledge distillation Knowledge distillation has been explored as a method for segmentation and for addressing heterogeneity in MRI datasets from diverse sources. He et al. [ 35 ] proposes a federated few-shot learning framework with dual knowledge distillation to segment knee cartilages from heterogeneous 3D MR images. The architecture employs a teacher-student model, where dual knowledge (response-based and feature-based) is distilled from a pre-trained teacher model (using high-resolution OAI repository data) to student models at individual clients with low-resolution data. The approach addresses annotation scarcity, imaging heterogeneity, and reduces data transfer. The method outperforms state-of-the-art federated approaches, achieving a DSC of 0.789 vs DSC of 0.746 (without using prior knowledge), with significant improvements in the segmentation of small cartilage like patellar cartilage (PC), i.e 0.690 vs 0.654. Recent approaches in knowledge distillation, such as SEN-MTKD [ 34 ], address domain shifts and noisy pseudo-labels in knee MRI segmentation. Using a teacher-student architecture with modules like Eigen Low-Rank Subspace (ELRS) and Successive Eigen Noise (SEN), it aligns features across domains from OAI DESS and 3D FSE datasets. This method segments knee tissues such as femoral cartilage, tibial cartilage, patellar cartilage, and meniscus, achieving a Dice accuracy of 83.52 &#8203;%, outperforming state-of-the-art methods using 25 &#8203;% of labelled data. 4 Challenges and solutions The advancement of DL models for knee cartilage segmentation is promising; however, clinical adoption is primarily limited by the lack of clearly established clinical use cases and integration pathways. Additional barriers include the knee's intricate anatomy, limited annotated datasets, variability in imaging protocols, and domain shifts in knee MRI. Addressing these obstacles is essential to achieve reliable, generalizable, and clinical applicable segmentation. In this section, we outline the primary technical challenges and summarize representative solutions. 4.1 Label scarcity and data variability A significant challenge in developing DL methods for knee MRI segmentation is the limited availability of training datasets with high-quality manual segmentation labels. This limitation is further compounded by variations in acquisition protocols, hardware configurations, scanner models, and vendors, which introduce inconsistencies and hinder the generalizability of these models. Although most published knee cartilage segmentation studies rely on 3D gradient-echo MRI (e.g., DESS/SPGR), multislice two-dimensional (2D) FSE remains the standard imaging sequence in clinical knee MRI. Increasingly, 3D FSE with variable flip angle modulation achieves high scan efficiency by using long echo trains without excessive blurring caused by T2 relaxation [ 50 ]. All major MRI vendors provide commercial implementations of such techniques. With isotropic resolution, 3D FSE reduces partial volume effects along the through-plane direction, enables reformatting to arbitrary planes, and shortens overall exam time [ 51 ]. Other rapid 3D MRI acquisition and quantitative imaging methods have also been introduced for imaging of OA [ 50 , 52 ]. This mismatch between research datasets (often 3D gradient-echo) and clinical acquisitions (2D/3D FSE) motivates methods that transfer or generalize across sequences. Given the prevalence of FSE contrast in knee MRI, it is important to develop DL methods that can generalize to the segmentation of FSE images. However, publicly available 3D FSE data remains limited. The OAI database provides a substantial dataset acquired using the 3D DESS pulse sequence, accompanied by manually segmented labels. However, adapting models trained on OAI data to 3D FSE remains challenging. The thin, irregular 3D structure of cartilage, combined with patient-specific variability in knee anatomy and OA severity, further complicates this task [ 36 , 53 ]. The variability in image features between the source domain (DESS) and the target domain (FSE) highlights the problem of domain shift, which is further exacerbated by differences in scanner models, vendors, and acquisition protocols. 4.2 Domain adaptation and transfer learning Transfer learning offers a partial solution by fine-tuning pre-trained models on specific datasets [ 14 ]. However, this approach still depends on additional labelled data from the target domain. Several studies have applied UDA techniques to knee MRI segmentation. For instance, Liu et al. [ 30 ] incorporated a segmentation network into an adversarial framework to achieve bone and cartilage segmentation. On PD-FSE, this method yielded femoral/tibial cartilage DSCs of 0.66 and 0.65 vs 0.77 and 0.70 for supervised U-Net; on T2-FSE, 0.81 and 0.75 vs 0.82 and 0.76. These DSCs (&#8764;0.65&#8211;0.82) reflect the difficulty of unsupervised adaptation from gradient echo acquisitions to FSE without target labels. Panfilov et al. [ 49 ] employed UDA through cross-domain alignment to enhance cartilage segmentation performance. Specifically, segmentation accuracy improved from 0.791 to 0.819 for femoral cartilage and from 0.746 to 0.802 for tibial cartilage across datasets obtained from different scanners, while maintaining a consistent pulse sequence. Li et al. [ 33 ] proposed a source-free UDA method for knee joint segmentation, enabling adaptation without requiring access to the source dataset and effectively addressing privacy concerns. Their approach achieved a mean DSC of 0.806 (SKI-10 to OAI-ZIB) and 0.781 (OAI-ZIB to SKI-10). In certain cases, such as bone structure segmentation, the results were comparable to those of fully supervised models. These studies demonstrated the potential of UDA in knee MRI segmentation. 4.3 Foundation model Foundation models are gaining attentions recently. Segment Anything (SAM) [ 54 ] and SAM2 [ 55 ] have been developed to improve generalizability of segmentation. These foundation models are trained using a very large dataset which includes diverse image contents. The original SAM and SAM2 were trained for segmenting natural images, and variants were created for medical data. MedSAM [ 56 ] finetuned the SAM on multiple medical datasets. In the context of knee MRI segmentation, Hoyer et al. [ 57 ] conducted a comprehensive evaluation of SAM, SAM2, and MedSAM on knee MRI data. The initial performance of the three models without fine-tuning was limited; however, with fine-tuning, their performance became comparable to traditional segmentation models such as U-Net. This highlights the importance of developing modality-specific foundation models tailored for knee MRI, as general-purpose models trained on natural images may face challenges in generalizing effectively to this domain without targeted adaptation. 5 Applications of knee MRI cartilage segmentation Accurate segmentation of knee cartilage is crucial for a variety of research and clinical applications, particularly in the context of OA and related musculoskeletal disorders. In practice, it enables progression monitoring, assessment of treatment response (e.g., after cartilage restoration or ligament/meniscal surgery), and supports surgical planning. By providing precise cartilage thickness and other morphometrics, segmentation underpins imaging biomarkers for disease tracking, cohort studies and personalized treatment strategies [ 19 ]. 5.1 Cartilage thickness and morphometrics Chaudhari et al. [ 58 ] applied DL for both super-resolution and cartilage segmentation in knee MRI. A 3D U-Net achieved Dice accuracy of 90.2 &#8203;% (original) and 89.6 &#8203;% (super-resolved) images, outperforming interpolation-based methods (86.3 &#8203;%). This demonstrates the ability of DL-based segmentation to maintain accurate cartilage morphometry, even in enhanced lower-resolution scans, and highlights its potential for scalable, automated OA analysis. Yao et al. introduces CartiMorph [ [59] , [60] ] an automated framework for knee articular cartilage morphometrics, aimed at improving imaging biomarker extraction for knee OA. The framework quantifies cartilage subregion metrics, including full-thickness cartilage loss (FCL), mean thickness, surface area, and volume, leveraging DL models for tissue segmentation, template construction, and image registration. The authors also developed CartiMorph Toolbox (CMT) [ 60 ] an AI-powered framework for automated knee cartilage morphometrics, focusing on cartilage shape and lesion quantification from medical images. Compared to atlas-based methods [ 12 ], CartiMorph consistently provide more robust and quantitative metrics, supporting a wide range of clinical applications including OA progression monitoring, biomarker development, and treatment evaluation. Kessler et al. [ 61 ] combined DL-based segmentations with 3D cartilage surface mapping (3D-CaSM) to assess cartilage thickness and T2 values. Their findings demonstrated that 3D U-Nets produced more accurate and region-specific thickness estimates compared to 2D U-Nets, particularly in anatomically complex regions such as the femoral condyle. These results underscore the potential of DL-based segmentation for detailed, surface-level cartilage analysis. Khan et al. [ 48 ] presents an automatic segmentation framework for knee tissue analysis from MRI, focusing on cartilage and meniscus. The method combines a multipath convolutional neural network (CNN) with low-rank (LR) tensor reconstruction to extract structural similarities from 3D MRI blocks, generates trimaps to identify high-confidence regions, and employs alpha matting for accurate boundary refinement. Validated on the OAI dataset, the method achieved average DSC of 0.892 across six knee tissue compartments, with femoral and tibial cartilage exceeding 0.9. The approach also demonstrated robust segmentation in thin cartilage regions and late-stage OA cases, along with thickness mapping on 3D DESS and FFET1 MRI volumes. Iriondo et al. [ 62 ] developed a fully automated DL pipeline using CNN ensembles for knee cartilage segmentation and thickness measurement, achieving high accuracy (DSC: femur 0.89, tibia 0.88, patella 0.85; concordance correlation coefficient (CCC) up to 0.93 vs. manual). They analyzed 8-year trajectories in 1453 knees, identifying distinct patterns of cartilage thinning and thickening. Nonstable trajectories, especially in the medial compartments, were associated with significantly higher odds of incident radiographic OA (e.g., odds ratio &#8203;= &#8203;10.1 for accelerated thinning in medial femur). This approach enables improved OA phenotyping and longitudinal assessment of cartilage degeneration. While DL markedly reduces reader time, longitudinal utility depends on responsiveness to change. A fully automated U-Net trained on radiographic OA knees detected 24-month cartilage thickness loss with responsiveness comparable to expert manual segmentation and similar cohort discrimination, identifying a comparable proportion of individual progressors [ 63 ]. DL model trained on healthy-reference knees showed reduced responsiveness, highlighting the need for OA-specific training. Table 3 provides a summary of the cartilage thickness mapping methods, along with their final outcomes based on thickness measurements. Table 3 Summarized details of deep learning methods in knee MRI cartilage segmentation and their applications in thickness measurement. Table 3 Cartilage Segmentation applications in thickness Reference MRI Dataset Method Task Results of Task Chaudhari et al., 2020 [ 58 ] 3D DESS OAI DeepResolve (3D CNN SR) &#8203;+ &#8203;3D U-Net segmentation Super-resolution &#8203;+ &#8203;Cartilage segmentation &#8203;+ &#8203;Morphometry DSCs: 89.6 &#8203;% (SR), 90.2 &#8203;% (HR); Overlap with HR: 97.6 &#8203;% (SR), 95.0 &#8203;% (TCI); RMS-CV% (volume): 2.8 &#8203;% (SR), 3.1 &#8203;% (HR), 4.9 &#8203;% (TCI) Iriondo et al., 2021 [ 62 ] 3D DESS, OAI-ZIB Dataset Ensemble of 6 CNNs (2D and 3D) &#8203;+ &#8203;Euclidean Distance Transform &#8203;+ &#8203;Skeletonization Automatic segmentation &#8203;+ &#8203;Subcompartmentalization &#8203;+ &#8203;Thickness measurement &#8203;+ &#8203;Longitudinal trajectory analysis MAE: 0.11&#8211;0.14 &#8203;mm (vs manual); Reproducibility: 0.04&#8211;0.07 &#8203;mm; DSCs: femoral: 0.890, tibial: 0.880, patellar: 0.850; CCC: 0.817&#8211;0.929; RMS CV%: &lt;3.5 &#8203;%; Kessler et al. 2022 [ 61 ] 3D DESS, FFET1 OAI Imorphics Surface-based cartilage analysis, thickness, T2 composition, manual segmentation, network-generated segmentation, OAI-ZIB testing images. Segmentation &#8203;+ &#8203;Cartilage thickness map &#8203;+ &#8203;measurement Range: 3D UNet: 0.07 to 0.14 [-0.14, 0.39] mm. For T2, mean bias: 95 &#8203;% Range: 0.16 to 1.32 [-4.71, 4.83] ms Khan et al., 2022 [ 48 ] 3D DESS, FFET1 OAI Imorphics and Self Efficient UNet &#8203;+ &#8203;Matting &#8203;+ &#8203;Geometric norm Segmentation &#8203;+ &#8203;Cartilage thickness map FC (0.91),LTC (0.91), MTC (0.89), PC (0.87), LM (0.88), MM (0.87) Yao et al., 2024 [ 59 ] 3D DESS, OAI-ZIB Dataset Ensemble of 2D and 3D Models Surface-Normal-Based Thickness Mapping Segmentation &#8203;+ &#8203;Cartilage thickness map &#8203;+ &#8203;measurement RMSD: &lt;8 &#8203;%. CVRMSD: &lt;0.17 Mean Thickness: 0.82&#8211;0.97 Surface Area: 0.82&#8211;0.98 Volume: 0.89&#8211;0.98 Jansen et al., 2025 [ 79 ] 3D SPGR IMI-APPROACH [ 80 ] Deep learning &#8203;+ &#8203;manual correction &#8203;+ &#8203;CaSM (3D surface mapping) Cartilage segmentation &#8203;+ &#8203;Thickness mapping &#8203;+ &#8203;Statistical analysis Vertex-wise thickness (min &#8764;1.5 &#8203;mm); male sex &amp; height linked to increased thickness; OA severity (KL, JSN, BMLs, osteophytes) linked to region-specific thinning or thickening (&#8722;0.35 to +0.5 &#8203;mm) G. Hoyer et al., 2025 [ 69 ] 3D DESS OAI Ensemble of 2D and 3D V-Nets &#8203;+ &#8203;PCA &#8203;+ &#8203;Multivariate regression analysis Bone and cartilage segmentation &#8203;+ &#8203;Bone Shape &#8203;+ &#8203;Cartilage thickness DSCs: Meniscus (0.87); FC (0.89); TC(0.88); PC(0.85) and Bones (0.85). Cartilage Thickness: MAE (auto vs manual): &#8804;0.15 &#8203;mm; Reproducibility (scan&#8211;rescan): &#8804;0.053 &#8203;&#177; &#8203;0.03 &#8203;mm Abbreviations-3D DESS: three-dimensional double-echo steady state; 3D SPGR: three-dimensional spoiled gradient echo; FFE/T1: fast field echo T1; SR: super-resolution; HR: high resolution; TCI: tricubic interpolation; EDT: Euclidean distance transform; CaSM: cartilage surface mapping; PCA: principal component analysis; CCC: concordance correlation coefficient; MAE: mean absolute error; RMSD: root-mean-square difference; CVRMSD: coefficient of variation of RMSD; RMS-CV%: root-mean-square coefficient of variation; DSC: Dice similarity coefficient; KL: Kellgren-Lawrence grade; JSN: joint space narrowing; BML: bone marrow lesion. Anatomy-FB: femur; TB: tibia; FC: femoral cartilage; TC: tibial cartilage; MTC: medial tibial cartilage; LTC: lateral tibial cartilage; PC: patellar cartilage; MM: medial meniscus; LM: lateral meniscus. Measurements-thickness maps/values are in mm unless noted; T2 values in ms. 5.2 MRI segmentation with biochemical imaging Razmjoo et al. [ 64 ] developed a 3D V-Net DL model for automatic cartilage segmentation and T2 relaxometry across the entire OAI dataset (25,729 MRIs). The model achieved DSC up to 0.75 and T2 values strongly correlated with manual measurements. Elevated T2 in medial femur and tibia was significantly associated with future OA incidence and total knee replacement. This study highlights T2 mapping as a promising early imaging biomarker for OA diagnosis and risk prediction. Zhong et al. [ 65 ] proposes an automated post-processing pipeline for T1&#961; imaging of knee cartilage to facilitate quantitative MRI analysis. The pipeline includes image standardization, DL-based cartilage segmentation, subregion parcellation into 20 regions, and T1&#961; quantification. Evaluated on 40 subjects (30 OA patients, 10 healthy volunteers), the method showed reliable segmentation performance (DSCs: 0.74&#8211;0.88) and T1&#961; quantification with minimal error (RMSD: 0.79 &#8203;ms for patients, 0.56 &#8203;ms for volunteers). This pipeline enables efficient subregional cartilage mapping, supporting early OA detection, prognosis, and treatment monitoring in clinical applications. Schmidt et al. [ 53 ] evaluated two 2D U-Net models for automated knee cartilage segmentation across diverse qDESS MRI (SKM-TEA dataset). The qDESS-trained model achieved strong performance (DSCs: 0.79&#8211;0.93; T2 CCC: 0.75&#8211;0.98) across scanners and populations without fine-tuning. Its robust accuracy in both morphology and relaxometry supports its application in large-scale, multi-site quantitative MRI studies. Goyal et al. [ 66 ] present an open-source, fully automated &#8220;KneePipeline&#8221; that segments knee bones, cartilage, and menisci from qDESS MRI using a 2D U-Net and derives key biochemical/morphometric biomarkers (cartilage T2, cartilage thickness, meniscus volume, femoral BScore). In a 20-subject prospective cohort with two manual annotators, cartilage segmentation achieved DSC &#8776;0.84&#8211;0.91 (higher for bone; meniscus &#8764;0.85&#8211;0.89). Automated quantitative outputs closely matched manual references (cartilage T2 ICC 0.89&#8211;0.99; thickness ICC 0.68&#8211;0.93). The pipeline enables rapid, reproducible whole-joint biochemical MRI analysis for knee osteoarthritis, with optional support for PET-based bone metabolism metrics. Pedoia et al. [ 67 ] used baseline OAI T2 maps to classify knees with and without radiographic OA. Using atlas-based segmentation and voxel-based relaxometry, they found widespread T2 prolongation in OA, especially in deep cartilage layers. A DenseNet trained on flattened T2 maps achieved area under the curve (AUC) 83.4 &#8203;% (95 &#8203;% CI&#8764;82.5&#8211;84.3) with Sensitivity 77.0 &#8203;% (95 &#8203;% CI&#8764;74.2&#8211;79.8), Specificity 77.9 &#8203;% (95 &#8203;% CI&#8764;75.1&#8211;80.6), outperforming a best shallow model using principal component analysis (PCA) features and demographics (AUC 77.8 &#8203;%). The difference in misclassification rates (22.83 &#8203;% vs 30.5 &#8203;%) was statistically significant (McNemar's &#967; 2 &#8203;= &#8203;10.33, p &#8203;= &#8203;0.0013). The study demonstrates that deep learning on T2 relaxometry captures meaningful biochemical changes and improves early OA detection over traditional approaches. 5.3 MRI-based OA analytics and knee replacement Qiu et al. [ 68 ] presented cross-plane and cross-sequence attention with ResNet3D-based encoders to diagnose 12 knee abnormalities, including meniscal tears and ligament injuries, from multi-sequence MRI data (PDW, T1W, T2W across sagittal, coronal, and axial planes). Tested on 1748 patients, it achieved an area under the receiver operating characteristic curve (AUC-ROC) of 0.812, outperforming junior radiologists and enhancing diagnostic accuracy as an assistive tool for senior radiologists. Tack et al. [ 27 ] proposed a fully automated method combining 2D and 3D U-Net CNNs with statistical shape models for segmenting knee menisci and tibial cartilage from sagittal DESS MRI. The approach utilized segmentation, enabling extraction of quantitative biomarkers like meniscal volume, tibial coverage, and extrusion. Notably, medial meniscal extrusion predicted incident OA with an odds ratio of 1.51 (P &#8203;= &#8203;0.001), demonstrating the utility of DL-based segmentation for OA biomarker analysis in large-scale MRI studies. G. Hoyer et al. [ 69 ] presents a framework for creating a knee joint digital twin using quantitative MRI and machine learning to predict OA progression and knee replacement (KR) outcomes. Using OAI data with over 4700 participants, the authors identified significant imaging biomarkers across cartilage thickness, T2 relaxation time, and bone and meniscus shapes. Notably, femoral cartilage thickness principal component (PC-2) was protective in both OA incidence and KR models (e.g., odds ratio&#8776;0.95, p &#8203;&lt; &#8203;0.001), while tibial bone shape and patellar/femoral T2 modes were associated with increased KR risk (p &#8203;&lt; &#8203;0.01). The study also introduced a 3D visualization tool to help radiologists interpret biomarkers, enabling personalized knee health monitoring. Zhong et al. [ 70 ] proposes an automated knee OA phenotype classification along with UDA. Using a CNN encoder trained on the OAI dataset and adapted to a smaller, locally collected 3D FSE MRI dataset, the method classifies cartilage/meniscus and subchondral bone phenotypes. The integration of segmentation outputs into phenotype classification pipelines strengthens the anatomical relevance of predictions, facilitating their application in OA grading and progression tracking. 6 Conclusion Automated segmentation methods, powered by DL are at least as accurate as expert manual approaches, often more consistent than traditional (non-DL, hand-crafted) pipelines. The advancements in DL methods facilitate precise identification of structural changes in cartilage and other knee tissues, enabling automatic detection of degenerative conditions and more effective clinical decision-making. Despite significant progress, several hurdles remain. Variability in imaging protocols and patient-specific anatomical differences often lead to inconsistencies when applying models across diverse datasets. Efforts to overcome this issue, such as leveraging domain adaptation and integration of synthetic data, have shown promise but require further refinement to ensure broader applicability. Additionally, the limited availability of annotated datasets continues to constrain the development of robust models, with researchers exploring alternative solutions like semi-supervised learning and the foundation models to mitigate this bottleneck. Author contribution Sheheryar Khan led study's conceptualization, performed the main part of the writing, data preparation, experimentation and results presentation. Muhammad Ammar Khawar contributed in writeup, focusing on DL methods, writing analysis of Knowledge distillation methods. Muhammad Asim assisted in writing the manuscript and preparing figures. Junru Zhong provided dataset information and created data tables along with editing and analysis. Rizwan Qureshi contributed to writing the section on applications in knee cartilage segmentation. Weitian Chen aided in conceptualization, overseeing the work, critical analysis on MRI pulse sequences, IRB approval, provided resources, and contributed to reviewing and editing the manuscript for submission. IRB approval This study was conducted with IRB approval from the joint CUHK-NTEC. Clinical Research Ethics Committee (reference number: CREC 2020.115 (Apr 15, 2020). Conflict of interest None of the authors have conflict of interest to disclose. References 1 Cross M. The global burden of hip and knee osteoarthritis: estimates from the global burden of disease 2010 study Ann. Rheum. Dis. 73 7 2014 1323 1330 24553908 10.1136/annrheumdis-2013-204763 2 Bousson V. Benoist N. Guetat P. Attan&#233; G. Salvat C. Perronne L. Application of artificial intelligence to imaging interpretations in the musculoskeletal area: where are we? Where are we going? Jt. Bone Spine 90 1 2023 105493 10.1016/j.jbspin.2022.105493 36423783 3 Felson D.T. A new approach yields high rates of radiographic progression in knee osteoarthritis J. Rheumatol. 35 10 2008 2047 2054 18793000 PMC2758234 4 Wang Y. Wluka A.E. Jones G. Ding C. Cicuttini F.M. Use magnetic resonance imaging to assess articular cartilage Ther. Adv. Musculoskelet. Dis. 4 2 2012 77 97 22870497 10.1177/1759720X11431005 PMC3383521 5 Roemer F.W. Crema M.D. Trattnig S. Guermazi A. Advances in imaging of osteoarthritis and cartilage Radiology 260 2 2011 332 354 21778451 10.1148/radiol.11101359 6 Link T.M. Joseph G.B. Li X. MRI-based T1rho and T2 cartilage compositional imaging in osteoarthritis: what have we learned and what is needed to apply it clinically and in a trial setting? Skelet. Radiol. 52 11 Nov.2023 2137 2147 10.1007/S00256-023-04310-X/METRICS PMC11409322 37000230 7 Oei E.H.G. Hirvasniemi J. vanZadelhoff T.A. van derHeijden R.A. Osteoarthritis year in review 2021: imaging Osteoarthr. Cartil. 30 2 Feb.2022 226 236 10.1016/J.JOCA.2021.11.012 34838670 8 Atkinson H.F. MRI T2 and T1&#961; relaxation in patients at risk for knee osteoarthritis: a systematic review and meta-analysis BMC Musculoskelet. Disord. 20 1 2019 1 18 10.1186/S12891-019-2547-7 2019 201 31039785 PMC6492327 9 Le J. Peng Q. Sperling K. Biochemical magnetic resonance imaging of knee articular cartilage: T1rho and T2 mapping as cartilage degeneration biomarkers Ann. N. Y. Acad. Sci. 1383 1 Nov.2016 34 42 10.1111/NYAS.13189 27472534 10 Rankin I.A. Fast-field cycling magnetic resonance imaging &#8211; developing a new biomarker for early osteoarthritis of the knee Osteoarthr. Cartil. 26 Apr.2018 S467 10.1016/j.joca.2018.02.881 11 Zayniddinov X.N. Normatov R.M. Azimov B.R. Gafurov S.A. Tools for manual 3D medical image segmentation and data preprocessing for automatic 3D medical image segmentation Int. J. Sci. Res. Index. 5 1 2024 233 237 12 Ebrahimkhani S. Jaward M.H. Cicuttini F.M. Dharmaratne A. Wang Y. deHerrera A.G.S. A review on segmentation of knee articular cartilage: from conventional methods towards deep learning Artif. Intell. Med. 106 January 2019 2020 101851 10.1016/j.artmed.2020.101851 32593389 13 Ronneberger O. Fischer P. Brox T. U-net: convolutional networks for biomedical image segmentation Medical Image Computing and computer-assisted intervention&#8211;MICCAI 2015: 18Th International Conference, Munich, Germany, October 5-9, 2015, Proceedings, Part III 18 2015 Springer 234 241 14 Mead K. Cross T. Roger G. Sabharwal R. Singh S. Giannotti N. MRI deep learning models for assisted diagnosis of knee pathologies: a systematic review Eur. Radiol. 2024 1 13 10.1007/s00330-024-11105-8 PMC12021734 39422725 15 Mathiessen A. Ashbeck E.L. Huang E. Bedrick E.J. Kwoh C.K. Duryea J. Cartilage topography assessment with local area cartilage segmentation (LACS) for knee MRI Arthritis Care Res. 74 12 Dec.2022 2013 10.1002/ACR.24745 PMC8727638 34219396 16 Latif M.H.A. Faye I. Automated tibiofemoral joint segmentation based on deeply supervised 2D-3D ensemble U-Net: data from the osteoarthritis initiative Artif. Intell. Med. 122 2021 10.1016/j.artmed.2021.102213 34823835 17 Wirth W. Accuracy and longitudinal reproducibility of quantitative femorotibial cartilage measures derived from automated U-Net-based segmentation of two different MRI contrasts: data from the osteoarthritis initiative healthy reference cohort Magn. Reson. Mater. Physics, Biol. Med. 34 3 Jun.2021 337 354 10.1007/S10334-020-00889-7/TABLES/6 PMC8154803 33025284 18 Martel-Pelletier J. Paiement P. Pelletier J.P. Magnetic resonance imaging assessments for knee segmentation and their use in combination with machine/deep learning as predictors of early osteoarthritis diagnosis and prognosis Ther. Adv. Musculoskelet. Dis. 15 Jan.2023 10.1177/1759720X231165560 1759720X231165560 PMC10155034 37151912 19 Martel-Pelletier J. Paiement P. Pelletier J.-P. Magnetic resonance imaging assessments for knee segmentation and their use in combination with machine/deep learning as predictors of early osteoarthritis diagnosis and prognosis Ther. Adv. Musculoskelet. Dis. 15 2023 1759720X231165560 10.1177/1759720X231165560 PMC10155034 37151912 20 Avanzo M. Stancanello J. Pirrone G. Drigo A. Retico A. The evolution of artificial intelligence in medical imaging: from computer science to machine and deep learning Cancers (Basel) 16 21 2024 3702 39518140 10.3390/cancers16213702 PMC11545079 21 Zhou Z. Rahman Siddiquee M.M. Tajbakhsh N. Liang J. Unet++: a nested u-net architecture for medical image segmentation Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support: 4Th International Workshop, DLMIA 2018, and 8th International Workshop, ML-CDS 2018, Held in Conjunction with MICCAI 2018, Granada, Spain, September 20, 2018 2018 Springer 3 11 10.1007/978-3-030-00889-5_1 PMC7329239 32613207 22 Isensee F. Jaeger P.F. Kohl S.A.A. Petersen J. Maier-Hein K.H. nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation Nat. Methods 18 2 Feb.2021 203 211 10.1038/S41592-020-01008-Z SUBJMETA=114,1564,308,575,631,692;KWRD=IMAGE+PROCESSING,TRANSLATIONAL+RESEARCH 33288961 23 Kumar D. Gandhamal A. Talbar S. Hani A.F.M. Knee articular cartilage segmentation from MR images: a review ACM Comput. Surv. 51 5 2018 1 29 24 Byra M. Knee menisci segmentation and relaxometry of 3D ultrashort echo time cones MR imaging using attention U-Net with transfer learning Magn. Reson. Med. 83 3 2020 1109 1122 31535731 10.1002/mrm.27969 PMC6879791 25 Yang M. Automated knee cartilage segmentation for heterogeneous clinical MRI using generative adversarial networks with transfer learning Quant. Imag. Med. Surg. 12 5 2022 2620 10.21037/qims-21-459 PMC9014147 35502381 26 Ambellan F. Tack A. Ehlke M. Zachow S. Automated segmentation of knee bone and cartilage combining statistical shape knowledge and convolutional neural networks: data from the osteoarthritis initiative Med. Image Anal. 52 2019 109 118 30529224 10.1016/j.media.2018.11.009 27 Tack A. Mukhopadhyay A. Zachow S. Knee menisci segmentation using convolutional neural networks: data from the osteoarthritis initiative Osteoarthr. Cartil. 26 5 2018 680 688 10.1016/J.JOCA.2018.02.907 29526784 28 Liu H. Sun Y. Cheng X. Jiang D. Prior-based 3D U-Net: a model for knee-cartilage segmentation in MRI images Comput. Graph. 115 Oct.2023 167 180 10.1016/J.CAG.2023.07.008 29 Yeoh P.S.Q. Emergence of deep learning in knee osteoarthritis diagnosis Comput. Intell. Neurosci. 2021 1 Jan.2021 4931437 10.1155/2021/4931437 PMC8598325 34804143 30 Liu F. SUSAN: segment unannotated image structure using adversarial network Magn. Reson. Med. 81 5 2019 3330 3345 30536427 10.1002/mrm.27627 PMC7140982 31 khan S. Source independent multiple-domain adaptation for knee osteoarthritis cartilage and meniscus segmentation in clinical magnetic resonance imaging Intell. Med. Jun.2025 10.1016/J.IMED.2024.12.002 32 Li X. SDMT: spatial dependence multi-task transformer network for 3D knee MRI segmentation and landmark localization IEEE Trans. Med. Imag. 42 8 Aug.2023 2274 2285 10.1109/TMI.2023.3247543 37027574 33 Li S. Zhao S. Zhang Y. Hong J. Chen W. Source-free unsupervised adaptive segmentation for knee joint MRI Biomed. Signal Process Control 92 Jun.2024 106028 10.1016/J.BSPC.2024.106028 34 Khan S. Semi-supervised knee cartilage segmentation with successive eigen noise-assisted mean teacher knowledge distillation IEEE Trans. Med. Imag. 2025 10.1109/TMI.2025.3556870 40168230 35 He X. Dealing with heterogeneous 3d Mr knee images: a federated few-shot learning method with dual knowledge distillation Proc. Int. Symp. Biomed. Imag. 2023-April, 2023 10.1109/ISBI53787.2023.10230679 36 Peng Y. KCB-Net: a 3D knee cartilage and bone segmentation network via sparse annotation Med. Image Anal. 82 2022 102574 10.1016/j.media.2022.102574 PMC10515734 36126403 37 OAI-The OSteoarthritis initiative&#8221;, Online. Available: https://nda.nih.gov/oai . 38 Williams T.G. Measurement and visualisation of focal cartilage thickness change by MRI in a study of knee osteoarthritis using a novel image analysis tool Br. J. Radiol. 83 995 2010 940 948 20223905 10.1259/bjr/68875123 PMC3473735 39 Desai A.D. SKM-TEA: A dataset for accelerated mri reconstruction with dense image labels for quantitative clinical evaluation, in Proc. Int. Conf. Neural Inf. Process. Syst. 2021 2531 2544 40 OAI-ZIB datset.&#8221; Online. Available: https://www.zib.de/research/projects/analysis-and-quantification-morphological-and-structural-changes-cartilage . 41 Mugler J.P. Optimized three-dimensional fast-spin-echo MRI J. Magn. Reson. Imag. 39 4 2014 745 767 10.1002/JMRI.24542 24399498 42 Norman B. Pedoia V. Majumdar S. Use of 2D U-Net convolutional neural networks for automated cartilage and meniscus segmentation of knee MR imaging data to determine relaxometry and morphometry Radiology 288 1 Jul.2018 177 185 10.1148/RADIOL.2018172322 29584598 PMC6013406 43 Desai A.D. DOSMA: a deep-learning, open-source framework for musculoskeletal MRI analysis Proc 27th Annual Meeting 2019 ISMRM Montreal 1135 44 Esrafilian A. An automated and robust tool for musculoskeletal and finite element modeling of the knee joint IEEE Trans. Biomed. Eng. 72 1 2024 56 69 10.1109/TBME.2024.3438272 39236141 45 Liang D. Liu J. Wang K. Luo G. Wang W. Li S. Position-prior clustering-based self-attention module for knee cartilage segmentation Lect. Notes Comput. Sci. 13435 LNCS 2022 193 202 10.1007/978-3-031-16443-9_19 46 Wang X. Shi C. Patch attention U-Net for knee cartilage segmentation in magnetic resonance images Biomed. Signal Process Control 106 Aug.2025 107754 10.1016/J.BSPC.2025.107754 47 Badrinarayanan V. Kendall A. Cipolla R. SegNet: a deep convolutional encoder-decoder architecture for image segmentation IEEE Trans. Pattern Anal. Mach. Intell. 39 12 Dec.2017 2481 2495 10.1109/TPAMI.2016.2644615 28060704 48 Khan S. Azam B. Yao Y. Chen W. Deep collaborative network with alpha matte for precise knee tissue segmentation from MRI Comput. Methods Progr. Biomed. 222 Jul.2022 106963 10.1016/J.CMPB.2022.106963 35752117 49 Panfilov E. Tiulpin A. Klein S. Nieminen M.T. Saarakkala S. Improving Robustness of Deep Learning Based Knee MRI Segmentation: Mixup and Adversarial Domain Adaptation 2019 [Online]. Available: https://github.com/facebookresearch/ 50 Mugler J.P. Optimized three-dimensional fast-spin-echo MRI J. Magn. Reson. Imag. 39 4 Apr.2014 745 767 10.1002/JMRI.24542 24399498 51 Gold G.E. Isotropic MRI of the knee with 3D fast spin-echo extended echo-train acquisition (XETA): initial experience Am. J. Roentgenol. 188 5 2007 1287 1293 10.2214/AJR.06.1208/ASSET/IMAGES/06_1208_07B.JPEG 17449772 52 Kijowski R. 3D MRI of articular cartilage Semin. Muscoskel. Radiol. 25 3 Jun.2021 397 408 10.1055/S-0041-1730913 34547805 53 Schmidt A.M. Generalizability of deep learning segmentation algorithms for automated assessment of cartilage morphology and MRI relaxometry J. Magn. Reson. Imag. 57 4 Apr.2023 1029 1039 10.1002/JMRI.28365 PMC9849481 35852498 54 Kirillov A. Segment anything Proc. IEEE Int. Conf. Comput. Vis. 2023 3992 4003 10.1109/ICCV51070.2023.00371 55 Ravi N. SAM 2: Segment anything in Images and Videos Aug.2024 [Online]. Available: https://arxiv.org/pdf/2408.00714 56 Ma J. He Y. Li F. Han L. You C. Wang B. Segment anything in medical images Nat. Commun. 15 1 Jan.2024 1 9 10.1038/s41467-024-44824-z 2024 151 38253604 PMC10803759 57 Hoyer G. Tong M.W. Bhattacharjee R. Pedoia V. Majumdar S. Scalable Evaluation Framework for Foundation Models in Musculoskeletal MRI Bridging Computational Innovation with Clinical Utility Jan.2025 [Online]. Available: https://arxiv.org/pdf/2501.13376 58 Chaudhari A.S. Utility of deep learning super-resolution in the context of osteoarthritis MRI biomarkers J. Magn. Reson. Imag. 51 3 Mar.2020 768 779 10.1002/JMRI.26872 PMC6962563 31313397 59 Yao Y. Zhong J. Zhang L. Khan S. Chen W. CartiMorph: a framework for automated knee articular cartilage morphometrics Med. Image Anal. 91 Jan.2024 103035 10.1016/J.MEDIA.2023.103035 37992496 60 Yao Y. Chen W. Quantifying Knee Cartilage Shape and Lesion: from Image to Metrics Sep.2025 162 172 10.1007/978-3-031-82007-6_16 61 Kessler D.A. Segmentation of knee MRI data with convolutional neural networks for semi-automated three-dimensional surface-based analysis of cartilage morphology and composition Osteoarthr. Imag. 2 2 2022 100010 62 Iriondo C. Liu F. Caliv&#224; F. Kamat S. Majumdar S. Pedoia V. Towards understanding mechanistic subgroups of osteoarthritis: 8-year cartilage thickness trajectory analysis J. Orthop. Res. 39 6 Jun.2021 1305 1317 10.1002/JOR.24849;SUBPAGE:STRING:FULL 32897602 63 Eckstein F. Detection of differences in longitudinal cartilage thickness loss using a deep-learning automated segmentation algorithm: data from the foundation for the national institutes of health biomarkers study of the osteoarthritis initiative Arthritis Care Res. 74 6 Jun.2022 929 936 10.1002/ACR.24539 PMC9321555 33337584 64 Razmjoo A. T2 analysis of the entire osteoarthritis initiative dataset J. Orthop. Res. 39 1 Jan.2021 74 85 10.1002/JOR.24811 32691905 65 Zhong J. A Systematic Post-processing Approach for Quantitative T1 Rho Imaging of Knee Articular Cartilage Sep.2024 [Online]. Available: https://arxiv.org/abs/2409.12600v1 66 Goyal A. Automating imaging biomarker analysis for knee osteoarthritis using an open-source MRI-based deep learning pipeline medRxiv Feb.2025 2025 10.1101/2025.02.21.25322094 02.21.25322094 67 Pedoia V. Lee J. Norman B. Link T.M. Majumdar S. Diagnosing osteoarthritis from T2 maps using deep learning: an analysis of the entire osteoarthritis initiative baseline cohort Osteoarthr. Cartil. 27 7 Jul.2019 1002 1010 10.1016/j.joca.2019.02.800 PMC6579664 30905742 68 Qiu Z. Learning co-plane attention across MRI sequences for diagnosing twelve types of knee abnormalities Nat. Commun. 15 1 Sep.2024 1 11 10.1038/s41467-024-51888-4 2024 151 39223149 PMC11368947 69 Hoyer G. Foundations of a Knee Joint Digital Twin from qMRI Biomarkers for Osteoarthritis and Knee Replacement Jan.2025 [Online]. Available: https://arxiv.org/abs/2501.15396v1 10.1038/s41746-025-01507-3 PMC11845592 39984725 70 Zhong J. Unsupervised domain adaptation for automated knee osteoarthritis phenotype classification Quant. Imag. Med. Surg. 13 11 Nov.2023 7444 7458 10.21037/QIMS-23-704/COIF PMC10644135 37969620 71 Overview and description of central image assessments.&#8221; Online. Available: https://s3.amazonaws.com/nda.nih.gov/cms/prod/ImageAssessmentDataOverview.pdf . 72 Peterfy C.G. Schneider E. Nevitt M. The osteoarthritis initiative: report on the design rationale for the magnetic resonance imaging protocol for the knee Osteoarthr. Cartil. 16 12 2008 1433 1441 10.1016/j.joca.2008.06.016 PMC3048821 18786841 73 S. K. W. Tobias Heimann, Martin Styner, &#8220;SKi10 grand-challenge.&#8221; Online. Available: https://ski10.grand-challenge.org/ . 74 Desai A.D. The international workshop on osteoarthritis imaging knee MRI segmentation challenge: a multi-institute evaluation and analysis framework on a standardized dataset Radiol. Artif. Intell. 3 3 2021 e200078 10.1148/ryai.2021200078 PMC8231759 34235438 75 Zhou Z. Zhao G. Kijowski R. Liu F. Deep convolutional neural network for segmentation of knee joint anatomy Magn. Reson. Med. 80 6 Dec.2018 2759 2770 10.1002/MRM.27229 29774599 PMC6342268 76 Liu F. Zhou Z. Jang H. Samsonov A. Zhao G. Kijowski R. Deep convolutional neural network and 3D deformable approach for tissue segmentation in musculoskeletal magnetic resonance imaging Magn. Reson. Med. 79 4 Apr.2018 2379 2391 10.1002/MRM.26841 28733975 PMC6271435 77 Chadoulos C.G. Tsaopoulos D.E. Moustakidis S. Tsakiridis N.L. Theocharis J.B. A novel multi-atlas segmentation approach under the semi-supervised learning framework: application to knee cartilage segmentation Comput. Methods Progr. Biomed. 227 2022 107208 10.1016/j.cmpb.2022.107208 36384059 78 Khawer A. Khan S. Qureshi R. Awais M. Chen W. Wu J. MTKD-LRS: semi supervised knee cartilage segmentation using eigen low rank subspace assisted mean-teacher framework Proc. Int. Symp. Biomed. Imag. 2025 10.1109/ISBI60581.2025.10980909 79 Jansen M.P. Cartilage thickness distribution and its dependence on demographic, radiographic, and MRI structural pathology in knee osteoarthritis-data from the IMI-APPROACH cohort Skelet. Radiol. 12 Mar.2025 1 10 10.1007/S00256-025-04907-4/FIGURES/6 PMC12361290 40113602 80 vanHelvoort E.M. Cohort profile: the applied public-private research enabling OsteoArthritis clinical headway (IMI-APPROACH) study: a 2-year, European, cohort study to describe, validate and predict phenotypes of osteoarthritis using clinical, imaging and biochemical markers BMJ Open 10 7 Jul.2020 e035101 10.1136/BMJOPEN-2019-035101 PMC7389775 32723735 Acknowledgement This work is supported by a grant from the Research Grants Council of the Hong Kong SAR (UGC/FDS24/E18/22), and partially supported by a grant from the Innovation and Technology Commission of the Hong Kong SAR (Project MRP/001/18X). This article is part of a special issue entitled: Artificial intelligence in Osteoarthritis imaging published in Osteoarthritis and Cartilage Open."
}