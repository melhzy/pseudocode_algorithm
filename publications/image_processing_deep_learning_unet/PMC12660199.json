{
  "pmcid": "PMC12660199",
  "source": "PMC",
  "download_date": "2025-12-09T16:11:29.528028",
  "metadata": {
    "journal_title": "Frontiers in Neuroscience",
    "journal_nlm_ta": "Front Neurosci",
    "journal_iso_abbrev": "Front Neurosci",
    "journal": "Frontiers in Neuroscience",
    "pmcid": "PMC12660199",
    "pmid": "41322350",
    "doi": "10.3389/fnins.2025.1623497",
    "title": "Review of deep learning models with Spiking Neural Networks for modeling and analysis of multimodal neuroimaging data",
    "authors": [
      "Khan Ayesha",
      "Shim Vickie",
      "Fernandez Justin",
      "Kasabov Nikola K.",
      "Wang Alan"
    ],
    "abstract": "Medical imaging has become an essential tool for identifying and treating neurological conditions. Traditional deep learning (DL) models have made tremendous advances in neuroimaging analysis; however, they face difficulties when modeling complicated spatiotemporal brain data. Spiking Neural Networks (SNNs), which are inspired by real neurons, provide a promising option for efficiently processing spatiotemporal data. This review discusses current improvements in using SNNs for multimodal neuroimaging analysis. Quantitative and thematic analyses were conducted on 21 selected publications to assess trends, research topics, and geographical contributions. Results show that SNNs outperform traditional DL approaches in classification, feature extraction, and prediction tasks, especially when combining multiple modalities. Despite their potential, challenges of multimodal data fusion, computational demands, and limited large-scale datasets persist. We discussed the growth of SNNs in analysis, prediction, and diagnosis of neurological data, along with the emphasis on future direction and improvements for more efficient and clinically applicable models.",
    "keywords": [
      "neuroimaging",
      "multimodalities",
      "deep learning",
      "machine learning",
      "spiking neurons",
      "Spiking Neural Networks",
      "functional MRI",
      "structural MRI"
    ]
  },
  "xml": "<?xml version=\"1.0\"  ?><!DOCTYPE pmc-articleset PUBLIC \"-//NLM//DTD ARTICLE SET 2.0//EN\" \"https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd\"><pmc-articleset><article xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:ali=\"http://www.niso.org/schemas/ali/1.0/\" xml:lang=\"en\" article-type=\"review-article\" dtd-version=\"1.4\"><processing-meta base-tagset=\"archiving\" mathml-version=\"3.0\" table-model=\"xhtml\" tagset-family=\"jats\"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type=\"nlm-ta\">Front Neurosci</journal-id><journal-id journal-id-type=\"iso-abbrev\">Front Neurosci</journal-id><journal-id journal-id-type=\"pmc-domain-id\">670</journal-id><journal-id journal-id-type=\"pmc-domain\">frontneurosci</journal-id><journal-id journal-id-type=\"publisher-id\">Front. Neurosci.</journal-id><journal-title-group><journal-title>Frontiers in Neuroscience</journal-title></journal-title-group><issn pub-type=\"ppub\">1662-4548</issn><issn pub-type=\"epub\">1662-453X</issn><publisher><publisher-name>Frontiers Media SA</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type=\"pmcid\">PMC12660199</article-id><article-id pub-id-type=\"pmcid-ver\">PMC12660199.1</article-id><article-id pub-id-type=\"pmcaid\">12660199</article-id><article-id pub-id-type=\"pmcaiid\">12660199</article-id><article-id pub-id-type=\"pmid\">41322350</article-id><article-id pub-id-type=\"doi\">10.3389/fnins.2025.1623497</article-id><article-version-alternatives><article-version article-version-type=\"pmc-version\">1</article-version><article-version article-version-type=\"Version of Record\" vocab=\"NISO-RP-8-2008\"/></article-version-alternatives><article-categories><subj-group subj-group-type=\"heading\"><subject>Review</subject></subj-group></article-categories><title-group><article-title>Review of deep learning models with Spiking Neural Networks for modeling and analysis of multimodal neuroimaging data</article-title></title-group><contrib-group><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Khan</surname><given-names initials=\"A\">Ayesha</given-names></name><xref rid=\"aff1\" ref-type=\"aff\">\n<sup>1</sup>\n</xref><uri xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"http://loop.frontiersin.org/people/3055978/overview\"/><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Writing &#x2013; original draft\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/writing-original-draft/\">Writing &#8211; original draft</role><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Writing &#x2013; review &amp; editing\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/writing-review-editing/\">Writing &#8211; review &amp; editing</role></contrib><contrib contrib-type=\"author\" equal-contrib=\"yes\"><name name-style=\"western\"><surname>Shim</surname><given-names initials=\"V\">Vickie</given-names></name><xref rid=\"aff1\" ref-type=\"aff\">\n<sup>1</sup>\n</xref><xref rid=\"fn002\" ref-type=\"author-notes\">\n<sup>&#8224;</sup>\n</xref><uri xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"http://loop.frontiersin.org/people/962455/overview\"/><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Writing &#x2013; review &amp; editing\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/writing-review-editing/\">Writing &#8211; review &amp; editing</role></contrib><contrib contrib-type=\"author\" equal-contrib=\"yes\"><name name-style=\"western\"><surname>Fernandez</surname><given-names initials=\"J\">Justin</given-names></name><xref rid=\"aff1\" ref-type=\"aff\">\n<sup>1</sup>\n</xref><xref rid=\"aff2\" ref-type=\"aff\">\n<sup>2</sup>\n</xref><xref rid=\"fn002\" ref-type=\"author-notes\">\n<sup>&#8224;</sup>\n</xref><uri xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"http://loop.frontiersin.org/people/1440886/overview\"/><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Writing &#x2013; review &amp; editing\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/writing-review-editing/\">Writing &#8211; review &amp; editing</role></contrib><contrib contrib-type=\"author\" equal-contrib=\"yes\"><name name-style=\"western\"><surname>Kasabov</surname><given-names initials=\"NK\">Nikola K.</given-names></name><xref rid=\"aff3\" ref-type=\"aff\">\n<sup>3</sup>\n</xref><xref rid=\"fn002\" ref-type=\"author-notes\">\n<sup>&#8224;</sup>\n</xref><uri xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"http://loop.frontiersin.org/people/67261/overview\"/><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Conceptualization\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/conceptualization/\">Conceptualization</role><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Supervision\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/supervision/\">Supervision</role><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Writing &#x2013; review &amp; editing\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/writing-review-editing/\">Writing &#8211; review &amp; editing</role></contrib><contrib contrib-type=\"author\" corresp=\"yes\"><name name-style=\"western\"><surname>Wang</surname><given-names initials=\"A\">Alan</given-names></name><xref rid=\"aff1\" ref-type=\"aff\">\n<sup>1</sup>\n</xref><xref rid=\"aff4\" ref-type=\"aff\">\n<sup>4</sup>\n</xref><xref rid=\"aff5\" ref-type=\"aff\">\n<sup>5</sup>\n</xref><xref rid=\"aff6\" ref-type=\"aff\">\n<sup>6</sup>\n</xref><xref rid=\"c001\" ref-type=\"corresp\">\n<sup>*</sup>\n</xref><uri xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"http://loop.frontiersin.org/people/905415/overview\"/><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Supervision\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/supervision/\">Supervision</role><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Conceptualization\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/conceptualization/\">Conceptualization</role><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Funding acquisition\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/funding-acquisition/\">Funding acquisition</role><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Writing &#x2013; review &amp; editing\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/writing-review-editing/\">Writing &#8211; review &amp; editing</role><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Resources\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/resources/\">Resources</role></contrib></contrib-group><aff id=\"aff1\"><label>1</label><institution>Auckland Bioengineering Institute, The University of Auckland</institution>, <city>Auckland</city>, <country country=\"nz\">New Zealand</country></aff><aff id=\"aff2\"><label>2</label><institution>Department of Engineering Science and Biomedical Engineering, The University of Auckland</institution>, <city>Auckland</city>, <country country=\"nz\">New Zealand</country></aff><aff id=\"aff3\"><label>3</label><institution>Knowledge Engineering and Discovery Research Institute, Auckland University of Technology</institution>, <city>Auckland</city>, <country country=\"nz\">New Zealand</country></aff><aff id=\"aff4\"><label>4</label><institution>Medical Imaging Research Center, Faculty of Medical and Health Sciences, The University of Auckland</institution>, <city>Auckland</city>, <country country=\"nz\">New Zealand</country></aff><aff id=\"aff5\"><label>5</label><institution>Centre for Co-Created Aging Research, The University of Auckland</institution>, <city>Auckland</city>, <country country=\"nz\">New Zealand</country></aff><aff id=\"aff6\"><label>6</label><institution>Centre for Brain Research, The University of Auckland</institution>, <city>Auckland</city>, <country country=\"nz\">New Zealand</country></aff><author-notes><corresp id=\"c001\"><label>*</label>Correspondence: Alan Wang, <email xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"mailto:alan.wang@auckland.ac.nz\">alan.wang@auckland.ac.nz</email></corresp><fn fn-type=\"equal\" id=\"fn002\"><label>&#8224;</label><p>These authors have contributed equally to this work</p></fn></author-notes><pub-date publication-format=\"electronic\" date-type=\"pub\" iso-8601-date=\"2025-11-14\"><day>14</day><month>11</month><year>2025</year></pub-date><pub-date publication-format=\"electronic\" date-type=\"collection\"><year>2025</year></pub-date><volume>19</volume><issue-id pub-id-type=\"pmc-issue-id\">480891</issue-id><elocation-id>1623497</elocation-id><history><date date-type=\"received\"><day>06</day><month>5</month><year>2025</year></date><date date-type=\"accepted\"><day>22</day><month>10</month><year>2025</year></date></history><pub-history><event event-type=\"pmc-release\"><date><day>14</day><month>11</month><year>2025</year></date></event><event event-type=\"pmc-live\"><date><day>29</day><month>11</month><year>2025</year></date></event><event event-type=\"pmc-last-change\"><date iso-8601-date=\"2025-12-01 15:25:13.087\"><day>01</day><month>12</month><year>2025</year></date></event></pub-history><permissions><copyright-statement>Copyright &#169; 2025 Khan, Shim, Fernandez, Kasabov and Wang.</copyright-statement><copyright-year>2025</copyright-year><copyright-holder>Khan, Shim, Fernandez, Kasabov and Wang</copyright-holder><license><ali:license_ref specific-use=\"textmining\" content-type=\"ccbylicense\" start_date=\"2025-11-14\">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open-access article distributed under the terms of the <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://creativecommons.org/licenses/by/4.0/\">Creative Commons Attribution License (CC BY)</ext-link>. The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p></license></permissions><self-uri xmlns:xlink=\"http://www.w3.org/1999/xlink\" content-type=\"pmc-pdf\" xlink:href=\"fnins-19-1623497.pdf\"/><abstract><p>Medical imaging has become an essential tool for identifying and treating neurological conditions. Traditional deep learning (DL) models have made tremendous advances in neuroimaging analysis; however, they face difficulties when modeling complicated spatiotemporal brain data. Spiking Neural Networks (SNNs), which are inspired by real neurons, provide a promising option for efficiently processing spatiotemporal data. This review discusses current improvements in using SNNs for multimodal neuroimaging analysis. Quantitative and thematic analyses were conducted on 21 selected publications to assess trends, research topics, and geographical contributions. Results show that SNNs outperform traditional DL approaches in classification, feature extraction, and prediction tasks, especially when combining multiple modalities. Despite their potential, challenges of multimodal data fusion, computational demands, and limited large-scale datasets persist. We discussed the growth of SNNs in analysis, prediction, and diagnosis of neurological data, along with the emphasis on future direction and improvements for more efficient and clinically applicable models.</p></abstract><kwd-group><kwd>neuroimaging</kwd><kwd>multimodalities</kwd><kwd>deep learning</kwd><kwd>machine learning</kwd><kwd>spiking neurons</kwd><kwd>Spiking Neural Networks</kwd><kwd>functional MRI</kwd><kwd>structural MRI</kwd></kwd-group><funding-group><award-group id=\"gs1\"><funding-source id=\"sp1\"><institution-wrap><institution>University of Auckland</institution><institution-id institution-id-type=\"doi\" vocab=\"open-funder-registry\" vocab-identifier=\"10.13039/open_funder_registry\">10.13039/501100001537</institution-id></institution-wrap></funding-source></award-group><funding-statement>The author(s) declare financial support was received for the research and/or publication of this article. This work was partially supported by the Health Research Council of New Zealand&#8217;s Project 21/144, the Marsden Fund Project 22-UOA-120, and the Royal Society Catalyst: Seeding General Project 23-UOA-055-CSG.</funding-statement></funding-group><counts><fig-count count=\"8\"/><table-count count=\"5\"/><equation-count count=\"0\"/><ref-count count=\"46\"/><page-count count=\"13\"/><word-count count=\"8072\"/></counts><custom-meta-group><custom-meta><meta-name>pmc-status-qastatus</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>pmc-status-live</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-status-embargo</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-status-released</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-open-access</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-olf</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-manuscript</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-legally-suppressed</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-pdf</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-supplement</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-pdf-only</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-suppress-copyright</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-real-version</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-scanned-article</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-preprint</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-in-epmc</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>section-at-acceptance</meta-name><meta-value>Neuromorphic Engineering</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec sec-type=\"intro\" id=\"S1\"><label>1</label><title>Introduction</title><p>Medical imaging is a fundamental and widely used tool for diagnosing various diseases and planning their treatments in the medical field. Different medical imaging techniques, including X-ray, ultrasound, digital mammography, computed tomography (CT), magnetic resonance imaging (MRI), positron emission tomography (PET), and digital pathology, are used to produce images (<xref rid=\"B31\" ref-type=\"bibr\">Pham et al., 2000</xref>; <xref rid=\"B40\" ref-type=\"bibr\">Tsuneki, 2022</xref>). In neuroscience, multimodal neuroimaging techniques, including functional MRI (fMRI), structural MRI (sMRI), diffusion tensor imaging (DTI), and others provides distinct yet interrelated aspects of neural anatomy and activity. Integrating these modalities enables a more comprehensive understanding of neural mechanisms and disease processes. Furthermore, the healthcare sector focuses on adopting computer-assisted tools to increase diagnostic accuracy and efficiency because of the advancements in artificial intelligence and neuroimaging techniques. These AI-based systems facilitate real-time disease prediction and thoroughly evaluate treatment options (<xref rid=\"B40\" ref-type=\"bibr\">Tsuneki, 2022</xref>; <xref rid=\"B45\" ref-type=\"bibr\">Yang and Yu, 2021</xref>).</p><p>Rapid progress in artificial intelligence (AI) and machine learning has further advanced neuroimaging, especially through deep learning (DL) techniques that automate the analysis of complex, high-dimensional brain data. Compared with conventional machine learning methods, DL can handle high-dimensional neuroimaging datasets with minimal manual preprocessing. As a result, multiple tasks like disease classification, predictive modeling, and the visualization of brain structure and function can be achieved more efficiently and with increased productivity (<xref rid=\"B44\" ref-type=\"bibr\">Yan et al., 2022</xref>). These advances have been supported by the growing availability of large-scale datasets and increased computational power (<xref rid=\"B3\" ref-type=\"bibr\">Calhoun et al., 2014</xref>).</p><p>However, most existing DL approaches rely on static or single modality data, which limits their ability to capture the complex patterns across space and time of the human brain (<xref rid=\"B32\" ref-type=\"bibr\">Plis et al., 2014</xref>). This gap highlights the requirement of the models that are not only data-driven but also biologically interpretable Spiking Neural Networks (SNNs) effectively transform neuroimaging and help diagnose neurological disorders by stimulating the brain&#8217;s natural processing. This makes SNN highly effective for spatiotemporal data analysis. SNN enables early detection of conditions like dementia and predicts epileptic seizures by identifying complex EEG patterns. Additionally, integrating SNN with multimodal neuroimaging, such as EEG and MRI, can enhance diagnostic accuracy by highlighting their transformative potential in neurological healthcare (<xref rid=\"B24\" ref-type=\"bibr\">Kasabov, 2019</xref>).</p><p>This study aims to critically evaluate the role of SNNs in multimodal MRI analysis and assess their potential to overcome the limitations of traditional deep learning models. The review will explore:</p><list list-type=\"order\"><list-item><p>How have SNNs been applied to neuroimaging, particularly multimodal MRI data?</p></list-item><list-item><p>What are the advantages of SNNs over conventional deep learning models in capturing spatio-temporal features?</p></list-item><list-item><p>How can SNNs integrate multiple MRI modalities to enhance diagnostic accuracy?</p></list-item><list-item><p>What are the current challenges in implementing SNNs for large-scale multimodal MRI analysis?</p></list-item></list><p>By answering these questions, the review aims to highlight the strengths, limitations, and clinical potential of SNNs in neuroimaging and the findings will contribute to the advancement of biologically inspired deep learning models for more accurate, interpretable, and clinically relevant neuroimaging solutions.</p><sec id=\"S1.SS1\"><label>1.1</label><title>Background</title><p>Over the past decade, deep learning (DL) models, including convolutional neural networks (CNNs), recurrent neural networks (RNNs), and long short-term memory (LSTM) networks, have transformed neuroimaging research. These models excel at extracting hierarchical features from brain images and temporal sequences, enabling improvements in classification and disease prediction (<xref rid=\"B44\" ref-type=\"bibr\">Yan et al., 2022</xref>; <xref rid=\"B45\" ref-type=\"bibr\">Yang and Yu, 2021</xref>). However, the dynamic nature of brain data poses challenges for traditional deep learning models, especially basic feedforward architectures. Their primary shortcoming is that they are unable to efficiently learn the temporal relationships that exist in spatiotemporal neurons due to a lack of internal state or memory. More importantly, their continuous, rate-based functioning is not well suited to mimic the sparse, event-driven communication of real neurons, where information is frequently contained in the exact timing of discrete spikes. <xref rid=\"T1\" ref-type=\"table\">Table 1</xref> below represents a small conceptual comparison of other Deep Learning (DL) and Spiking Neural Networks (SNN) models for the most relevant aspects.</p><table-wrap position=\"float\" id=\"T1\" orientation=\"portrait\"><label>TABLE 1</label><caption><p>Conceptual overview comparing deep learning (DL) and Spiking Neural Networks (SNN).</p></caption><table frame=\"box\" rules=\"all\" cellspacing=\"5\" cellpadding=\"5\"><thead><tr><th valign=\"top\" align=\"left\" rowspan=\"1\" colspan=\"1\">Aspect</th><th valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Deep learning</th><th valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Spiking Neural Networks</th></tr></thead><tbody><tr><td valign=\"top\" align=\"left\" rowspan=\"1\" colspan=\"1\">Information type</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Continuous activation</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Discrete spike events</td></tr><tr><td valign=\"top\" align=\"left\" rowspan=\"1\" colspan=\"1\">Temporal modeling</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Limited</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Strong temporal dynamics</td></tr><tr><td valign=\"top\" align=\"left\" rowspan=\"1\" colspan=\"1\">Biological realism</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Low</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">High (mimics neuron firing)</td></tr><tr><td valign=\"top\" align=\"left\" rowspan=\"1\" colspan=\"1\">Energy efficiency</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">High computational cost</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Neuromorphic efficiency</td></tr><tr><td valign=\"top\" align=\"left\" rowspan=\"1\" colspan=\"1\">Neuroimaging relevance</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Good for static data</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Effective for spatiotemporal data</td></tr></tbody></table></table-wrap><p>Spiking Neural Networks (SNNs) process information through discrete spikes, mimicking the temporal firing patterns of biological neurons (<xref rid=\"B17\" ref-type=\"bibr\">Izhikevich, 2006</xref>). This spike-based communication allows SNNs to model time-dependent and event-driven brain dynamics more effectively. Especially for neuroimaging, this biologically plausible computation offers a promising bridge between neuroscience and AI, making the way for interpretable and energy-efficient models (<xref rid=\"B24\" ref-type=\"bibr\">Kasabov, 2019</xref>). Traditional deep learning models use continuous mathematical functions to represent neuron activations, whereas spiking neural networks transmit information through discrete spike events that occur over time. This difference gives SNNs a temporal dimension that is absent in most deep learning models. While CNNs and RNNs can provide efficiency in spatial or sequential pattern recognition, in contrast, SNNs capture both simultaneously, enabling effective modeling of dynamic brain processes (<xref rid=\"B13\" ref-type=\"bibr\">Ghosh-Dastidar and Adeli, 2009</xref>; <xref rid=\"B20\" ref-type=\"bibr\">Kasabov et al., 2016</xref>). Moreover, SNNs have the potential for low-power and neuromorphic hardware implementation, making them especially suitable for real-time neuroimaging analysis (<xref rid=\"B13\" ref-type=\"bibr\">Ghosh-Dastidar and Adeli, 2009</xref>).</p></sec></sec><sec id=\"S2\"><label>2</label><title>Literature review methodology</title><p>Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines are used for conducting this review (<xref rid=\"B29\" ref-type=\"bibr\">Moher et al., 2009</xref>). The primary purpose of conducting this literature review is to analyze the trends and landscape of current advancements in deep learning models with SNN for multimodal neuroimaging data analysis.</p><p>Multiple databases are used to extract articles for this study, including PubMed, IEEE Xplore, ScienceDirect, Scopus, and Nature. A few of the papers were added from other internet sources. The main keywords used are &#8220;Neuroimaging,&#8221; &#8220;Spiking Neural Networks,&#8221; and &#8220;Deep Learning,&#8221; refined with Boolean operators for accuracy. Ten years of studies are used to retrieve relevant data (ranging from 2015 to 2025 for thematic study) to ensure the inclusion of comprehensive coverage of the knowledge and up-to-date information, as fewer relevant studies have been found in recent years.</p><p>Article selection followed PRISMA guidelines, with inclusion and exclusion determined through a three-phase process. In the identification section, all duplications are removed. During the screening phase, the title and abstract are used to identify articles that are irrelevant for exclusion and those that are relevant for inclusion. Afterward, the full text is used to extract the most relevant studies in this review. Full inclusion criteria and the list of keywords are provided in the <xref rid=\"DS1\" ref-type=\"supplementary-material\">Supplementary material</xref>.</p></sec><sec id=\"S3\"><label>3</label><title>Search results</title><p>Firstly, for conducting this research, the query was executed on March 10, 2025, considering the three main topics mentioned in the above section to align the study&#8217;s objectives. As a result of the query, 440 papers were retrieved from multiple databases, along with three articles from other sources. The PRISMA flowchart in <xref rid=\"F1\" ref-type=\"fig\">Figure 1</xref> illustrates the exclusion criteria applied to articles searched in each phase. After applying the exclusion criteria to the selected dataset in each phase, only 21 articles were chosen for this literature review.</p><fig position=\"float\" id=\"F1\" orientation=\"portrait\"><label>FIGURE 1</label><caption><p>Overview of the PRISMA flowchart for this research representing the complete process followed for selecting articles for this review paper for quantitative and qualitative analysis.</p></caption><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" position=\"float\" orientation=\"portrait\" xlink:href=\"fnins-19-1623497-g001.jpg\"><alt-text content-type=\"machine-generated\">Flowchart detailing the identification and screening process of studies via databases. Identification phase lists databases like Scopus, PubMed, ScienceDirect, IEEE Xplore, Nature, and others, totaling 440 records with 35 duplicates removed. Screening phase includes 405 records screened with 376 removed due to various out-of-scope reasons. Full text screening had 29 records with 8 removed. The included phase resulted in 21 studies for the literature review.</alt-text></graphic></fig><sec id=\"S3.SS1\"><label>3.1</label><title>Quantitative analysis</title><p>This section analyzes 21 selected articles categorized into three main perspectives quantitatively. Firstly, the study represents the annual publication trends focusing on tracking the progress of SNNs in healthcare. Secondly, research field analysis includes the articles&#8217; distribution across various study domains. Lastly, geographical publication trends highlight contributions from different parts of the world.</p><sec id=\"S3.SS1.SSS1\"><label>3.1.1</label><title>Annual publication trends: tracking progress in SNN adoption for healthcare</title><p>The analysis of 21 selected publications highlights the evolving application of Spiking Neural Networks (SNNs) in neuroimaging over the past decade, as shown in <xref rid=\"F2\" ref-type=\"fig\">Figure 2</xref>. The citations of all 21 publications were collectively analyzed, as presented in <xref rid=\"T2\" ref-type=\"table\">Table 2</xref>.</p><fig position=\"float\" id=\"F2\" orientation=\"portrait\"><label>FIGURE 2</label><caption><p>Overview of the annual publication trend, <italic toggle=\"yes\">X</italic>-axis shows the years whereas the <italic toggle=\"yes\">Y</italic>-axis represents the total number of publications (present on the bars) each year from the selected studies.</p></caption><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" position=\"float\" orientation=\"portrait\" xlink:href=\"fnins-19-1623497-g002.jpg\"><alt-text content-type=\"machine-generated\">Bar chart showing the number of publications from 2015 to 2024. There are 2 publications in 2015 and 2017, 1 in 2018 to 2020, 4 in 2021, 1 in 2022, 5 in 2023, and 4 in 2024.</alt-text></graphic></fig><table-wrap position=\"float\" id=\"T2\" orientation=\"portrait\"><label>TABLE 2</label><caption><p>Chronological overview of citations of the selected studies.</p></caption><table frame=\"box\" rules=\"all\" cellspacing=\"5\" cellpadding=\"5\"><thead><tr><th valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Years</th><th valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">No. of publications</th><th valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Total citations</th><th valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Citations &#8804; 20</th><th valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">&gt;20 &amp; &#8804;50 citations</th><th valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">&gt;50 &amp; &#8804;100 citations</th><th valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Average citations per year</th></tr></thead><tbody><tr><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">2015</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">2</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">49</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">1</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">1</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">0</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">\n<bold>24.5</bold>\n</td></tr><tr><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">2017</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">2</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">100</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">0</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">1</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">1</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">\n<bold>50</bold>\n</td></tr><tr><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">2018</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">1</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">25</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">0</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">1</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">0</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">\n<bold>25</bold>\n</td></tr><tr><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">2019</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">1</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">12</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">1</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">0</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">0</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">\n<bold>12</bold>\n</td></tr><tr><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">2020</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">1</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">0</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">1</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">0</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">0</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">\n<bold>0</bold>\n</td></tr><tr><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">2021</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">4</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">128</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">2</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">2</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">0</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">\n<bold>32</bold>\n</td></tr><tr><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">2022</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">1</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">21</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">0</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">1</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">0</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">\n<bold>21</bold>\n</td></tr><tr><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">2023</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">5</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">49</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">4</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">1</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">0</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">\n<bold>8.17</bold>\n</td></tr><tr><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">2024</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">4</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">9</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">1</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">0</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">0</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">\n<bold>2.25</bold>\n</td></tr></tbody></table><table-wrap-foot><fn><p>The bold values represent the average annual citations of the studies.</p></fn></table-wrap-foot></table-wrap><p>States reveal that, from 2015 to 2017, this area of study was in the early exploration phase, as only two publications from the selected studies were available each year. Moreover, the trend shows the same results for 2018, 2019 and 2020, limiting studies to just one article per year from the chosen dataset. The reason for this decline could be methodological challenges.</p><p>However, there was a noticeable rise in research in 2021 with four publications, suggesting increasing feasibility with advancements in deep learning. After a drop in 2022 to only one study (which could be due to the selected dataset), results showed a surge in 2023 in this research area, with five studies marking a significant shift toward SNN applications. The most probable reason for this growth could be the improvements in computational resources and model efficiency.</p><p>However, the publication trend declined to four in the year 2024, still reflecting that this research area is reaching stability and reflecting the growing integration of SNNs in neuroimaging. Overall, the research has progressively grown from initial exploration to more practical implementation and refinement, which reflects a growing confidence in the field.</p></sec><sec id=\"S3.SS1.SSS2\"><label>3.1.2</label><title>Research field analysis</title><p>Based on classifications from the selected databases, the chosen articles are linked with 10 distinctive research fields, with some spanning multiple areas. In total, 40 connections have been established between the 21 publications and these research domains. As depicted in <xref rid=\"F3\" ref-type=\"fig\">Figure 3</xref>, many publications fall within &#8220;Computer Science&#8221; (<italic toggle=\"yes\">n</italic> = 14), followed by &#8220;Neuroscience&#8221; (<italic toggle=\"yes\">n</italic> = 8) and &#8220;Medicine&#8221; (<italic toggle=\"yes\">n</italic> = 6).</p><fig position=\"float\" id=\"F3\" orientation=\"portrait\"><label>FIGURE 3</label><caption><p>The figure provides an overview of 10 distinctive research fields and number of publications in each subject, selected for this review.</p></caption><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" position=\"float\" orientation=\"portrait\" xlink:href=\"fnins-19-1623497-g003.jpg\"><alt-text content-type=\"machine-generated\">Bar chart showing the total number of publications across various research fields: Computer Science (14), Neuroscience (8), Engineering (6), Decision Sciences (3), Biochemistry, Genetics, and Molecular Biology (2), Chemistry (1), Immunology and Microbiology (1), Mathematics (1), Medicine (1), Multidisciplinary (1).</alt-text></graphic></fig><p>From the perspective of the biomedical research field, a collective contribution is found to make it a multidisciplinary nature of studies, such as &#8220;Medicine&#8221; (<italic toggle=\"yes\">n</italic> = 6), &#8220;Biochemistry, Genetics, and Molecular Biology&#8221; (<italic toggle=\"yes\">n</italic> = 2), and &#8220;Immunology and Microbiology&#8221; (<italic toggle=\"yes\">n</italic> = 1).</p><p>From an engineering and computational standpoint, &#8220;Computer Science&#8221; (<italic toggle=\"yes\">n</italic> = 15) and &#8220;Engineering&#8221; (<italic toggle=\"yes\">n</italic> = 3) reflect a major division of the associations.</p><p>Additionally, research contributions span other diverse fields, including &#8220;Mathematics&#8221; (<italic toggle=\"yes\">n</italic> = 2), &#8220;Decision Sciences&#8221; (<italic toggle=\"yes\">n</italic> = 1), &#8220;Multidisciplinary&#8221; (<italic toggle=\"yes\">n</italic> = 1), and &#8220;Chemistry&#8221; (<italic toggle=\"yes\">n</italic> = 1), further highlighting the interdisciplinary scope of the selected publications.</p></sec><sec id=\"S3.SS1.SSS3\"><label>3.1.3</label><title>Geographical publication trends</title><p>In terms of geographical trend, each publication has been linked to the countries affiliated with its authors. The study of 21 selected publications reveals contributions from multiple countries. A single paper can be linked to one or multiple countries, as each publication might have multiple authors, and each author can be affiliated with more than one country. However, if a paper has multiple authors from the same country, we only consider it once to avoid duplication.</p><p>At the point of analysis, 10 countries have contributed to at least one publication. <xref rid=\"F4\" ref-type=\"fig\">Figure 4</xref> below categorizes the publications into single-country papers and international collaboration papers, highlighting the involvement of different countries.</p><fig position=\"float\" id=\"F4\" orientation=\"portrait\"><label>FIGURE 4</label><caption><p>An overview of publication trends by geography highlights both the number of publications and the countries where the authors are based.</p></caption><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" position=\"float\" orientation=\"portrait\" xlink:href=\"fnins-19-1623497-g004.jpg\"><alt-text content-type=\"machine-generated\">Map showing geographical publication trends with countries in different colors indicating publication counts. The United States and New Zealand are highlighted with four publications each. Other countries like China, India, and Russia have one publication each.</alt-text></graphic></fig><p>China is the most frequent among the contributing countries, participating in 8 publications from the selected studies. Afterward, the highest contribution is found from the authors from New Zealand and India, each contributing to 4 publications. The United States has been involved in 3 publications. Regarding international collaboration, contributions were found in this area of research from the United Kingdom, Iran, Australia, and New Zealand. Other contributing countries include Malaysia, Russia, Ghana, Spain, Bangladesh, South Korea, and Italy, all of whom have participated in at least one publication.</p><p>Below is the comparison between a country&#8217;s contributions vs. international collaboration: -</p><list list-type=\"bullet\"><list-item><p>Results of single-country publications: 10 out of 21 papers (49%) were found to have authors solely from one country.</p></list-item><list-item><p>Results of international collaboration publications: 11 out of 21 papers (51%) involved authors from multiple countries, demonstrating a strong trend of global cooperation in this study area.</p></list-item></list><p>China is the most active in single-country and collaborative research, as signified by its leadership in this field from the selected studies. New Zealand and the United Kingdom are heavily engaged in international collaborations, reflecting their strong global research attitude and commitment to cross-border partnerships. India and China are leading in solely conducted research, showcasing their independent research contributions and advancements in the field. Notably, the United States appears only in collaborative research in our selected dataset. It suggests that the US primarily participates in multinational research projects rather than independent studies.</p></sec></sec><sec id=\"S3.SS2\"><label>3.2</label><title>Thematic analysis of selected studies</title><p>This section provides a detailed insight into selected studies for the literature review. Neuroimaging, multimodal data analysis, utilization of spiking neural networks, and clinical applications are the focus of this review section.</p><sec id=\"S3.SS2.SSS1\"><label>3.2.1</label><title>Neuroimaging and multimodal data analysis</title><p>Healthcare professionals have used multiple types of medical data, including biomedical data such as electroencephalography (EEG), electromyographic signal (EMG), electrocardiogram (ECG), ultrasound, X-rays, computed tomography and magnetic resonance imaging (MRI), for a long time to judge patients&#8217; diseases, diagnoses, and health conditions. Neuroimaging techniques are one of the various types for dealing with a wide range of conditions in the brain. MRI has recently been the most used technique, and it is said to be a vital technique for diagnosing brain tumors (<xref rid=\"B1\" ref-type=\"bibr\">Ahmadi et al., 2021</xref>; <xref rid=\"B34\" ref-type=\"bibr\">Sam et al., 2023</xref>) because it can generate images without damaging brain tissues (<xref rid=\"B9\" ref-type=\"bibr\">Dong et al., 2024</xref>). Furthermore, <xref rid=\"B19\" ref-type=\"bibr\">Kamal et al. (2023)</xref> used MRI to identify microbleeds in the brain, including the gene expression data, making it a multimodal analysis for determining the severity of Alzheimer&#8217;s disease.</p><p>In addition to traditional imaging techniques, other non-invasive methods such as functional magnetic resonance imaging (fMRI), diffusion tensor imaging (DTI), and electroencephalography (EEG) have been used for brain data collection in the recent past. These techniques played a dynamic role in helping us understand the functional and structural characteristics of the human brain in a better way (<xref rid=\"B35\" ref-type=\"bibr\">Sengupta et al., 2018</xref>). <xref rid=\"B4\" ref-type=\"bibr\">Capecci et al. (2015b)</xref> presented that EEG spatiotemporal data were used to study brain pathology and degeneration to analyze the functional changes in the brain activities of the controlled and Alzheimer&#8217;s disease (AD) groups. Furthermore, <xref rid=\"B25\" ref-type=\"bibr\">Kasabov N. K. et al. (2017)</xref> used fMRI in their research to develop a methodology using the NeuCube architecture of spiking neural network (SNN) for visualization, classification, and dynamic learning for spatiotemporal brain data. <xref rid=\"B15\" ref-type=\"bibr\">Guo et al. (2023)</xref> also applied fMRI like (<xref rid=\"B25\" ref-type=\"bibr\">Kasabov N. K. et al., 2017</xref>) for their study based on a fMRI based SNN for verifying anti-damage capabilities under random attacks.</p><p>In addition to the above-mentioned diseases, <xref rid=\"B34\" ref-type=\"bibr\">Sam et al. (2023)</xref> presented the use of EEG signal data for the quantitative assessment of depression levels by examining and categorizing EEG signals, and <xref rid=\"B11\" ref-type=\"bibr\">Francis and Al-Hababi (2023)</xref> utilized structural magnetic resonance images (sMRI) for early detection of suicidal ideation in youngsters and used depression as a biomarker in sMRI, respectively.</p><p>Most studies used a single or a few modalities to analyze different areas. However, combining predictive modeling with multimodal brain data has great potential; research in this area is still in its early stages due to a lack of advanced methods. The major challenge in combining brain data into a single model captured from various modalities is that each modality uses different temporal and spatial characteristics. To address this, the recent advancement in Spiking neural network systems (SSNs) makes it possible to incorporate multidimensional data within a single model (<xref rid=\"B35\" ref-type=\"bibr\">Sengupta et al., 2018</xref>).</p></sec><sec id=\"S3.SS2.SSS2\"><label>3.2.2</label><title>Integration of deep learning models with SNNs for neuroimaging</title><p>Spiking neural networks are one of the most reliable techniques that computer simulations and computational models use to study the brain, e.g., brain-inspired machine learning. These techniques can reveal and learn frequency, time, and space information usually hidden in spatiotemporal brain data (STBD) <xref rid=\"B5\" ref-type=\"bibr\">Capecci et al. (2015a)</xref>, <xref rid=\"B35\" ref-type=\"bibr\">Sengupta et al. (2018)</xref> presented an approach integrating multimodal information with a spiking neural network framework, creating a personalized SNNc-based architecture using the NeuCube. This experiment was run to represent the algorithm&#8217;s capabilities (oiSTDP) to capture discriminative join information from the data through its connection strengths. Utilizing this framework, the study showcases the integration of DTI and fMRI data of individuals who are beginning antipsychotic treatment to develop a personalized classifier for the prediction of treatment response in schizophrenia. Analysis with the SNNc network uncovered improved connectivity in the cerebellar region, which suggests that the captured activity of this area can be an aid as a potential biomarker that would help in treatment response in individuals with schizophrenia.</p><p><xref rid=\"B19\" ref-type=\"bibr\">Kamal et al. (2023)</xref> stated that machine learning techniques are practical for analyzing Alzheimer&#8217;s disease datasets. Machine learning techniques can predict the disease by detecting microbleeds in the brain. The study used MRI images and gene expression data, making it multimodal for identifying microbleeds using SNN and decision trees. Afterward, pixel density analysis (PDA) was used to locate microbleed areas in MRI images. PDA and probabilistic graphical model (PGM) were also used to explain and decide on the diagnosis of microbleeds, and the severity of AD. <xref rid=\"F5\" ref-type=\"fig\">Figure 5</xref> represents the framework used in this research for identifying cerebral microbleeds and Alzheimer&#8217;s using multimodal data.</p><fig position=\"float\" id=\"F5\" orientation=\"portrait\"><label>FIGURE 5</label><caption><p>A framework to identify cerebral microbleeds and Alzheimer from multimodal data (<xref rid=\"B19\" ref-type=\"bibr\">Kamal et al., 2023</xref>).</p></caption><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" position=\"float\" orientation=\"portrait\" xlink:href=\"fnins-19-1623497-g005.jpg\"><alt-text content-type=\"machine-generated\">Diagram illustrating a process flow with three main sections. &#8220;Input File Format&#8221; includes an Alzheimer MRI image and gene expression data. &#8220;Black Box&#8221; shows a spike neural network and a decision tree. &#8220;XAI Outcomes&#8221; presents pixel density analysis and a probabilistic graphical approach with feature nodes leading to a classification result.</alt-text></graphic></fig><p>Furthermore, the study compared SNN with other state-of-the-art methods for performance evaluation using recall, accuracy, precision, and F-score. <xref rid=\"T3\" ref-type=\"table\">Table 3</xref> below shows that SNN yielded the highest performance with 96.13%, 97.02%, 97.13%, and 96.84% for recall, accuracy, precision, and F-score, respectively.</p><table-wrap position=\"float\" id=\"T3\" orientation=\"portrait\"><label>TABLE 3</label><caption><p>Performance evaluation for SNN and CNN (<xref rid=\"B19\" ref-type=\"bibr\">Kamal et al., 2023</xref>).</p></caption><table frame=\"box\" rules=\"all\" cellspacing=\"5\" cellpadding=\"5\"><thead><tr><th valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Method</th><th valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Training</th><th valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Test</th><th valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">PREC</th><th valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">REC</th><th valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">ACC</th><th valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">F-score</th></tr></thead><tbody><tr><td valign=\"top\" align=\"center\" rowspan=\"4\" colspan=\"1\">SNN</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">552</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">98</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">97.13</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">96.13</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">97.02</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">96.84</td></tr><tr><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">520</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">1300</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">96.23</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">94.33</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">97.12</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">95.14</td></tr><tr><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">487</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">163</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">95.19</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">96.23</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">96.82</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">96.04</td></tr><tr><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">455</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">195</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">94.03</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">95.03</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">95.62</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">95.14</td></tr><tr><td valign=\"top\" align=\"center\" rowspan=\"4\" colspan=\"1\">CNN</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">552</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">98</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">91.53</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">93.43</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">94.61</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">94.05</td></tr><tr><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">520</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">130</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">91.47</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">92.45</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">92.24</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">92.46</td></tr><tr><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">487</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">163</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">91.19</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">94.39</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">92.53</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">93.24</td></tr><tr><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">455</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">195</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">92.73</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">91.03</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">91.92</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">91.47</td></tr></tbody></table></table-wrap><p>Whereas <xref rid=\"B41\" ref-type=\"bibr\">Turkson et al. (2021)</xref> proposed a hybrid model, a spiking deep convolutional neural network architecture to classify MRI images to detect Alzheimer&#8217;s disease. <xref rid=\"F6\" ref-type=\"fig\">Figure 6</xref> shows the general architecture proposed in this study. The Alzheimer&#8217;s disease neuroimaging initiative (ADNI) dataset (450 scans) was used to perform three binary classification tasks (AD vs. NC, AD vs. MCI, and NC vs. MCI). The pre-processed images were used to extract AD key features using an unsupervised spiking neural network. The pre-trained spikes were then classified using a supervised deep convolutional neural network (CNN). The SNN was tested with two models, firstly with a model that was pre-trained with a spike, and secondly with a model without a pre-trained spike, and the results were more accurate with a pre-trained model for three binary classification tasks. The study stated that SNN improved performance, demonstrating the potential of spiking networks for reliable neuroimaging analysis.</p><fig position=\"float\" id=\"F6\" orientation=\"portrait\"><label>FIGURE 6</label><caption><p>An overview of the proposed hybrid model, called the spiking deep convolutional neural network, is shown in the figure. It highlights three main modules: raw data input, preprocessing, and the spiking model (<xref rid=\"B41\" ref-type=\"bibr\">Turkson et al., 2021</xref>).</p></caption><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" position=\"float\" orientation=\"portrait\" xlink:href=\"fnins-19-1623497-g006.jpg\"><alt-text content-type=\"machine-generated\">Flowchart depicting MRI processing for classification. Raw MRI images undergo skull stripping, white and gray matter differentiation, and segmentation. Preprocessed data are input into a Spiking CNN, including spike generation and deep CNN processing, resulting in classifications: Alzheimer&#8217;s Disease (AD), Mild Cognitive Impairment (MCI), or Cognitively Normal (CN).</alt-text></graphic></fig><p>Moreover, <xref rid=\"B7\" ref-type=\"bibr\">Doborjeh et al. (2021)</xref> used longitudinal neuroimaging data to utilize the advancements in deep learning models through brain-inspired spiking neural networks (SNNs), which can model structural brain data across time and space. The study introduced a methodology and an SNN-based computational framework for developing personalized, predictive models from longitudinal brain data to detect, interpret, and predict changes in an individual&#8217;s functional brain state. The approach consists of several steps, such as clustering similar data, incorporating missing values, and training a 3D brain-template SNN for classifying and predicting outcomes and visualizing structural brain changes. All this information is then used to interpret results and identify predictive markers at both individual and group levels. As a result, the model successfully classified and predicted cognitive decline, for example, dementia and mild cognitive impairment (MCI), 2 years ahead with 91% and 95% accuracy.</p></sec><sec id=\"S3.SS2.SSS3\"><label>3.2.3</label><title>Clinical applications</title><p>Previous sections primarily focused on the types of modalities used by several researchers, along with the integration of machine learning models using SNN to analyze neuroimaging data (<xref rid=\"B8\" ref-type=\"bibr\">Doborjeh et al., 2019</xref>; <xref rid=\"B33\" ref-type=\"bibr\">Saeedinia et al., 2021</xref>; <xref rid=\"B12\" ref-type=\"bibr\">Ghazali et al., 2020</xref>). Moreover, multiple studies highlight practical applications using neuroimaging and SNNs for several diseases, such as the detection of AD and the prediction of schizophrenia. However, neuroimaging, multimodal data analysis, and integration of deep learning with spiking neural networks are not only vital for AD but also for many other clinical areas, such as brain tumor classification (<xref rid=\"B18\" ref-type=\"bibr\">Kalpana et al., 2024</xref>) or segmentation (<xref rid=\"B1\" ref-type=\"bibr\">Ahmadi et al., 2021</xref>), suicide ideation assessment (<xref rid=\"B11\" ref-type=\"bibr\">Francis and Al-Hababi, 2023</xref>), Depression identification (<xref rid=\"B34\" ref-type=\"bibr\">Sam et al., 2023</xref>), Parkinson&#8217;s disease detection (<xref rid=\"B6\" ref-type=\"bibr\">Das et al., 2024</xref>), and so on.</p><p><xref rid=\"B18\" ref-type=\"bibr\">Kalpana et al. (2024)</xref> proposed a hybrid model integrating SNNs with convolutional neural networks (CNNs) for brain tumor classification. As per the results, the model achieved a testing accuracy of 97.50 % and a training accuracy of 97.79% with a slight loss value of 0.38%. Also stated, these results present the model&#8217;s strength in capturing complex data in medical imaging, which is promising for clinical applications within the biomedical field. On the other hand, <xref rid=\"B1\" ref-type=\"bibr\">Ahmadi et al. (2021)</xref> utilized MRI for tumor area segmentation using a deep spiking neural network. The process for achieving the results consists of preprocessing and segmentation using DSNN. <xref rid=\"T4\" ref-type=\"table\">Table 4</xref> shows the accuracy percentages compared in this study for the proposed method and previous approaches.</p><table-wrap position=\"float\" id=\"T4\" orientation=\"portrait\"><label>TABLE 4</label><caption><p>Performance evaluation for QAIS-DSNN and other methods (<xref rid=\"B1\" ref-type=\"bibr\">Ahmadi et al., 2021</xref>).</p></caption><table frame=\"box\" rules=\"all\" cellspacing=\"5\" cellpadding=\"5\"><thead><tr><th valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Accuracy (%)</th><th valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Method</th><th valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Reference</th></tr></thead><tbody><tr><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">98.20%</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">GCNN</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">\n<xref rid=\"B28\" ref-type=\"bibr\">Mittal et al., 2019</xref>\n</td></tr><tr><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">95%</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">3D cascaded CNN-TTA</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">\n<xref rid=\"B42\" ref-type=\"bibr\">Wang et al., 2019</xref>\n</td></tr><tr><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">88.50%</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">MCCNN</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">\n<xref rid=\"B16\" ref-type=\"bibr\">Hu et al., 2019</xref>\n</td></tr><tr><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">96.12%</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">BAT-IT2FCM</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">\n<xref rid=\"B2\" ref-type=\"bibr\">Alagarsamy et al., 2019</xref>\n</td></tr><tr><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">92%</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">ADNN-PSO</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">\n<xref rid=\"B37\" ref-type=\"bibr\">Sharif M. I. et al., 2020</xref>\n</td></tr><tr><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">98%</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">PSO-LDA-GA-ANN</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">\n<xref rid=\"B36\" ref-type=\"bibr\">Sharif M. et al., 2020</xref>\n</td></tr><tr><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">98.21%</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">QAIS-DSNN</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Proposed approach (<xref rid=\"B1\" ref-type=\"bibr\">Ahmadi et al., 2021</xref>)</td></tr></tbody></table></table-wrap><p>Furthermore, <xref rid=\"B11\" ref-type=\"bibr\">Francis and Al-Hababi (2023)</xref> also incorporated a hybrid version like <xref rid=\"B18\" ref-type=\"bibr\">Kalpana et al. (2024)</xref>. However, they combined an attention mechanism (AM) with SNN for suicide ideation assessment using sMRI of healthy controls and depressive individuals who did not show any suicide ideation (SI). The hybrid model completed the classification tasks using stratified 5-fold cross-validation and achieved a test accuracy of 94%, sensitivity of 100%, specificity of 92%, and an area under the curve (AUC) of 0.96. The proposed algorithm provides an objective tool that can support clinical assessments in identifying early signs of SI risk among depressed patients who are currently not showing any suicidal thoughts.</p><p><xref rid=\"B34\" ref-type=\"bibr\">Sam et al. (2023)</xref> performed a similar study to <xref rid=\"B11\" ref-type=\"bibr\">Francis and Al-Hababi (2023)</xref> by combining long short-term memory (LSTM) and SNN using EGG signals for depression identification. These models were used for the first time to analyze and categorize EEG signals according to the level of depression (minimum, mild, moderate, and severe). The model utilized spatial data mapping using SNN, leading to unsupervised learning and visualization of spiking patterns and unique perceptions about brain mechanisms. Comparative analysis of time-space brain data showed that SNN is more advantageous than other deep learning models. The study achieved higher accuracy in classifying samples from various groups and disclosed different patterns of brain activity, helping to understand the severity of depression. The findings in the study have the potential for early prediction and, thus, preventing depression by using the brain data acquired from different depression levels. The methodology used in this study showcases excellent potential for application in neuroimaging and clinical longitudinal data.</p><p>Apart from the above-mentioned clinical applications, SNN and neuroimaging are also helpful for Parkinson&#8217;s disease (PD) detection, as presented by <xref rid=\"B6\" ref-type=\"bibr\">Das et al. (2024)</xref>. This study investigated the SEFRON (time-varying synaptic efficacy function based leaky integrate and fire neuron model) model and compared it with other previously used neural network models such as RBF, RNN, LSTM, and MLP. Results showed a higher accuracy for this model over others, making it reliable for clinical trials. Moreover, because of its performance, this model can help develop an automated PD detection device that physicians can utilize to diagnose PD in its early stages. However, this study has a limitation in that the sample size of the dataset used is small.</p><p>Another study proposed by <xref rid=\"B14\" ref-type=\"bibr\">Gowsikraja et al. (2025)</xref> uses MRI for AD classification using a model named SBERO_Deep SNN (skill Al-Biruni Earth Radius Optimization-enabled Deep Spiking Neural Network), encompassing the benefits of SNN. Segmentation was performed using a hybrid algorithm using UNeXt, combining the Skill Optimization Algorithm (SOA) and the Al-Biruni Earth Radius (BER). In the next step, statistical features were extracted and classified using a Deep SNN trained with SBERO. The study achieved the highest accuracy rate compared to other AD classification techniques. It also states that the proposed methodology is reliable for AD identification, allowing timely intervention to slow the disease progression and improve patient quality of life. <xref rid=\"T5\" ref-type=\"table\">Table 5</xref> represents the overview of selected studies below.</p><table-wrap position=\"float\" id=\"T5\" orientation=\"portrait\"><label>TABLE 5</label><caption><p>Overview of selected literature.</p></caption><table frame=\"box\" rules=\"all\" cellspacing=\"5\" cellpadding=\"5\"><thead><tr><th valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">References</th><th valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Models used</th><th valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Modalities</th><th valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Compared with</th><th valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Accuracy %/ performance</th></tr></thead><tbody><tr><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">\n<xref rid=\"B1\" ref-type=\"bibr\">Ahmadi et al., 2021</xref>\n</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">QAIS-DSNN</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">MRI</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">KNN, Genetic algorithm, SVM, SOM, CNN, GCNN, BAT-IT2FCM</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">DSNN with 98.21 %</td></tr><tr><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">\n<xref rid=\"B9\" ref-type=\"bibr\">Dong et al., 2024</xref>\n</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">ONSNPSamos</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">MRI</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">ABC, CMA-ES, SHADE, CSO, RMSProp, FROFI, DAOSNPS, ONSNPS, FCN8s, FCNs16, FCNs32, Unet, HybridUnet, NestedUnet</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Effective for a Single-area brain tumor</td></tr><tr><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">\n<xref rid=\"B19\" ref-type=\"bibr\">Kamal et al., 2023</xref>\n</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">SNN</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">MRI &amp; Gene expression</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">CNN</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">97.02%</td></tr><tr><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">\n<xref rid=\"B35\" ref-type=\"bibr\">Sengupta et al., 2018</xref>\n</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">SNN</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">DTI &amp; fMRI</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Not applicable</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Effective</td></tr><tr><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">\n<xref rid=\"B4\" ref-type=\"bibr\">Capecci et al., 2015b</xref>\n</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">SNN</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">EEG</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">MLP, SVM, IECF, ECMC</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">100%</td></tr><tr><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">\n<xref rid=\"B5\" ref-type=\"bibr\">Capecci et al., 2015a</xref>\n</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">SNN (NeuCube)</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">EEG</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">MLR, SVM, MLP, ECM</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">86%, 79%</td></tr><tr><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">\n<xref rid=\"B21\" ref-type=\"bibr\">Kasabov N. et al., 2017</xref>\n</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">SNN (NeuCube)</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">fMRI</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">SVM, MLP, ECF, ECMC, MLR</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">90%, 85%, 85%</td></tr><tr><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">\n<xref rid=\"B15\" ref-type=\"bibr\">Guo et al., 2023</xref>\n</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">SNN</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">fMRI</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">SFSNN, SWSNN</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Outperformed</td></tr><tr><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">\n<xref rid=\"B34\" ref-type=\"bibr\">Sam et al., 2023</xref>\n</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">SNN</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">EEG</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">CNN-TCN, CNN-LSTM, Deep CNN</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">98%: 96%, Eyes-Closed: Eyes-Open</td></tr><tr><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">\n<xref rid=\"B11\" ref-type=\"bibr\">Francis and Al-Hababi, 2023</xref>\n</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">SNN</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">sMRI</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">CNN, SVM, FCNN</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">94%</td></tr><tr><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">\n<xref rid=\"B41\" ref-type=\"bibr\">Turkson et al., 2021</xref>\n</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Spiking deep convolutional neural network</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">MRI</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">SVM, CNN, random forest, KNN, NB</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">90.15%</td></tr><tr><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">\n<xref rid=\"B7\" ref-type=\"bibr\">Doborjeh et al., 2021</xref>\n</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">SNN</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Longitudinal MRI</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Not applicable</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">95% &amp; 91%</td></tr><tr><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">\n<xref rid=\"B8\" ref-type=\"bibr\">Doborjeh et al., 2019</xref>\n</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Personalized SNN - d2WKNN</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">EEG</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">WWKNN, WKNN, KNN</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">80% to 93%</td></tr><tr><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">\n<xref rid=\"B33\" ref-type=\"bibr\">Saeedinia et al., 2021</xref>\n</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">MRI-SNNr</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">MRI, EEG</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Random walk, NeuCube</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Better prediction</td></tr><tr><td rowspan=\"1\" colspan=\"1\"/><td rowspan=\"1\" colspan=\"1\"/><td rowspan=\"1\" colspan=\"1\"/><td rowspan=\"1\" colspan=\"1\"/><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">accuracy</td></tr><tr><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">\n<xref rid=\"B30\" ref-type=\"bibr\">Murli et al., 2020</xref>\n</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">eSNN (NeuCube)</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">fMRI</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">SVM, MLP</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">85%</td></tr><tr><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">\n<xref rid=\"B18\" ref-type=\"bibr\">Kalpana et al., 2024</xref>\n</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Hybrid SCNN</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">MRI</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Not applicable</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">97.50%</td></tr><tr><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">\n<xref rid=\"B6\" ref-type=\"bibr\">Das et al., 2024</xref>\n</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">SEFRON (SNN-based)</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">speech measurements</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">RBF-NN, MLP-NN, RNN, LSTM</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">94% to 91.94%</td></tr><tr><td rowspan=\"1\" colspan=\"1\"/><td rowspan=\"1\" colspan=\"1\"/><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">collected/acoustic features</td><td rowspan=\"1\" colspan=\"1\"/><td rowspan=\"1\" colspan=\"1\"/></tr><tr><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">\n<xref rid=\"B21\" ref-type=\"bibr\">Kasabov N. et al., 2017</xref>\n</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">SNN (NeuCube)</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">fMRI</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Not applicable</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Compatible</td></tr><tr><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">\n<xref rid=\"B14\" ref-type=\"bibr\">Gowsikraja et al., 2025</xref>\n</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Hybrid SBERO_Deep SNN</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">MRI</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">CNN+LSTM, Deep ensemble model, Hybrid DNN, TL, Deep SNN, SOA_Deep SNN, BER_Deep SNN</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">90.49%</td></tr><tr><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">\n<xref rid=\"B46\" ref-type=\"bibr\">Zhu et al., 2022</xref>\n</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">DenseNet-based SNN</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">MRI</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">Restricted DenseNet, SNN,</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">98.46% &#177; 2.05%</td></tr><tr><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">\n<xref rid=\"B10\" ref-type=\"bibr\">Dong et al., 2023</xref>\n</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">STPD-based SNN</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">CIFAR10 random images</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">MNIST, FashionMNIST</td><td valign=\"top\" align=\"center\" rowspan=\"1\" colspan=\"1\">81.45%</td></tr></tbody></table></table-wrap></sec></sec></sec><sec sec-type=\"discussion\" id=\"S4\"><label>4</label><title>Discussion</title><p>This section provides a detailed discussion of principal findings, including neuroimaging and analysis of clinical features and use of SNN. The section also discusses this review&#8217;s challenges, gaps, future direction, and limitations.</p><sec id=\"S4.SS1\"><label>4.1</label><title>Principal findings</title><p>The primary findings of the literature review of the selected 21 studies expose a massive gap in defusing multiple modalities for developing a deep learning model using SNN for real-time clinical applications. Out of 21, only a few studies proposed the utilization of two or more modalities together for analysis. The rest of the studies focused on a single modality in their research.</p><p>The literature review reveals a significant trend toward utilizing the benefits of neuroimaging data combined with deep learning models, specifically SNN, for understanding and diagnosing neurological disorders. Researchers are applying spiking neural networks with MRI, EEG, fMRI, and DTI for personalized and dynamic modeling of brain functionalities. A comparative analysis of the selected studies on SNNs shows that SNNs provide more accuracy than other previously used methods, such as traditional CNNs, in terms of precision, recall, and accuracy. Furthermore, conventional neural networks have a significant disadvantage of slower computational speed and higher energy consumption (<xref rid=\"B43\" ref-type=\"bibr\">Xiaoxue et al., 2023</xref>).</p></sec><sec id=\"S4.SS2\"><label>4.2</label><title>Neuroimaging and clinical features</title><p>Neuroimaging, including structural MRI (sMRI), fMRI, DTI, and EEG are important in understanding the clinical features of psychiatric and neurological disorders. All these modalities provide a detailed map of brain structure, activity, and function, which is helpful for clinicians and researchers in making more accurate diagnoses and guiding the right treatments.</p><p>As per the selected studies, researchers emphasize the importance of neuroimaging in identifying biomarkers such as microbleeds, structural abnormalities, and functional connectivity changes. However, using multiple modalities can enhance the depth of clinical insights. <xref rid=\"F7\" ref-type=\"fig\">Figure 7</xref> represents the overview of clinical features from the selected studies.</p><fig position=\"float\" id=\"F7\" orientation=\"portrait\"><label>FIGURE 7</label><caption><p>Overview of the clinical features from the selected studies, <italic toggle=\"yes\">X</italic>-axis represents the clinical features, and <italic toggle=\"yes\">Y</italic>-axis is used to display the number of times a clinical feature used in selected research articles.</p></caption><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" position=\"float\" orientation=\"portrait\" xlink:href=\"fnins-19-1623497-g007.jpg\"><alt-text content-type=\"machine-generated\">Bar chart showing the sum of occurrences for various clinical features. Cognitive dynamics, Alzheimer&#8217;s disease, brain functionality, and others each have a count of one. Brain tumor detection has a count of two, and brain lateralization is the highest with four.</alt-text></graphic></fig></sec><sec id=\"S4.SS3\"><label>4.3</label><title>Use of deep learning with SNN and neuroimaging</title><p>Spiking Neural Networks (SNNs) are computational models consisting of spiking neurons, interconnections, and learning algorithms designed for processing data (<xref rid=\"B17\" ref-type=\"bibr\">Izhikevich, 2006</xref>; <xref rid=\"B20\" ref-type=\"bibr\">Kasabov et al., 2016</xref>). Unlike traditional neural networks, SNNs capture spatial and temporal data as inputs. SNN incorporates not only neural synaptic states but also the concept of time within its computational framework. This computational framework makes SNNs a more biologically realistic approach for modeling spatiotemporal brain dynamics (STBD) (<xref rid=\"B21\" ref-type=\"bibr\">Kasabov N. et al., 2017</xref>). Other than that, SNN techniques offer many benefits, including fast information processing and memory-based processing. It also supports frequency- and time-based data, allowing for post-training analysis and data interpretation (<xref rid=\"B4\" ref-type=\"bibr\">Capecci et al., 2015b</xref>).</p><p>Spiking Neural Networks (SNNs), especially implemented as NeuCube, are gaining importance due to their ability to model spatiotemporal data more efficiently and naturally (<xref rid=\"B23\" ref-type=\"bibr\">Kasabov, 2014</xref>). As aforementioned, SNNs process data in both space and time using discrete spike trains, offering an alternative that closely resembles neuronal communication in the brain, contrasting traditional artificial neural networks (ANNs) like MLPs or Transformers (<xref rid=\"B13\" ref-type=\"bibr\">Ghosh-Dastidar and Adeli, 2009</xref>; <xref rid=\"B23\" ref-type=\"bibr\">Kasabov, 2014</xref>). NeuCube provides a structured framework for developing models that process spatiotemporal brain data (STBD). It mirrors how the brain encodes and learns information through spikes, using spatial mapping and brain-inspired learning rules. The model evolves over time, continuously learning and adapting to new patterns while maintaining a spatiotemporal memory that supports the analysis of cognitive functions. The overall architecture of NeuCube is illustrated in <xref rid=\"F8\" ref-type=\"fig\">Figure 8</xref>.</p><fig position=\"float\" id=\"F8\" orientation=\"portrait\"><label>FIGURE 8</label><caption><p>A schematic diagram of a general NeuCube architecture, consisting of, input encoding module, SNN Cube, Output module, and gene regulatory module (<xref rid=\"B23\" ref-type=\"bibr\">Kasabov, 2014</xref>).</p></caption><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" position=\"float\" orientation=\"portrait\" xlink:href=\"fnins-19-1623497-g008.jpg\"><alt-text content-type=\"machine-generated\">Diagram illustrating a neurogenetic brain cube (NBC) model. It shows input data as spatio/spectro-temporal chunks leading to classification and modeling through an NBC. The system connects to a gene regulatory network with probabilistic parameters. An output module categorizes data into classes, depicted in a chart. A graph displays output data trends over time.</alt-text></graphic></fig><p>Furthermore, <xref rid=\"B20\" ref-type=\"bibr\">Kasabov et al. (2016)</xref> mentioned that the NeuCube can be used for the visualization of input features interactions at the group level as well as the individual level. It provides a more profound understanding of underlying data relationships and their impact on the individual risk of stroke.</p><p>However, this review demonstrated that SNN is also being integrated with other models, such as CNNs and LSTMs, making it a hybrid model for more efficient spatiotemporal data modeling using neuroimaging. <xref rid=\"B41\" ref-type=\"bibr\">Turkson et al. (2021)</xref>, <xref rid=\"B18\" ref-type=\"bibr\">Kalpana et al. (2024)</xref> and <xref rid=\"B11\" ref-type=\"bibr\">Francis and Al-Hababi (2023)</xref> proposed a hybrid model integrating other models with SNNs using neuroimaging for the assessment of suicidal ideations, brain tumor classification, and detection of Alzheimer&#8217;s diseases, showcasing better results in terms of accuracy than other previously used deep learning models.</p><p>Likewise, SNN-based frameworks such as NeuCube (<xref rid=\"B23\" ref-type=\"bibr\">Kasabov, 2014</xref>) and other brain-inspired models make it easy to learn and utilize multiple modalities, improving accuracy even at a higher level. <xref rid=\"B4\" ref-type=\"bibr\">Capecci et al. (2015b)</xref> stated that the overall performance of NeuCube was considerably better in terms of highest precision and sensitivity than other compared classification methods, including multilayer perceptron (MLP), inductive evolving classification function (IECF) (<xref rid=\"B22\" ref-type=\"bibr\">Kasabov, 2007</xref>), support vector machine (SVM), and evolving clustering method for classification (ECMC) (<xref rid=\"B39\" ref-type=\"bibr\">Song and Kasabov, 2002</xref>). The literature review also uncovers the performance of SNNs in longitudinal studies and real-time prediction tasks, confirming their potential for future clinical applications.</p><p>Furthermore, <xref rid=\"B26\" ref-type=\"bibr\">Kundu et al. (2024)</xref> presented the recent progress in SNN algorithms and their integration with sensor and memory technologies. It underscores how SNNs enable deployable AI systems that are energy-efficient, reliable, and well-suited for real-world tasks.</p></sec></sec><sec id=\"S5\"><label>5</label><title>Conclusion, and future research directions</title><p>As per the scope of this literature review, the aim was to incorporate neuroimaging data and SNN-based models. According to the available evidence suggests that SNN-based models may offer advantages over traditional neural networks when applied to neuroimaging data. Furthermore, these studies represent the integration of neuroimaging and deep learning models using SNN for analysis, classification, feature extraction, and diagnosis of diseases. Different types of modalities were utilized in these studies, including MRI, fMRI, DTI, and EEG. However, MRI-based modalities dominated either as a single modality or by defusing a few others. It is observed that there are only a few studies that use multimodality, either combining MRI with DTI or EEG, or with another type of data, such as gene expression. Multiple studies on Alzheimer&#8217;s disease use only a single modality. Furthermore, many studies use small or specific datasets, maybe due to the high computational power SNNs require for training. Furthermore, it is stated that the diffusion of modalities with different spatial and temporal resolutions remains a key barrier <xref rid=\"B35\" ref-type=\"bibr\">Sengupta et al. (2018)</xref>. While current SNN studies have mainly focused on sMRI, fMRI, or EEG, primarily using single-modality data for Alzheimer&#8217;s disease, the study by <xref rid=\"B27\" ref-type=\"bibr\">Li and Yap (2022)</xref>, which employs generative modeling, particularly for fMRI and DTI, offers a path toward mechanistic connectomes that extends beyond descriptive connectivity and explains how it captures the brain connectivity changes in response to tasks, stimuli, or internal states. The presented approach could have a significant impact on future SNN frameworks by providing better integration of multimodal data, thereby supporting improved prediction and classification accuracy.</p><p>Hence, the review suggests that exploring multiple modalities like MRI, fMRI, DTI, and perfusing MRI defusing together to develop a deep learning model using SNN for better analyses and use of clinical features for disease diagnosis, prevention, and to provide treatment plans for slower progression. Improvement in methods for multimodal data fusion is required. Moreover, large and more diverse datasets should be utilized to increase the accuracy of the models. Additionally, integrating the above-mentioned modalities with PET images can provide a critical analysis of specific disease detection, such as Alzheimer&#8217;s disease, as PET imaging techniques are a popular and non-invasive technique used to capture brain tissue characteristics, as explained by <xref rid=\"B38\" ref-type=\"bibr\">Song et al. (2021)</xref> in their study, along with the ability to directly visualize AD-specific biomarkers.</p><p>Furthermore, future studies can aim to develop a sophisticated AI partner for Alzheimer&#8217;s patients and their families or friends to help them with their diagnosis, treatment plans, reports, and daily queries. It will be helpful support for healthcare professionals in dealing with their patients. The AI model and agent should integrate all international guidelines relating to Alzheimer&#8217;s disease treatment plans and patient care.</p><sec id=\"S5.SS1\"><label>5.1</label><title>Limitations</title><p>Firstly, the literature review is conducted with a few limitations, including a narrow picture of current trends in this area, as it only considers papers in English that are published in conferences or journals. This review may not cover all relevant work due to inclusion/exclusion criteria. Secondly, the review was conducted using specific keywords and databases, because of which many relevant studies might be overlooked, as limited datasets can reduce external validations.</p></sec></sec></body><back><ack><title>Acknowledgments</title><p>We would like to extend their sincere gratitude to everyone who gave guidance and assistance throughout this research. Special appreciation to family for their constant support and understanding.</p></ack><fn-group><fn id=\"n1\" fn-type=\"edited-by\"><p>Edited by: <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"https://loop.frontiersin.org/people/594500/overview\" ext-link-type=\"uri\">Badong Chen</ext-link>, Xi&#8217;an Jiaotong University, China</p></fn><fn id=\"n2\" fn-type=\"reviewed-by\"><p>Reviewed by: <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"https://loop.frontiersin.org/people/2795923/overview\" ext-link-type=\"uri\">Anirban Das</ext-link>, Intel, United States</p><p><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"https://loop.frontiersin.org/people/1371667/overview\" ext-link-type=\"uri\">Eric Jacob Bacon</ext-link>, Northeastern University, China</p></fn></fn-group><sec sec-type=\"author-contributions\" id=\"S6\"><title>Author contributions</title><p>AK: Writing &#8211; original draft, Writing &#8211; review &amp; editing. VS: Writing &#8211; review &amp; editing. JF: Writing &#8211; review &amp; editing. NK: Conceptualization, Supervision, Writing &#8211; review &amp; editing. AW: Supervision, Conceptualization, Funding acquisition, Writing &#8211; review &amp; editing, Resources.</p></sec><sec sec-type=\"COI-statement\" id=\"S8\"><title>Conflict of interest</title><p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p></sec><sec sec-type=\"ai-statement\" id=\"S9\"><title>Generative AI statement</title><p>The author(s) declare that no Generative AI was used in the creation of this manuscript.</p><p>Any alternative text (alt text) provided alongside figures in this article has been generated by Frontiers with the support of artificial intelligence and reasonable efforts have been made to ensure accuracy, including review by the authors wherever possible. If you identify any issues, please contact us.</p></sec><sec sec-type=\"disclaimer\" id=\"S10\"><title>Publisher&#8217;s note</title><p>All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.</p></sec><sec sec-type=\"supplementary-material\" id=\"S11\"><title>Supplementary material</title><p>The Supplementary Material for this article can be found online at: <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"https://www.frontiersin.org/articles/10.3389/fnins.2025.1623497/full#supplementary-material\" ext-link-type=\"uri\">https://www.frontiersin.org/articles/10.3389/fnins.2025.1623497/full#supplementary-material</ext-link></p><supplementary-material id=\"DS1\" position=\"float\" content-type=\"local-data\" orientation=\"portrait\"><media xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"Data_Sheet_1.docx\" position=\"float\" orientation=\"portrait\"/></supplementary-material><supplementary-material id=\"TS1\" position=\"float\" content-type=\"local-data\" orientation=\"portrait\"><media xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"Table_1.xlsx\" position=\"float\" orientation=\"portrait\"/></supplementary-material></sec><ref-list><title>References</title><ref id=\"B1\"><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Ahmadi</surname><given-names>M.</given-names></name><name name-style=\"western\"><surname>Sharifi</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Hassantabar</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Enayati</surname><given-names>S.</given-names></name></person-group> (<year>2021</year>). <article-title>QAIS-DSNN: Tumor area segmentation of MRI image with optimized quantum matched-filter technique and deep spiking neural network.</article-title><source><italic toggle=\"yes\">BioMed Res. Int.</italic></source><volume>2021</volume>:<fpage>6653879</fpage>. <pub-id pub-id-type=\"doi\">10.1155/2021/6653879</pub-id><pub-id pub-id-type=\"pmid\">33542920</pub-id><pub-id pub-id-type=\"pmcid\">PMC7843186</pub-id></mixed-citation></ref><ref id=\"B2\"><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Alagarsamy</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Kamatchi</surname><given-names>K.</given-names></name><name name-style=\"western\"><surname>Govindaraj</surname><given-names>V.</given-names></name><name name-style=\"western\"><surname>Zhang</surname><given-names>Y. D.</given-names></name><name name-style=\"western\"><surname>Thiyagarajan</surname><given-names>A.</given-names></name></person-group> (<year>2019</year>). <article-title>Multi-channeled MR brain image segmentation: A new automated approach combining BAT and clustering technique for better identification of heterogeneous tumors.</article-title><source><italic toggle=\"yes\">Biocybernet. Biomed. Eng.</italic></source><volume>39</volume><fpage>1005</fpage>&#8211;<lpage>1035</lpage>. <pub-id pub-id-type=\"doi\">10.1016/j.bbe.2019.05.007</pub-id></mixed-citation></ref><ref id=\"B3\"><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Calhoun</surname><given-names>V. D.</given-names></name><name name-style=\"western\"><surname>Miller</surname><given-names>R.</given-names></name><name name-style=\"western\"><surname>Pearlson</surname><given-names>G.</given-names></name><name name-style=\"western\"><surname>Adal&#305;</surname><given-names>T.</given-names></name></person-group> (<year>2014</year>). <article-title>The chronnectome: Time-varying connectivity networks as the next frontier in fMRI data discovery.</article-title><source><italic toggle=\"yes\">Neuron</italic></source><volume>84</volume><fpage>262</fpage>&#8211;<lpage>274</lpage>. <pub-id pub-id-type=\"doi\">10.1016/j.neuron.2014.10.015</pub-id><pub-id pub-id-type=\"pmid\">25374354</pub-id><pub-id pub-id-type=\"pmcid\">PMC4372723</pub-id></mixed-citation></ref><ref id=\"B4\"><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Capecci</surname><given-names>E.</given-names></name><name name-style=\"western\"><surname>Kasabov</surname><given-names>N.</given-names></name><name name-style=\"western\"><surname>Wang</surname><given-names>G. Y.</given-names></name></person-group> (<year>2015b</year>). <article-title>Analysis of connectivity in NeuCube spiking neural network models trained on EEG data for the understanding of functional changes in the brain: A case study on opiate dependence treatment.</article-title><source><italic toggle=\"yes\">Neural Netw.</italic></source><volume>68</volume><fpage>62</fpage>&#8211;<lpage>77</lpage>. <pub-id pub-id-type=\"doi\">10.1016/j.neunet.2015.03.009</pub-id><pub-id pub-id-type=\"pmid\">26000776</pub-id></mixed-citation></ref><ref id=\"B5\"><mixed-citation publication-type=\"book\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Capecci</surname><given-names>E.</given-names></name><name name-style=\"western\"><surname>Morabito</surname><given-names>F. C.</given-names></name><name name-style=\"western\"><surname>Campolo</surname><given-names>M.</given-names></name><name name-style=\"western\"><surname>Mammone</surname><given-names>N.</given-names></name><name name-style=\"western\"><surname>Labate</surname><given-names>D.</given-names></name><name name-style=\"western\"><surname>Kasabov</surname><given-names>N.</given-names></name></person-group> (<year>2015a</year>). &#8220;<article-title>A feasibility study of using the neucube spiking neural network architecture for modelling alzheimer&#8217;s disease eeg data</article-title>,&#8221; in <source><italic toggle=\"yes\">Advances in neural networks: Computational and theoretical issues</italic></source>, <role>eds</role><person-group person-group-type=\"editor\"><name name-style=\"western\"><surname>Bassis</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Esposito</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Morabito</surname><given-names>F. C.</given-names></name></person-group> (<publisher-loc>Cham</publisher-loc>: <publisher-name>Springer International Publishing</publisher-name>), <fpage>159</fpage>&#8211;<lpage>172</lpage>. <pub-id pub-id-type=\"doi\">10.1007/978-3-319-18164-6_16</pub-id></mixed-citation></ref><ref id=\"B6\"><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Das</surname><given-names>P.</given-names></name><name name-style=\"western\"><surname>Nanda</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Panda</surname><given-names>G.</given-names></name><name name-style=\"western\"><surname>Dash</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Ksibi</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Alsenan</surname><given-names>S.</given-names></name><etal/></person-group> (<year>2024</year>). <article-title>A robust Parkinson&#8217;s disease detection model based on time-varying synaptic efficacy function in spiking neural network.</article-title><source><italic toggle=\"yes\">BMC Neurol.</italic></source><volume>24</volume>:<fpage>492</fpage>. <pub-id pub-id-type=\"doi\">10.1186/s12883-024-04001-7</pub-id><pub-id pub-id-type=\"pmid\">39734199</pub-id><pub-id pub-id-type=\"pmcid\">PMC11684134</pub-id></mixed-citation></ref><ref id=\"B7\"><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Doborjeh</surname><given-names>M.</given-names></name><name name-style=\"western\"><surname>Doborjeh</surname><given-names>Z.</given-names></name><name name-style=\"western\"><surname>Merkin</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Bahrami</surname><given-names>H.</given-names></name><name name-style=\"western\"><surname>Sumich</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Krishnamurthi</surname><given-names>R.</given-names></name><etal/></person-group> (<year>2021</year>). <article-title>Personalised predictive modelling with brain-inspired spiking neural networks of longitudinal MRI neuroimaging data and the case study of dementia.</article-title><source><italic toggle=\"yes\">Neural Netw.</italic></source><volume>144</volume><fpage>522</fpage>&#8211;<lpage>539</lpage>. <pub-id pub-id-type=\"doi\">10.1016/j.neunet.2021.09.013</pub-id><pub-id pub-id-type=\"pmid\">34619582</pub-id></mixed-citation></ref><ref id=\"B8\"><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Doborjeh</surname><given-names>M.</given-names></name><name name-style=\"western\"><surname>Kasabov</surname><given-names>N.</given-names></name><name name-style=\"western\"><surname>Doborjeh</surname><given-names>Z.</given-names></name><name name-style=\"western\"><surname>Enayatollahi</surname><given-names>R.</given-names></name><name name-style=\"western\"><surname>Tu</surname><given-names>E.</given-names></name><name name-style=\"western\"><surname>Gandomi</surname><given-names>A. H.</given-names></name></person-group> (<year>2019</year>). <article-title>Personalised modelling with spiking neural networks integrating temporal and static information.</article-title><source><italic toggle=\"yes\">Neural Netw.</italic></source><volume>119</volume><fpage>162</fpage>&#8211;<lpage>177</lpage>. <pub-id pub-id-type=\"doi\">10.1016/j.neunet.2019.07.021</pub-id><pub-id pub-id-type=\"pmid\">31446235</pub-id></mixed-citation></ref><ref id=\"B9\"><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Dong</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>Zhang</surname><given-names>G.</given-names></name><name name-style=\"western\"><surname>Hu</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>Wu</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>Rong</surname><given-names>H.</given-names></name></person-group> (<year>2024</year>). <article-title>An optimization numerical spiking neural membrane system with adaptive multi-mutation operators for brain tumor segmentation.</article-title><source><italic toggle=\"yes\">Int. J. Neural Syst.</italic></source><volume>34</volume>:<fpage>2450036</fpage>. <pub-id pub-id-type=\"doi\">10.1142/S0129065724500369</pub-id><pub-id pub-id-type=\"pmid\">38686911</pub-id></mixed-citation></ref><ref id=\"B10\"><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Dong</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>Zhao</surname><given-names>D.</given-names></name><name name-style=\"western\"><surname>Li</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>Zeng</surname><given-names>Y.</given-names></name></person-group> (<year>2023</year>). <article-title>An unsupervised STDP-based spiking neural network inspired by biologically plausible learning rules and connections</article-title>. <source><italic toggle=\"yes\">Neural Netw.</italic></source><volume>165</volume>, <fpage>799</fpage>&#8211;<lpage>808</lpage>. <pub-id pub-id-type=\"doi\">10.1016/j.neunet.2023.06.019</pub-id><pub-id pub-id-type=\"pmid\">37418862</pub-id></mixed-citation></ref><ref id=\"B11\"><mixed-citation publication-type=\"book\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Francis</surname><given-names>C.</given-names></name><name name-style=\"western\"><surname>Al-Hababi</surname><given-names>A. Y. S.</given-names></name></person-group> (<year>2023</year>). &#8220;<article-title>Performance evaluation of attention mechanism and spiking neural networks on smri data for suicide ideation assessment</article-title>,&#8221; in <source><italic toggle=\"yes\">Proceedings of the 2023 IEEE International Conference on Computing</italic></source>, (<publisher-loc>Langkawi</publisher-loc>: <publisher-name>IEEE</publisher-name>), <fpage>408</fpage>&#8211;<lpage>413</lpage>. <pub-id pub-id-type=\"doi\">10.1109/ICOCO59262.2023.10397625</pub-id></mixed-citation></ref><ref id=\"B12\"><mixed-citation publication-type=\"book\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Ghazali</surname><given-names>R.</given-names></name><name name-style=\"western\"><surname>Nawi</surname><given-names>N. M.</given-names></name><name name-style=\"western\"><surname>Deris</surname><given-names>M. M.</given-names></name><name name-style=\"western\"><surname>Abawajy</surname><given-names>J. H.</given-names></name></person-group> (<year>2020</year>). &#8220;<article-title>Recent advances on soft computing and data mining</article-title>,&#8221; in <source><italic toggle=\"yes\">Proceedings of the 4th International Conference on Soft Computing and Data Mining (SCDM 2020), Melaka, Malaysia, January 22&#8211;23, 2020</italic></source>, (<publisher-loc>Cham</publisher-loc>: <publisher-name>Springer International Publishing</publisher-name>), <pub-id pub-id-type=\"doi\">10.1007/978-3-030-36056-6</pub-id></mixed-citation></ref><ref id=\"B13\"><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Ghosh-Dastidar</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Adeli</surname><given-names>H.</given-names></name></person-group> (<year>2009</year>). <article-title>Spiking neural networks.</article-title><source><italic toggle=\"yes\">Int. J. Neural Syst.</italic></source><volume>19</volume><fpage>295</fpage>&#8211;<lpage>308</lpage>. <pub-id pub-id-type=\"doi\">10.1142/S0129065709002002</pub-id><pub-id pub-id-type=\"pmid\">19731402</pub-id></mixed-citation></ref><ref id=\"B14\"><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Gowsikraja</surname><given-names>P.</given-names></name><name name-style=\"western\"><surname>Geetha</surname><given-names>K.</given-names></name><name name-style=\"western\"><surname>Rajan</surname><given-names>C.</given-names></name></person-group> (<year>2025</year>). <article-title>SBERO skill al-biruni earth radius optimization for Alzheimer&#8217;s disease classification using magnetic resonance image.</article-title><source><italic toggle=\"yes\">NMR Biomed.</italic></source><volume>38</volume>:<fpage>e5323</fpage>. <pub-id pub-id-type=\"doi\">10.1002/nbm.5323</pub-id><pub-id pub-id-type=\"pmid\">39887547</pub-id></mixed-citation></ref><ref id=\"B15\"><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Guo</surname><given-names>L.</given-names></name><name name-style=\"western\"><surname>Liu</surname><given-names>C.</given-names></name><name name-style=\"western\"><surname>Wu</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>Xu</surname><given-names>G.</given-names></name></person-group> (<year>2023</year>). <article-title>fMRI-based spiking neural network verified by anti-damage capabilities under random attacks.</article-title><source><italic toggle=\"yes\">Chaos Solitons Fractals</italic></source><volume>176</volume>:<fpage>114083</fpage>. <pub-id pub-id-type=\"doi\">10.1016/j.chaos.2023.114083</pub-id></mixed-citation></ref><ref id=\"B16\"><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Hu</surname><given-names>K.</given-names></name><name name-style=\"western\"><surname>Gan</surname><given-names>Q.</given-names></name><name name-style=\"western\"><surname>Zhang</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>Deng</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Xiao</surname><given-names>F.</given-names></name><name name-style=\"western\"><surname>Huang</surname><given-names>W.</given-names></name><etal/></person-group> (<year>2019</year>). <article-title>Brain tumor segmentation using multi-cascaded convolutional neural networks and conditional random field.</article-title><source><italic toggle=\"yes\">IEEE Access</italic></source><volume>7</volume><fpage>92615</fpage>&#8211;<lpage>92629</lpage>. <pub-id pub-id-type=\"doi\">10.1109/ACCESS.2019.2927433</pub-id></mixed-citation></ref><ref id=\"B17\"><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Izhikevich</surname><given-names>E. M.</given-names></name></person-group> (<year>2006</year>). <article-title>Polychronization: Computation with spikes.</article-title><source><italic toggle=\"yes\">Neural Comput.</italic></source><volume>18</volume><fpage>245</fpage>&#8211;<lpage>282</lpage>. <pub-id pub-id-type=\"doi\">10.1162/089976606775093882</pub-id><pub-id pub-id-type=\"pmid\">16378515</pub-id></mixed-citation></ref><ref id=\"B18\"><mixed-citation publication-type=\"book\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Kalpana</surname><given-names>T.</given-names></name><name name-style=\"western\"><surname>Meghana</surname><given-names>P.</given-names></name><name name-style=\"western\"><surname>Spandana</surname><given-names>M.</given-names></name><name name-style=\"western\"><surname>Kumar</surname><given-names>T. S.</given-names></name></person-group> (<year>2024</year>). &#8220;<article-title>Biologically inspired spiking CNN for brain tumor classification</article-title>,&#8221; in <source><italic toggle=\"yes\">Proceedings of the 2024 5th International Conference on Image Processing and Capsule Networks (ICIPCN)</italic></source>, (<publisher-loc>Nepal</publisher-loc>: <publisher-name>IEEE</publisher-name>), <pub-id pub-id-type=\"doi\">10.1109/ICIPCN63822.2024.00035</pub-id></mixed-citation></ref><ref id=\"B19\"><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Kamal</surname><given-names>M. S.</given-names></name><name name-style=\"western\"><surname>Chowdhury</surname><given-names>L.</given-names></name><name name-style=\"western\"><surname>Nimmy</surname><given-names>S. F.</given-names></name><name name-style=\"western\"><surname>Hasan Rafi</surname><given-names>T. H.</given-names></name><name name-style=\"western\"><surname>Chae</surname><given-names>D. K.</given-names></name></person-group> (<year>2023</year>). <article-title>An interpretable framework for identifying cerebral microbleeds and Alzheimer&#8217;s disease severity using multimodal data.</article-title><source><italic toggle=\"yes\">Annu. Int. Conf. IEEE Eng. Med. Biol. Soc.</italic></source><volume>2023</volume><fpage>1</fpage>&#8211;<lpage>4</lpage>. <pub-id pub-id-type=\"doi\">10.1109/EMBC40787.2023.10340088</pub-id><pub-id pub-id-type=\"pmid\">38082672</pub-id></mixed-citation></ref><ref id=\"B20\"><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Kasabov</surname><given-names>N.</given-names></name><name name-style=\"western\"><surname>Scott</surname><given-names>N. M.</given-names></name><name name-style=\"western\"><surname>Tu</surname><given-names>E.</given-names></name><name name-style=\"western\"><surname>Marks</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Sengupta</surname><given-names>N.</given-names></name><name name-style=\"western\"><surname>Capecci</surname><given-names>E.</given-names></name><etal/></person-group> (<year>2016</year>). <article-title>Evolving spatio-temporal data machines based on the NeuCube neuromorphic framework: Design methodology and selected applications.</article-title><source><italic toggle=\"yes\">Neural Netw.</italic></source><volume>78</volume><fpage>1</fpage>&#8211;<lpage>14</lpage>. <pub-id pub-id-type=\"doi\">10.1016/j.neunet.2015.09.011</pub-id><pub-id pub-id-type=\"pmid\">26576468</pub-id></mixed-citation></ref><ref id=\"B21\"><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Kasabov</surname><given-names>N.</given-names></name><name name-style=\"western\"><surname>Zhou</surname><given-names>L.</given-names></name><name name-style=\"western\"><surname>Doborjeh</surname><given-names>M. G.</given-names></name><name name-style=\"western\"><surname>Doborjeh</surname><given-names>Z. G.</given-names></name><name name-style=\"western\"><surname>Yang</surname><given-names>J.</given-names></name></person-group> (<year>2017</year>). <article-title>New algorithms for encoding, learning and classification of fMRI data in a spiking neural network architecture: A case on modeling and understanding of dynamic cognitive processes.</article-title><source><italic toggle=\"yes\">IEEE Trans. Cogn. Dev. Syst.</italic></source><volume>9</volume><fpage>293</fpage>&#8211;<lpage>303</lpage>. <pub-id pub-id-type=\"doi\">10.1109/TCDS.2016.2636291</pub-id></mixed-citation></ref><ref id=\"B22\"><mixed-citation publication-type=\"book\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Kasabov</surname><given-names>N. K.</given-names></name></person-group> (<year>2007</year>). <source><italic toggle=\"yes\">Evolving connectionist systems: The knowledge engineering approach</italic></source>, <edition>2nd Edn</edition>. <publisher-loc>London</publisher-loc>: <publisher-name>Springer</publisher-name>.</mixed-citation></ref><ref id=\"B23\"><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Kasabov</surname><given-names>N. K.</given-names></name></person-group> (<year>2014</year>). <article-title>NeuCube: A spiking neural network architecture for mapping, learning and understanding of spatio-temporal brain data.</article-title><source><italic toggle=\"yes\">Neural Netw.</italic></source><volume>52</volume><fpage>62</fpage>&#8211;<lpage>76</lpage>. <pub-id pub-id-type=\"doi\">10.1016/j.neunet.2014.01.006</pub-id><pub-id pub-id-type=\"pmid\">24508754</pub-id></mixed-citation></ref><ref id=\"B24\"><mixed-citation publication-type=\"book\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Kasabov</surname><given-names>N. K.</given-names></name></person-group> (<year>2019</year>). <source><italic toggle=\"yes\">Time-Space, spiking neural networks and brain-inspired artificial intelligence.</italic></source><publisher-loc>Berlin</publisher-loc>: <publisher-name>Springer</publisher-name>.</mixed-citation></ref><ref id=\"B25\"><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Kasabov</surname><given-names>N. K.</given-names></name><name name-style=\"western\"><surname>Doborjeh</surname><given-names>M. G.</given-names></name><name name-style=\"western\"><surname>Doborjeh</surname><given-names>Z. G.</given-names></name></person-group> (<year>2017</year>). <article-title>Mapping, learning, visualization, classification, and understanding of fMRI data in the neucube evolving spatiotemporal data machine of spiking neural networks.</article-title><source><italic toggle=\"yes\">IEEE Trans. Neural Netw. Learn. Syst.</italic></source><volume>28</volume><fpage>887</fpage>&#8211;<lpage>899</lpage>. <pub-id pub-id-type=\"doi\">10.1109/TNNLS.2016.2612890</pub-id><pub-id pub-id-type=\"pmid\">27723607</pub-id></mixed-citation></ref><ref id=\"B26\"><mixed-citation publication-type=\"book\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Kundu</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Zhu</surname><given-names>R. J.</given-names></name><name name-style=\"western\"><surname>Jaiswal</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Beerel</surname><given-names>P. A.</given-names></name></person-group> (<year>2024</year>). &#8220;<article-title>Recent advances in scalable energy-efficient and trustworthy spiking neural networks: From algorithms to technology</article-title>,&#8221; in <source><italic toggle=\"yes\">Proceedings of the ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</italic></source>, (<publisher-loc>Korea</publisher-loc>: <publisher-name>IEEE</publisher-name>), <pub-id pub-id-type=\"doi\">10.1109/ICASSP48485.2024.10445826</pub-id></mixed-citation></ref><ref id=\"B27\"><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Li</surname><given-names>G.</given-names></name><name name-style=\"western\"><surname>Yap</surname><given-names>P. T.</given-names></name></person-group> (<year>2022</year>). <article-title>From descriptive connectome to mechanistic connectome: Generative modeling in functional magnetic resonance imaging analysis.</article-title><source><italic toggle=\"yes\">Front. Hum. Neurosci.</italic></source><volume>16</volume>:<fpage>940842</fpage>. <pub-id pub-id-type=\"doi\">10.3389/fnhum.2022.940842</pub-id><pub-id pub-id-type=\"pmid\">36061504</pub-id><pub-id pub-id-type=\"pmcid\">PMC9428697</pub-id></mixed-citation></ref><ref id=\"B28\"><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Mittal</surname><given-names>M.</given-names></name><name name-style=\"western\"><surname>Goyal</surname><given-names>L. M.</given-names></name><name name-style=\"western\"><surname>Kaur</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Kaur</surname><given-names>I.</given-names></name><name name-style=\"western\"><surname>Verma</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Hemanth</surname><given-names>D. J.</given-names></name></person-group> (<year>2019</year>). <article-title>Deep learning based enhanced tumor segmentation approach for MR brain images.</article-title><source><italic toggle=\"yes\">Appl. Soft Comp.</italic></source><volume>78</volume><fpage>346</fpage>&#8211;<lpage>354</lpage>. <pub-id pub-id-type=\"doi\">10.1016/j.asoc.2019.02.036</pub-id></mixed-citation></ref><ref id=\"B29\"><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Moher</surname><given-names>D.</given-names></name><name name-style=\"western\"><surname>Liberati</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Tetzlaff</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>Altman</surname><given-names>D. G.</given-names></name></person-group> (<year>2009</year>). <article-title>Preferred reporting items for systematic reviews and meta-analyses: The PRISMA statement.</article-title><source><italic toggle=\"yes\">PLoS Med.</italic></source><volume>6</volume>:<fpage>e1000097</fpage>. <pub-id pub-id-type=\"doi\">10.1371/journal.pmed.1000097</pub-id><pub-id pub-id-type=\"pmid\">19621072</pub-id><pub-id pub-id-type=\"pmcid\">PMC2707599</pub-id></mixed-citation></ref><ref id=\"B30\"><mixed-citation publication-type=\"book\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Murli</surname><given-names>N.</given-names></name><name name-style=\"western\"><surname>Kasabov</surname><given-names>N.</given-names></name><name name-style=\"western\"><surname>Paham</surname><given-names>N. A.</given-names></name></person-group> (<year>2020</year>). <article-title>&#8220;eSNN for Spatio-temporal fMRI brain pattern recognition with a graphical object recognition case study,&#8221;</article-title> in <source><italic toggle=\"yes\">Recent advances on soft computing and data mining. SCDM 2020. Advances in intelligent systems and computing</italic></source>, vol <volume>978</volume>, <role>eds</role>. <person-group person-group-type=\"editor\"><name name-style=\"western\"><surname>Ghazali</surname><given-names>R.</given-names></name><name name-style=\"western\"><surname>Nawi</surname><given-names>N.</given-names></name><name name-style=\"western\"><surname>Deris</surname><given-names>M.</given-names></name><name name-style=\"western\"><surname>Abawajy</surname><given-names>J.</given-names></name></person-group> (<publisher-loc>Cham</publisher-loc>: <publisher-name>Springer</publisher-name>). <pub-id pub-id-type=\"doi\">10.1007/978-3-030-36056-6_44</pub-id></mixed-citation></ref><ref id=\"B31\"><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Pham</surname><given-names>D. L.</given-names></name><name name-style=\"western\"><surname>Xu</surname><given-names>C.</given-names></name><name name-style=\"western\"><surname>Prince</surname><given-names>J. L.</given-names></name></person-group> (<year>2000</year>). <article-title>Current methods in medical image segmentation.</article-title><source><italic toggle=\"yes\">Annu. Rev. Biomed. Eng.</italic></source><volume>2</volume><fpage>315</fpage>&#8211;<lpage>337</lpage>. <pub-id pub-id-type=\"doi\">10.1146/annurev.bioeng.2.1.315</pub-id><pub-id pub-id-type=\"pmid\">11701515</pub-id></mixed-citation></ref><ref id=\"B32\"><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Plis</surname><given-names>S. M.</given-names></name><name name-style=\"western\"><surname>Hjelm</surname><given-names>D. R.</given-names></name><name name-style=\"western\"><surname>Salakhutdinov</surname><given-names>R.</given-names></name><name name-style=\"western\"><surname>Allen</surname><given-names>E. A.</given-names></name><name name-style=\"western\"><surname>Bockholt</surname><given-names>H. J.</given-names></name><name name-style=\"western\"><surname>Long</surname><given-names>J. D.</given-names></name><etal/></person-group> (<year>2014</year>). <article-title>Deep learning for neuroimaging: A validation study.</article-title><source><italic toggle=\"yes\">Front. Neurosci.</italic></source><volume>8</volume>:<fpage>229</fpage>. <pub-id pub-id-type=\"doi\">10.3389/fnins.2014.00229</pub-id><pub-id pub-id-type=\"pmid\">25191215</pub-id><pub-id pub-id-type=\"pmcid\">PMC4138493</pub-id></mixed-citation></ref><ref id=\"B33\"><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Saeedinia</surname><given-names>S. A.</given-names></name><name name-style=\"western\"><surname>Jahed-Motlagh</surname><given-names>M. R.</given-names></name><name name-style=\"western\"><surname>Tafakhori</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Kasabov</surname><given-names>N.</given-names></name></person-group> (<year>2021</year>). <article-title>Design of MRI structured spiking neural networks and learning algorithms for personalized modelling, analysis, and prediction of EEG signals.</article-title><source><italic toggle=\"yes\">Sci. Rep.</italic></source><volume>11</volume>:<fpage>12064</fpage>. <pub-id pub-id-type=\"doi\">10.1038/s41598-021-90029-5</pub-id><pub-id pub-id-type=\"pmid\">34103545</pub-id><pub-id pub-id-type=\"pmcid\">PMC8187669</pub-id></mixed-citation></ref><ref id=\"B34\"><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Sam</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Boostani</surname><given-names>R.</given-names></name><name name-style=\"western\"><surname>Hashempour</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Taghavi</surname><given-names>M.</given-names></name><name name-style=\"western\"><surname>Sanei</surname><given-names>S.</given-names></name></person-group> (<year>2023</year>). <article-title>Depression identification using EEG signals via a hybrid of LSTM and spiking neural networks.</article-title><source><italic toggle=\"yes\">IEEE Trans. Neural Syst. Rehabil. Eng.</italic></source><volume>31</volume><fpage>4725</fpage>&#8211;<lpage>4737</lpage>. <pub-id pub-id-type=\"doi\">10.1109/TNSRE.2023.3336467</pub-id><pub-id pub-id-type=\"pmid\">37995160</pub-id></mixed-citation></ref><ref id=\"B35\"><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Sengupta</surname><given-names>N.</given-names></name><name name-style=\"western\"><surname>McNabb</surname><given-names>C. B.</given-names></name><name name-style=\"western\"><surname>Kasabov</surname><given-names>N.</given-names></name><name name-style=\"western\"><surname>Russell</surname><given-names>B. R.</given-names></name></person-group> (<year>2018</year>). <article-title>Integrating space, time, and orientation in spiking neural networks: A case study on multimodal brain data modeling.</article-title><source><italic toggle=\"yes\">IEEE Trans. Neural Netw. Learn. Syst.</italic></source><volume>29</volume><fpage>5249</fpage>&#8211;<lpage>5263</lpage>. <pub-id pub-id-type=\"doi\">10.1109/TNNLS.2018.2796023</pub-id><pub-id pub-id-type=\"pmid\">29994642</pub-id></mixed-citation></ref><ref id=\"B36\"><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Sharif</surname><given-names>M.</given-names></name><name name-style=\"western\"><surname>Amin</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>Raza</surname><given-names>M.</given-names></name><name name-style=\"western\"><surname>Yasmin</surname><given-names>M.</given-names></name><name name-style=\"western\"><surname>Satapathy</surname><given-names>S. C.</given-names></name></person-group> (<year>2020</year>). <article-title>An integrated design of particle swarm optimization (PSO) with fusion of features for detection of brain tumor.</article-title><source><italic toggle=\"yes\">Pattern Recogn. Lett.</italic></source><volume>129</volume><fpage>150</fpage>&#8211;<lpage>157</lpage>. <pub-id pub-id-type=\"doi\">10.1016/j.patrec.2019.11.017</pub-id></mixed-citation></ref><ref id=\"B37\"><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Sharif</surname><given-names>M. I.</given-names></name><name name-style=\"western\"><surname>Li</surname><given-names>J. P.</given-names></name><name name-style=\"western\"><surname>Khan</surname><given-names>M. A.</given-names></name><name name-style=\"western\"><surname>Saleem</surname><given-names>M. A.</given-names></name></person-group> (<year>2020</year>). <article-title>Active deep neural network features selection for segmentation and recognition of brain tumors using MRI images.</article-title><source><italic toggle=\"yes\">Pattern Recogn. Lett.</italic></source><volume>129</volume><fpage>181</fpage>&#8211;<lpage>189</lpage>. <pub-id pub-id-type=\"doi\">10.1016/j.patrec.2019.11.019</pub-id></mixed-citation></ref><ref id=\"B38\"><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Song</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>Zheng</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>Li</surname><given-names>P.</given-names></name><name name-style=\"western\"><surname>Lu</surname><given-names>X.</given-names></name><name name-style=\"western\"><surname>Zhu</surname><given-names>G.</given-names></name><name name-style=\"western\"><surname>Shen</surname><given-names>P.</given-names></name></person-group> (<year>2021</year>). <article-title>An effective multimodal image fusion method using MRI and PET for Alzheimer&#8217;s disease diagnosis.</article-title><source><italic toggle=\"yes\">Front. Digit. Health</italic></source><volume>3</volume>:<fpage>637386</fpage>. <pub-id pub-id-type=\"doi\">10.3389/fdgth.2021.637386</pub-id><pub-id pub-id-type=\"pmid\">34713109</pub-id><pub-id pub-id-type=\"pmcid\">PMC8521941</pub-id></mixed-citation></ref><ref id=\"B39\"><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Song</surname><given-names>Q.</given-names></name><name name-style=\"western\"><surname>Kasabov</surname><given-names>N.</given-names></name></person-group> (<year>2002</year>). <source><italic toggle=\"yes\">ECM &#8212; a novel on-line, evolving clustering method and its applications.</italic></source></mixed-citation></ref><ref id=\"B40\"><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Tsuneki</surname><given-names>M.</given-names></name></person-group> (<year>2022</year>). <article-title>Deep learning models in medical image analysis.</article-title><source><italic toggle=\"yes\">J. Oral Biosci.</italic></source><volume>64</volume><fpage>312</fpage>&#8211;<lpage>320</lpage>. <pub-id pub-id-type=\"doi\">10.1016/j.job.2022.03.003</pub-id><pub-id pub-id-type=\"pmid\">35306172</pub-id></mixed-citation></ref><ref id=\"B41\"><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Turkson</surname><given-names>R. E.</given-names></name><name name-style=\"western\"><surname>Qu</surname><given-names>H.</given-names></name><name name-style=\"western\"><surname>Mawuli</surname><given-names>C. B.</given-names></name><name name-style=\"western\"><surname>Eghan</surname><given-names>M. J.</given-names></name></person-group> (<year>2021</year>). <article-title>Classification of Alzheimer&#8217;s disease using deep convolutional spiking neural network.</article-title><source><italic toggle=\"yes\">Neural Process. Lett.</italic></source><volume>53</volume><fpage>2649</fpage>&#8211;<lpage>2663</lpage>. <pub-id pub-id-type=\"doi\">10.1007/s11063-021-10514-w</pub-id></mixed-citation></ref><ref id=\"B42\"><mixed-citation publication-type=\"book\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Wang</surname><given-names>G.</given-names></name><name name-style=\"western\"><surname>Li</surname><given-names>W.</given-names></name><name name-style=\"western\"><surname>Ourselin</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Vercauteren</surname><given-names>T.</given-names></name></person-group> (<year>2019</year>). &#8220;<article-title>Automatic brain tumor segmentation using convolutional neural networks with test-time augmentation</article-title>,&#8221; in <source><italic toggle=\"yes\">Brainlesion: Glioma, multiple sclerosis, stroke and traumatic brain injuries</italic></source>, <role>eds</role><person-group person-group-type=\"editor\"><name name-style=\"western\"><surname>Crimi</surname><given-names>A.</given-names></name><etal/></person-group> (<publisher-loc>Cham</publisher-loc>: <publisher-name>Springer International Publishing</publisher-name>), <fpage>61</fpage>&#8211;<lpage>72</lpage>. <pub-id pub-id-type=\"doi\">10.1007/978-3-030-11726-9_6</pub-id></mixed-citation></ref><ref id=\"B43\"><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Xiaoxue</surname><given-names>L.</given-names></name><name name-style=\"western\"><surname>Xiaofan</surname><given-names>Z.</given-names></name><name name-style=\"western\"><surname>Xin</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>Dan</surname><given-names>L.</given-names></name><name name-style=\"western\"><surname>He</surname><given-names>W.</given-names></name><name name-style=\"western\"><surname>Bowen</surname><given-names>Z.</given-names></name><etal/></person-group> (<year>2023</year>). <article-title>Review of medical data analysis based on spiking neural networks.</article-title><source><italic toggle=\"yes\">Proc. Comp. Sci.</italic></source><volume>221</volume><fpage>1527</fpage>&#8211;<lpage>1538</lpage>. <pub-id pub-id-type=\"doi\">10.1016/j.procs.2023.08.138</pub-id></mixed-citation></ref><ref id=\"B44\"><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Yan</surname><given-names>W.</given-names></name><name name-style=\"western\"><surname>Qu</surname><given-names>G.</given-names></name><name name-style=\"western\"><surname>Hu</surname><given-names>W.</given-names></name><name name-style=\"western\"><surname>Abrol</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Cai</surname><given-names>B.</given-names></name><name name-style=\"western\"><surname>Qiao</surname><given-names>C.</given-names></name><etal/></person-group> (<year>2022</year>). <article-title>Deep learning in neuroimaging: Promises and challenges.</article-title><source><italic toggle=\"yes\">IEEE Signal Process. Magazine</italic></source><volume>39</volume><fpage>87</fpage>&#8211;<lpage>98</lpage>. <pub-id pub-id-type=\"doi\">10.1109/MSP.2021.3128348</pub-id></mixed-citation></ref><ref id=\"B45\"><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Yang</surname><given-names>R.</given-names></name><name name-style=\"western\"><surname>Yu</surname><given-names>Y.</given-names></name></person-group> (<year>2021</year>). <article-title>Artificial convolutional neural network in object detection and semantic segmentation for medical imaging analysis.</article-title><source><italic toggle=\"yes\">Front. Oncol.</italic></source><volume>11</volume>:<fpage>638182</fpage>. <pub-id pub-id-type=\"doi\">10.3389/fonc.2021.638182</pub-id><pub-id pub-id-type=\"pmid\">33768000</pub-id><pub-id pub-id-type=\"pmcid\">PMC7986719</pub-id></mixed-citation></ref><ref id=\"B46\"><mixed-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Zhu</surname><given-names>Z.</given-names></name><name name-style=\"western\"><surname>Lu</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Wang</surname><given-names>S.-H.</given-names></name><name name-style=\"western\"><surname>Gorriz</surname><given-names>J. M.</given-names></name><name name-style=\"western\"><surname>Zhang</surname><given-names>Y.-D.</given-names></name></person-group> (<year>2022</year>). <article-title>DSNN: A DenseNet-based SNN for explainable brain disease classification</article-title>. <source><italic toggle=\"yes\">Front. Syst. Neurosci.</italic></source><volume>16</volume>:<fpage>838822</fpage>. <pub-id pub-id-type=\"doi\">10.3389/fnsys.2022.838822</pub-id><pub-id pub-id-type=\"pmid\">35720439</pub-id><pub-id pub-id-type=\"pmcid\">PMC9204288</pub-id></mixed-citation></ref></ref-list></back></article></pmc-articleset>",
  "text": "pmc Front Neurosci Front Neurosci 670 frontneurosci Front. Neurosci. Frontiers in Neuroscience 1662-4548 1662-453X Frontiers Media SA PMC12660199 PMC12660199.1 12660199 12660199 41322350 10.3389/fnins.2025.1623497 1 Review Review of deep learning models with Spiking Neural Networks for modeling and analysis of multimodal neuroimaging data Khan Ayesha 1 Writing &#8211; original draft Writing &#8211; review &amp; editing Shim Vickie 1 &#8224; Writing &#8211; review &amp; editing Fernandez Justin 1 2 &#8224; Writing &#8211; review &amp; editing Kasabov Nikola K. 3 &#8224; Conceptualization Supervision Writing &#8211; review &amp; editing Wang Alan 1 4 5 6 * Supervision Conceptualization Funding acquisition Writing &#8211; review &amp; editing Resources 1 Auckland Bioengineering Institute, The University of Auckland , Auckland , New Zealand 2 Department of Engineering Science and Biomedical Engineering, The University of Auckland , Auckland , New Zealand 3 Knowledge Engineering and Discovery Research Institute, Auckland University of Technology , Auckland , New Zealand 4 Medical Imaging Research Center, Faculty of Medical and Health Sciences, The University of Auckland , Auckland , New Zealand 5 Centre for Co-Created Aging Research, The University of Auckland , Auckland , New Zealand 6 Centre for Brain Research, The University of Auckland , Auckland , New Zealand * Correspondence: Alan Wang, alan.wang@auckland.ac.nz &#8224; These authors have contributed equally to this work 14 11 2025 2025 19 480891 1623497 06 5 2025 22 10 2025 14 11 2025 29 11 2025 01 12 2025 Copyright &#169; 2025 Khan, Shim, Fernandez, Kasabov and Wang. 2025 Khan, Shim, Fernandez, Kasabov and Wang https://creativecommons.org/licenses/by/4.0/ This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY) . The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms. Medical imaging has become an essential tool for identifying and treating neurological conditions. Traditional deep learning (DL) models have made tremendous advances in neuroimaging analysis; however, they face difficulties when modeling complicated spatiotemporal brain data. Spiking Neural Networks (SNNs), which are inspired by real neurons, provide a promising option for efficiently processing spatiotemporal data. This review discusses current improvements in using SNNs for multimodal neuroimaging analysis. Quantitative and thematic analyses were conducted on 21 selected publications to assess trends, research topics, and geographical contributions. Results show that SNNs outperform traditional DL approaches in classification, feature extraction, and prediction tasks, especially when combining multiple modalities. Despite their potential, challenges of multimodal data fusion, computational demands, and limited large-scale datasets persist. We discussed the growth of SNNs in analysis, prediction, and diagnosis of neurological data, along with the emphasis on future direction and improvements for more efficient and clinically applicable models. neuroimaging multimodalities deep learning machine learning spiking neurons Spiking Neural Networks functional MRI structural MRI University of Auckland 10.13039/501100001537 The author(s) declare financial support was received for the research and/or publication of this article. This work was partially supported by the Health Research Council of New Zealand&#8217;s Project 21/144, the Marsden Fund Project 22-UOA-120, and the Royal Society Catalyst: Seeding General Project 23-UOA-055-CSG. pmc-status-qastatus 0 pmc-status-live yes pmc-status-embargo no pmc-status-released yes pmc-prop-open-access yes pmc-prop-olf no pmc-prop-manuscript no pmc-prop-legally-suppressed no pmc-prop-has-pdf yes pmc-prop-has-supplement yes pmc-prop-pdf-only no pmc-prop-suppress-copyright no pmc-prop-is-real-version no pmc-prop-is-scanned-article no pmc-prop-preprint no pmc-prop-in-epmc yes section-at-acceptance Neuromorphic Engineering 1 Introduction Medical imaging is a fundamental and widely used tool for diagnosing various diseases and planning their treatments in the medical field. Different medical imaging techniques, including X-ray, ultrasound, digital mammography, computed tomography (CT), magnetic resonance imaging (MRI), positron emission tomography (PET), and digital pathology, are used to produce images ( Pham et al., 2000 ; Tsuneki, 2022 ). In neuroscience, multimodal neuroimaging techniques, including functional MRI (fMRI), structural MRI (sMRI), diffusion tensor imaging (DTI), and others provides distinct yet interrelated aspects of neural anatomy and activity. Integrating these modalities enables a more comprehensive understanding of neural mechanisms and disease processes. Furthermore, the healthcare sector focuses on adopting computer-assisted tools to increase diagnostic accuracy and efficiency because of the advancements in artificial intelligence and neuroimaging techniques. These AI-based systems facilitate real-time disease prediction and thoroughly evaluate treatment options ( Tsuneki, 2022 ; Yang and Yu, 2021 ). Rapid progress in artificial intelligence (AI) and machine learning has further advanced neuroimaging, especially through deep learning (DL) techniques that automate the analysis of complex, high-dimensional brain data. Compared with conventional machine learning methods, DL can handle high-dimensional neuroimaging datasets with minimal manual preprocessing. As a result, multiple tasks like disease classification, predictive modeling, and the visualization of brain structure and function can be achieved more efficiently and with increased productivity ( Yan et al., 2022 ). These advances have been supported by the growing availability of large-scale datasets and increased computational power ( Calhoun et al., 2014 ). However, most existing DL approaches rely on static or single modality data, which limits their ability to capture the complex patterns across space and time of the human brain ( Plis et al., 2014 ). This gap highlights the requirement of the models that are not only data-driven but also biologically interpretable Spiking Neural Networks (SNNs) effectively transform neuroimaging and help diagnose neurological disorders by stimulating the brain&#8217;s natural processing. This makes SNN highly effective for spatiotemporal data analysis. SNN enables early detection of conditions like dementia and predicts epileptic seizures by identifying complex EEG patterns. Additionally, integrating SNN with multimodal neuroimaging, such as EEG and MRI, can enhance diagnostic accuracy by highlighting their transformative potential in neurological healthcare ( Kasabov, 2019 ). This study aims to critically evaluate the role of SNNs in multimodal MRI analysis and assess their potential to overcome the limitations of traditional deep learning models. The review will explore: How have SNNs been applied to neuroimaging, particularly multimodal MRI data? What are the advantages of SNNs over conventional deep learning models in capturing spatio-temporal features? How can SNNs integrate multiple MRI modalities to enhance diagnostic accuracy? What are the current challenges in implementing SNNs for large-scale multimodal MRI analysis? By answering these questions, the review aims to highlight the strengths, limitations, and clinical potential of SNNs in neuroimaging and the findings will contribute to the advancement of biologically inspired deep learning models for more accurate, interpretable, and clinically relevant neuroimaging solutions. 1.1 Background Over the past decade, deep learning (DL) models, including convolutional neural networks (CNNs), recurrent neural networks (RNNs), and long short-term memory (LSTM) networks, have transformed neuroimaging research. These models excel at extracting hierarchical features from brain images and temporal sequences, enabling improvements in classification and disease prediction ( Yan et al., 2022 ; Yang and Yu, 2021 ). However, the dynamic nature of brain data poses challenges for traditional deep learning models, especially basic feedforward architectures. Their primary shortcoming is that they are unable to efficiently learn the temporal relationships that exist in spatiotemporal neurons due to a lack of internal state or memory. More importantly, their continuous, rate-based functioning is not well suited to mimic the sparse, event-driven communication of real neurons, where information is frequently contained in the exact timing of discrete spikes. Table 1 below represents a small conceptual comparison of other Deep Learning (DL) and Spiking Neural Networks (SNN) models for the most relevant aspects. TABLE 1 Conceptual overview comparing deep learning (DL) and Spiking Neural Networks (SNN). Aspect Deep learning Spiking Neural Networks Information type Continuous activation Discrete spike events Temporal modeling Limited Strong temporal dynamics Biological realism Low High (mimics neuron firing) Energy efficiency High computational cost Neuromorphic efficiency Neuroimaging relevance Good for static data Effective for spatiotemporal data Spiking Neural Networks (SNNs) process information through discrete spikes, mimicking the temporal firing patterns of biological neurons ( Izhikevich, 2006 ). This spike-based communication allows SNNs to model time-dependent and event-driven brain dynamics more effectively. Especially for neuroimaging, this biologically plausible computation offers a promising bridge between neuroscience and AI, making the way for interpretable and energy-efficient models ( Kasabov, 2019 ). Traditional deep learning models use continuous mathematical functions to represent neuron activations, whereas spiking neural networks transmit information through discrete spike events that occur over time. This difference gives SNNs a temporal dimension that is absent in most deep learning models. While CNNs and RNNs can provide efficiency in spatial or sequential pattern recognition, in contrast, SNNs capture both simultaneously, enabling effective modeling of dynamic brain processes ( Ghosh-Dastidar and Adeli, 2009 ; Kasabov et al., 2016 ). Moreover, SNNs have the potential for low-power and neuromorphic hardware implementation, making them especially suitable for real-time neuroimaging analysis ( Ghosh-Dastidar and Adeli, 2009 ). 2 Literature review methodology Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines are used for conducting this review ( Moher et al., 2009 ). The primary purpose of conducting this literature review is to analyze the trends and landscape of current advancements in deep learning models with SNN for multimodal neuroimaging data analysis. Multiple databases are used to extract articles for this study, including PubMed, IEEE Xplore, ScienceDirect, Scopus, and Nature. A few of the papers were added from other internet sources. The main keywords used are &#8220;Neuroimaging,&#8221; &#8220;Spiking Neural Networks,&#8221; and &#8220;Deep Learning,&#8221; refined with Boolean operators for accuracy. Ten years of studies are used to retrieve relevant data (ranging from 2015 to 2025 for thematic study) to ensure the inclusion of comprehensive coverage of the knowledge and up-to-date information, as fewer relevant studies have been found in recent years. Article selection followed PRISMA guidelines, with inclusion and exclusion determined through a three-phase process. In the identification section, all duplications are removed. During the screening phase, the title and abstract are used to identify articles that are irrelevant for exclusion and those that are relevant for inclusion. Afterward, the full text is used to extract the most relevant studies in this review. Full inclusion criteria and the list of keywords are provided in the Supplementary material . 3 Search results Firstly, for conducting this research, the query was executed on March 10, 2025, considering the three main topics mentioned in the above section to align the study&#8217;s objectives. As a result of the query, 440 papers were retrieved from multiple databases, along with three articles from other sources. The PRISMA flowchart in Figure 1 illustrates the exclusion criteria applied to articles searched in each phase. After applying the exclusion criteria to the selected dataset in each phase, only 21 articles were chosen for this literature review. FIGURE 1 Overview of the PRISMA flowchart for this research representing the complete process followed for selecting articles for this review paper for quantitative and qualitative analysis. Flowchart detailing the identification and screening process of studies via databases. Identification phase lists databases like Scopus, PubMed, ScienceDirect, IEEE Xplore, Nature, and others, totaling 440 records with 35 duplicates removed. Screening phase includes 405 records screened with 376 removed due to various out-of-scope reasons. Full text screening had 29 records with 8 removed. The included phase resulted in 21 studies for the literature review. 3.1 Quantitative analysis This section analyzes 21 selected articles categorized into three main perspectives quantitatively. Firstly, the study represents the annual publication trends focusing on tracking the progress of SNNs in healthcare. Secondly, research field analysis includes the articles&#8217; distribution across various study domains. Lastly, geographical publication trends highlight contributions from different parts of the world. 3.1.1 Annual publication trends: tracking progress in SNN adoption for healthcare The analysis of 21 selected publications highlights the evolving application of Spiking Neural Networks (SNNs) in neuroimaging over the past decade, as shown in Figure 2 . The citations of all 21 publications were collectively analyzed, as presented in Table 2 . FIGURE 2 Overview of the annual publication trend, X -axis shows the years whereas the Y -axis represents the total number of publications (present on the bars) each year from the selected studies. Bar chart showing the number of publications from 2015 to 2024. There are 2 publications in 2015 and 2017, 1 in 2018 to 2020, 4 in 2021, 1 in 2022, 5 in 2023, and 4 in 2024. TABLE 2 Chronological overview of citations of the selected studies. Years No. of publications Total citations Citations &#8804; 20 &gt;20 &amp; &#8804;50 citations &gt;50 &amp; &#8804;100 citations Average citations per year 2015 2 49 1 1 0 24.5 2017 2 100 0 1 1 50 2018 1 25 0 1 0 25 2019 1 12 1 0 0 12 2020 1 0 1 0 0 0 2021 4 128 2 2 0 32 2022 1 21 0 1 0 21 2023 5 49 4 1 0 8.17 2024 4 9 1 0 0 2.25 The bold values represent the average annual citations of the studies. States reveal that, from 2015 to 2017, this area of study was in the early exploration phase, as only two publications from the selected studies were available each year. Moreover, the trend shows the same results for 2018, 2019 and 2020, limiting studies to just one article per year from the chosen dataset. The reason for this decline could be methodological challenges. However, there was a noticeable rise in research in 2021 with four publications, suggesting increasing feasibility with advancements in deep learning. After a drop in 2022 to only one study (which could be due to the selected dataset), results showed a surge in 2023 in this research area, with five studies marking a significant shift toward SNN applications. The most probable reason for this growth could be the improvements in computational resources and model efficiency. However, the publication trend declined to four in the year 2024, still reflecting that this research area is reaching stability and reflecting the growing integration of SNNs in neuroimaging. Overall, the research has progressively grown from initial exploration to more practical implementation and refinement, which reflects a growing confidence in the field. 3.1.2 Research field analysis Based on classifications from the selected databases, the chosen articles are linked with 10 distinctive research fields, with some spanning multiple areas. In total, 40 connections have been established between the 21 publications and these research domains. As depicted in Figure 3 , many publications fall within &#8220;Computer Science&#8221; ( n = 14), followed by &#8220;Neuroscience&#8221; ( n = 8) and &#8220;Medicine&#8221; ( n = 6). FIGURE 3 The figure provides an overview of 10 distinctive research fields and number of publications in each subject, selected for this review. Bar chart showing the total number of publications across various research fields: Computer Science (14), Neuroscience (8), Engineering (6), Decision Sciences (3), Biochemistry, Genetics, and Molecular Biology (2), Chemistry (1), Immunology and Microbiology (1), Mathematics (1), Medicine (1), Multidisciplinary (1). From the perspective of the biomedical research field, a collective contribution is found to make it a multidisciplinary nature of studies, such as &#8220;Medicine&#8221; ( n = 6), &#8220;Biochemistry, Genetics, and Molecular Biology&#8221; ( n = 2), and &#8220;Immunology and Microbiology&#8221; ( n = 1). From an engineering and computational standpoint, &#8220;Computer Science&#8221; ( n = 15) and &#8220;Engineering&#8221; ( n = 3) reflect a major division of the associations. Additionally, research contributions span other diverse fields, including &#8220;Mathematics&#8221; ( n = 2), &#8220;Decision Sciences&#8221; ( n = 1), &#8220;Multidisciplinary&#8221; ( n = 1), and &#8220;Chemistry&#8221; ( n = 1), further highlighting the interdisciplinary scope of the selected publications. 3.1.3 Geographical publication trends In terms of geographical trend, each publication has been linked to the countries affiliated with its authors. The study of 21 selected publications reveals contributions from multiple countries. A single paper can be linked to one or multiple countries, as each publication might have multiple authors, and each author can be affiliated with more than one country. However, if a paper has multiple authors from the same country, we only consider it once to avoid duplication. At the point of analysis, 10 countries have contributed to at least one publication. Figure 4 below categorizes the publications into single-country papers and international collaboration papers, highlighting the involvement of different countries. FIGURE 4 An overview of publication trends by geography highlights both the number of publications and the countries where the authors are based. Map showing geographical publication trends with countries in different colors indicating publication counts. The United States and New Zealand are highlighted with four publications each. Other countries like China, India, and Russia have one publication each. China is the most frequent among the contributing countries, participating in 8 publications from the selected studies. Afterward, the highest contribution is found from the authors from New Zealand and India, each contributing to 4 publications. The United States has been involved in 3 publications. Regarding international collaboration, contributions were found in this area of research from the United Kingdom, Iran, Australia, and New Zealand. Other contributing countries include Malaysia, Russia, Ghana, Spain, Bangladesh, South Korea, and Italy, all of whom have participated in at least one publication. Below is the comparison between a country&#8217;s contributions vs. international collaboration: - Results of single-country publications: 10 out of 21 papers (49%) were found to have authors solely from one country. Results of international collaboration publications: 11 out of 21 papers (51%) involved authors from multiple countries, demonstrating a strong trend of global cooperation in this study area. China is the most active in single-country and collaborative research, as signified by its leadership in this field from the selected studies. New Zealand and the United Kingdom are heavily engaged in international collaborations, reflecting their strong global research attitude and commitment to cross-border partnerships. India and China are leading in solely conducted research, showcasing their independent research contributions and advancements in the field. Notably, the United States appears only in collaborative research in our selected dataset. It suggests that the US primarily participates in multinational research projects rather than independent studies. 3.2 Thematic analysis of selected studies This section provides a detailed insight into selected studies for the literature review. Neuroimaging, multimodal data analysis, utilization of spiking neural networks, and clinical applications are the focus of this review section. 3.2.1 Neuroimaging and multimodal data analysis Healthcare professionals have used multiple types of medical data, including biomedical data such as electroencephalography (EEG), electromyographic signal (EMG), electrocardiogram (ECG), ultrasound, X-rays, computed tomography and magnetic resonance imaging (MRI), for a long time to judge patients&#8217; diseases, diagnoses, and health conditions. Neuroimaging techniques are one of the various types for dealing with a wide range of conditions in the brain. MRI has recently been the most used technique, and it is said to be a vital technique for diagnosing brain tumors ( Ahmadi et al., 2021 ; Sam et al., 2023 ) because it can generate images without damaging brain tissues ( Dong et al., 2024 ). Furthermore, Kamal et al. (2023) used MRI to identify microbleeds in the brain, including the gene expression data, making it a multimodal analysis for determining the severity of Alzheimer&#8217;s disease. In addition to traditional imaging techniques, other non-invasive methods such as functional magnetic resonance imaging (fMRI), diffusion tensor imaging (DTI), and electroencephalography (EEG) have been used for brain data collection in the recent past. These techniques played a dynamic role in helping us understand the functional and structural characteristics of the human brain in a better way ( Sengupta et al., 2018 ). Capecci et al. (2015b) presented that EEG spatiotemporal data were used to study brain pathology and degeneration to analyze the functional changes in the brain activities of the controlled and Alzheimer&#8217;s disease (AD) groups. Furthermore, Kasabov N. K. et al. (2017) used fMRI in their research to develop a methodology using the NeuCube architecture of spiking neural network (SNN) for visualization, classification, and dynamic learning for spatiotemporal brain data. Guo et al. (2023) also applied fMRI like ( Kasabov N. K. et al., 2017 ) for their study based on a fMRI based SNN for verifying anti-damage capabilities under random attacks. In addition to the above-mentioned diseases, Sam et al. (2023) presented the use of EEG signal data for the quantitative assessment of depression levels by examining and categorizing EEG signals, and Francis and Al-Hababi (2023) utilized structural magnetic resonance images (sMRI) for early detection of suicidal ideation in youngsters and used depression as a biomarker in sMRI, respectively. Most studies used a single or a few modalities to analyze different areas. However, combining predictive modeling with multimodal brain data has great potential; research in this area is still in its early stages due to a lack of advanced methods. The major challenge in combining brain data into a single model captured from various modalities is that each modality uses different temporal and spatial characteristics. To address this, the recent advancement in Spiking neural network systems (SSNs) makes it possible to incorporate multidimensional data within a single model ( Sengupta et al., 2018 ). 3.2.2 Integration of deep learning models with SNNs for neuroimaging Spiking neural networks are one of the most reliable techniques that computer simulations and computational models use to study the brain, e.g., brain-inspired machine learning. These techniques can reveal and learn frequency, time, and space information usually hidden in spatiotemporal brain data (STBD) Capecci et al. (2015a) , Sengupta et al. (2018) presented an approach integrating multimodal information with a spiking neural network framework, creating a personalized SNNc-based architecture using the NeuCube. This experiment was run to represent the algorithm&#8217;s capabilities (oiSTDP) to capture discriminative join information from the data through its connection strengths. Utilizing this framework, the study showcases the integration of DTI and fMRI data of individuals who are beginning antipsychotic treatment to develop a personalized classifier for the prediction of treatment response in schizophrenia. Analysis with the SNNc network uncovered improved connectivity in the cerebellar region, which suggests that the captured activity of this area can be an aid as a potential biomarker that would help in treatment response in individuals with schizophrenia. Kamal et al. (2023) stated that machine learning techniques are practical for analyzing Alzheimer&#8217;s disease datasets. Machine learning techniques can predict the disease by detecting microbleeds in the brain. The study used MRI images and gene expression data, making it multimodal for identifying microbleeds using SNN and decision trees. Afterward, pixel density analysis (PDA) was used to locate microbleed areas in MRI images. PDA and probabilistic graphical model (PGM) were also used to explain and decide on the diagnosis of microbleeds, and the severity of AD. Figure 5 represents the framework used in this research for identifying cerebral microbleeds and Alzheimer&#8217;s using multimodal data. FIGURE 5 A framework to identify cerebral microbleeds and Alzheimer from multimodal data ( Kamal et al., 2023 ). Diagram illustrating a process flow with three main sections. &#8220;Input File Format&#8221; includes an Alzheimer MRI image and gene expression data. &#8220;Black Box&#8221; shows a spike neural network and a decision tree. &#8220;XAI Outcomes&#8221; presents pixel density analysis and a probabilistic graphical approach with feature nodes leading to a classification result. Furthermore, the study compared SNN with other state-of-the-art methods for performance evaluation using recall, accuracy, precision, and F-score. Table 3 below shows that SNN yielded the highest performance with 96.13%, 97.02%, 97.13%, and 96.84% for recall, accuracy, precision, and F-score, respectively. TABLE 3 Performance evaluation for SNN and CNN ( Kamal et al., 2023 ). Method Training Test PREC REC ACC F-score SNN 552 98 97.13 96.13 97.02 96.84 520 1300 96.23 94.33 97.12 95.14 487 163 95.19 96.23 96.82 96.04 455 195 94.03 95.03 95.62 95.14 CNN 552 98 91.53 93.43 94.61 94.05 520 130 91.47 92.45 92.24 92.46 487 163 91.19 94.39 92.53 93.24 455 195 92.73 91.03 91.92 91.47 Whereas Turkson et al. (2021) proposed a hybrid model, a spiking deep convolutional neural network architecture to classify MRI images to detect Alzheimer&#8217;s disease. Figure 6 shows the general architecture proposed in this study. The Alzheimer&#8217;s disease neuroimaging initiative (ADNI) dataset (450 scans) was used to perform three binary classification tasks (AD vs. NC, AD vs. MCI, and NC vs. MCI). The pre-processed images were used to extract AD key features using an unsupervised spiking neural network. The pre-trained spikes were then classified using a supervised deep convolutional neural network (CNN). The SNN was tested with two models, firstly with a model that was pre-trained with a spike, and secondly with a model without a pre-trained spike, and the results were more accurate with a pre-trained model for three binary classification tasks. The study stated that SNN improved performance, demonstrating the potential of spiking networks for reliable neuroimaging analysis. FIGURE 6 An overview of the proposed hybrid model, called the spiking deep convolutional neural network, is shown in the figure. It highlights three main modules: raw data input, preprocessing, and the spiking model ( Turkson et al., 2021 ). Flowchart depicting MRI processing for classification. Raw MRI images undergo skull stripping, white and gray matter differentiation, and segmentation. Preprocessed data are input into a Spiking CNN, including spike generation and deep CNN processing, resulting in classifications: Alzheimer&#8217;s Disease (AD), Mild Cognitive Impairment (MCI), or Cognitively Normal (CN). Moreover, Doborjeh et al. (2021) used longitudinal neuroimaging data to utilize the advancements in deep learning models through brain-inspired spiking neural networks (SNNs), which can model structural brain data across time and space. The study introduced a methodology and an SNN-based computational framework for developing personalized, predictive models from longitudinal brain data to detect, interpret, and predict changes in an individual&#8217;s functional brain state. The approach consists of several steps, such as clustering similar data, incorporating missing values, and training a 3D brain-template SNN for classifying and predicting outcomes and visualizing structural brain changes. All this information is then used to interpret results and identify predictive markers at both individual and group levels. As a result, the model successfully classified and predicted cognitive decline, for example, dementia and mild cognitive impairment (MCI), 2 years ahead with 91% and 95% accuracy. 3.2.3 Clinical applications Previous sections primarily focused on the types of modalities used by several researchers, along with the integration of machine learning models using SNN to analyze neuroimaging data ( Doborjeh et al., 2019 ; Saeedinia et al., 2021 ; Ghazali et al., 2020 ). Moreover, multiple studies highlight practical applications using neuroimaging and SNNs for several diseases, such as the detection of AD and the prediction of schizophrenia. However, neuroimaging, multimodal data analysis, and integration of deep learning with spiking neural networks are not only vital for AD but also for many other clinical areas, such as brain tumor classification ( Kalpana et al., 2024 ) or segmentation ( Ahmadi et al., 2021 ), suicide ideation assessment ( Francis and Al-Hababi, 2023 ), Depression identification ( Sam et al., 2023 ), Parkinson&#8217;s disease detection ( Das et al., 2024 ), and so on. Kalpana et al. (2024) proposed a hybrid model integrating SNNs with convolutional neural networks (CNNs) for brain tumor classification. As per the results, the model achieved a testing accuracy of 97.50 % and a training accuracy of 97.79% with a slight loss value of 0.38%. Also stated, these results present the model&#8217;s strength in capturing complex data in medical imaging, which is promising for clinical applications within the biomedical field. On the other hand, Ahmadi et al. (2021) utilized MRI for tumor area segmentation using a deep spiking neural network. The process for achieving the results consists of preprocessing and segmentation using DSNN. Table 4 shows the accuracy percentages compared in this study for the proposed method and previous approaches. TABLE 4 Performance evaluation for QAIS-DSNN and other methods ( Ahmadi et al., 2021 ). Accuracy (%) Method Reference 98.20% GCNN Mittal et al., 2019 95% 3D cascaded CNN-TTA Wang et al., 2019 88.50% MCCNN Hu et al., 2019 96.12% BAT-IT2FCM Alagarsamy et al., 2019 92% ADNN-PSO Sharif M. I. et al., 2020 98% PSO-LDA-GA-ANN Sharif M. et al., 2020 98.21% QAIS-DSNN Proposed approach ( Ahmadi et al., 2021 ) Furthermore, Francis and Al-Hababi (2023) also incorporated a hybrid version like Kalpana et al. (2024) . However, they combined an attention mechanism (AM) with SNN for suicide ideation assessment using sMRI of healthy controls and depressive individuals who did not show any suicide ideation (SI). The hybrid model completed the classification tasks using stratified 5-fold cross-validation and achieved a test accuracy of 94%, sensitivity of 100%, specificity of 92%, and an area under the curve (AUC) of 0.96. The proposed algorithm provides an objective tool that can support clinical assessments in identifying early signs of SI risk among depressed patients who are currently not showing any suicidal thoughts. Sam et al. (2023) performed a similar study to Francis and Al-Hababi (2023) by combining long short-term memory (LSTM) and SNN using EGG signals for depression identification. These models were used for the first time to analyze and categorize EEG signals according to the level of depression (minimum, mild, moderate, and severe). The model utilized spatial data mapping using SNN, leading to unsupervised learning and visualization of spiking patterns and unique perceptions about brain mechanisms. Comparative analysis of time-space brain data showed that SNN is more advantageous than other deep learning models. The study achieved higher accuracy in classifying samples from various groups and disclosed different patterns of brain activity, helping to understand the severity of depression. The findings in the study have the potential for early prediction and, thus, preventing depression by using the brain data acquired from different depression levels. The methodology used in this study showcases excellent potential for application in neuroimaging and clinical longitudinal data. Apart from the above-mentioned clinical applications, SNN and neuroimaging are also helpful for Parkinson&#8217;s disease (PD) detection, as presented by Das et al. (2024) . This study investigated the SEFRON (time-varying synaptic efficacy function based leaky integrate and fire neuron model) model and compared it with other previously used neural network models such as RBF, RNN, LSTM, and MLP. Results showed a higher accuracy for this model over others, making it reliable for clinical trials. Moreover, because of its performance, this model can help develop an automated PD detection device that physicians can utilize to diagnose PD in its early stages. However, this study has a limitation in that the sample size of the dataset used is small. Another study proposed by Gowsikraja et al. (2025) uses MRI for AD classification using a model named SBERO_Deep SNN (skill Al-Biruni Earth Radius Optimization-enabled Deep Spiking Neural Network), encompassing the benefits of SNN. Segmentation was performed using a hybrid algorithm using UNeXt, combining the Skill Optimization Algorithm (SOA) and the Al-Biruni Earth Radius (BER). In the next step, statistical features were extracted and classified using a Deep SNN trained with SBERO. The study achieved the highest accuracy rate compared to other AD classification techniques. It also states that the proposed methodology is reliable for AD identification, allowing timely intervention to slow the disease progression and improve patient quality of life. Table 5 represents the overview of selected studies below. TABLE 5 Overview of selected literature. References Models used Modalities Compared with Accuracy %/ performance Ahmadi et al., 2021 QAIS-DSNN MRI KNN, Genetic algorithm, SVM, SOM, CNN, GCNN, BAT-IT2FCM DSNN with 98.21 % Dong et al., 2024 ONSNPSamos MRI ABC, CMA-ES, SHADE, CSO, RMSProp, FROFI, DAOSNPS, ONSNPS, FCN8s, FCNs16, FCNs32, Unet, HybridUnet, NestedUnet Effective for a Single-area brain tumor Kamal et al., 2023 SNN MRI &amp; Gene expression CNN 97.02% Sengupta et al., 2018 SNN DTI &amp; fMRI Not applicable Effective Capecci et al., 2015b SNN EEG MLP, SVM, IECF, ECMC 100% Capecci et al., 2015a SNN (NeuCube) EEG MLR, SVM, MLP, ECM 86%, 79% Kasabov N. et al., 2017 SNN (NeuCube) fMRI SVM, MLP, ECF, ECMC, MLR 90%, 85%, 85% Guo et al., 2023 SNN fMRI SFSNN, SWSNN Outperformed Sam et al., 2023 SNN EEG CNN-TCN, CNN-LSTM, Deep CNN 98%: 96%, Eyes-Closed: Eyes-Open Francis and Al-Hababi, 2023 SNN sMRI CNN, SVM, FCNN 94% Turkson et al., 2021 Spiking deep convolutional neural network MRI SVM, CNN, random forest, KNN, NB 90.15% Doborjeh et al., 2021 SNN Longitudinal MRI Not applicable 95% &amp; 91% Doborjeh et al., 2019 Personalized SNN - d2WKNN EEG WWKNN, WKNN, KNN 80% to 93% Saeedinia et al., 2021 MRI-SNNr MRI, EEG Random walk, NeuCube Better prediction accuracy Murli et al., 2020 eSNN (NeuCube) fMRI SVM, MLP 85% Kalpana et al., 2024 Hybrid SCNN MRI Not applicable 97.50% Das et al., 2024 SEFRON (SNN-based) speech measurements RBF-NN, MLP-NN, RNN, LSTM 94% to 91.94% collected/acoustic features Kasabov N. et al., 2017 SNN (NeuCube) fMRI Not applicable Compatible Gowsikraja et al., 2025 Hybrid SBERO_Deep SNN MRI CNN+LSTM, Deep ensemble model, Hybrid DNN, TL, Deep SNN, SOA_Deep SNN, BER_Deep SNN 90.49% Zhu et al., 2022 DenseNet-based SNN MRI Restricted DenseNet, SNN, 98.46% &#177; 2.05% Dong et al., 2023 STPD-based SNN CIFAR10 random images MNIST, FashionMNIST 81.45% 4 Discussion This section provides a detailed discussion of principal findings, including neuroimaging and analysis of clinical features and use of SNN. The section also discusses this review&#8217;s challenges, gaps, future direction, and limitations. 4.1 Principal findings The primary findings of the literature review of the selected 21 studies expose a massive gap in defusing multiple modalities for developing a deep learning model using SNN for real-time clinical applications. Out of 21, only a few studies proposed the utilization of two or more modalities together for analysis. The rest of the studies focused on a single modality in their research. The literature review reveals a significant trend toward utilizing the benefits of neuroimaging data combined with deep learning models, specifically SNN, for understanding and diagnosing neurological disorders. Researchers are applying spiking neural networks with MRI, EEG, fMRI, and DTI for personalized and dynamic modeling of brain functionalities. A comparative analysis of the selected studies on SNNs shows that SNNs provide more accuracy than other previously used methods, such as traditional CNNs, in terms of precision, recall, and accuracy. Furthermore, conventional neural networks have a significant disadvantage of slower computational speed and higher energy consumption ( Xiaoxue et al., 2023 ). 4.2 Neuroimaging and clinical features Neuroimaging, including structural MRI (sMRI), fMRI, DTI, and EEG are important in understanding the clinical features of psychiatric and neurological disorders. All these modalities provide a detailed map of brain structure, activity, and function, which is helpful for clinicians and researchers in making more accurate diagnoses and guiding the right treatments. As per the selected studies, researchers emphasize the importance of neuroimaging in identifying biomarkers such as microbleeds, structural abnormalities, and functional connectivity changes. However, using multiple modalities can enhance the depth of clinical insights. Figure 7 represents the overview of clinical features from the selected studies. FIGURE 7 Overview of the clinical features from the selected studies, X -axis represents the clinical features, and Y -axis is used to display the number of times a clinical feature used in selected research articles. Bar chart showing the sum of occurrences for various clinical features. Cognitive dynamics, Alzheimer&#8217;s disease, brain functionality, and others each have a count of one. Brain tumor detection has a count of two, and brain lateralization is the highest with four. 4.3 Use of deep learning with SNN and neuroimaging Spiking Neural Networks (SNNs) are computational models consisting of spiking neurons, interconnections, and learning algorithms designed for processing data ( Izhikevich, 2006 ; Kasabov et al., 2016 ). Unlike traditional neural networks, SNNs capture spatial and temporal data as inputs. SNN incorporates not only neural synaptic states but also the concept of time within its computational framework. This computational framework makes SNNs a more biologically realistic approach for modeling spatiotemporal brain dynamics (STBD) ( Kasabov N. et al., 2017 ). Other than that, SNN techniques offer many benefits, including fast information processing and memory-based processing. It also supports frequency- and time-based data, allowing for post-training analysis and data interpretation ( Capecci et al., 2015b ). Spiking Neural Networks (SNNs), especially implemented as NeuCube, are gaining importance due to their ability to model spatiotemporal data more efficiently and naturally ( Kasabov, 2014 ). As aforementioned, SNNs process data in both space and time using discrete spike trains, offering an alternative that closely resembles neuronal communication in the brain, contrasting traditional artificial neural networks (ANNs) like MLPs or Transformers ( Ghosh-Dastidar and Adeli, 2009 ; Kasabov, 2014 ). NeuCube provides a structured framework for developing models that process spatiotemporal brain data (STBD). It mirrors how the brain encodes and learns information through spikes, using spatial mapping and brain-inspired learning rules. The model evolves over time, continuously learning and adapting to new patterns while maintaining a spatiotemporal memory that supports the analysis of cognitive functions. The overall architecture of NeuCube is illustrated in Figure 8 . FIGURE 8 A schematic diagram of a general NeuCube architecture, consisting of, input encoding module, SNN Cube, Output module, and gene regulatory module ( Kasabov, 2014 ). Diagram illustrating a neurogenetic brain cube (NBC) model. It shows input data as spatio/spectro-temporal chunks leading to classification and modeling through an NBC. The system connects to a gene regulatory network with probabilistic parameters. An output module categorizes data into classes, depicted in a chart. A graph displays output data trends over time. Furthermore, Kasabov et al. (2016) mentioned that the NeuCube can be used for the visualization of input features interactions at the group level as well as the individual level. It provides a more profound understanding of underlying data relationships and their impact on the individual risk of stroke. However, this review demonstrated that SNN is also being integrated with other models, such as CNNs and LSTMs, making it a hybrid model for more efficient spatiotemporal data modeling using neuroimaging. Turkson et al. (2021) , Kalpana et al. (2024) and Francis and Al-Hababi (2023) proposed a hybrid model integrating other models with SNNs using neuroimaging for the assessment of suicidal ideations, brain tumor classification, and detection of Alzheimer&#8217;s diseases, showcasing better results in terms of accuracy than other previously used deep learning models. Likewise, SNN-based frameworks such as NeuCube ( Kasabov, 2014 ) and other brain-inspired models make it easy to learn and utilize multiple modalities, improving accuracy even at a higher level. Capecci et al. (2015b) stated that the overall performance of NeuCube was considerably better in terms of highest precision and sensitivity than other compared classification methods, including multilayer perceptron (MLP), inductive evolving classification function (IECF) ( Kasabov, 2007 ), support vector machine (SVM), and evolving clustering method for classification (ECMC) ( Song and Kasabov, 2002 ). The literature review also uncovers the performance of SNNs in longitudinal studies and real-time prediction tasks, confirming their potential for future clinical applications. Furthermore, Kundu et al. (2024) presented the recent progress in SNN algorithms and their integration with sensor and memory technologies. It underscores how SNNs enable deployable AI systems that are energy-efficient, reliable, and well-suited for real-world tasks. 5 Conclusion, and future research directions As per the scope of this literature review, the aim was to incorporate neuroimaging data and SNN-based models. According to the available evidence suggests that SNN-based models may offer advantages over traditional neural networks when applied to neuroimaging data. Furthermore, these studies represent the integration of neuroimaging and deep learning models using SNN for analysis, classification, feature extraction, and diagnosis of diseases. Different types of modalities were utilized in these studies, including MRI, fMRI, DTI, and EEG. However, MRI-based modalities dominated either as a single modality or by defusing a few others. It is observed that there are only a few studies that use multimodality, either combining MRI with DTI or EEG, or with another type of data, such as gene expression. Multiple studies on Alzheimer&#8217;s disease use only a single modality. Furthermore, many studies use small or specific datasets, maybe due to the high computational power SNNs require for training. Furthermore, it is stated that the diffusion of modalities with different spatial and temporal resolutions remains a key barrier Sengupta et al. (2018) . While current SNN studies have mainly focused on sMRI, fMRI, or EEG, primarily using single-modality data for Alzheimer&#8217;s disease, the study by Li and Yap (2022) , which employs generative modeling, particularly for fMRI and DTI, offers a path toward mechanistic connectomes that extends beyond descriptive connectivity and explains how it captures the brain connectivity changes in response to tasks, stimuli, or internal states. The presented approach could have a significant impact on future SNN frameworks by providing better integration of multimodal data, thereby supporting improved prediction and classification accuracy. Hence, the review suggests that exploring multiple modalities like MRI, fMRI, DTI, and perfusing MRI defusing together to develop a deep learning model using SNN for better analyses and use of clinical features for disease diagnosis, prevention, and to provide treatment plans for slower progression. Improvement in methods for multimodal data fusion is required. Moreover, large and more diverse datasets should be utilized to increase the accuracy of the models. Additionally, integrating the above-mentioned modalities with PET images can provide a critical analysis of specific disease detection, such as Alzheimer&#8217;s disease, as PET imaging techniques are a popular and non-invasive technique used to capture brain tissue characteristics, as explained by Song et al. (2021) in their study, along with the ability to directly visualize AD-specific biomarkers. Furthermore, future studies can aim to develop a sophisticated AI partner for Alzheimer&#8217;s patients and their families or friends to help them with their diagnosis, treatment plans, reports, and daily queries. It will be helpful support for healthcare professionals in dealing with their patients. The AI model and agent should integrate all international guidelines relating to Alzheimer&#8217;s disease treatment plans and patient care. 5.1 Limitations Firstly, the literature review is conducted with a few limitations, including a narrow picture of current trends in this area, as it only considers papers in English that are published in conferences or journals. This review may not cover all relevant work due to inclusion/exclusion criteria. Secondly, the review was conducted using specific keywords and databases, because of which many relevant studies might be overlooked, as limited datasets can reduce external validations. Acknowledgments We would like to extend their sincere gratitude to everyone who gave guidance and assistance throughout this research. Special appreciation to family for their constant support and understanding. Edited by: Badong Chen , Xi&#8217;an Jiaotong University, China Reviewed by: Anirban Das , Intel, United States Eric Jacob Bacon , Northeastern University, China Author contributions AK: Writing &#8211; original draft, Writing &#8211; review &amp; editing. VS: Writing &#8211; review &amp; editing. JF: Writing &#8211; review &amp; editing. NK: Conceptualization, Supervision, Writing &#8211; review &amp; editing. AW: Supervision, Conceptualization, Funding acquisition, Writing &#8211; review &amp; editing, Resources. Conflict of interest The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest. Generative AI statement The author(s) declare that no Generative AI was used in the creation of this manuscript. Any alternative text (alt text) provided alongside figures in this article has been generated by Frontiers with the support of artificial intelligence and reasonable efforts have been made to ensure accuracy, including review by the authors wherever possible. If you identify any issues, please contact us. Publisher&#8217;s note All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher. Supplementary material The Supplementary Material for this article can be found online at: https://www.frontiersin.org/articles/10.3389/fnins.2025.1623497/full#supplementary-material References Ahmadi M. Sharifi A. Hassantabar S. Enayati S. ( 2021 ). QAIS-DSNN: Tumor area segmentation of MRI image with optimized quantum matched-filter technique and deep spiking neural network. BioMed Res. Int. 2021 : 6653879 . 10.1155/2021/6653879 33542920 PMC7843186 Alagarsamy S. Kamatchi K. Govindaraj V. Zhang Y. D. Thiyagarajan A. ( 2019 ). Multi-channeled MR brain image segmentation: A new automated approach combining BAT and clustering technique for better identification of heterogeneous tumors. Biocybernet. Biomed. Eng. 39 1005 &#8211; 1035 . 10.1016/j.bbe.2019.05.007 Calhoun V. D. Miller R. Pearlson G. Adal&#305; T. ( 2014 ). The chronnectome: Time-varying connectivity networks as the next frontier in fMRI data discovery. Neuron 84 262 &#8211; 274 . 10.1016/j.neuron.2014.10.015 25374354 PMC4372723 Capecci E. Kasabov N. Wang G. Y. ( 2015b ). Analysis of connectivity in NeuCube spiking neural network models trained on EEG data for the understanding of functional changes in the brain: A case study on opiate dependence treatment. Neural Netw. 68 62 &#8211; 77 . 10.1016/j.neunet.2015.03.009 26000776 Capecci E. Morabito F. C. Campolo M. Mammone N. Labate D. Kasabov N. ( 2015a ). &#8220; A feasibility study of using the neucube spiking neural network architecture for modelling alzheimer&#8217;s disease eeg data ,&#8221; in Advances in neural networks: Computational and theoretical issues , eds Bassis S. Esposito A. Morabito F. C. ( Cham : Springer International Publishing ), 159 &#8211; 172 . 10.1007/978-3-319-18164-6_16 Das P. Nanda S. Panda G. Dash S. Ksibi A. Alsenan S. ( 2024 ). A robust Parkinson&#8217;s disease detection model based on time-varying synaptic efficacy function in spiking neural network. BMC Neurol. 24 : 492 . 10.1186/s12883-024-04001-7 39734199 PMC11684134 Doborjeh M. Doborjeh Z. Merkin A. Bahrami H. Sumich A. Krishnamurthi R. ( 2021 ). Personalised predictive modelling with brain-inspired spiking neural networks of longitudinal MRI neuroimaging data and the case study of dementia. Neural Netw. 144 522 &#8211; 539 . 10.1016/j.neunet.2021.09.013 34619582 Doborjeh M. Kasabov N. Doborjeh Z. Enayatollahi R. Tu E. Gandomi A. H. ( 2019 ). Personalised modelling with spiking neural networks integrating temporal and static information. Neural Netw. 119 162 &#8211; 177 . 10.1016/j.neunet.2019.07.021 31446235 Dong J. Zhang G. Hu Y. Wu Y. Rong H. ( 2024 ). An optimization numerical spiking neural membrane system with adaptive multi-mutation operators for brain tumor segmentation. Int. J. Neural Syst. 34 : 2450036 . 10.1142/S0129065724500369 38686911 Dong Y. Zhao D. Li Y. Zeng Y. ( 2023 ). An unsupervised STDP-based spiking neural network inspired by biologically plausible learning rules and connections . Neural Netw. 165 , 799 &#8211; 808 . 10.1016/j.neunet.2023.06.019 37418862 Francis C. Al-Hababi A. Y. S. ( 2023 ). &#8220; Performance evaluation of attention mechanism and spiking neural networks on smri data for suicide ideation assessment ,&#8221; in Proceedings of the 2023 IEEE International Conference on Computing , ( Langkawi : IEEE ), 408 &#8211; 413 . 10.1109/ICOCO59262.2023.10397625 Ghazali R. Nawi N. M. Deris M. M. Abawajy J. H. ( 2020 ). &#8220; Recent advances on soft computing and data mining ,&#8221; in Proceedings of the 4th International Conference on Soft Computing and Data Mining (SCDM 2020), Melaka, Malaysia, January 22&#8211;23, 2020 , ( Cham : Springer International Publishing ), 10.1007/978-3-030-36056-6 Ghosh-Dastidar S. Adeli H. ( 2009 ). Spiking neural networks. Int. J. Neural Syst. 19 295 &#8211; 308 . 10.1142/S0129065709002002 19731402 Gowsikraja P. Geetha K. Rajan C. ( 2025 ). SBERO skill al-biruni earth radius optimization for Alzheimer&#8217;s disease classification using magnetic resonance image. NMR Biomed. 38 : e5323 . 10.1002/nbm.5323 39887547 Guo L. Liu C. Wu Y. Xu G. ( 2023 ). fMRI-based spiking neural network verified by anti-damage capabilities under random attacks. Chaos Solitons Fractals 176 : 114083 . 10.1016/j.chaos.2023.114083 Hu K. Gan Q. Zhang Y. Deng S. Xiao F. Huang W. ( 2019 ). Brain tumor segmentation using multi-cascaded convolutional neural networks and conditional random field. IEEE Access 7 92615 &#8211; 92629 . 10.1109/ACCESS.2019.2927433 Izhikevich E. M. ( 2006 ). Polychronization: Computation with spikes. Neural Comput. 18 245 &#8211; 282 . 10.1162/089976606775093882 16378515 Kalpana T. Meghana P. Spandana M. Kumar T. S. ( 2024 ). &#8220; Biologically inspired spiking CNN for brain tumor classification ,&#8221; in Proceedings of the 2024 5th International Conference on Image Processing and Capsule Networks (ICIPCN) , ( Nepal : IEEE ), 10.1109/ICIPCN63822.2024.00035 Kamal M. S. Chowdhury L. Nimmy S. F. Hasan Rafi T. H. Chae D. K. ( 2023 ). An interpretable framework for identifying cerebral microbleeds and Alzheimer&#8217;s disease severity using multimodal data. Annu. Int. Conf. IEEE Eng. Med. Biol. Soc. 2023 1 &#8211; 4 . 10.1109/EMBC40787.2023.10340088 38082672 Kasabov N. Scott N. M. Tu E. Marks S. Sengupta N. Capecci E. ( 2016 ). Evolving spatio-temporal data machines based on the NeuCube neuromorphic framework: Design methodology and selected applications. Neural Netw. 78 1 &#8211; 14 . 10.1016/j.neunet.2015.09.011 26576468 Kasabov N. Zhou L. Doborjeh M. G. Doborjeh Z. G. Yang J. ( 2017 ). New algorithms for encoding, learning and classification of fMRI data in a spiking neural network architecture: A case on modeling and understanding of dynamic cognitive processes. IEEE Trans. Cogn. Dev. Syst. 9 293 &#8211; 303 . 10.1109/TCDS.2016.2636291 Kasabov N. K. ( 2007 ). Evolving connectionist systems: The knowledge engineering approach , 2nd Edn . London : Springer . Kasabov N. K. ( 2014 ). NeuCube: A spiking neural network architecture for mapping, learning and understanding of spatio-temporal brain data. Neural Netw. 52 62 &#8211; 76 . 10.1016/j.neunet.2014.01.006 24508754 Kasabov N. K. ( 2019 ). Time-Space, spiking neural networks and brain-inspired artificial intelligence. Berlin : Springer . Kasabov N. K. Doborjeh M. G. Doborjeh Z. G. ( 2017 ). Mapping, learning, visualization, classification, and understanding of fMRI data in the neucube evolving spatiotemporal data machine of spiking neural networks. IEEE Trans. Neural Netw. Learn. Syst. 28 887 &#8211; 899 . 10.1109/TNNLS.2016.2612890 27723607 Kundu S. Zhu R. J. Jaiswal A. Beerel P. A. ( 2024 ). &#8220; Recent advances in scalable energy-efficient and trustworthy spiking neural networks: From algorithms to technology ,&#8221; in Proceedings of the ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) , ( Korea : IEEE ), 10.1109/ICASSP48485.2024.10445826 Li G. Yap P. T. ( 2022 ). From descriptive connectome to mechanistic connectome: Generative modeling in functional magnetic resonance imaging analysis. Front. Hum. Neurosci. 16 : 940842 . 10.3389/fnhum.2022.940842 36061504 PMC9428697 Mittal M. Goyal L. M. Kaur S. Kaur I. Verma A. Hemanth D. J. ( 2019 ). Deep learning based enhanced tumor segmentation approach for MR brain images. Appl. Soft Comp. 78 346 &#8211; 354 . 10.1016/j.asoc.2019.02.036 Moher D. Liberati A. Tetzlaff J. Altman D. G. ( 2009 ). Preferred reporting items for systematic reviews and meta-analyses: The PRISMA statement. PLoS Med. 6 : e1000097 . 10.1371/journal.pmed.1000097 19621072 PMC2707599 Murli N. Kasabov N. Paham N. A. ( 2020 ). &#8220;eSNN for Spatio-temporal fMRI brain pattern recognition with a graphical object recognition case study,&#8221; in Recent advances on soft computing and data mining. SCDM 2020. Advances in intelligent systems and computing , vol 978 , eds . Ghazali R. Nawi N. Deris M. Abawajy J. ( Cham : Springer ). 10.1007/978-3-030-36056-6_44 Pham D. L. Xu C. Prince J. L. ( 2000 ). Current methods in medical image segmentation. Annu. Rev. Biomed. Eng. 2 315 &#8211; 337 . 10.1146/annurev.bioeng.2.1.315 11701515 Plis S. M. Hjelm D. R. Salakhutdinov R. Allen E. A. Bockholt H. J. Long J. D. ( 2014 ). Deep learning for neuroimaging: A validation study. Front. Neurosci. 8 : 229 . 10.3389/fnins.2014.00229 25191215 PMC4138493 Saeedinia S. A. Jahed-Motlagh M. R. Tafakhori A. Kasabov N. ( 2021 ). Design of MRI structured spiking neural networks and learning algorithms for personalized modelling, analysis, and prediction of EEG signals. Sci. Rep. 11 : 12064 . 10.1038/s41598-021-90029-5 34103545 PMC8187669 Sam A. Boostani R. Hashempour S. Taghavi M. Sanei S. ( 2023 ). Depression identification using EEG signals via a hybrid of LSTM and spiking neural networks. IEEE Trans. Neural Syst. Rehabil. Eng. 31 4725 &#8211; 4737 . 10.1109/TNSRE.2023.3336467 37995160 Sengupta N. McNabb C. B. Kasabov N. Russell B. R. ( 2018 ). Integrating space, time, and orientation in spiking neural networks: A case study on multimodal brain data modeling. IEEE Trans. Neural Netw. Learn. Syst. 29 5249 &#8211; 5263 . 10.1109/TNNLS.2018.2796023 29994642 Sharif M. Amin J. Raza M. Yasmin M. Satapathy S. C. ( 2020 ). An integrated design of particle swarm optimization (PSO) with fusion of features for detection of brain tumor. Pattern Recogn. Lett. 129 150 &#8211; 157 . 10.1016/j.patrec.2019.11.017 Sharif M. I. Li J. P. Khan M. A. Saleem M. A. ( 2020 ). Active deep neural network features selection for segmentation and recognition of brain tumors using MRI images. Pattern Recogn. Lett. 129 181 &#8211; 189 . 10.1016/j.patrec.2019.11.019 Song J. Zheng J. Li P. Lu X. Zhu G. Shen P. ( 2021 ). An effective multimodal image fusion method using MRI and PET for Alzheimer&#8217;s disease diagnosis. Front. Digit. Health 3 : 637386 . 10.3389/fdgth.2021.637386 34713109 PMC8521941 Song Q. Kasabov N. ( 2002 ). ECM &#8212; a novel on-line, evolving clustering method and its applications. Tsuneki M. ( 2022 ). Deep learning models in medical image analysis. J. Oral Biosci. 64 312 &#8211; 320 . 10.1016/j.job.2022.03.003 35306172 Turkson R. E. Qu H. Mawuli C. B. Eghan M. J. ( 2021 ). Classification of Alzheimer&#8217;s disease using deep convolutional spiking neural network. Neural Process. Lett. 53 2649 &#8211; 2663 . 10.1007/s11063-021-10514-w Wang G. Li W. Ourselin S. Vercauteren T. ( 2019 ). &#8220; Automatic brain tumor segmentation using convolutional neural networks with test-time augmentation ,&#8221; in Brainlesion: Glioma, multiple sclerosis, stroke and traumatic brain injuries , eds Crimi A. ( Cham : Springer International Publishing ), 61 &#8211; 72 . 10.1007/978-3-030-11726-9_6 Xiaoxue L. Xiaofan Z. Xin Y. Dan L. He W. Bowen Z. ( 2023 ). Review of medical data analysis based on spiking neural networks. Proc. Comp. Sci. 221 1527 &#8211; 1538 . 10.1016/j.procs.2023.08.138 Yan W. Qu G. Hu W. Abrol A. Cai B. Qiao C. ( 2022 ). Deep learning in neuroimaging: Promises and challenges. IEEE Signal Process. Magazine 39 87 &#8211; 98 . 10.1109/MSP.2021.3128348 Yang R. Yu Y. ( 2021 ). Artificial convolutional neural network in object detection and semantic segmentation for medical imaging analysis. Front. Oncol. 11 : 638182 . 10.3389/fonc.2021.638182 33768000 PMC7986719 Zhu Z. Lu S. Wang S.-H. Gorriz J. M. Zhang Y.-D. ( 2022 ). DSNN: A DenseNet-based SNN for explainable brain disease classification . Front. Syst. Neurosci. 16 : 838822 . 10.3389/fnsys.2022.838822 35720439 PMC9204288"
}