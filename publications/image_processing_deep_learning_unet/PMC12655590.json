{
  "pmcid": "PMC12655590",
  "source": "PMC",
  "download_date": "2025-12-09T16:11:32.029449",
  "metadata": {
    "journal_title": "Plants",
    "journal_nlm_ta": "Plants (Basel)",
    "journal_iso_abbrev": "Plants (Basel)",
    "journal": "Plants",
    "pmcid": "PMC12655590",
    "pmid": "41304585",
    "doi": "10.3390/plants14223434",
    "title": "Depth Imaging-Based Framework for Efficient Phenotypic Recognition in Tomato Fruit",
    "year": "2025",
    "month": "11",
    "day": "10",
    "pub_date": {
      "year": "2025",
      "month": "11",
      "day": "10"
    },
    "authors": [
      "Li Junqing",
      "Dong Guoao",
      "Liu Yuhang",
      "Yuan Hua",
      "Xu Zheng",
      "Nie Wenfeng",
      "Zhang Yan",
      "Shi Qinghua"
    ],
    "abstract": "Tomato is a globally significant horticultural crop with substantial economic and nutritional value. High-precision phenotypic analysis of tomato fruit characteristics, enabled by computer vision and image-based phenotyping technologies, is essential for varietal selection and automated quality evaluation. An intelligent detection framework for phenomics analysis of tomato fruits was developed in this study, which combines image processing techniques with deep learning algorithms to automate the extraction and quantitative analysis of 12 phenotypic traits, including fruit morphology, structure, color and so on. First, a dataset of tomato fruit section images was developed using a depth camera. Second, the SegFormer model was improved by incorporating the MLLA linear attention mechanism, and a lightweight SegFormer-MLLA model for tomato fruit phenotype segmentation was proposed. Accurate segmentation of tomato fruit stem scars and locular structures was achieved, with significantly reduced computational cost by the proposed model. Finally, a Hybrid Depth Regression Model was designed to optimize the estimation of optimal depth. By fusing RGB and depth information, the framework enabled efficient detection of key phenotypic traits, including fruit longitudinal diameter, transverse diameter, mesocarp thickness, and depth and width of stem scar. Experimental results demonstrated a high correlation between the phenotypic parameters detected by the proposed model and the manually measured values, effectively validating the accuracy and feasibility of the model. Hence, we developed an equipment automatically phenotyping tomato fruits and the corresponding software system, providing reliable data support for precision tomato breeding and intelligent cultivation, as well as a reference methodology for phenotyping other fruit crops.",
    "keywords": [
      "tomato fruit phenotyping",
      "phenotypic recognition",
      "deep learning",
      "depth imaging",
      "phenotypic analysis"
    ]
  },
  "xml": "<?xml version=\"1.0\"  ?><!DOCTYPE pmc-articleset PUBLIC \"-//NLM//DTD ARTICLE SET 2.0//EN\" \"https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd\"><pmc-articleset><article xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:ali=\"http://www.niso.org/schemas/ali/1.0/\" xml:lang=\"en\" article-type=\"research-article\" dtd-version=\"1.4\"><processing-meta base-tagset=\"archiving\" mathml-version=\"3.0\" table-model=\"xhtml\" tagset-family=\"jats\"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type=\"nlm-ta\">Plants (Basel)</journal-id><journal-id journal-id-type=\"iso-abbrev\">Plants (Basel)</journal-id><journal-id journal-id-type=\"pmc-domain-id\">2909</journal-id><journal-id journal-id-type=\"pmc-domain\">plants</journal-id><journal-id journal-id-type=\"publisher-id\">plants</journal-id><journal-title-group><journal-title>Plants</journal-title></journal-title-group><issn pub-type=\"epub\">2223-7747</issn><publisher><publisher-name>Multidisciplinary Digital Publishing Institute  (MDPI)</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type=\"pmcid\">PMC12655590</article-id><article-id pub-id-type=\"pmcid-ver\">PMC12655590.1</article-id><article-id pub-id-type=\"pmcaid\">12655590</article-id><article-id pub-id-type=\"pmcaiid\">12655590</article-id><article-id pub-id-type=\"pmid\">41304585</article-id><article-id pub-id-type=\"doi\">10.3390/plants14223434</article-id><article-id pub-id-type=\"publisher-id\">plants-14-03434</article-id><article-version article-version-type=\"pmc-version\">1</article-version><article-categories><subj-group subj-group-type=\"heading\"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Depth Imaging-Based Framework for Efficient Phenotypic Recognition in Tomato Fruit</article-title></title-group><contrib-group><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Li</surname><given-names initials=\"J\">Junqing</given-names></name><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Conceptualization\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/conceptualization/\">Conceptualization</role><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Methodology\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/methodology/\">Methodology</role><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Formal analysis\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/formal analysis/\">Formal analysis</role><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Writing &#x2013; review &amp; editing\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/writing &#x2013; review &amp; editing/\">Writing &#8211; review &amp; editing</role><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Supervision\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/supervision/\">Supervision</role><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Project administration\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/project administration/\">Project administration</role><xref rid=\"af1-plants-14-03434\" ref-type=\"aff\">1</xref></contrib><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Dong</surname><given-names initials=\"G\">Guoao</given-names></name><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Conceptualization\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/conceptualization/\">Conceptualization</role><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Methodology\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/methodology/\">Methodology</role><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Software\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/software/\">Software</role><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Investigation\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/investigation/\">Investigation</role><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Data curation\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/data curation/\">Data curation</role><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Writing &#x2013; original draft\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/writing &#x2013; original draft/\">Writing &#8211; original draft</role><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Visualization\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/visualization/\">Visualization</role><xref rid=\"af1-plants-14-03434\" ref-type=\"aff\">1</xref></contrib><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Liu</surname><given-names initials=\"Y\">Yuhang</given-names></name><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Data curation\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/data curation/\">Data curation</role><xref rid=\"af2-plants-14-03434\" ref-type=\"aff\">2</xref></contrib><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Yuan</surname><given-names initials=\"H\">Hua</given-names></name><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Validation\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/validation/\">Validation</role><xref rid=\"af1-plants-14-03434\" ref-type=\"aff\">1</xref></contrib><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Xu</surname><given-names initials=\"Z\">Zheng</given-names></name><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Validation\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/validation/\">Validation</role><xref rid=\"af1-plants-14-03434\" ref-type=\"aff\">1</xref></contrib><contrib contrib-type=\"author\"><contrib-id contrib-id-type=\"orcid\" authenticated=\"true\">https://orcid.org/0000-0002-8494-1742</contrib-id><name name-style=\"western\"><surname>Nie</surname><given-names initials=\"W\">Wenfeng</given-names></name><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Resources\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/resources/\">Resources</role><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Writing &#x2013; review &amp; editing\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/writing &#x2013; review &amp; editing/\">Writing &#8211; review &amp; editing</role><xref rid=\"af2-plants-14-03434\" ref-type=\"aff\">2</xref></contrib><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Zhang</surname><given-names initials=\"Y\">Yan</given-names></name><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Formal analysis\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/formal analysis/\">Formal analysis</role><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Resources\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/resources/\">Resources</role><xref rid=\"af2-plants-14-03434\" ref-type=\"aff\">2</xref></contrib><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Shi</surname><given-names initials=\"Q\">Qinghua</given-names></name><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Formal analysis\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/formal analysis/\">Formal analysis</role><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Resources\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/resources/\">Resources</role><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Writing &#x2013; review &amp; editing\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/writing &#x2013; review &amp; editing/\">Writing &#8211; review &amp; editing</role><role vocab=\"credit\" vocab-identifier=\"https://credit.niso.org/\" vocab-term=\"Funding acquisition\" vocab-term-identifier=\"https://credit.niso.org/contributor-roles/funding acquisition/\">Funding acquisition</role><xref rid=\"af2-plants-14-03434\" ref-type=\"aff\">2</xref><xref rid=\"c1-plants-14-03434\" ref-type=\"corresp\">*</xref></contrib></contrib-group><contrib-group><contrib contrib-type=\"editor\"><name name-style=\"western\"><surname>Martellos</surname><given-names initials=\"S\">Stefano</given-names></name><role>Academic Editor</role></contrib></contrib-group><aff id=\"af1-plants-14-03434\"><label>1</label>College of Information Science and Engineering, Shandong Agricultural University, Tai&#8217;an 271018, China; <email>junqing.li@sdau.edu.cn</email> (J.L.); <email>d_guoao@163.com</email> (G.D.); <email>17661290553@163.com</email> (H.Y.); <email>xbzz101800@163.com</email> (Z.X.)</aff><aff id=\"af2-plants-14-03434\"><label>2</label>College of Horticulture Science and Engineering, Shandong Agricultural University, Tai&#8217;an 271018, China; <email>13210693446@163.com</email> (Y.L.); <email>nwf2024@sdau.edu.cn</email> (W.N.); <email>zhangyan2022@sdau.edu.cn</email> (Y.Z.)</aff><author-notes><corresp id=\"c1-plants-14-03434\"><label>*</label>Correspondence: <email>qhshi@sdau.edu.cn</email></corresp></author-notes><pub-date pub-type=\"epub\"><day>10</day><month>11</month><year>2025</year></pub-date><pub-date pub-type=\"collection\"><month>11</month><year>2025</year></pub-date><volume>14</volume><issue>22</issue><issue-id pub-id-type=\"pmc-issue-id\">501331</issue-id><elocation-id>3434</elocation-id><history><date date-type=\"received\"><day>04</day><month>10</month><year>2025</year></date><date date-type=\"rev-recd\"><day>03</day><month>11</month><year>2025</year></date><date date-type=\"accepted\"><day>06</day><month>11</month><year>2025</year></date></history><pub-history><event event-type=\"pmc-release\"><date><day>10</day><month>11</month><year>2025</year></date></event><event event-type=\"pmc-live\"><date><day>27</day><month>11</month><year>2025</year></date></event><event event-type=\"pmc-last-change\"><date iso-8601-date=\"2025-11-28 09:25:12.970\"><day>28</day><month>11</month><year>2025</year></date></event></pub-history><permissions><copyright-statement>&#169; 2025 by the authors.</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref specific-use=\"textmining\" content-type=\"ccbylicense\">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (<ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://creativecommons.org/licenses/by/4.0/\">https://creativecommons.org/licenses/by/4.0/</ext-link>).</license-p></license></permissions><self-uri xmlns:xlink=\"http://www.w3.org/1999/xlink\" content-type=\"pmc-pdf\" xlink:href=\"plants-14-03434.pdf\"/><abstract><p>Tomato is a globally significant horticultural crop with substantial economic and nutritional value. High-precision phenotypic analysis of tomato fruit characteristics, enabled by computer vision and image-based phenotyping technologies, is essential for varietal selection and automated quality evaluation. An intelligent detection framework for phenomics analysis of tomato fruits was developed in this study, which combines image processing techniques with deep learning algorithms to automate the extraction and quantitative analysis of 12 phenotypic traits, including fruit morphology, structure, color and so on. First, a dataset of tomato fruit section images was developed using a depth camera. Second, the SegFormer model was improved by incorporating the MLLA linear attention mechanism, and a lightweight SegFormer-MLLA model for tomato fruit phenotype segmentation was proposed. Accurate segmentation of tomato fruit stem scars and locular structures was achieved, with significantly reduced computational cost by the proposed model. Finally, a Hybrid Depth Regression Model was designed to optimize the estimation of optimal depth. By fusing RGB and depth information, the framework enabled efficient detection of key phenotypic traits, including fruit longitudinal diameter, transverse diameter, mesocarp thickness, and depth and width of stem scar. Experimental results demonstrated a high correlation between the phenotypic parameters detected by the proposed model and the manually measured values, effectively validating the accuracy and feasibility of the model. Hence, we developed an equipment automatically phenotyping tomato fruits and the corresponding software system, providing reliable data support for precision tomato breeding and intelligent cultivation, as well as a reference methodology for phenotyping other fruit crops.</p></abstract><kwd-group><kwd>tomato fruit phenotyping</kwd><kwd>phenotypic recognition</kwd><kwd>deep learning</kwd><kwd>depth imaging</kwd><kwd>phenotypic analysis</kwd></kwd-group><funding-group><award-group><funding-source>Shandong Vegetable Research System</funding-source><award-id>SDAIT-05</award-id></award-group><award-group><funding-source>Key Research and Development Program of Shandong Province</funding-source><award-id>2022TZXD0025</award-id></award-group><funding-statement>This work was supported by the Shandong Vegetable Research System (SDAIT-05), and the Key Research and Development Program of Shandong Province (2022TZXD0025).</funding-statement></funding-group><custom-meta-group><custom-meta><meta-name>pmc-status-qastatus</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>pmc-status-live</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-status-embargo</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-status-released</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-open-access</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-olf</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-manuscript</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-legally-suppressed</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-pdf</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-supplement</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-pdf-only</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-suppress-copyright</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-real-version</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-scanned-article</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-preprint</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-in-epmc</meta-name><meta-value>yes</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec sec-type=\"intro\" id=\"sec1-plants-14-03434\"><title>1. Introduction</title><p>Tomato (<italic toggle=\"yes\">Solanum lycopersicum</italic> L.) is a globally significant horticultural crop with high economic and nutritional value, containing functional substances, such as vitamin C and lycopene [<xref rid=\"B1-plants-14-03434\" ref-type=\"bibr\">1</xref>,<xref rid=\"B2-plants-14-03434\" ref-type=\"bibr\">2</xref>]. Modern cultivated tomatoes originated from the red-fruited wild species (<italic toggle=\"yes\">Solanum pimpinellifolium</italic>) through domestication and selection for traits such as fruit size and sugar accumulation [<xref rid=\"B3-plants-14-03434\" ref-type=\"bibr\">3</xref>]. In recent years, advances in breeding technologies have resulted in a diversification of tomato varieties, significantly enriching the available germplasm resources [<xref rid=\"B4-plants-14-03434\" ref-type=\"bibr\">4</xref>,<xref rid=\"B5-plants-14-03434\" ref-type=\"bibr\">5</xref>]. Phenotypic characteristics of tomato fruits, including shape, color and texture, directly influence their commercial grading, mechanized harvesting, and post-harvest quality [<xref rid=\"B6-plants-14-03434\" ref-type=\"bibr\">6</xref>]. For instance, traditional soft-textured tomato varieties are unsuitable for mechanical harvesting, prompting breeding efforts toward firmer textures [<xref rid=\"B7-plants-14-03434\" ref-type=\"bibr\">7</xref>]. The locular gel (a gelatinous tissue within fruit locules) in tomato fruits constitutes the second most abundant tissue after the pericarp, accounting for approximately 23% of the fruit&#8217;s fresh weight [<xref rid=\"B8-plants-14-03434\" ref-type=\"bibr\">8</xref>]. Research has demonstrated that the size and number of locules affect fruit weight, shape, and texture, and to some extent influence flavor and mouthfeel [<xref rid=\"B9-plants-14-03434\" ref-type=\"bibr\">9</xref>,<xref rid=\"B10-plants-14-03434\" ref-type=\"bibr\">10</xref>]. In tomato breeding, traits such as locule number, mesocarp thickness, transverse and longitudinal diameters, fruit shape index, and color are emphasized by breeders. Additionally, the depth and width of the stem scar in the fruit are identified as important factors affecting the appearance and commercial value of tomatoes.</p><p>Underlying genetic regulatory mechanisms of tomato fruit traits, including size, shape, color, taste and nutritional content, have emerged as key research foci in plant science [<xref rid=\"B11-plants-14-03434\" ref-type=\"bibr\">11</xref>,<xref rid=\"B12-plants-14-03434\" ref-type=\"bibr\">12</xref>,<xref rid=\"B13-plants-14-03434\" ref-type=\"bibr\">13</xref>,<xref rid=\"B14-plants-14-03434\" ref-type=\"bibr\">14</xref>]. Modern tomato breeding strategies have transitioned from phenotypic selection to integrated genotype-phenotype prediction [<xref rid=\"B15-plants-14-03434\" ref-type=\"bibr\">15</xref>]. This shift has made the acquisition of high-throughput phenomics data a critical step in tomato breeding. Current phenotyping relies heavily on manual measurements, which are subjective, inefficient, and unscalable for high-throughput breeding. Through in-depth studies, researchers have achieved significant breakthroughs in understanding the genetic basis and regulatory mechanisms of tomato development [<xref rid=\"B16-plants-14-03434\" ref-type=\"bibr\">16</xref>,<xref rid=\"B17-plants-14-03434\" ref-type=\"bibr\">17</xref>,<xref rid=\"B18-plants-14-03434\" ref-type=\"bibr\">18</xref>]. However, the morphological diversity of tomato fruits, such as locule number ranging from 3 to 10, and their developmental dynamics pose substantial challenges. In this context, the development of high-precision and rapid techniques for identifying and measuring tomato fruit phenotypes is essential for the quantitative analysis of fruit traits. Such techniques also provide high-frequency dynamic phenomics inputs for genomic selection models, which are significant for enhancing the efficiency of tomato fruit improvement and establishing robust fruit evaluation models.</p><p>In recent years, innovations in artificial intelligence technology have injected strong momentum into crop phenomics. Notably, the integration of computer vision and deep learning has significantly enhanced the automated parsing capabilities of phenotypic parameters [<xref rid=\"B19-plants-14-03434\" ref-type=\"bibr\">19</xref>,<xref rid=\"B20-plants-14-03434\" ref-type=\"bibr\">20</xref>,<xref rid=\"B21-plants-14-03434\" ref-type=\"bibr\">21</xref>], providing technical support for efficient breeding decisions. In the field of fruit detection, Zhang et al. [<xref rid=\"B22-plants-14-03434\" ref-type=\"bibr\">22</xref>] proposed a lightweight fruit-detection algorithm using Light-CSPNet as the backbone network. By incorporating improved feature extraction modules, downsampling methods, and feature fusion modules, they achieved real-time detection of tomato fruits on edge devices while maintaining detection accuracy. For the task of winter jujube detection, Yu et al. [<xref rid=\"B23-plants-14-03434\" ref-type=\"bibr\">23</xref>] introduced an MLG-YOLO model based on YOLOv8n, which achieves three-dimensional localization of winter jujubes by integrating an RGB-D camera. In the field of maturity assessment, Wan et al. [<xref rid=\"B24-plants-14-03434\" ref-type=\"bibr\">24</xref>] combined characteristic color values with backpropagation Neural Network (BPNN) technology to detect the maturity of commercially available tomatoes. They constructed a quantitative model for tomato fruit maturity based on threshold segmentation and concentric sub-region division strategies. In the field of commercial grading, Ireri et al. [<xref rid=\"B25-plants-14-03434\" ref-type=\"bibr\">25</xref>] proposed a machine vision system for tomato grading based on RGB images, which accurately identified abnormalities in calyx morphology and fruit scars. In the field of crop disease diagnosis, Deng et al. [<xref rid=\"B26-plants-14-03434\" ref-type=\"bibr\">26</xref>] proposed an image-based method for segmenting tomato leaf diseases, MC-UNet, which employs a multi-scale convolution module to capture multi-scale information of tomato diseases. By utilizing a cross-layer attention fusion mechanism with gating structures and fusion operations, they effectively improved the boundary consistency of leaf spot segmentation. Kang et al. [<xref rid=\"B27-plants-14-03434\" ref-type=\"bibr\">27</xref>] improved the deep learning network YOLO-TGI by integrating Ghost and CBAM modules to assess the health status of tomato leaves and simultaneously count tomatoes in video streams. These technologies collectively demonstrate the technical feasibility of automated extraction of fruit phenotypes.</p><p>The key to accurate extraction of fruit phenotypic characteristics is the precise assessment and quantification of multidimensional data such as the transverse diameter, longitudinal diameter, and color of the fruit [<xref rid=\"B28-plants-14-03434\" ref-type=\"bibr\">28</xref>]. Zhu et al. [<xref rid=\"B29-plants-14-03434\" ref-type=\"bibr\">29</xref>] proposed an automatic detection method for tomato fruit phenotypes based on image recognition, using the Mask R-CNN model to train and test the structural indicators of tomato fruit locules. They extracted the color, transverse and longitudinal diameters, top and navel angles, locule number, and pericarp thickness of tomato fruits, achieving automated measurement of multiple phenotypic parameters. Xu et al. [<xref rid=\"B30-plants-14-03434\" ref-type=\"bibr\">30</xref>] successfully extracted 11 phenotypic traits, such as melon size, pedicel, and color, by constructing a deep learning algorithm framework, and R<sup>2</sup> values were above 0.94 for fruit transverse diameter and 0.698 for fruit longitudinal diameter. Xue et al. [<xref rid=\"B31-plants-14-03434\" ref-type=\"bibr\">31</xref>] proposed a cucumber fruit morphological trait recognition framework and software called CucumberAI, which integrates deep learning algorithms and can effectively identify 51 cucumber features, and achieved R<sup>2</sup> values greater than 0.9 for fruit diameter, neck length, and fruit length. These phenotype extraction methods, based on image recognition and deep learning, provide new technical approaches for the precise analysis of fruit phenotypic traits.</p><p>When obtaining the size of tomato fruits, traditional methods often rely on introducing a reference object in the image and inferring the actual size of the fruit by comparing the size ratio of the fruit to the reference object in the image. However, this method has significant limitations: to ensure measurement accuracy, the reference object and the fruit should ideally be on the same plane. Considering that tomato fruits vary in size and grow in different positions, it is difficult to ensure that all fruits and the reference object are on the same plane, thus easily introducing measurement errors. With the rapid advancement of perceptual imaging technology and the widespread adoption of consumer-grade RGB-D cameras, real-time depth estimation combined with RGB imaging can be achieved at low cost. This significantly enhances remote non-contact sensing capabilities, continuously improves measurement accuracy, and greatly boosts environmental adaptability. These devices mostly use the time-of-flight (TOF) principle for ranging, which not only provides 2D information of the target object but also the depth value of each pixel in the image, providing rich data information for the study of crop morphological characteristics [<xref rid=\"B32-plants-14-03434\" ref-type=\"bibr\">32</xref>,<xref rid=\"B33-plants-14-03434\" ref-type=\"bibr\">33</xref>,<xref rid=\"B34-plants-14-03434\" ref-type=\"bibr\">34</xref>]. Due to their convenience and practicality, RGB-D cameras are increasingly recognized by researchers and agricultural practitioners, and are gradually becoming important tools for detecting and extracting crop morphological characteristics.</p><p>For high-throughput automatic phenotypic analysis of tomato fruit traits, in this study, a more comprehensive and efficient intelligent phenotyping framework was developed. The contributions are summarized as follows:<list list-type=\"order\"><list-item><p>The framework analyzes 12 phenotypic traits, including fruit transverse and longitudinal diameters, shape index, stem scar structure in the fruit, as well as stem scar depth and width, locule structure, locule number, locule area, mesocarp thickness, mesocarp color, and locule color.</p></list-item><list-item><p>Based on the SegFormer architecture [<xref rid=\"B35-plants-14-03434\" ref-type=\"bibr\">35</xref>], the MLLA linear attention mechanism was introduced to develop a SegFormer-MLLA model for tomato fruit phenotypic traits segmentation [<xref rid=\"B36-plants-14-03434\" ref-type=\"bibr\">36</xref>]. This model enhances computational efficiency while maintaining high segmentation accuracy, enabling precise segmentation of the locule and stem scar structures in tomato fruits.</p></list-item><list-item><p>By integrating depth information, the dimensions of tomato fruit traits were measured. To address depth information errors caused by optical interference, such as specular reflections, a Hybrid Depth Regression Model (HDRM) was designed. This model captures the optimal depth distance of the tomato fruit images through modeling parameter errors, calculating residuals, and applying random forest-based residual correction.</p></list-item><list-item><p>We designed an intelligent detection system for tomato fruit phenomics analysis, which integrates both software and hardware components. During the detection process, each sample was assigned a corresponding label to establish a mapping with its phenotypic data, enabling efficient and accurate detection and data storage of tomato fruit phenotypic traits.</p></list-item></list></p></sec><sec id=\"sec2-plants-14-03434\"><title>2. Materials and Methods</title><sec id=\"sec2dot1-plants-14-03434\"><title>2.1. Image Acquisition</title><p>Tomato fruit samples used in this study were collected from Shandong Agricultural University Science and Technology Innovation Park (36.163&#176; N, 117.165&#176; E) and Taian Hengchang Ecological Agriculture Company (36.221&#176; N, 116.864&#176; E). The tomato varieties used in this study were previously collected materials in our laboratory. A total of 322 mature tomato fruits, representing multiple varieties and colors, were randomly selected. For longitudinal sections, the fruits were cut along the central axis passing through the stem scar. For transverse sections, the fruits were cut through the fruit center. The resulting sections were placed on a uniform white background, and high-resolution images of both longitudinal and transverse sections were captured using an Azure Kinect 3.0 depth camera under consistent illumination conditions. The depth camera was fixed using a top-view bracket, and images were captured at a resolution of 3840 &#215; 2160 pixels. Some examples of the tomato fruit images are shown in <xref rid=\"plants-14-03434-f001\" ref-type=\"fig\">Figure 1</xref>, illustrating detailed features of the stem scar and locules. Specifically, considerable variation was observed in the tomato for the number of locules (2&#8211;10 per fruit), along with the stem scar, and the shape and size of the locules.</p></sec><sec id=\"sec2dot2-plants-14-03434\"><title>2.2. Image Preprocessing</title><p>To eliminate background noise interference in the tomato section images and unify the data scale, an image preprocessing workflow was designed, which consists of four main modules: binarization, image cropping, data annotation, and data partitioning.</p><list list-type=\"order\"><list-item><p>Binarization module</p></list-item></list><p>The binarization process is shown in <xref rid=\"plants-14-03434-f002\" ref-type=\"fig\">Figure 2</xref>a. Tomato fruits were extracted based on the HSV color space, and noise interference was reduced using closing and opening operations to enhance image quality. Due to color differences in tomatoes and interference from the stem scar color domain, the extracted tomatoes exhibited some pixel loss. To address this issue, Canny edge detection [<xref rid=\"B37-plants-14-03434\" ref-type=\"bibr\">37</xref>] combined with contour extraction was employed to identify the edges of the tomato fruits. After removing noise through opening operations and multiple rounds of erosion, the image binarization process was completed.</p><list list-type=\"simple\"><list-item><label>2.</label><p>Image cropping module</p></list-item></list><p>The image cropping process is illustrated in <xref rid=\"plants-14-03434-f002\" ref-type=\"fig\">Figure 2</xref>b. To ensure consistency in the size of tomato section images and to meet the requirements for model training, all image samples were cropped and resized to 512 &#215; 512 pixels, resulting in individual tomato fruit section images.</p><list list-type=\"simple\"><list-item><label>3.</label><p>Data annotation module</p></list-item></list><p>The LabelMe tool was employed to annotate longitudinal and transverse sections of tomato fruits with distinct strategies: longitudinal sections were annotated along the stem scar contour, while transverse sections were marked along locule contours, including irregular locule structures. Annotated data were then converted into JSON files and formatted for model training.</p><list list-type=\"simple\"><list-item><label>4.</label><p>Data partitioning module</p></list-item></list><p>For the purpose of model training and validation, the dataset was randomly split into training, validation, and test subsets in a 7:2:1 ratio. To prevent potential data leakage, the training, validation, and test datasets were stored in separate directories. For data augmentation, the training set was subjected to a combination of cropping, scaling, rotation, and brightness adjustment to enhance sample diversity, while the validation and test sets retained only cropping, scaling, and rotation to preserve the original data characteristics. After data augmentation, a total of 8392 tomato section images were obtained.</p></sec><sec id=\"sec2dot3-plants-14-03434\"><title>2.3. SegFormer-MLLA Model</title><p>SegFormer [<xref rid=\"B35-plants-14-03434\" ref-type=\"bibr\">35</xref>] is a semantic segmentation model based on Transformer [<xref rid=\"B38-plants-14-03434\" ref-type=\"bibr\">38</xref>], consisting of an encoder and a decoder. The encoder is constructed with four layers of transformer blocks, each stage employing downsampling rates of 4, 8, 16, and 32, respectively, to progressively extract multi-scale features. Each transformer block includes an efficient self-attention module, a Mix-FFN (mixed feed-forward network) module, and an overlapped patch merging module to efficiently capture both global and local features. The four feature maps of different resolutions from the encoder layers are fused in the decoder after passing through an MLP layer, and then the prediction mask is obtained after another MLP. Unlike traditional segmentation models with complex decoder architectures, SegFormer utilizes a lightweight all-MLP decoder, effectively reducing computational overhead and simplifying parameter tuning.</p><p>The standard self-attention mechanism based on the Transformer architecture has a quadratic computational complexity of O(<italic toggle=\"yes\">N</italic><sup>2</sup>), which poses bottlenecks in terms of computational resources and memory usage. SegFormer employs a hierarchically structured Transformer encoder architecture combined with efficient sequence reduction techniques, lowering the time complexity from O(<italic toggle=\"yes\">N</italic><sup>2</sup>) to O(<italic toggle=\"yes\">N</italic><sup>2</sup>/<italic toggle=\"yes\">R</italic>). Nevertheless, as its core is still based on an inherently quadratic-complexity attention mechanism, the overall optimization is limited. Early linear attention mechanisms replaced the nonlinear Softmax function with linear normalization, reducing the computational complexity to O(<italic toggle=\"yes\">N</italic>). However, due to limitations in feature representation capability, their actual performance still lags behind traditional attention mechanisms. Recently, the Mamba architecture based on state space models (SSMs) has achieved significant development in the field of image segmentation [<xref rid=\"B39-plants-14-03434\" ref-type=\"bibr\">39</xref>,<xref rid=\"B40-plants-14-03434\" ref-type=\"bibr\">40</xref>,<xref rid=\"B41-plants-14-03434\" ref-type=\"bibr\">41</xref>], as it maintains linear computational complexity while establishing long-range dependencies. MLLA [<xref rid=\"B36-plants-14-03434\" ref-type=\"bibr\">36</xref>] combines the selective mechanism of Mamba with the advantages of linear attention, achieving parallel processing efficiency for attention and adaptive feature selection capability of SSM, thereby enabling efficient image processing with O(<italic toggle=\"yes\">N</italic>) complexity. MLLA Attention employs RoPE positional encoding [<xref rid=\"B42-plants-14-03434\" ref-type=\"bibr\">42</xref>] instead of a forget gate, providing necessary positional information while maintaining parallel computation and fast inference speed, thereby overcoming the limitations of recursive computation. By combining LePE positional encoding [<xref rid=\"B43-plants-14-03434\" ref-type=\"bibr\">43</xref>] with RoPE positional encoding, it can flexibly handle features at different scales.</p><p>To achieve efficient and precise segmentation of tomato fruit stem scar and locule structures, we proposed the SegFormer-MLLA model for tomato fruit phenotyping, which optimizes the encoder layer based on SegFormer and introduces the MLLA linear attention mechanism. The overall architecture of SegFormer-MLLA is shown in <xref rid=\"plants-14-03434-f003\" ref-type=\"fig\">Figure 3</xref>a. To enhance the generalization ability of MLLA, a linear projection layer (<italic toggle=\"yes\">Proj</italic>) is used to map features to a unified embedding dimension, thereby improving feature representation, and dropout is combined for regularization to reduce the risk of overfitting.</p><p>The MLLA Attention module, which is the key feature extraction component of the model, has an overall architecture as shown in <xref rid=\"plants-14-03434-f003\" ref-type=\"fig\">Figure 3</xref>b and aims to capture long-range and local dependencies in images with linear complexity. The projections of the query (<italic toggle=\"yes\">Q</italic>), key (<italic toggle=\"yes\">K</italic>), and value (<italic toggle=\"yes\">V</italic>) vectors are processed through activation functions and then realized via linear transformations. The formula for calculating the attention output of MLLA Attention is given in Equations (1) and (2):\n<disp-formula id=\"FD1-plants-14-03434\"><label>(1)</label><mml:math id=\"mm1\" display=\"block\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:mi>Q</mml:mi><mml:mo>=</mml:mo><mml:mi>&#981;</mml:mi><mml:mo stretchy=\"false\">(</mml:mo><mml:mi>x</mml:mi><mml:msub><mml:mi>W</mml:mi><mml:mi>Q</mml:mi></mml:msub><mml:mo stretchy=\"false\">)</mml:mo><mml:mo>,</mml:mo><mml:mo>&#160;</mml:mo><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mi>&#981;</mml:mi><mml:mo stretchy=\"false\">(</mml:mo><mml:mi>x</mml:mi><mml:msub><mml:mi>W</mml:mi><mml:mi>K</mml:mi></mml:msub><mml:mo stretchy=\"false\">)</mml:mo><mml:mo>,</mml:mo><mml:mo>&#160;</mml:mo><mml:mi>V</mml:mi><mml:mo>=</mml:mo><mml:mi>x</mml:mi><mml:msub><mml:mi>W</mml:mi><mml:mi>V</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula>\n<disp-formula id=\"FD2-plants-14-03434\"><label>(2)</label><mml:math id=\"mm2\" display=\"block\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mstyle displaystyle=\"true\"><mml:munderover><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msubsup><mml:mi>K</mml:mi><mml:mi>j</mml:mi><mml:mo>&#8868;</mml:mo></mml:msubsup></mml:mrow><mml:mrow><mml:mstyle displaystyle=\"true\"><mml:msubsup><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msubsup><mml:mi>K</mml:mi><mml:mi>j</mml:mi><mml:mo>&#8868;</mml:mo></mml:msubsup></mml:mrow></mml:mstyle></mml:mrow></mml:mfrac><mml:msub><mml:mi>V</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo></mml:mrow></mml:mstyle><mml:mstyle scriptlevel=\"0\" displaystyle=\"true\"><mml:mfrac><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy=\"false\">(</mml:mo><mml:mstyle displaystyle=\"true\"><mml:msubsup><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:mrow><mml:msubsup><mml:mi>K</mml:mi><mml:mi>j</mml:mi><mml:mo>&#8868;</mml:mo></mml:msubsup><mml:msub><mml:mi>V</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mstyle><mml:mo stretchy=\"false\">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy=\"false\">(</mml:mo><mml:mstyle displaystyle=\"true\"><mml:msubsup><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:mrow><mml:msubsup><mml:mi>K</mml:mi><mml:mi>j</mml:mi><mml:mo>&#8868;</mml:mo></mml:msubsup></mml:mrow></mml:mstyle><mml:mo stretchy=\"false\">)</mml:mo></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mrow></mml:math></disp-formula> where <italic toggle=\"yes\">&#981;</italic> denotes the additional kernel function introduced, <italic toggle=\"yes\">x</italic> denotes the input, and <italic toggle=\"yes\">W<sub>Q</sub></italic>, <italic toggle=\"yes\">W<sub>K</sub></italic>, and <italic toggle=\"yes\">W<sub>V</sub></italic> denote the learnable weight matrices for the <italic toggle=\"yes\">Q</italic>, <italic toggle=\"yes\">K</italic>, and <italic toggle=\"yes\">V</italic> projections, respectively, with each <italic toggle=\"yes\">Q</italic> aggregating information from all <italic toggle=\"yes\">K</italic> and <italic toggle=\"yes\">V</italic>.\n<disp-formula id=\"FD3-plants-14-03434\"><label>(3)</label><mml:math id=\"mm3\" display=\"block\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mstyle scriptlevel=\"0\" displaystyle=\"true\"><mml:mfrac><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>Z</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>,</mml:mo><mml:mo>&#160;</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mstyle displaystyle=\"true\"><mml:munderover><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>i</mml:mi></mml:munderover><mml:mrow><mml:msubsup><mml:mi>K</mml:mi><mml:mi>j</mml:mi><mml:mo>&#8868;</mml:mo></mml:msubsup><mml:msub><mml:mi>V</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo>&#160;</mml:mo><mml:msub><mml:mi>Z</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mstyle displaystyle=\"true\"><mml:munderover><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>i</mml:mi></mml:munderover><mml:mrow><mml:msubsup><mml:mi>K</mml:mi><mml:mi>j</mml:mi><mml:mo>&#8868;</mml:mo></mml:msubsup></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>This further derives cyclic linear attention, as expressed in Equation (4).\n<disp-formula id=\"FD4-plants-14-03434\"><label>(4)</label><mml:math id=\"mm4\" display=\"block\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#8722;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msubsup><mml:mi>K</mml:mi><mml:mi>i</mml:mi><mml:mo>&#8868;</mml:mo></mml:msubsup><mml:msub><mml:mi>V</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo>&#160;</mml:mo><mml:msub><mml:mi>Z</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>Z</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#8722;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msubsup><mml:mi>K</mml:mi><mml:mi>i</mml:mi><mml:mo>&#8868;</mml:mo></mml:msubsup><mml:mo>,</mml:mo><mml:mo>&#160;</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mstyle scriptlevel=\"0\" displaystyle=\"true\"><mml:mfrac><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>Z</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>RoPE [<xref rid=\"B42-plants-14-03434\" ref-type=\"bibr\">42</xref>] uses rotational position embeddings to provide global position information for Q and K, allowing the attention mechanism to capture relative positional dependencies. LePE [<xref rid=\"B43-plants-14-03434\" ref-type=\"bibr\">43</xref>] uses depthwise convolution to extract local spatial features for V. This mechanism acts like a forget gate, which enhances the model&#8217;s fine-grained spatial perception. MLLA Attention integrates RoPE and LePE to effectively fuse global and local information [<xref rid=\"B40-plants-14-03434\" ref-type=\"bibr\">40</xref>], as described below:\n<disp-formula id=\"FD5-plants-14-03434\"><label>(5)</label><mml:math id=\"mm5\" display=\"block\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mi>o</mml:mi><mml:mi>P</mml:mi><mml:mi>E</mml:mi><mml:mo stretchy=\"false\">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>&#952;</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy=\"false\">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>&#8901;</mml:mo><mml:mo stretchy=\"false\">(</mml:mo><mml:mi>cos</mml:mi><mml:mo stretchy=\"false\">(</mml:mo><mml:mi>m</mml:mi><mml:msub><mml:mi>&#952;</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy=\"false\">)</mml:mo><mml:mo>+</mml:mo><mml:mi>sin</mml:mi><mml:mo stretchy=\"false\">(</mml:mo><mml:mi>m</mml:mi><mml:msub><mml:mi>&#952;</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy=\"false\">)</mml:mo><mml:mo stretchy=\"false\">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>\n<disp-formula id=\"FD6-plants-14-03434\"><label>(6)</label><mml:math id=\"mm6\" display=\"block\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>e</mml:mi><mml:mi>P</mml:mi><mml:mi>E</mml:mi><mml:mo stretchy=\"false\">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy=\"false\">)</mml:mo><mml:mo>=</mml:mo><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi>D</mml:mi><mml:mi>W</mml:mi><mml:mi>C</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>v</mml:mi><mml:mo stretchy=\"false\">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy=\"false\">)</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula>\n<disp-formula id=\"FD7-plants-14-03434\"><label>(7)</label><mml:math id=\"mm7\" display=\"block\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy=\"false\">(</mml:mo><mml:mi>R</mml:mi><mml:mi>o</mml:mi><mml:mi>P</mml:mi><mml:mi>E</mml:mi><mml:mo stretchy=\"false\">(</mml:mo><mml:mi>Q</mml:mi><mml:mo stretchy=\"false\">)</mml:mo><mml:mo>,</mml:mo><mml:mo>&#160;</mml:mo><mml:mi>R</mml:mi><mml:mi>o</mml:mi><mml:mi>P</mml:mi><mml:mi>E</mml:mi><mml:mo stretchy=\"false\">(</mml:mo><mml:mi>K</mml:mi><mml:mo stretchy=\"false\">)</mml:mo><mml:mo>,</mml:mo><mml:mo>&#160;</mml:mo><mml:mi>V</mml:mi><mml:mo>+</mml:mo><mml:mi>L</mml:mi><mml:mi>e</mml:mi><mml:mi>P</mml:mi><mml:mi>E</mml:mi><mml:mo stretchy=\"false\">(</mml:mo><mml:mi>V</mml:mi><mml:mo stretchy=\"false\">)</mml:mo><mml:mo stretchy=\"false\">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula> where <italic toggle=\"yes\">m</italic> denotes the dimensionality of the input <italic toggle=\"yes\">x</italic>, <italic toggle=\"yes\">&#952;<sub>i</sub></italic> denotes the position-related angle, <italic toggle=\"yes\">W<sub>L</sub></italic> denotes the learnable weight matrix, and <italic toggle=\"yes\">DWConv</italic> denotes a depthwise convolution with a kernel size of <italic toggle=\"yes\">k</italic>.</p></sec><sec id=\"sec2dot4-plants-14-03434\"><title>2.4. Tomato Fruit Phenotypic Size Transformation</title><p>Based on the acquired phenotypic parameters of tomato fruit sections, this study utilizes depth information to convert pixel distances into real-world physical distances. Specifically, RGB image pixels were remapped through distortion correction to generate an undistorted image. The depth image records the actual depth value d of each pixel from the camera. By integrating the camera&#8217;s intrinsic matrix <italic toggle=\"yes\">K</italic> with the depth value <italic toggle=\"yes\">d</italic>, a mapping relationship from pixel coordinates (<italic toggle=\"yes\">u</italic>, <italic toggle=\"yes\">v</italic>) to three-dimensional physical coordinates (<italic toggle=\"yes\">X</italic>, <italic toggle=\"yes\">Y</italic>, <italic toggle=\"yes\">Z</italic>) was established, as given by Equations (8) and (9):\n<disp-formula id=\"FD8-plants-14-03434\"><label>(8)</label><mml:math id=\"mm8\" display=\"block\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mfenced close=\"|\" open=\"|\"><mml:mrow><mml:mtable equalrows=\"true\" equalcolumns=\"true\"><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>x</mml:mi></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>x</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>y</mml:mi></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>y</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>1</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula>\n<disp-formula id=\"FD9-plants-14-03434\"><label>(9)</label><mml:math id=\"mm9\" display=\"block\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:mo stretchy=\"false\">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy=\"false\">)</mml:mo><mml:mo>=</mml:mo><mml:mo stretchy=\"false\">(</mml:mo><mml:mstyle scriptlevel=\"0\" displaystyle=\"true\"><mml:mfrac><mml:mrow><mml:mo stretchy=\"false\">(</mml:mo><mml:mi>u</mml:mi><mml:mo>&#8722;</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo stretchy=\"false\">)</mml:mo><mml:mo>&#8901;</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>x</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>,</mml:mo><mml:mstyle scriptlevel=\"0\" displaystyle=\"true\"><mml:mfrac><mml:mrow><mml:mo stretchy=\"false\">(</mml:mo><mml:mi>v</mml:mi><mml:mo>&#8722;</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo stretchy=\"false\">)</mml:mo><mml:mo>&#8901;</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>y</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy=\"false\">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula> where <italic toggle=\"yes\">K</italic> denotes the intrinsic matrix, <italic toggle=\"yes\">f<sub>x</sub></italic> and <italic toggle=\"yes\">f<sub>y</sub></italic> represent the focal length parameters, (<italic toggle=\"yes\">c<sub>x</sub></italic>, <italic toggle=\"yes\">c<sub>y</sub></italic>) indicates the principal point coordinates, and <italic toggle=\"yes\">d</italic> is the raw distance value obtained from the depth sensor.</p><p>A preliminary analysis of the phenotypic data from tomato fruit sections revealed deviations in both fruit depth values and measured dimensions. The potential causes are hypothesized to include the following: (1) the specular reflection effect, where the smooth surface of the tomato fruit sections causes specular reflection of structured light, disrupting phase computation; (2) the light scattering effect due to tissue moisture, where water-rich tomato tissues and cellular structures induce multiple light scattering, resulting in distortion of light distribution and errors in depth estimation; (3) multipath errors, where positional variations in multiple tomatoes in the image lead to depth estimation errors. To address these issues, a Hybrid Depth Regression Model (HDRM) was developed to fit the optimal depth distance, with its core process depicted in <xref rid=\"plants-14-03434-f004\" ref-type=\"fig\">Figure 4</xref>.</p><p>The key modules illustrated in <xref rid=\"plants-14-03434-f004\" ref-type=\"fig\">Figure 4</xref> are designed as follows:</p><list list-type=\"order\"><list-item><p>Parameterized Modeling for Error Correction. A nonlinear parametric model was established, and the optimal parameter solution was obtained by fitting the objective function using the least squares method. Let <italic toggle=\"yes\">d<sub>c</sub></italic> denote the depth value measured by the camera, <italic toggle=\"yes\">d<sub>b</sub></italic> denote the optimal depth value, which is obtained through multiple rounds of tuning and calibration, and <italic toggle=\"yes\">d<sub>param</sub></italic> denote the initial predicted depth value as given by Equation (10):\n<disp-formula id=\"FD10-plants-14-03434\"><label>(10)</label><mml:math id=\"mm10\" display=\"block\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy=\"false\">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>&#945;</mml:mi><mml:mo stretchy=\"false\">)</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>&#946;</mml:mi><mml:msubsup><mml:mi>d</mml:mi><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:mi>&#981;</mml:mi><mml:mo>+</mml:mo><mml:mstyle scriptlevel=\"0\" displaystyle=\"true\"><mml:mfrac><mml:mi>&#947;</mml:mi><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mrow></mml:math></disp-formula> where <italic toggle=\"yes\">&#945;</italic>, <italic toggle=\"yes\">&#946;</italic>, <italic toggle=\"yes\">&#981;</italic>, and <italic toggle=\"yes\">&#947;</italic> are parameters derived from data fitting.</p></list-item><list-item><p>Residual Calculation. The residual error <italic toggle=\"yes\">e</italic>, which denotes the deviation predicted by the parametric error model, was calculated for further correction using a random forest regression model, as defined below:\n<disp-formula id=\"FD11-plants-14-03434\"><label>(11)</label><mml:math id=\"mm11\" display=\"block\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mo stretchy=\"false\">(</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy=\"false\">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>b</mml:mi></mml:msub><mml:mo>&#8722;</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula></p></list-item><list-item><p>Feature Engineering. To further capture the nonlinear relationships within the residuals, an extended feature set <italic toggle=\"yes\">X<sub>extended</sub></italic> was constructed, including linear, quadratic, cubic, logarithmic, and reciprocal terms:\n<disp-formula id=\"FD12-plants-14-03434\"><label>(12)</label><mml:math id=\"mm12\" display=\"block\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy=\"false\">[</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mi>d</mml:mi><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>d</mml:mi><mml:mi>c</mml:mi><mml:mn>3</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:mi>ln</mml:mi><mml:mo stretchy=\"false\">(</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy=\"false\">)</mml:mo><mml:mo>,</mml:mo><mml:mstyle scriptlevel=\"0\" displaystyle=\"true\"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>d</mml:mi></mml:mfrac></mml:mstyle><mml:mo stretchy=\"false\">]</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p></list-item><list-item><p>Standardization. To prevent feature scale discrepancies from affecting model training, the feature set was standardized to obtain <italic toggle=\"yes\">X<sub>norm</sub></italic>, ensuring consistency in the input to the random forest model. Here, <italic toggle=\"yes\">&#956;</italic> denotes the mean of the feature vector, and <italic toggle=\"yes\">&#963;</italic> denotes the standard deviation of the feature vector:\n<disp-formula id=\"FD13-plants-14-03434\"><label>(13)</label><mml:math id=\"mm13\" display=\"block\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle scriptlevel=\"0\" displaystyle=\"true\"><mml:mfrac><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>&#8722;</mml:mo><mml:mi>&#956;</mml:mi></mml:mrow><mml:mi>&#963;</mml:mi></mml:mfrac></mml:mstyle></mml:mrow></mml:mrow></mml:math></disp-formula></p></list-item><list-item><p>Random Forest Regressor for Residual Correction (<italic toggle=\"yes\">RF</italic>). A random forest <italic toggle=\"yes\">RF</italic> model was employed to predict the residual correction value <inline-formula><mml:math id=\"mm666\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:mover><mml:mi>e</mml:mi><mml:mo>&#8743;</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:math></inline-formula>. The <italic toggle=\"yes\">RF</italic> model integrates the outputs of multiple decision trees, <italic toggle=\"yes\">T<sub>k</sub></italic>, and its predicted value is given by:\n<disp-formula id=\"FD14-plants-14-03434\"><label>(14)</label><mml:math id=\"mm14\" display=\"block\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:mover><mml:mi>e</mml:mi><mml:mo>&#8743;</mml:mo></mml:mover><mml:mo stretchy=\"false\">(</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy=\"false\">)</mml:mo><mml:mo>=</mml:mo><mml:mi>R</mml:mi><mml:mi>F</mml:mi><mml:mo stretchy=\"false\">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo stretchy=\"false\">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p></list-item><list-item><p>Final Corrected Model Depth. The final corrected depth is the sum of the parametric model prediction and the random forest residual prediction:\n<disp-formula id=\"FD15-plants-14-03434\"><label>(15)</label><mml:math id=\"mm15\" display=\"block\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mover><mml:mi>e</mml:mi><mml:mo>&#8743;</mml:mo></mml:mover><mml:mo stretchy=\"false\">(</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy=\"false\">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p></list-item></list></sec><sec id=\"sec2dot5-plants-14-03434\"><title>2.5. Tomato Fruit Phenotype Recognition Process</title><p>By integrating image processing techniques with deep learning algorithms, this study analyzed tomato fruits from both longitudinal and transverse sectional views and proposed a framework for the automated identification of phenotypic traits, as shown in <xref rid=\"plants-14-03434-f005\" ref-type=\"fig\">Figure 5</xref>.</p><p>The framework enables high-throughput and precise extraction of multi-dimensional phenotypic traits from tomato fruits of various varieties, including transverse and longitudinal diameters, fruit shape index, stem scar structure, stem scar depth and width, locule structure, locule number, locule area, mesocarp thickness, mesocarp color, and locule color. The main modules were structured as follows:</p><p><xref rid=\"plants-14-03434-f005\" ref-type=\"fig\">Figure 5</xref>a illustrates the extraction of phenotypic features from longitudinal sections of tomato fruits, focusing on shape and stem scar features.</p><list list-type=\"order\"><list-item><p>To extract morphological features from tomato sections, this study used image processing and threshold segmentation algorithms to generate a binary mask for each tomato fruit. A minimum bounding rectangle was fitted to each tomato fruit in the image, with its height defined as the longitudinal diameter and its width as the transverse diameter. The fruit shape index was calculated as the ratio between the longitudinal and transverse diameters of the fruit.</p></list-item><list-item><p>We utilized a SegFormer-MLLA model for tomato fruit phenotypic trait segmentation to achieve efficient and precise segmentation of the stem scar boundary. Based on the segmentation results, a minimum bounding rectangle was fitted to the stem scar, with its width and depth determined.</p></list-item><list-item><p>Using the obtained data, we integrated RGB-D information from the depth camera and employed the HDRM model to optimize depth values, thereby converting pixel distances into physical dimensions and obtaining the actual values of the tomato fruit&#8217;s transverse diameter, longitudinal diameter, stem scar depth, and stem scar width.</p></list-item></list><p><xref rid=\"plants-14-03434-f005\" ref-type=\"fig\">Figure 5</xref>b illustrates the extraction of phenotypic features from transverse sections of tomato fruits, emphasizing locule features, locule area, and mesocarp thickness.</p><list list-type=\"order\"><list-item><p>Tomato fruit transverse section images were processed at 512 &#215; 512 resolution. The SegFormer-MLLA model was applied to segment the locule structure for quantitative analysis of locule number and area. To ensure systematic and traceable analysis, a numbering system was designed for tomato fruits and their internal locules, assigning unique identifiers to establish correspondence.</p></list-item><list-item><p>Three rays were drawn from the centroid of each tomato fruit toward each locule. Experimental results showed that offsetting the two side rays by 12&#176; from the central ray provided optimal performance. The minimum Euclidean distance between the intersection points of rays with the locule contour and the tomato outer contour was calculated, and their average was used as an approximate estimate of mesocarp thickness.</p></list-item><list-item><p>Using the depth information provided by the depth image and the HDRM model, pixel-based measurements of mesocarp thickness and locule area were converted into actual physical dimensions.</p></list-item><list-item><p>Further color recognition analysis was conducted. By averaging the RGB values of each tomato locule, the representative color features of the locule were obtained. Additionally, based on a tomato flesh mask (generated by subtracting the locule mask from the overall tomato mask), a morphological erosion algorithm was employed to extract the pericarp region near the tomato&#8217;s outer edge, and its color features were identified.</p></list-item></list></sec></sec><sec sec-type=\"results\" id=\"sec3-plants-14-03434\"><title>3. Results</title><sec id=\"sec3dot1-plants-14-03434\"><title>3.1. Experimental Environment</title><p>The experiments were conducted on a system equipped with an NVIDIA GeForce RTX 4070 GPU and an Intel Core i5-13490F CPU, running the Windows 11 operating system. The integrated development environment was PyCharm 2024.2.2, and the compilation environment was Python 3.8. The MMSegmentation algorithm library was employed as the algorithmic framework. Input images were processed at a resolution of 512 &#215; 512 pixels, using the AdamW optimizer with a learning rate of 1 &#215; 10<sup>&#8722;3</sup>. The batch size was set to 4.</p><p>The imaging parameters of the Azure Kinect 3.0 depth camera were maintained at fixed values during data acquisition to ensure consistent illumination and color characteristics. Specifically, the brightness, contrast, saturation, and sharpness were set to 20, 50, 64, and 24, respectively. These values were obtained through tuning and calibration to achieve optimal visual clarity and depth stability under the controlled lighting conditions of the imaging environment.</p><p>Model training was conducted for 320,000 iterations for tomato stem scar segmentation and 240,000 iterations for tomato locule segmentation. The poly learning rate decay strategy was adopted, and the weight decay was 0.01. To address the class imbalance problem, particularly for small structures such as stem scars, a hybrid loss function combining Cross-Entropy Loss (weight = 0.7) and Dice Loss (weight = 0.3) was employed.</p></sec><sec id=\"sec3dot2-plants-14-03434\"><title>3.2. Evaluation Metrics</title><p>The segmentation performance of the SegFormer-MLLA model was evaluated using Intersection over Union (IoU), Dice coefficient, Accuracy, Precision, and Recall. IoU denotes the overlap between predicted and ground-truth regions. The Dice coefficient quantifies the boundary matching accuracy. Precision denotes the proportion of correctly predicted positive regions among all predicted positive regions. Recall denotes the proportion of correctly identified target regions relative to all actual target regions. The formulas for these four metrics are presented below:\n<disp-formula id=\"FD16-plants-14-03434\"><label>(16)</label><mml:math id=\"mm16\" display=\"block\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mi>o</mml:mi><mml:mi>U</mml:mi><mml:mo>=</mml:mo><mml:mstyle scriptlevel=\"0\" displaystyle=\"true\"><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mrow></mml:math></disp-formula>\n<disp-formula id=\"FD17-plants-14-03434\"><label>(17)</label><mml:math id=\"mm17\" display=\"block\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mo>&#160;</mml:mo><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mstyle scriptlevel=\"0\" displaystyle=\"true\"><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo>&#215;</mml:mo><mml:mfenced close=\"|\" open=\"|\"><mml:mrow><mml:mi>X</mml:mi><mml:mo>&#8745;</mml:mo><mml:mi>Y</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mfenced close=\"|\" open=\"|\"><mml:mi>X</mml:mi></mml:mfenced><mml:mo>+</mml:mo><mml:mfenced close=\"|\" open=\"|\"><mml:mi>Y</mml:mi></mml:mfenced></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>=</mml:mo><mml:mstyle scriptlevel=\"0\" displaystyle=\"true\"><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mrow></mml:math></disp-formula>\n<disp-formula id=\"FD18-plants-14-03434\"><label>(18)</label><mml:math id=\"mm18\" display=\"block\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mstyle scriptlevel=\"0\" displaystyle=\"true\"><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mrow></mml:math></disp-formula>\n<disp-formula id=\"FD19-plants-14-03434\"><label>(19)</label><mml:math id=\"mm19\" display=\"block\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mstyle scriptlevel=\"0\" displaystyle=\"true\"><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mrow></mml:math></disp-formula> where <italic toggle=\"yes\">TP</italic>, <italic toggle=\"yes\">FP</italic>, and <italic toggle=\"yes\">FN</italic> denote the number of true positives, false positives, and false negatives, respectively. <italic toggle=\"yes\">X</italic> represents the segmented region predicted by the model, and <italic toggle=\"yes\">Y</italic> indicates the ground-truth segmented region.</p><p>We evaluated the Hybrid Depth Regression Model using Root Mean Square Error (<italic toggle=\"yes\">RMSE</italic>) to quantify its performance. Phenotypic traits of tomato fruit sections, including transverse and longitudinal diameters, mesocarp thickness, and stem scar depth and width, were manually measured using a vernier caliper. The fruit shape index was calculated as the ratio of longitudinal diameter to transverse diameter. To evaluate the performance of image-based dimension measurements, <italic toggle=\"yes\">RMSE</italic>, <italic toggle=\"yes\">MAE</italic>, and <italic toggle=\"yes\">R</italic><sup>2</sup> were used as metrics:\n<disp-formula id=\"FD20-plants-14-03434\"><label>(20)</label><mml:math id=\"mm20\" display=\"block\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mi>M</mml:mi><mml:mi>S</mml:mi><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:mstyle scriptlevel=\"0\" displaystyle=\"true\"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac></mml:mstyle><mml:mstyle displaystyle=\"true\"><mml:munderover><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:msup><mml:mrow><mml:mfenced><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#8722;</mml:mo></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mover><mml:mi>y</mml:mi><mml:mo>&#8743;</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:mrow></mml:msqrt></mml:mrow></mml:mrow></mml:math></disp-formula>\n<disp-formula id=\"FD21-plants-14-03434\"><label>(21)</label><mml:math id=\"mm21\" display=\"block\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>A</mml:mi><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mstyle scriptlevel=\"0\" displaystyle=\"true\"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac></mml:mstyle><mml:mstyle displaystyle=\"true\"><mml:munderover><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:mfenced close=\"|\" open=\"|\"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#8722;</mml:mo></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mover><mml:mi>y</mml:mi><mml:mo>&#8743;</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mstyle></mml:mrow></mml:mrow></mml:math></disp-formula>\n<disp-formula id=\"FD22-plants-14-03434\"><label>(22)</label><mml:math id=\"mm22\" display=\"block\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>&#8722;</mml:mo><mml:mstyle scriptlevel=\"0\" displaystyle=\"true\"><mml:mfrac><mml:mrow><mml:mstyle displaystyle=\"true\"><mml:munderover><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy=\"false\">(</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>y</mml:mi><mml:mo>&#8743;</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>&#8722;</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy=\"false\">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:mrow><mml:mrow><mml:mstyle displaystyle=\"true\"><mml:munderover><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:msup><mml:mrow><mml:mfenced><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#8722;</mml:mo><mml:mover accent=\"true\"><mml:mi>y</mml:mi><mml:mo stretchy=\"true\">&#175;</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mrow></mml:math></disp-formula> where <inline-formula><mml:math id=\"mm777\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>y</mml:mi><mml:mo>&#8743;</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> denotes the predicted dimension, <italic toggle=\"yes\">y<sub>i</sub></italic> represents the ground-truth dimension, and <italic toggle=\"yes\">N</italic> denotes the sample size.</p></sec><sec id=\"sec3dot3-plants-14-03434\"><title>3.3. Evaluation of Segmentation Results</title><p>To evaluate the performance of the SegFormer-MLLA model, comparative experiments were conducted under identical experimental conditions and test sets against several classical semantic segmentation algorithms, including UNet [<xref rid=\"B44-plants-14-03434\" ref-type=\"bibr\">44</xref>], DeepLabv3+ [<xref rid=\"B45-plants-14-03434\" ref-type=\"bibr\">45</xref>], PIDNet [<xref rid=\"B46-plants-14-03434\" ref-type=\"bibr\">46</xref>], Convnext [<xref rid=\"B47-plants-14-03434\" ref-type=\"bibr\">47</xref>], and Mask2Former [<xref rid=\"B48-plants-14-03434\" ref-type=\"bibr\">48</xref>]. The SegFormer model comprises multiple variants, such as B0 and B2, which differ in embedding dimensions and layer counts, representing lightweight and more complex architectures, respectively. In this study, SegFormer-MLLA-a and SegFormer-MLLA-b were proposed based, respectively, on the embedding dimensions and layer counts of the B0 and B2 models.</p><p><xref rid=\"plants-14-03434-t001\" ref-type=\"table\">Table 1</xref> shows the evaluation results for tomato stem scar segmentation. The lightweight SegFormer-MLLA-a model, with only 3.06 M parameters, achieved an IoU of 77.86%, comparable to the Mask2Former model&#8217;s IoU of 77.64% with 44.00 M parameters. Furthermore, the SegFormer-MLLA-b model, an enhanced version of the SegFormer-B2 architecture, achieved an IoU of 78.36% with a 23.2% parameter reduction (from 24.72 M to 18.98 M). It slightly outperformed the baseline model while maintaining stability in the Dice coefficient (87.87%) and Recall (87.59%). These results demonstrate the significant performance advantages of the SegFormer-MLLA model optimized with the MLLA Attention module.</p><p><xref rid=\"plants-14-03434-t002\" ref-type=\"table\">Table 2</xref> shows the evaluation results for tomato locules segmentation. As presented in <xref rid=\"plants-14-03434-t002\" ref-type=\"table\">Table 2</xref>, the SegFormer-MLLA model exhibited outstanding performance. The SegFormer-MLLA-a model, with only 3.06 M parameters, attained an IoU of 85.00%, representing a 0.16% improvement over the baseline SegFormer-B0, and increased the Dice coefficient to 91.88%. The SegFormer-MLLA-b model, with 18.98 M parameters, achieved an IoU of 85.24%, surpassing the Mask2Former model (IoU 85.15%) with 2.32 times the parameters. These results indicate that the MLLA module provides exceptional performance in fine-structure segmentation while maintaining high computational efficiency, highlighting the model&#8217;s effective balance between performance and resource demands.</p></sec><sec id=\"sec3dot4-plants-14-03434\"><title>3.4. Tomato Fruit Size Phenotypic Information Extraction</title><p>For the segmentation and dimension recognition tasks of tomato fruit section images, a strategy integrating preprocessing and depth information was employed. As original images contained multiple tomato targets with excessive background elements and small target sizes, training and prediction using unprocessed images led to reduced model segmentation accuracy. Therefore, an HSV color space segmentation combined with contour detection was initially applied to crop the original images into multiple 512 &#215; 512 pixel single-tomato images, while the positional information of each tomato in the original image was recorded. Subsequently, semantic segmentation was performed on the cropped single-tomato images, and the segmentation results were recombined into the original image layout using the retained positional information. Ultimately, Precise measurements of the actual physical dimensions of tomato fruit sections were achieved by integrating RGB images with depth information. This approach effectively reduces background interference on segmentation accuracy, providing reliable support for depth vision-based tomato phenotyping.</p><p>The performance of the tomato fruit phenotyping intelligent detection framework was evaluated using 50 independent tomato samples imaged at two different heights, resulting in 100 independent sample sets in total. Benchmark values for fruit geometric parameters were obtained through manual measurements, and the fruit shape index was calculated. The phenotypic measurement results were compared with the corresponding predictions from the phenotypic detection model, depicted in <xref rid=\"plants-14-03434-f006\" ref-type=\"fig\">Figure 6</xref>, which shows high consistency in the model&#8217;s predictions for transverse diameter, longitudinal diameter, and fruit shape index of tomato fruits. The RMSE values were 1.09 mm, 0.87 mm, and 0.01, respectively. The MAE values were 0.87 mm, 0.68 mm, and 0.01, respectively. The R<sup>2</sup> values were 0.945, 0.956, and 0.920, respectively. For mesocarp thickness, the model achieved an RMSE of 0.52 mm, MAE of 0.42 mm, and R<sup>2</sup> of 0.907.</p><p>Compared to the aforementioned parameters, the R<sup>2</sup> value for the tomato fruit stem scar was slightly lower, attributable to its morphological diversity and the influence of segmentation outcomes. The violin plots in <xref rid=\"plants-14-03434-f007\" ref-type=\"fig\">Figure 7</xref>, which illustrate the residual distributions for scar depth and width, provide evidence for this issue. In some varieties, the fruit stem scar area appears off-white or light yellow&#8212;a color similar to the placental tissue&#8212;resulting in unclear boundary recognition; hence, manual detection is recommended.</p><p>Additionally, this study quantified color features by extracting RGB tri-channel values from the mesocarp and locules, illustrated in <xref rid=\"plants-14-03434-f008\" ref-type=\"fig\">Figure 8</xref>, enabling a new dimension for assessing fruit maturity and internal structural characteristics. The color differences observed between the mesocarp and the locules in tomatoes are not merely visual but are intrinsically linked to the spatial distribution of key biochemical traits, particularly lycopene content [<xref rid=\"B49-plants-14-03434\" ref-type=\"bibr\">49</xref>]. The inclusion of color data enhances the diversity of phenotypic parameters and provides a data foundation for correlations between fruit quality and phenotypic traits. Compared to traditional manual measurements, this automated identification method enables rapid phenotyping of tomato fruits and effectively supports variety selection and quality grading in high-throughput agricultural phenotyping applications, significantly improving breeding screening efficiency.</p></sec><sec id=\"sec3dot5-plants-14-03434\"><title>3.5. Ablation Experiment</title><p>Building on the SegFormer-MLLA model for tomato fruit structure segmentation, this study extracted 10 key phenotypic parameters from RGB-D images of fruit sections. The precision issue in size measurement arises from depth value bias in depth cameras. A Hybrid Depth Regression Model (HDRM) was introduced to correct the depth values, effectively improving measurement accuracy. A total of 264 paired samples were used, divided into training and testing sets with a 9:1 ratio, and evaluated through ten-fold cross-validation to ensure model robustness. As shown in <xref rid=\"plants-14-03434-f009\" ref-type=\"fig\">Figure 9</xref>, the optimized depth measurements significantly reduced the RMSE from 18.754 mm (original) to 3.011 mm using the proposed HDRM, compared to 3.154 mm for the parameterized modeling approach and 3.500 mm for the Random Forest model.</p><p>To evaluate the performance of different modeling strategies in predicting fruit morphological parameters, the predictive accuracy of the Random Forest model, the parametric model, and the HDRM (combining both approaches) was compared. The results in <xref rid=\"plants-14-03434-t003\" ref-type=\"table\">Table 3</xref> show that the Random Forest model can capture nonlinear relationships but tends to exhibit bias when the dataset is small or lacks sufficient constraints. The parametric model provides good interpretability but has limited ability to fit systematic errors. In contrast, the proposed HDRM achieved the best performance across all metrics, with RMSE values for transverse diameter, longitudinal diameter reduced to 1.064 mm and 0.956 mm.</p><p>Furthermore, the contribution of each component within the overall framework was evaluated through an ablation study, as presented in <xref rid=\"plants-14-03434-t004\" ref-type=\"table\">Table 4</xref>. When employing the Segormer-MALL, the model achieved strong detection performance, with the introduction of the MLLA module enhancing its ability to represent structural details of tomato locules and stem scars. In the depth correction component, using the Random Forest model alone exhibited a certain degree of instability, whereas the parametric modeling approach effectively reduced systematic errors. By integrating both methods, the HDRM mitigated fitting bias and improved prediction stability. The complete framework achieved the lowest RMSE and MAE across most evaluation metrics.</p></sec><sec id=\"sec3dot6-plants-14-03434\"><title>3.6. Device Detection and Software Development</title><p>To automate the extraction and quantitative analysis of tomato fruit phenotypic traits, we integrated multiple algorithms and techniques, including image processing, semantic segmentation, and regression models. Using these methods, we successfully designed and implemented an efficient automated detection equipment for tomato fruit phenotyping, along with its supporting software, as shown in <xref rid=\"plants-14-03434-f010\" ref-type=\"fig\">Figure 10</xref>. The equipment primarily consists of the following components: an Azure Kinect depth camera, a sample tray for the stable placement of fruits (capable of holding six tomatoes), LED light strips to provide a uniform and controllable lighting environment, and a sealed light-shielded imaging box to isolate ambient light. The accompanying software provides a user-friendly interface and integrates core functions, including real-time capture, processing, and storage of RGB-D images, automatic extraction and quantitative analysis of tomato fruit phenotypic parameters, and the creation of a phenotypic database for structured storage and management of tomato fruit data. This device serves as a laboratory tool designed for precise internal phenotyping of tomato fruits obtained from breeding and cultivation experiments.</p></sec></sec><sec sec-type=\"discussion\" id=\"sec4-plants-14-03434\"><title>4. Discussion</title><p>Amid the rapid advancement of intelligent breeding technologies, efficiently and accurately extracting phenotypic information from tomato fruits remains a key challenge. Because traditional manual phenotyping measurement methods are time-consuming and labor-intensive, they are not suitable for the high-throughput, large-sample demands of modern breeding. In the field of automated tomato fruit analysis, there has been considerable research on external quality attributes [<xref rid=\"B50-plants-14-03434\" ref-type=\"bibr\">50</xref>,<xref rid=\"B51-plants-14-03434\" ref-type=\"bibr\">51</xref>,<xref rid=\"B52-plants-14-03434\" ref-type=\"bibr\">52</xref>], while studies on intelligent recognition of internal structures remain relatively limited. This study focuses on methodological research for the intelligent acquisition of internal phenotypic traits in tomato fruits. We obtained internal phenotypic traits such as locule number, mesocarp thickness, and stem scar morphology by performing both transverse and longitudinal sectioning of tomato fruits. These destructive measurements are necessary to access internal structures that cannot be observed non-invasively. Although the method is inherently destructive, it enables the acquisition of precise and detailed internal phenotypic data at a low cost. Furthermore, the enclosed imaging box ensures stable and uniform illumination, effectively minimizing ambient light interference and guaranteeing consistent imaging quality across samples. Accordingly, the accuracy reported in this study is specific to the conditions used: the analysis of sectioned fruits within an enclosed imaging system. The results are therefore not directly applicable to intact fruits in open environments.</p><p>In tomato fruit phenotypic size detection, most methods typically rely on a ruler or black-and-white scale card as a reference for measuring fruit-related phenotypic traits [<xref rid=\"B30-plants-14-03434\" ref-type=\"bibr\">30</xref>,<xref rid=\"B31-plants-14-03434\" ref-type=\"bibr\">31</xref>,<xref rid=\"B53-plants-14-03434\" ref-type=\"bibr\">53</xref>], which require the reference object and the fruit to be positioned on the same focal plane and aligned with the fruit&#8217;s primary measurement axis; otherwise, substantial measurement errors may arise. In this study, a method that combined RGB images with depth information was employed for the accurate detection of tomato fruit phenotypic size, eliminating the need for a black-and-white scale card, and enabling high-throughput measurement across large sample sets. This approach can be extended to other crops with similar fruit characteristics, requiring minor fine-tuning and recalibration to accommodate differences in tissue structure and phenotypic traits.</p><sec id=\"sec4dot1-plants-14-03434\"><title>4.1. The Feasibility and Practical Significance of SegFormer-MLLA in Tomato Fruit Trait Analysis</title><p>With the increasing demand for automated analysis of tomato fruit traits, efficient utilization of computational resources in resource-constrained environments is critical for real-time or near-real-time applications [<xref rid=\"B54-plants-14-03434\" ref-type=\"bibr\">54</xref>]. To address the challenge of automated and precise phenotyping of complex tomato fruit traits, we propose a novel lightweight segmentation model, SegFormer-MLLA, for efficient locule and stem scar segmentation, meeting the demands of resource-constrained environments. The segmentation results generated by this model further enable the automatic extraction of multiple key phenotypic parameters, such as tomato mesocarp thickness and stem scar characteristics. Previous research [<xref rid=\"B29-plants-14-03434\" ref-type=\"bibr\">29</xref>] utilized the Mask R-CNN model to extract tomato fruit phenotypes, but it exhibited limitations in model efficiency. The model proposed in this study has only 3.06 M parameters, offering higher efficiency and greater suitability for scalable deployment.</p></sec><sec id=\"sec4dot2-plants-14-03434\"><title>4.2. Effect of HDRM Model on Size Detection</title><p>During the experiment, we observed deviations in the restoration of fruit phenotypic dimensions using depth information. This deviation is likely due to light absorption by moisture in the tomato fruit&#8217;s cross-sectional tissue and light reflection caused by its smooth surface. To overcome this limitation, a Hybrid Depth Regression Model (HDRM) is used to optimize the captured depth values, which, together with the camera&#8217;s intrinsic matrix, enables conversion of pixel measurements in RGB images into the fruit&#8217;s actual physical dimensions. Evaluated using R<sup>2</sup>, RMSE, and MAE metrics, our method achieved high accuracy in measuring tomato phenotypic traits, including transverse diameter, longitudinal diameter, mesocarp thickness, and fruit shape index.</p></sec><sec id=\"sec4dot3-plants-14-03434\"><title>4.3. Phenotypic Research of Tomato Stem Scars</title><p>Currently, significant progress has been made in rapid phenotyping of vegetables such as tomatoes, but research has primarily focused on external fruit traits, such as size and shape, while studies on internal structures and localized features, such as stem scars, remain scarce. The tomato stem scar is a wound formed when the stem separates from the fruit during harvesting. Its rapid healing forms a hydrophobic barrier, which helps reduce post-harvest water loss and microbial infection, thereby extending the storage period and thus its importance in tomato post-harvest handling [<xref rid=\"B55-plants-14-03434\" ref-type=\"bibr\">55</xref>]. Based on our method, the extraction and segmentation of stem scars were successfully achieved, with dimensional detection errors controlled at the sub-millimeter level, providing significant advantages for automated phenotypic analysis in breeding programs.</p></sec><sec id=\"sec4dot4-plants-14-03434\"><title>4.4. Benefits of the Automated Phenotyping System</title><p>To apply our established models and methods more efficiently to the systematic analysis of tomato fruit phenotyping, we built on the intelligent detection framework and developed automated phenotyping equipment and software. This system effectively eliminates subjective errors in manual measurements, enhances detection convenience, significantly improves the consistency and reliability of phenotypic data, and lowers the operational threshold. Furthermore, we established a comprehensive tomato phenotyping database, enabling long-term storage, traceability, and reuse of detection data and images, which facilitates comparative analysis, model training, and data sharing, providing critical support for genotype-phenotype association studies.</p></sec><sec id=\"sec4dot5-plants-14-03434\"><title>4.5. Limitations and Future Work</title><p>Although this study has made progress in the automated detection of tomato fruit phenotypic traits, certain limitations remain.</p><p>During fruit size detection, slight angular deviations between the tomato fruit section plane and the camera may occur, even if visually undetectable. These deviations can lead to non-uniform depth value distribution across the plane, introducing measurement errors. As shown in <xref rid=\"plants-14-03434-t005\" ref-type=\"table\">Table 5</xref>, our method demonstrates high accuracy in measuring tomato fruit phenotypic traits by comparing the true and detected values of multiple tomato samples at six equipment positions. Slight variations in the detection outcomes were primarily due to changes in orientation or visual perspective. For instance, a 5&#176; tilt in the tomato fruit section resulted in a deviation of approximately 2&#8211;3 mm in the depth value.</p><p>To address these challenges, our research will focus on key directions to advance tomato phenomics. First, we will refine our model and expand training datasets to include a broader range of tomato cultivars, thereby enhancing the accuracy and robustness of detecting tomato fruit phenotypic traits. Second, we plan to explore the application of point cloud, spectral, and three-dimensional technologies in tomato phenotyping, aiming to develop innovative approaches to study more phenotypes, thereby enhancing the precision and scope of trait analysis in agricultural research. Third, we will implement equipment enhancements, such as replacing the fixed tray for holding tomato fruits with a conveyorized system to mitigate angular deviations between the fruit section plane and the camera.</p></sec></sec><sec sec-type=\"conclusions\" id=\"sec5-plants-14-03434\"><title>5. Conclusions</title><p>In this study, an intelligent detection framework for tomato fruit phenomics analysis was developed, which combines image processing techniques with deep learning algorithms to automate the extraction and quantitative analysis of 12 phenotypic traits. First, a dataset of tomato fruit section images was developed using a depth camera. Second, a lightweight SegFormer-MLLA model for tomato fruit phenotype segmentation was proposed. Accurate segmentation of tomato fruit stem scars and locular structures was achieved, with significantly reduced computational cost by the proposed model. Finally, an HDRM model was designed to optimize the estimation of optimal depth. Building on this, we developed an automated phenotyping system for tomato fruits, which provides a controlled and stable environment to enable precise trait detection. The results showed that the RMSEs were approximately 1 mm for the longitudinal diameter, transverse diameter, and stem scar width of the tomato fruit sections, and below 0.6 mm for the mesocarp thickness and stem scar depth.</p></sec></body><back><fn-group><fn><p><bold>Disclaimer/Publisher&#8217;s Note:</bold> The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content.</p></fn></fn-group><notes><title>Author Contributions</title><p>Conceptualization, J.L. and G.D.; methodology, J.L. and G.D.; software, G.D.; validation, H.Y., Z.X.; formal analysis, J.L., Y.Z. and Q.S.; investigation, G.D.; resources, Y.Z., W.N. and Q.S.; data curation, G.D. and Y.L.; writing&#8212;original draft preparation, G.D.; writing&#8212;review and editing, J.L., W.N. and Q.S.; visualization, G.D.; supervision, J.L.; project administration, J.L.; funding acquisition, Q.S. All authors have read and agreed to the published version of the manuscript.</p></notes><notes notes-type=\"data-availability\"><title>Data Availability Statement</title><p>Some datasets, model weights, and code used in the present study are available at <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"https://github.com/Snail-code-wq/Plants_Tomato_2025\" ext-link-type=\"uri\">https://github.com/Snail-code-wq/Plants_Tomato_2025</ext-link> (accessed on 5 November 2025). All self-developed datasets can be obtained by contacting the corresponding author.</p></notes><notes notes-type=\"COI-statement\"><title>Conflicts of Interest</title><p>The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.</p></notes><ref-list><title>References</title><ref id=\"B1-plants-14-03434\"><label>1.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Kim</surname><given-names>M.</given-names></name><name name-style=\"western\"><surname>Nguyen</surname><given-names>T.T.P.</given-names></name><name name-style=\"western\"><surname>Ahn</surname><given-names>J.-H.</given-names></name><name name-style=\"western\"><surname>Kim</surname><given-names>G.-J.</given-names></name><name name-style=\"western\"><surname>Sim</surname><given-names>S.-C.</given-names></name></person-group><article-title>Genome-wide association study identifies QTL for eight fruit traits in cultivated tomato (<italic toggle=\"yes\">Solanum lycopersicum</italic> L.)</article-title><source>Hortic. Res.</source><year>2021</year><volume>8</volume><fpage>203</fpage><pub-id pub-id-type=\"doi\">10.1038/s41438-021-00638-4</pub-id><pub-id pub-id-type=\"pmid\">34465758</pub-id><pub-id pub-id-type=\"pmcid\">PMC8408251</pub-id></element-citation></ref><ref id=\"B2-plants-14-03434\"><label>2.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Perveen</surname><given-names>R.</given-names></name><name name-style=\"western\"><surname>Suleria</surname><given-names>H.A.R.</given-names></name><name name-style=\"western\"><surname>Anjum</surname><given-names>F.M.</given-names></name><name name-style=\"western\"><surname>Butt</surname><given-names>M.S.</given-names></name><name name-style=\"western\"><surname>Pasha</surname><given-names>I.</given-names></name><name name-style=\"western\"><surname>Ahmad</surname><given-names>S.J.</given-names></name></person-group><article-title>Tomato (<italic toggle=\"yes\">Solanum lycopersicum</italic>) carotenoids and lycopenes chemistry; metabolism, absorption, nutrition, and allied health claims&#8212;A comprehensive review</article-title><source>Crit. Rev. Food Sci. Nutr.</source><year>2015</year><volume>55</volume><fpage>919</fpage><lpage>929</lpage><pub-id pub-id-type=\"doi\">10.1080/10408398.2012.657809</pub-id><pub-id pub-id-type=\"pmid\">24915375</pub-id></element-citation></ref><ref id=\"B3-plants-14-03434\"><label>3.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Lin</surname><given-names>T.</given-names></name><name name-style=\"western\"><surname>Zhu</surname><given-names>G.</given-names></name><name name-style=\"western\"><surname>Zhang</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>Xu</surname><given-names>X.</given-names></name><name name-style=\"western\"><surname>Yu</surname><given-names>Q.</given-names></name><name name-style=\"western\"><surname>Zheng</surname><given-names>Z.</given-names></name><name name-style=\"western\"><surname>Zhang</surname><given-names>Z.</given-names></name><name name-style=\"western\"><surname>Lun</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>Li</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Wang</surname><given-names>X.</given-names></name><etal/></person-group><article-title>Genomic analyses provide insights into the history of tomato breeding</article-title><source>Nat. Genet.</source><year>2014</year><volume>46</volume><fpage>1220</fpage><lpage>1226</lpage><pub-id pub-id-type=\"doi\">10.1038/ng.3117</pub-id><pub-id pub-id-type=\"pmid\">25305757</pub-id></element-citation></ref><ref id=\"B4-plants-14-03434\"><label>4.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Zhu</surname><given-names>G.</given-names></name><name name-style=\"western\"><surname>Wang</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Huang</surname><given-names>Z.</given-names></name><name name-style=\"western\"><surname>Zhang</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Liao</surname><given-names>Q.</given-names></name><name name-style=\"western\"><surname>Zhang</surname><given-names>C.</given-names></name><name name-style=\"western\"><surname>Lin</surname><given-names>T.</given-names></name><name name-style=\"western\"><surname>Qin</surname><given-names>M.</given-names></name><name name-style=\"western\"><surname>Peng</surname><given-names>M.</given-names></name><name name-style=\"western\"><surname>Yang</surname><given-names>C.</given-names></name><etal/></person-group><article-title>Rewiring of the Fruit Metabolome in Tomato Breeding</article-title><source>Cell</source><year>2018</year><volume>172</volume><fpage>249</fpage><lpage>261.e12</lpage><pub-id pub-id-type=\"doi\">10.1016/j.cell.2017.12.019</pub-id><pub-id pub-id-type=\"pmid\">29328914</pub-id></element-citation></ref><ref id=\"B5-plants-14-03434\"><label>5.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Mata-Nicol&#225;s</surname><given-names>E.</given-names></name><name name-style=\"western\"><surname>Montero-Pau</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>Gimeno-Paez</surname><given-names>E.</given-names></name><name name-style=\"western\"><surname>Garcia-Carpintero</surname><given-names>V.</given-names></name><name name-style=\"western\"><surname>Ziarsolo</surname><given-names>P.</given-names></name><name name-style=\"western\"><surname>Menda</surname><given-names>N.</given-names></name><name name-style=\"western\"><surname>Mueller</surname><given-names>L.A.</given-names></name><name name-style=\"western\"><surname>Blanca</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>Ca&#241;izares</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>van der Knaap</surname><given-names>E.</given-names></name><etal/></person-group><article-title>Exploiting the diversity of tomato: The development of a phenotypically and genetically detailed germplasm collection</article-title><source>Hortic. Res.</source><year>2020</year><volume>7</volume><fpage>66</fpage><pub-id pub-id-type=\"doi\">10.1038/s41438-020-0291-7</pub-id><pub-id pub-id-type=\"pmid\">32377357</pub-id><pub-id pub-id-type=\"pmcid\">PMC7192925</pub-id></element-citation></ref><ref id=\"B6-plants-14-03434\"><label>6.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Oltman</surname><given-names>A.E.</given-names></name><name name-style=\"western\"><surname>Jervis</surname><given-names>S.M.</given-names></name><name name-style=\"western\"><surname>Drake</surname><given-names>M.A.</given-names></name></person-group><article-title>Consumer Attitudes and Preferences for Fresh Market Tomatoes</article-title><source>J. Food Sci.</source><year>2014</year><volume>79</volume><fpage>S2091</fpage><lpage>S2097</lpage><pub-id pub-id-type=\"doi\">10.1111/1750-3841.12638</pub-id><pub-id pub-id-type=\"pmid\">25219281</pub-id></element-citation></ref><ref id=\"B7-plants-14-03434\"><label>7.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Tanksley</surname><given-names>S.D.</given-names></name></person-group><article-title>The Genetic, Developmental, and Molecular Bases of Fruit Size and Shape Variation in Tomato</article-title><source>Plant Cell.</source><year>2004</year><volume>16</volume><issue>(Suppl. S1)</issue><fpage>S181</fpage><lpage>S189</lpage><pub-id pub-id-type=\"doi\">10.1105/tpc.018119</pub-id><pub-id pub-id-type=\"pmid\">15131251</pub-id><pub-id pub-id-type=\"pmcid\">PMC2643388</pub-id></element-citation></ref><ref id=\"B8-plants-14-03434\"><label>8.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Mounet</surname><given-names>F.</given-names></name><name name-style=\"western\"><surname>Moing</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Garcia</surname><given-names>V.</given-names></name><name name-style=\"western\"><surname>Petit</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>Maucourt</surname><given-names>M.</given-names></name><name name-style=\"western\"><surname>Deborde</surname><given-names>C.</given-names></name><name name-style=\"western\"><surname>Bernillon</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Le Gall</surname><given-names>G.</given-names></name><name name-style=\"western\"><surname>Colquhoun</surname><given-names>I.</given-names></name><name name-style=\"western\"><surname>Defernez</surname><given-names>M.</given-names></name><etal/></person-group><article-title>Gene and Metabolite Regulatory Network Analysis of Early Developing Fruit Tissues Highlights New Candidate Genes for the Control of Tomato Fruit Composition and Development</article-title><source>Plant Physiol.</source><year>2009</year><volume>149</volume><fpage>1505</fpage><lpage>1528</lpage><pub-id pub-id-type=\"doi\">10.1104/pp.108.133967</pub-id><pub-id pub-id-type=\"pmid\">19144766</pub-id><pub-id pub-id-type=\"pmcid\">PMC2649409</pub-id></element-citation></ref><ref id=\"B9-plants-14-03434\"><label>9.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Barrero</surname><given-names>L.S.</given-names></name><name name-style=\"western\"><surname>Tanksley</surname><given-names>S.D.</given-names></name></person-group><article-title>Evaluating the genetic basis of multiple-locule fruit in a broad cross section of tomato cultivars</article-title><source>Theor. Appl. Genet.</source><year>2004</year><volume>109</volume><fpage>669</fpage><lpage>679</lpage><pub-id pub-id-type=\"doi\">10.1007/s00122-004-1676-y</pub-id><pub-id pub-id-type=\"pmid\">15292992</pub-id></element-citation></ref><ref id=\"B10-plants-14-03434\"><label>10.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>van der Knaap</surname><given-names>E.</given-names></name><name name-style=\"western\"><surname>Chakrabarti</surname><given-names>M.</given-names></name><name name-style=\"western\"><surname>Chu</surname><given-names>Y.H.</given-names></name><name name-style=\"western\"><surname>Clevenger</surname><given-names>J.P.</given-names></name><name name-style=\"western\"><surname>Illa-Berenguer</surname><given-names>E.</given-names></name><name name-style=\"western\"><surname>Huang</surname><given-names>Z.</given-names></name><name name-style=\"western\"><surname>Keyhaninejad</surname><given-names>N.</given-names></name><name name-style=\"western\"><surname>Mu</surname><given-names>Q.</given-names></name><name name-style=\"western\"><surname>Sun</surname><given-names>L.</given-names></name><name name-style=\"western\"><surname>Wang</surname><given-names>Y.</given-names></name><etal/></person-group><article-title>What lies beyond the eye: The molecular mechanisms regulating tomato fruit weight and shape</article-title><source>Front. Plant Sci.</source><year>2014</year><volume>5</volume><elocation-id>227</elocation-id><pub-id pub-id-type=\"doi\">10.3389/fpls.2014.00227</pub-id><pub-id pub-id-type=\"pmid\">24904622</pub-id><pub-id pub-id-type=\"pmcid\">PMC4034497</pub-id></element-citation></ref><ref id=\"B11-plants-14-03434\"><label>11.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Yang</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>Liu</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>Liang</surname><given-names>B.</given-names></name><name name-style=\"western\"><surname>Yang</surname><given-names>Q.</given-names></name><name name-style=\"western\"><surname>Li</surname><given-names>X.</given-names></name><name name-style=\"western\"><surname>Chen</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>Li</surname><given-names>H.</given-names></name><name name-style=\"western\"><surname>Lyu</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>Lin</surname><given-names>T.</given-names></name></person-group><article-title>Genomic basis of selective breeding from the closest wild relative of large-fruited tomato</article-title><source>Hortic. Res.</source><year>2023</year><volume>10</volume><fpage>uhad142</fpage><pub-id pub-id-type=\"doi\">10.1093/hr/uhad142</pub-id><pub-id pub-id-type=\"pmid\">37564272</pub-id><pub-id pub-id-type=\"pmcid\">PMC10410300</pub-id></element-citation></ref><ref id=\"B12-plants-14-03434\"><label>12.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Kumar</surname><given-names>P.</given-names></name><name name-style=\"western\"><surname>Irfan</surname><given-names>M.</given-names></name></person-group><article-title>Green ripe fruit in tomato: Unraveling the genetic tapestry from cultivated to wild varieties</article-title><source>J. Exp. Bot.</source><year>2024</year><volume>75</volume><fpage>3203</fpage><lpage>3205</lpage><pub-id pub-id-type=\"doi\">10.1093/jxb/erae149</pub-id><pub-id pub-id-type=\"pmid\">38845353</pub-id><pub-id pub-id-type=\"pmcid\">PMC11156801</pub-id></element-citation></ref><ref id=\"B13-plants-14-03434\"><label>13.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Zhang</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>Lyu</surname><given-names>H.</given-names></name><name name-style=\"western\"><surname>Chen</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>Cao</surname><given-names>X.</given-names></name><name name-style=\"western\"><surname>Du</surname><given-names>R.</given-names></name><name name-style=\"western\"><surname>Ma</surname><given-names>L.</given-names></name><name name-style=\"western\"><surname>Wang</surname><given-names>N.</given-names></name><name name-style=\"western\"><surname>Zhu</surname><given-names>Z.</given-names></name><name name-style=\"western\"><surname>Rao</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>Wang</surname><given-names>J.</given-names></name><etal/></person-group><article-title>Releasing a sugar brake generates sweeter tomato without yield penalty</article-title><source>Nature</source><year>2024</year><volume>635</volume><fpage>647</fpage><lpage>656</lpage><pub-id pub-id-type=\"doi\">10.1038/s41586-024-08186-2</pub-id><pub-id pub-id-type=\"pmid\">39537922</pub-id><pub-id pub-id-type=\"pmcid\">PMC11578880</pub-id></element-citation></ref><ref id=\"B14-plants-14-03434\"><label>14.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Yang</surname><given-names>T.</given-names></name><name name-style=\"western\"><surname>Ali</surname><given-names>M.</given-names></name><name name-style=\"western\"><surname>Lin</surname><given-names>L.</given-names></name><name name-style=\"western\"><surname>Li</surname><given-names>P.</given-names></name><name name-style=\"western\"><surname>He</surname><given-names>H.</given-names></name><name name-style=\"western\"><surname>Zhu</surname><given-names>Q.</given-names></name><name name-style=\"western\"><surname>Sun</surname><given-names>C.</given-names></name><name name-style=\"western\"><surname>Wu</surname><given-names>N.</given-names></name><name name-style=\"western\"><surname>Zhang</surname><given-names>X.</given-names></name><name name-style=\"western\"><surname>Huang</surname><given-names>T.</given-names></name><etal/></person-group><article-title>Recoloring tomato fruit by CRISPR/Cas9-mediated multiplex gene editing</article-title><source>Hortic. Res.</source><year>2022</year><volume>10</volume><fpage>uhac214</fpage><pub-id pub-id-type=\"doi\">10.1093/hr/uhac214</pub-id><pub-id pub-id-type=\"pmid\">36643741</pub-id><pub-id pub-id-type=\"pmcid\">PMC9832834</pub-id></element-citation></ref><ref id=\"B15-plants-14-03434\"><label>15.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Mansoor</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Karunathilake</surname><given-names>E.M.B.M.</given-names></name><name name-style=\"western\"><surname>Tuan</surname><given-names>T.T.</given-names></name><name name-style=\"western\"><surname>Chung</surname><given-names>Y.S.</given-names></name></person-group><article-title>Genomics, phenomics, and machine learning in transforming plant research: Advancements and challenges</article-title><source>Hortic. Plant J.</source><year>2025</year><volume>11</volume><fpage>486</fpage><lpage>503</lpage><pub-id pub-id-type=\"doi\">10.1016/j.hpj.2023.09.005</pub-id></element-citation></ref><ref id=\"B16-plants-14-03434\"><label>16.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Einspanier</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Tominello-Ramirez</surname><given-names>C.</given-names></name><name name-style=\"western\"><surname>Hasler</surname><given-names>M.</given-names></name><name name-style=\"western\"><surname>Barbacci</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Raffaele</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Stam</surname><given-names>R.</given-names></name></person-group><article-title>High-Resolution Disease Phenotyping Reveals Distinct Resistance Mechanisms of Tomato Crop Wild Relatives against Sclerotinia sclerotiorum</article-title><source>Plant Phenomics</source><year>2024</year><volume>6</volume><fpage>0214</fpage><pub-id pub-id-type=\"doi\">10.34133/plantphenomics.0214</pub-id><pub-id pub-id-type=\"pmid\">39105186</pub-id><pub-id pub-id-type=\"pmcid\">PMC11298253</pub-id></element-citation></ref><ref id=\"B17-plants-14-03434\"><label>17.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Zhou</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>Zhang</surname><given-names>Z.</given-names></name><name name-style=\"western\"><surname>Bao</surname><given-names>Z.</given-names></name><name name-style=\"western\"><surname>Li</surname><given-names>H.</given-names></name><name name-style=\"western\"><surname>Lyu</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>Zan</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>Wu</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>Cheng</surname><given-names>L.</given-names></name><name name-style=\"western\"><surname>Fang</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>Wu</surname><given-names>K.</given-names></name><etal/></person-group><article-title>Graph pangenome captures missing heritability and empowers tomato breeding</article-title><source>Nature</source><year>2022</year><volume>606</volume><fpage>527</fpage><lpage>534</lpage><pub-id pub-id-type=\"doi\">10.1038/s41586-022-04808-9</pub-id><pub-id pub-id-type=\"pmid\">35676474</pub-id><pub-id pub-id-type=\"pmcid\">PMC9200638</pub-id></element-citation></ref><ref id=\"B18-plants-14-03434\"><label>18.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Gan</surname><given-names>L.</given-names></name><name name-style=\"western\"><surname>Song</surname><given-names>M.</given-names></name><name name-style=\"western\"><surname>Wang</surname><given-names>X.</given-names></name><name name-style=\"western\"><surname>Yang</surname><given-names>N.</given-names></name><name name-style=\"western\"><surname>Li</surname><given-names>H.</given-names></name><name name-style=\"western\"><surname>Liu</surname><given-names>X.</given-names></name><name name-style=\"western\"><surname>Li</surname><given-names>Y.</given-names></name></person-group><article-title>Cytokinins are involved in regulation of tomato pericarp thickness and fruit size</article-title><source>Hortic. Res.</source><year>2022</year><volume>9</volume><fpage>uhab041</fpage><pub-id pub-id-type=\"doi\">10.1093/hr/uhab041</pub-id><pub-id pub-id-type=\"pmid\">35043193</pub-id><pub-id pub-id-type=\"pmcid\">PMC8968492</pub-id></element-citation></ref><ref id=\"B19-plants-14-03434\"><label>19.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Fanourakis</surname><given-names>D.</given-names></name><name name-style=\"western\"><surname>Papadakis</surname><given-names>V.M.</given-names></name><name name-style=\"western\"><surname>Machado</surname><given-names>M.</given-names></name><name name-style=\"western\"><surname>Psyllakis</surname><given-names>E.</given-names></name><name name-style=\"western\"><surname>Nektarios</surname><given-names>P.A.</given-names></name></person-group><article-title>Non-invasive leaf hydration status determination through convolutional neural networks based on multispectral images in chrysanthemum</article-title><source>Plant Growth Regul.</source><year>2024</year><volume>102</volume><fpage>485</fpage><lpage>496</lpage><pub-id pub-id-type=\"doi\">10.1007/s10725-023-01072-3</pub-id></element-citation></ref><ref id=\"B20-plants-14-03434\"><label>20.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Jiang</surname><given-names>X.</given-names></name><name name-style=\"western\"><surname>Wang</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>Xie</surname><given-names>K.</given-names></name><name name-style=\"western\"><surname>Cui</surname><given-names>C.</given-names></name><name name-style=\"western\"><surname>Du</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Shi</surname><given-names>X.</given-names></name><name name-style=\"western\"><surname>Yang</surname><given-names>W.</given-names></name><name name-style=\"western\"><surname>Zhai</surname><given-names>R.</given-names></name></person-group><article-title>PlantCaFo: An efficient few-shot plant disease recognition method based on foundation models</article-title><source>Plant Phenomics</source><year>2025</year><volume>7</volume><fpage>100024</fpage><pub-id pub-id-type=\"doi\">10.1016/j.plaphe.2025.100024</pub-id></element-citation></ref><ref id=\"B21-plants-14-03434\"><label>21.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Zhang</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>Xie</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>Zhang</surname><given-names>F.</given-names></name><name name-style=\"western\"><surname>Gao</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>Yang</surname><given-names>C.</given-names></name><name name-style=\"western\"><surname>Song</surname><given-names>C.</given-names></name><name name-style=\"western\"><surname>Rao</surname><given-names>W.</given-names></name><name name-style=\"western\"><surname>Zhang</surname><given-names>Y.</given-names></name></person-group><article-title>Greenhouse tomato detection and pose classification algorithm based on improved YOLOv5</article-title><source>Comput. Electron. Agric.</source><year>2024</year><volume>216</volume><fpage>108519</fpage><pub-id pub-id-type=\"doi\">10.1016/j.compag.2023.108519</pub-id></element-citation></ref><ref id=\"B22-plants-14-03434\"><label>22.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Zhang</surname><given-names>W.</given-names></name><name name-style=\"western\"><surname>Liu</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>Chen</surname><given-names>K.</given-names></name><name name-style=\"western\"><surname>Li</surname><given-names>H.</given-names></name><name name-style=\"western\"><surname>Duan</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>Wu</surname><given-names>W.</given-names></name><name name-style=\"western\"><surname>Shi</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>Guo</surname><given-names>W.</given-names></name></person-group><article-title>Lightweight fruit-detection algorithm for edge computing applications</article-title><source>Front. Plant Sci.</source><year>2021</year><volume>12</volume><elocation-id>740936</elocation-id><pub-id pub-id-type=\"doi\">10.3389/fpls.2021.740936</pub-id><pub-id pub-id-type=\"pmid\">34721466</pub-id><pub-id pub-id-type=\"pmcid\">PMC8548576</pub-id></element-citation></ref><ref id=\"B23-plants-14-03434\"><label>23.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Yu</surname><given-names>C.</given-names></name><name name-style=\"western\"><surname>Shi</surname><given-names>X.</given-names></name><name name-style=\"western\"><surname>Luo</surname><given-names>W.</given-names></name><name name-style=\"western\"><surname>Feng</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>Zheng</surname><given-names>Z.</given-names></name><name name-style=\"western\"><surname>Yorozu</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Hu</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>Guo</surname><given-names>J.</given-names></name></person-group><article-title>MLG-YOLO: A Model for Real-Time Accurate Detection and Localization of Winter Jujube in Complex Structured Orchard Environments</article-title><source>Plant Phenomics</source><year>2024</year><volume>6</volume><fpage>0258</fpage><pub-id pub-id-type=\"doi\">10.34133/plantphenomics.0258</pub-id><pub-id pub-id-type=\"pmid\">39314991</pub-id><pub-id pub-id-type=\"pmcid\">PMC11418275</pub-id></element-citation></ref><ref id=\"B24-plants-14-03434\"><label>24.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Wan</surname><given-names>P.</given-names></name><name name-style=\"western\"><surname>Toudeshki</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Tan</surname><given-names>H.</given-names></name><name name-style=\"western\"><surname>Ehsani</surname><given-names>R.</given-names></name></person-group><article-title>A methodology for fresh tomato maturity detection using computer vision</article-title><source>Comput. Electron. Agric.</source><year>2018</year><volume>146</volume><fpage>43</fpage><lpage>50</lpage><pub-id pub-id-type=\"doi\">10.1016/j.compag.2018.01.011</pub-id></element-citation></ref><ref id=\"B25-plants-14-03434\"><label>25.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Ireri</surname><given-names>D.</given-names></name><name name-style=\"western\"><surname>Belal</surname><given-names>E.</given-names></name><name name-style=\"western\"><surname>Okinda</surname><given-names>C.</given-names></name><name name-style=\"western\"><surname>Makange</surname><given-names>N.</given-names></name><name name-style=\"western\"><surname>Ji</surname><given-names>C.</given-names></name></person-group><article-title>A computer vision system for defect discrimination and grading in tomatoes using machine learning and image processing</article-title><source>Artif. Intell. Agric.</source><year>2019</year><volume>2</volume><fpage>28</fpage><lpage>37</lpage><pub-id pub-id-type=\"doi\">10.1016/j.aiia.2019.06.001</pub-id></element-citation></ref><ref id=\"B26-plants-14-03434\"><label>26.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Deng</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>Xi</surname><given-names>H.</given-names></name><name name-style=\"western\"><surname>Zhou</surname><given-names>G.</given-names></name><name name-style=\"western\"><surname>Chen</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Wang</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>Li</surname><given-names>L.</given-names></name><name name-style=\"western\"><surname>Hu</surname><given-names>Y.</given-names></name></person-group><article-title>An Effective Image-Based Tomato Leaf Disease Segmentation Method Using MC-UNet</article-title><source>Plant Phenomics</source><year>2023</year><volume>5</volume><fpage>0049</fpage><pub-id pub-id-type=\"doi\">10.34133/plantphenomics.0049</pub-id><pub-id pub-id-type=\"pmid\">37228512</pub-id><pub-id pub-id-type=\"pmcid\">PMC10204749</pub-id></element-citation></ref><ref id=\"B27-plants-14-03434\"><label>27.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Kang</surname><given-names>R.</given-names></name><name name-style=\"western\"><surname>Huang</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>Zhou</surname><given-names>X.</given-names></name><name name-style=\"western\"><surname>Ren</surname><given-names>N.</given-names></name><name name-style=\"western\"><surname>Sun</surname><given-names>S.</given-names></name></person-group><article-title>Toward Real Scenery: A Lightweight Tomato Growth Inspection Algorithm for Leaf Disease Detection and Fruit Counting</article-title><source>Plant Phenomics</source><year>2024</year><volume>6</volume><fpage>0174</fpage><pub-id pub-id-type=\"doi\">10.34133/plantphenomics.0174</pub-id><pub-id pub-id-type=\"pmid\">38629080</pub-id><pub-id pub-id-type=\"pmcid\">PMC11018486</pub-id></element-citation></ref><ref id=\"B28-plants-14-03434\"><label>28.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Tsaniklidis</surname><given-names>G.</given-names></name><name name-style=\"western\"><surname>Makraki</surname><given-names>T.</given-names></name><name name-style=\"western\"><surname>Papadimitriou</surname><given-names>D.</given-names></name><name name-style=\"western\"><surname>Nikoloudakis</surname><given-names>N.</given-names></name><name name-style=\"western\"><surname>Taheri-Garavand</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Fanourakis</surname><given-names>D.</given-names></name></person-group><article-title>Non-Destructive Estimation of Area and Greenness in Leaf and Seedling Scales: A Case Study in Cucumber</article-title><source>Agronomy</source><year>2025</year><volume>15</volume><elocation-id>2294</elocation-id><pub-id pub-id-type=\"doi\">10.3390/agronomy15102294</pub-id></element-citation></ref><ref id=\"B29-plants-14-03434\"><label>29.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Zhu</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>Gu</surname><given-names>Q.</given-names></name><name name-style=\"western\"><surname>Zhao</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>Wan</surname><given-names>H.</given-names></name><name name-style=\"western\"><surname>Wang</surname><given-names>R.</given-names></name><name name-style=\"western\"><surname>Zhang</surname><given-names>X.</given-names></name><name name-style=\"western\"><surname>Cheng</surname><given-names>Y.</given-names></name></person-group><article-title>Quantitative Extraction and Evaluation of Tomato Fruit Phenotypes Based on Image Recognition</article-title><source>Front. Plant Sci.</source><year>2022</year><volume>13</volume><elocation-id>859290</elocation-id><pub-id pub-id-type=\"doi\">10.3389/fpls.2022.859290</pub-id><pub-id pub-id-type=\"pmid\">35498696</pub-id><pub-id pub-id-type=\"pmcid\">PMC9044966</pub-id></element-citation></ref><ref id=\"B30-plants-14-03434\"><label>30.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Xu</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Shen</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>Wei</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>Li</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>He</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>Hu</surname><given-names>H.</given-names></name><name name-style=\"western\"><surname>Feng</surname><given-names>X.</given-names></name></person-group><article-title>Automatic plant phenotyping analysis of Melon (<italic toggle=\"yes\">Cucumis melo</italic> L.) germplasm resources using deep learning methods and computer vision</article-title><source>Plant Methods</source><year>2024</year><volume>20</volume><fpage>166</fpage><pub-id pub-id-type=\"doi\">10.1186/s13007-024-01293-1</pub-id><pub-id pub-id-type=\"pmid\">39472934</pub-id><pub-id pub-id-type=\"pmcid\">PMC11524006</pub-id></element-citation></ref><ref id=\"B31-plants-14-03434\"><label>31.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Xue</surname><given-names>W.</given-names></name><name name-style=\"western\"><surname>Ding</surname><given-names>H.</given-names></name><name name-style=\"western\"><surname>Jin</surname><given-names>T.</given-names></name><name name-style=\"western\"><surname>Meng</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>Wang</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Liu</surname><given-names>Z.</given-names></name><name name-style=\"western\"><surname>Ma</surname><given-names>X.</given-names></name><name name-style=\"western\"><surname>Li</surname><given-names>J.</given-names></name></person-group><article-title>CucumberAI: Cucumber Fruit Morphology Identification System Based on Artificial Intelligence</article-title><source>Plant Phenomics</source><year>2024</year><volume>6</volume><fpage>0193</fpage><pub-id pub-id-type=\"doi\">10.34133/plantphenomics.0193</pub-id><pub-id pub-id-type=\"pmid\">39144674</pub-id><pub-id pub-id-type=\"pmcid\">PMC11324094</pub-id></element-citation></ref><ref id=\"B32-plants-14-03434\"><label>32.</label><element-citation publication-type=\"confproc\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Park</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>Kim</surname><given-names>H.</given-names></name><name name-style=\"western\"><surname>Tai</surname><given-names>Y.-W.</given-names></name><name name-style=\"western\"><surname>Brown</surname><given-names>M.S.</given-names></name><name name-style=\"western\"><surname>Kweon</surname><given-names>I.</given-names></name></person-group><article-title>High quality depth map upsampling for 3D-TOF cameras</article-title><source>Proceedings of the 2011 International Conference on Computer Vision</source><conf-loc>Barcelona, Spain</conf-loc><conf-date>6&#8211;13 November 2011</conf-date><publisher-name>IEEE</publisher-name><publisher-loc>New York, NY, USA</publisher-loc><fpage>1623</fpage><lpage>1630</lpage></element-citation></ref><ref id=\"B33-plants-14-03434\"><label>33.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Mufti</surname><given-names>F.</given-names></name><name name-style=\"western\"><surname>Mahony</surname><given-names>R.</given-names></name></person-group><article-title>Statistical analysis of signal measurement in time-of-flight cameras</article-title><source>ISPRS J. Photogramm. Remote. Sens.</source><year>2011</year><volume>66</volume><fpage>720</fpage><lpage>731</lpage><pub-id pub-id-type=\"doi\">10.1016/j.isprsjprs.2011.06.004</pub-id></element-citation></ref><ref id=\"B34-plants-14-03434\"><label>34.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Kang</surname><given-names>Z.</given-names></name><name name-style=\"western\"><surname>Zhou</surname><given-names>B.</given-names></name><name name-style=\"western\"><surname>Fei</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Wang</surname><given-names>N.</given-names></name></person-group><article-title>Predicting the greenhouse crop morphological parameters based on RGB-D Computer Vision</article-title><source>Smart Agric. Technol.</source><year>2025</year><volume>11</volume><fpage>100968</fpage><pub-id pub-id-type=\"doi\">10.1016/j.atech.2025.100968</pub-id></element-citation></ref><ref id=\"B35-plants-14-03434\"><label>35.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Xie</surname><given-names>E.</given-names></name><name name-style=\"western\"><surname>Wang</surname><given-names>W.</given-names></name><name name-style=\"western\"><surname>Yu</surname><given-names>Z.</given-names></name><name name-style=\"western\"><surname>Anandkumar</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Alvarez</surname><given-names>J.M.</given-names></name><name name-style=\"western\"><surname>Luo</surname><given-names>P.</given-names></name></person-group><article-title>SegFormer: Simple and efficient design for semantic segmentation with transformers</article-title><source>Adv. Neural Inf. Process. Syst.</source><year>2021</year><volume>34</volume><fpage>12077</fpage><lpage>12090</lpage></element-citation></ref><ref id=\"B36-plants-14-03434\"><label>36.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Han</surname><given-names>D.</given-names></name><name name-style=\"western\"><surname>Wang</surname><given-names>Z.</given-names></name><name name-style=\"western\"><surname>Xia</surname><given-names>Z.</given-names></name><name name-style=\"western\"><surname>Han</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>Pu</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>Ge</surname><given-names>C.</given-names></name><name name-style=\"western\"><surname>Song</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>Song</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Zheng</surname><given-names>B.</given-names></name><name name-style=\"western\"><surname>Huang</surname><given-names>G.</given-names></name></person-group><article-title>Demystify mamba in vision: A linear attention perspective</article-title><source>Adv. Neural Inf. Process. Syst.</source><year>2024</year><volume>37</volume><fpage>127181</fpage><lpage>127203</lpage></element-citation></ref><ref id=\"B37-plants-14-03434\"><label>37.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Canny</surname><given-names>J.</given-names></name></person-group><article-title>A Computational Approach to Edge Detection</article-title><source>IEEE Trans. Pattern Anal. Mach. Intell.</source><year>1986</year><volume>PAMI-8</volume><fpage>679</fpage><lpage>698</lpage><pub-id pub-id-type=\"doi\">10.1109/TPAMI.1986.4767851</pub-id><pub-id pub-id-type=\"pmid\">21869365</pub-id></element-citation></ref><ref id=\"B38-plants-14-03434\"><label>38.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Vaswani</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Shazeer</surname><given-names>N.</given-names></name><name name-style=\"western\"><surname>Parmar</surname><given-names>N.</given-names></name><name name-style=\"western\"><surname>Uszkoreit</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>Jones</surname><given-names>L.</given-names></name><name name-style=\"western\"><surname>Gomez</surname><given-names>A.N.</given-names></name><name name-style=\"western\"><surname>Kaiser</surname><given-names>&#321;.</given-names></name><name name-style=\"western\"><surname>Polosukhin</surname><given-names>I.</given-names></name></person-group><article-title>Attention is all you need</article-title><source>arXiv</source><year>2017</year><pub-id pub-id-type=\"arxiv\">1706.03762</pub-id><pub-id pub-id-type=\"doi\">10.48550/arXiv.1706.03762</pub-id></element-citation></ref><ref id=\"B39-plants-14-03434\"><label>39.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Gu</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Dao</surname><given-names>T.</given-names></name></person-group><article-title>Mamba: Linear-time sequence modeling with selective state spaces</article-title><source>arXiv</source><year>2023</year><pub-id pub-id-type=\"doi\">10.48550/arXiv.2312.00752</pub-id><pub-id pub-id-type=\"arxiv\">2312.00752</pub-id></element-citation></ref><ref id=\"B40-plants-14-03434\"><label>40.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Jiang</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>Li</surname><given-names>Z.</given-names></name><name name-style=\"western\"><surname>Chen</surname><given-names>X.</given-names></name><name name-style=\"western\"><surname>Xie</surname><given-names>H.</given-names></name><name name-style=\"western\"><surname>Cai</surname><given-names>J.</given-names></name></person-group><article-title>Mlla-unet: Mamba-like linear attention in an efficient u-shape model for medical image segmentation</article-title><source>arXiv</source><year>2024</year><pub-id pub-id-type=\"arxiv\">2410.23738</pub-id></element-citation></ref><ref id=\"B41-plants-14-03434\"><label>41.</label><element-citation publication-type=\"confproc\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>He</surname><given-names>H.</given-names></name><name name-style=\"western\"><surname>Zhang</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>Cai</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>Chen</surname><given-names>H.</given-names></name><name name-style=\"western\"><surname>Hu</surname><given-names>X.</given-names></name><name name-style=\"western\"><surname>Gan</surname><given-names>Z.</given-names></name><name name-style=\"western\"><surname>Wang</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>Wang</surname><given-names>C.</given-names></name><name name-style=\"western\"><surname>Wu</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>Xie</surname><given-names>L.</given-names></name></person-group><article-title>Mobilemamba: Lightweight multi-receptive visual mamba network</article-title><source>Proceedings of the Computer Vision and Pattern Recognition Conference</source><conf-loc>Nashville, TN, USA</conf-loc><conf-date>11&#8211;15 June 2025</conf-date><fpage>4497</fpage><lpage>4507</lpage></element-citation></ref><ref id=\"B42-plants-14-03434\"><label>42.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Su</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>Ahmed</surname><given-names>M.</given-names></name><name name-style=\"western\"><surname>Lu</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>Pan</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Bo</surname><given-names>W.</given-names></name><name name-style=\"western\"><surname>Liu</surname><given-names>Y.</given-names></name></person-group><article-title>RoFormer: Enhanced transformer with Rotary Position Embedding</article-title><source>Neurocomputing</source><year>2024</year><volume>568</volume><fpage>127063</fpage><pub-id pub-id-type=\"doi\">10.1016/j.neucom.2023.127063</pub-id></element-citation></ref><ref id=\"B43-plants-14-03434\"><label>43.</label><element-citation publication-type=\"confproc\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Dong</surname><given-names>X.</given-names></name><name name-style=\"western\"><surname>Bao</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>Chen</surname><given-names>D.</given-names></name><name name-style=\"western\"><surname>Zhang</surname><given-names>W.</given-names></name><name name-style=\"western\"><surname>Yu</surname><given-names>N.</given-names></name><name name-style=\"western\"><surname>Yuan</surname><given-names>L.</given-names></name><name name-style=\"western\"><surname>Chen</surname><given-names>D.</given-names></name><name name-style=\"western\"><surname>Guo</surname><given-names>B.</given-names></name></person-group><article-title>Cswin transformer: A general vision transformer backbone with cross-shaped windows</article-title><source>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</source><conf-loc>New Orleans, LA, USA</conf-loc><conf-date>18&#8211;24 June 2022</conf-date><fpage>12124</fpage><lpage>12134</lpage></element-citation></ref><ref id=\"B44-plants-14-03434\"><label>44.</label><element-citation publication-type=\"confproc\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Ronneberger</surname><given-names>O.</given-names></name><name name-style=\"western\"><surname>Fischer</surname><given-names>P.</given-names></name><name name-style=\"western\"><surname>Brox</surname><given-names>T.</given-names></name></person-group><article-title>In U-net: Convolutional networks for biomedical image segmentation</article-title><source>Proceedings of the International Conference on Medical image Computing and Computer-Assisted Intervention</source><conf-loc>Munich, Germany</conf-loc><conf-date>9&#8211;15 October 2015</conf-date><publisher-name>Springer</publisher-name><publisher-loc>Berlin/Heidelberg, Germany</publisher-loc><year>2015</year><fpage>234</fpage><lpage>241</lpage></element-citation></ref><ref id=\"B45-plants-14-03434\"><label>45.</label><element-citation publication-type=\"confproc\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Chen</surname><given-names>L.-C.</given-names></name><name name-style=\"western\"><surname>Zhu</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>Papandreou</surname><given-names>G.</given-names></name><name name-style=\"western\"><surname>Schroff</surname><given-names>F.</given-names></name><name name-style=\"western\"><surname>Adam</surname><given-names>H.</given-names></name></person-group><article-title>Encoder-decoder with atrous separable convolution for semantic image segmentation</article-title><source>Proceedings of the European Conference on Computer Vision (ECCV)</source><conf-loc>Munich, Germany</conf-loc><conf-date>8&#8211;14 September 2018</conf-date><fpage>801</fpage><lpage>818</lpage></element-citation></ref><ref id=\"B46-plants-14-03434\"><label>46.</label><element-citation publication-type=\"confproc\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Xu</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>Xiong</surname><given-names>Z.</given-names></name><name name-style=\"western\"><surname>Bhattacharyya</surname><given-names>S.P.</given-names></name></person-group><article-title>PIDNet: A real-time semantic segmentation network inspired by PID controllers</article-title><source>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</source><conf-loc>Vancouver, BC, Canada</conf-loc><conf-date>8&#8211;22 June 2023</conf-date><fpage>19529</fpage><lpage>19539</lpage></element-citation></ref><ref id=\"B47-plants-14-03434\"><label>47.</label><element-citation publication-type=\"confproc\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Liu</surname><given-names>Z.</given-names></name><name name-style=\"western\"><surname>Mao</surname><given-names>H.</given-names></name><name name-style=\"western\"><surname>Wu</surname><given-names>C.Y.</given-names></name><name name-style=\"western\"><surname>Feichtenhofer</surname><given-names>C.</given-names></name><name name-style=\"western\"><surname>Darrell</surname><given-names>T.</given-names></name><name name-style=\"western\"><surname>Xie</surname><given-names>S.</given-names></name></person-group><article-title>A convnet for the 2020s</article-title><source>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</source><conf-loc>New Orleans, LA, USA</conf-loc><conf-date>18&#8211;22 June 2022</conf-date><fpage>11976</fpage><lpage>11986</lpage></element-citation></ref><ref id=\"B48-plants-14-03434\"><label>48.</label><element-citation publication-type=\"confproc\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Cheng</surname><given-names>B.</given-names></name><name name-style=\"western\"><surname>Misra</surname><given-names>I.</given-names></name><name name-style=\"western\"><surname>Schwing</surname><given-names>A.G.</given-names></name><name name-style=\"western\"><surname>Kirillov</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Girdhar</surname><given-names>R.</given-names></name></person-group><article-title>In Masked-attention mask transformer for universal image segmentation</article-title><source>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</source><conf-loc>New Orleans, LA, USA</conf-loc><conf-date>18&#8211;22 June 2022</conf-date><fpage>1290</fpage><lpage>1299</lpage></element-citation></ref><ref id=\"B49-plants-14-03434\"><label>49.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Assad</surname><given-names>T.</given-names></name><name name-style=\"western\"><surname>Jabeen</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Roy</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Bhat</surname><given-names>N.</given-names></name><name name-style=\"western\"><surname>Maqbool</surname><given-names>N.</given-names></name><name name-style=\"western\"><surname>Yadav</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Aijaz</surname><given-names>T.</given-names></name></person-group><article-title>Using an image processing technique, correlating the lycopene and moisture content in dried tomatoes</article-title><source>Food Humanit.</source><year>2024</year><volume>2</volume><fpage>100186</fpage><pub-id pub-id-type=\"doi\">10.1016/j.foohum.2023.11.013</pub-id></element-citation></ref><ref id=\"B50-plants-14-03434\"><label>50.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Cardellicchio</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Solimani</surname><given-names>F.</given-names></name><name name-style=\"western\"><surname>Dimauro</surname><given-names>G.</given-names></name><name name-style=\"western\"><surname>Petrozza</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Summerer</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Cellini</surname><given-names>F.</given-names></name><name name-style=\"western\"><surname>Ren&#242;</surname><given-names>V.</given-names></name></person-group><article-title>Detection of tomato plant phenotyping traits using YOLOv5-based single stage detectors</article-title><source>Comput. Electron. Agric.</source><year>2023</year><volume>207</volume><fpage>107757</fpage><pub-id pub-id-type=\"doi\">10.1016/j.compag.2023.107757</pub-id></element-citation></ref><ref id=\"B51-plants-14-03434\"><label>51.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Rong</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>Zhou</surname><given-names>H.</given-names></name><name name-style=\"western\"><surname>Zhang</surname><given-names>F.</given-names></name><name name-style=\"western\"><surname>Yuan</surname><given-names>T.</given-names></name><name name-style=\"western\"><surname>Wang</surname><given-names>P.</given-names></name></person-group><article-title>Tomato cluster detection and counting using improved YOLOv5 based on RGB-D fusion</article-title><source>Comput. Electron. Agric.</source><year>2023</year><volume>207</volume><fpage>107741</fpage><pub-id pub-id-type=\"doi\">10.1016/j.compag.2023.107741</pub-id></element-citation></ref><ref id=\"B52-plants-14-03434\"><label>52.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Wang</surname><given-names>X.</given-names></name><name name-style=\"western\"><surname>Liu</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>Zhu</surname><given-names>X.</given-names></name></person-group><article-title>Early real-time detection algorithm of tomato diseases and pests in the natural environment</article-title><source>Plant Methods</source><year>2021</year><volume>17</volume><fpage>43</fpage><pub-id pub-id-type=\"doi\">10.1186/s13007-021-00745-2</pub-id><pub-id pub-id-type=\"pmid\">33892765</pub-id><pub-id pub-id-type=\"pmcid\">PMC8067659</pub-id></element-citation></ref><ref id=\"B53-plants-14-03434\"><label>53.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Rodr&#237;guez</surname><given-names>G.R.</given-names></name><name name-style=\"western\"><surname>Moyseenko</surname><given-names>J.B.</given-names></name><name name-style=\"western\"><surname>Robbins</surname><given-names>M.D.</given-names></name><name name-style=\"western\"><surname>Huarachi Morej&#243;n</surname><given-names>N.</given-names></name><name name-style=\"western\"><surname>Francis</surname><given-names>D.M.</given-names></name><name name-style=\"western\"><surname>van der Knaap</surname><given-names>E.</given-names></name></person-group><article-title>Tomato Analyzer: A Useful Software Application to Collect Accurate and Detailed Morphological and Colorimetric Data from Two-dimensional Objects</article-title><source>J. Vis. Exp.</source><year>2010</year><volume>37</volume><fpage>1856</fpage><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.3791/1856</pub-id><pub-id pub-id-type=\"pmcid\">PMC3146067</pub-id><pub-id pub-id-type=\"pmid\">20234339</pub-id></element-citation></ref><ref id=\"B54-plants-14-03434\"><label>54.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Lei</surname><given-names>L.</given-names></name><name name-style=\"western\"><surname>Yang</surname><given-names>Q.</given-names></name><name name-style=\"western\"><surname>Yang</surname><given-names>L.</given-names></name><name name-style=\"western\"><surname>Shen</surname><given-names>T.</given-names></name><name name-style=\"western\"><surname>Wang</surname><given-names>R.</given-names></name><name name-style=\"western\"><surname>Fu</surname><given-names>C.</given-names></name></person-group><article-title>Deep learning implementation of image segmentation in agricultural applications: A comprehensive review</article-title><source>Artif. Intell. Rev.</source><year>2024</year><volume>57</volume><fpage>149</fpage><pub-id pub-id-type=\"doi\">10.1007/s10462-024-10775-6</pub-id></element-citation></ref><ref id=\"B55-plants-14-03434\"><label>55.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Leide</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>Hildebrandt</surname><given-names>U.</given-names></name><name name-style=\"western\"><surname>Hartung</surname><given-names>W.</given-names></name><name name-style=\"western\"><surname>Riederer</surname><given-names>M.</given-names></name><name name-style=\"western\"><surname>Vogg</surname><given-names>G.</given-names></name></person-group><article-title>Abscisic acid mediates the formation of a suberized stem scar tissue in tomato fruits</article-title><source>New Phytol.</source><year>2012</year><volume>194</volume><fpage>402</fpage><lpage>415</lpage><pub-id pub-id-type=\"doi\">10.1111/j.1469-8137.2011.04047.x</pub-id><pub-id pub-id-type=\"pmid\">22296281</pub-id></element-citation></ref></ref-list></back><floats-group><fig position=\"float\" id=\"plants-14-03434-f001\" orientation=\"portrait\"><label>Figure 1</label><caption><p>Examples of tomato fruit section images. (<bold>a</bold>) Tomato fruit longitudinal section images; (<bold>b</bold>) Tomato fruit transverse section images.</p></caption><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" position=\"float\" orientation=\"portrait\" xlink:href=\"plants-14-03434-g001.jpg\"/></fig><fig position=\"float\" id=\"plants-14-03434-f002\" orientation=\"portrait\"><label>Figure 2</label><caption><p>Preprocessing workflow for tomato fruit section images. (<bold>a</bold>) Binary thresholding of tomato fruit images to remove background interference; (<bold>b</bold>) Cropping of tomato fruit images to 512 &#215; 512 pixels.</p></caption><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" position=\"float\" orientation=\"portrait\" xlink:href=\"plants-14-03434-g002.jpg\"/></fig><fig position=\"float\" id=\"plants-14-03434-f003\" orientation=\"portrait\"><label>Figure 3</label><caption><p>Schematic diagram of the SegFormer-MLLA model structure. (<bold>a</bold>) Overall architecture of SegFormer-MLLA, incorporating MLLA blocks to replace transformer blocks for improved feature extraction efficiency; (<bold>b</bold>) MLLA attention module, designed to capture both global and local features, enhancing the precision of tomato phenotypic trait analysis.</p></caption><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" position=\"float\" orientation=\"portrait\" xlink:href=\"plants-14-03434-g003.jpg\"/></fig><fig position=\"float\" id=\"plants-14-03434-f004\" orientation=\"portrait\"><label>Figure 4</label><caption><p>Schematic diagram of the HDRM model structure. The model is trained using captured depth information and optimal depth information to generate final prediction results.</p></caption><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" position=\"float\" orientation=\"portrait\" xlink:href=\"plants-14-03434-g004.jpg\"/></fig><fig position=\"float\" id=\"plants-14-03434-f005\" orientation=\"portrait\"><label>Figure 5</label><caption><p>Workflow for detecting phenotypic traits of tomato fruit. (<bold>a</bold>) Phenotypic detection of longitudinal sections; (<bold>b</bold>) Phenotypic detection of transverse sections.</p></caption><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" position=\"float\" orientation=\"portrait\" xlink:href=\"plants-14-03434-g005.jpg\"/></fig><fig position=\"float\" id=\"plants-14-03434-f006\" orientation=\"portrait\"><label>Figure 6</label><caption><p>Tomato fruit phenotypic trait detection performance evaluation. (<bold>a</bold>&#8211;<bold>f</bold>) Assessment of phenotypic traits, including transverse diameter, longitudinal diameter, fruit shape index, mesocarp thickness, stem scar width, and depth.</p></caption><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" position=\"float\" orientation=\"portrait\" xlink:href=\"plants-14-03434-g006.jpg\"/></fig><fig position=\"float\" id=\"plants-14-03434-f007\" orientation=\"portrait\"><label>Figure 7</label><caption><p>Residual distributions of fruit stem scar width (<bold>a</bold>) and depth (<bold>b</bold>).</p></caption><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" position=\"float\" orientation=\"portrait\" xlink:href=\"plants-14-03434-g007.jpg\"/></fig><fig position=\"float\" id=\"plants-14-03434-f008\" orientation=\"portrait\"><label>Figure 8</label><caption><p>Detection results for tomato fruit. (<bold>a</bold>) Segmentation results for stem scar structure; (<bold>b</bold>) Segmentation results for locule structure; (<bold>c</bold>) Detection results for locule and mesocarp color.</p></caption><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" position=\"float\" orientation=\"portrait\" xlink:href=\"plants-14-03434-g008.jpg\"/></fig><fig position=\"float\" id=\"plants-14-03434-f009\" orientation=\"portrait\"><label>Figure 9</label><caption><p>HDRM model detection performance evaluation. (<bold>a</bold>,<bold>b</bold>) HDRM model assessment through residual scatter plot and comparison of predicted versus ground-truth depth values.</p></caption><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" position=\"float\" orientation=\"portrait\" xlink:href=\"plants-14-03434-g009.jpg\"/></fig><fig position=\"float\" id=\"plants-14-03434-f010\" orientation=\"portrait\"><label>Figure 10</label><caption><p>Schematic diagram of the automated detection equipment and software for tomato fruit phenotyping. (<bold>a</bold>) Main functional modules of the detection system; (<bold>b</bold>) Structural diagram of the equipment; (<bold>c</bold>) Detection process for longitudinal and transverse sections of tomato fruit phenotypes; (<bold>d</bold>) Results of tomato fruit phenotype detection.</p></caption><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" position=\"float\" orientation=\"portrait\" xlink:href=\"plants-14-03434-g010.jpg\"/></fig><table-wrap position=\"float\" id=\"plants-14-03434-t001\" orientation=\"portrait\"><object-id pub-id-type=\"pii\">plants-14-03434-t001_Table 1</object-id><label>Table 1</label><caption><p>Evaluation results for tomato stem scar segmentation.</p></caption><table frame=\"hsides\" rules=\"groups\"><thead><tr><th rowspan=\"2\" align=\"center\" valign=\"middle\" style=\"border-top:solid thin;border-bottom:solid thin\" colspan=\"1\">Models</th><th colspan=\"5\" align=\"center\" valign=\"middle\" style=\"border-top:solid thin;border-bottom:solid thin\" rowspan=\"1\">Stem Scar</th></tr><tr><th align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">IoU (%)</th><th align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Dice (%)</th><th align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Precision (%)</th><th align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Recall (%)</th><th align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Parameters (M)</th></tr></thead><tbody><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">Unet</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">74.52</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">85.32</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">84.97</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">85.26</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">29.06</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">Deeplabv3+</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">74.78</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">85.41</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">85.73</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">85.41</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">43.59</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">Pidnet</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">73.37</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">84.64</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">85.14</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">84.15</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">7.72</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">Convnext</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">76.95</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">86.97</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">87.96</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">86.01</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">59.28</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">Mask2former</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">77.64</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">89.12</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">85.76</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">89.12</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">44.00</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">SegFormer-b0</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">77.82</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">87.46</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">87.34</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">87.58</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">3.72</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">SegFormer-MLLA-a</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">77.86</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">87.55</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">87.59</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">87.51</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">3.06</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">SegFormer-b2</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">78.29</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">87.82</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">88.44</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">87.21</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">24.72</td></tr><tr><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">SegFormer-MLLA-b</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">78.36</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">87.87</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">88.15</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">87.59</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">18.98</td></tr></tbody></table></table-wrap><table-wrap position=\"float\" id=\"plants-14-03434-t002\" orientation=\"portrait\"><object-id pub-id-type=\"pii\">plants-14-03434-t002_Table 2</object-id><label>Table 2</label><caption><p>Evaluation results for tomato locules segmentation.</p></caption><table frame=\"hsides\" rules=\"groups\"><thead><tr><th rowspan=\"2\" align=\"center\" valign=\"middle\" style=\"border-top:solid thin;border-bottom:solid thin\" colspan=\"1\">Models</th><th colspan=\"5\" align=\"center\" valign=\"middle\" style=\"border-top:solid thin;border-bottom:solid thin\" rowspan=\"1\">Locule</th></tr><tr><th align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">IoU (%)</th><th align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Dice (%)</th><th align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Precision (%)</th><th align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Recall (%)</th><th align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Parameters (M)</th></tr></thead><tbody><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">Unet</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">84.26</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">91.47</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">92.02</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">90.93</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">29.06</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">Deeplabv3+</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">84.43</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">91.56</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">92.03</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">91.10</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">43.59</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">Pidnet</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">84.33</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">91.50</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">92.27</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">90.74</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">7.72</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">Convnext</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">84.62</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">91.67</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">91.46</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">91.88</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">59.28</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">Mask2former</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">85.15</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">91.98</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">92.48</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">91.49</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">44.00</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">SegFormer-b0</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">84.84</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">91.80</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">92.33</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">91.27</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">3.72</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">SegFormer-MLLA-a</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">85.00</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">91.88</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">91.88</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">91.91</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">3.06</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">SegFormer-b2</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">85.04</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">91.92</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">92.57</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">91.27</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">24.72</td></tr><tr><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">SegFormer-MLLA-b</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">85.24</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">92.03</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">92.47</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">91.59</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">18.98</td></tr></tbody></table></table-wrap><table-wrap position=\"float\" id=\"plants-14-03434-t003\" orientation=\"portrait\"><object-id pub-id-type=\"pii\">plants-14-03434-t003_Table 3</object-id><label>Table 3</label><caption><p>Performance comparison of different modeling strategies for predicting fruit morphological parameters.</p></caption><table frame=\"hsides\" rules=\"groups\"><thead><tr><th colspan=\"2\" align=\"center\" valign=\"middle\" style=\"border-top:solid thin;border-bottom:solid thin\" rowspan=\"1\">HDRM</th><th colspan=\"2\" align=\"center\" valign=\"middle\" style=\"border-top:solid thin;border-bottom:solid thin\" rowspan=\"1\">Transverse <break/>Diameter (mm)</th><th colspan=\"2\" align=\"center\" valign=\"middle\" style=\"border-top:solid thin;border-bottom:solid thin\" rowspan=\"1\">Longitudinal <break/>Diameter (mm)</th></tr><tr><th align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Random Forest</th><th align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Parametric Model</th><th align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">\n<italic toggle=\"yes\">RMSE</italic>\n</th><th align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">\n<italic toggle=\"yes\">MAE</italic>\n</th><th align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">\n<italic toggle=\"yes\">RMSE</italic>\n</th><th align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">\n<italic toggle=\"yes\">MAE</italic>\n</th></tr></thead><tbody><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">&#160;</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">&#160;</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">2.312</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">2.176</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">2.824</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">2.600</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">&#8730;</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">&#160;</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">1.153</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.946</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.991</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.818</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">&#160;</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">&#8730;</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">1.072</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.891</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.970</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.808</td></tr><tr><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">&#8730;</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">&#8730;</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\"> 1.064 </td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">0.880</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">0.965</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">0.803</td></tr></tbody></table><table-wrap-foot><fn><p>The symbol &#8730; indicates that the corresponding module was used</p></fn></table-wrap-foot></table-wrap><table-wrap position=\"float\" id=\"plants-14-03434-t004\" orientation=\"portrait\"><object-id pub-id-type=\"pii\">plants-14-03434-t004_Table 4</object-id><label>Table 4</label><caption><p>Ablation Study Results of the Intelligent Tomato Fruit Detection Framework.</p></caption><table frame=\"hsides\" rules=\"groups\"><thead><tr><th rowspan=\"2\" align=\"center\" valign=\"middle\" style=\"border-top:solid thin;border-bottom:solid thin\" colspan=\"1\">SegFormer</th><th rowspan=\"2\" align=\"center\" valign=\"middle\" style=\"border-top:solid thin;border-bottom:solid thin\" colspan=\"1\">MLLA</th><th colspan=\"2\" align=\"center\" valign=\"middle\" style=\"border-top:solid thin;border-bottom:solid thin\" rowspan=\"1\">HDRM</th><th colspan=\"2\" align=\"center\" valign=\"middle\" style=\"border-top:solid thin;border-bottom:solid thin\" rowspan=\"1\">Mesocarp&#160;Thickness </th><th colspan=\"2\" align=\"center\" valign=\"middle\" style=\"border-top:solid thin;border-bottom:solid thin\" rowspan=\"1\">Stem&#160;Scar&#160;Width </th><th colspan=\"2\" align=\"center\" valign=\"middle\" style=\"border-top:solid thin;border-bottom:solid thin\" rowspan=\"1\">Stem&#160;Scar&#160;Depth </th></tr><tr><th align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Random Forest</th><th align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Parametric Model</th><th align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">\n<italic toggle=\"yes\">RMSE</italic>\n</th><th align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">\n<italic toggle=\"yes\">MAE</italic>\n</th><th align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">\n<italic toggle=\"yes\">RMSE</italic>\n</th><th align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">\n<italic toggle=\"yes\">MAE</italic>\n</th><th align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">\n<italic toggle=\"yes\">RMSE</italic>\n</th><th align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">\n<italic toggle=\"yes\">MAE</italic>\n</th></tr></thead><tbody><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">&#8730;</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">&#160;</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">&#160;</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">&#160;</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.682</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.586</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">1.163</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.957</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.553</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.457</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">&#8730;</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">&#8730;</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">&#160;</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">&#160;</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.686</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.527</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">1.147</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.944</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.473</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.371</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">&#8730;</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">&#160;</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">&#8730;</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">&#160;</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.484</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.378</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.990</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.740</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.447</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.367</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">&#8730;</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">&#8730;</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">&#8730;</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">&#160;</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.371</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.322</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.983</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.777</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.441</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.360</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">&#8730;</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">&#160;</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">&#160;</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">&#8730;</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.463</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.355</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.998</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.780</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.449</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.367</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">&#8730;</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">&#8730;</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">&#160;</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">&#8730;</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\"> 0.348 </td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.304</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.940</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.735</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.399</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.319</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">&#8730;</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">&#160;</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">&#8730;</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">&#8730;</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.458</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.353</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.986</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.772</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.447</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.367</td></tr><tr><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">&#8730;</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">&#8730;</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">&#8730;</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">&#8730;</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">0.349</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">0.303</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">0.937</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">0.735</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">0.397</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">0.315</td></tr></tbody></table><table-wrap-foot><fn><p>The symbol &#8730; indicates that the corresponding module was used</p></fn></table-wrap-foot></table-wrap><table-wrap position=\"float\" id=\"plants-14-03434-t005\" orientation=\"portrait\"><object-id pub-id-type=\"pii\">plants-14-03434-t005_Table 5</object-id><label>Table 5</label><caption><p>Comparison of Measured and Detected Phenotypes of Tomato Fruits Across Multiple Positions.</p></caption><table frame=\"hsides\" rules=\"groups\"><thead><tr><th rowspan=\"2\" align=\"center\" valign=\"middle\" style=\"border-top:solid thin;border-bottom:solid thin\" colspan=\"1\">Phenotypic Trait</th><th rowspan=\"2\" align=\"center\" valign=\"middle\" style=\"border-top:solid thin;border-bottom:solid thin\" colspan=\"1\">Measure<break/>Size</th><th colspan=\"6\" align=\"center\" valign=\"middle\" style=\"border-top:solid thin;border-bottom:solid thin\" rowspan=\"1\">Position</th></tr><tr><th align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">1</th><th align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">2</th><th align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">3</th><th align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">4</th><th align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">5</th><th align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">6</th></tr></thead><tbody><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">transverse diameter (mm)</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">74.91</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">74.61</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">73.36</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">75.17</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">74.28</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">73.20</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">74.48</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">longitudinal diameter (mm)</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">59.86</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">59.91</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">59.15</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">59.68</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">59.85</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">59.41</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">59.35</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">shape index</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.80</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.80</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.81</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.79</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.81</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.81</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.80</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">stem scar width (mm)</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">13.23</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">13.61</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">13.16</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">13.34</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">13.61</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">13.27</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">12.91</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">stem scar depth (mm)</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">4.67</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">4.64</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">5.13</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">4.99</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">5.28</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">5.32</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">5.31</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">mesocarp thickness (mm)</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">8.36</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">8.63</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">8.28</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">8.42</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">8.45</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">8.30</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">8.47</td></tr><tr><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">locule number</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">6</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">6</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">6</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">6</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">6</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">6</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">6</td></tr></tbody></table></table-wrap></floats-group></article></pmc-articleset>",
  "text": "pmc Plants (Basel) Plants (Basel) 2909 plants plants Plants 2223-7747 Multidisciplinary Digital Publishing Institute (MDPI) PMC12655590 PMC12655590.1 12655590 12655590 41304585 10.3390/plants14223434 plants-14-03434 1 Article Depth Imaging-Based Framework for Efficient Phenotypic Recognition in Tomato Fruit Li Junqing Conceptualization Methodology Formal analysis Writing &#8211; review &amp; editing Supervision Project administration 1 Dong Guoao Conceptualization Methodology Software Investigation Data curation Writing &#8211; original draft Visualization 1 Liu Yuhang Data curation 2 Yuan Hua Validation 1 Xu Zheng Validation 1 https://orcid.org/0000-0002-8494-1742 Nie Wenfeng Resources Writing &#8211; review &amp; editing 2 Zhang Yan Formal analysis Resources 2 Shi Qinghua Formal analysis Resources Writing &#8211; review &amp; editing Funding acquisition 2 * Martellos Stefano Academic Editor 1 College of Information Science and Engineering, Shandong Agricultural University, Tai&#8217;an 271018, China; junqing.li@sdau.edu.cn (J.L.); d_guoao@163.com (G.D.); 17661290553@163.com (H.Y.); xbzz101800@163.com (Z.X.) 2 College of Horticulture Science and Engineering, Shandong Agricultural University, Tai&#8217;an 271018, China; 13210693446@163.com (Y.L.); nwf2024@sdau.edu.cn (W.N.); zhangyan2022@sdau.edu.cn (Y.Z.) * Correspondence: qhshi@sdau.edu.cn 10 11 2025 11 2025 14 22 501331 3434 04 10 2025 03 11 2025 06 11 2025 10 11 2025 27 11 2025 28 11 2025 &#169; 2025 by the authors. 2025 https://creativecommons.org/licenses/by/4.0/ Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license ( https://creativecommons.org/licenses/by/4.0/ ). Tomato is a globally significant horticultural crop with substantial economic and nutritional value. High-precision phenotypic analysis of tomato fruit characteristics, enabled by computer vision and image-based phenotyping technologies, is essential for varietal selection and automated quality evaluation. An intelligent detection framework for phenomics analysis of tomato fruits was developed in this study, which combines image processing techniques with deep learning algorithms to automate the extraction and quantitative analysis of 12 phenotypic traits, including fruit morphology, structure, color and so on. First, a dataset of tomato fruit section images was developed using a depth camera. Second, the SegFormer model was improved by incorporating the MLLA linear attention mechanism, and a lightweight SegFormer-MLLA model for tomato fruit phenotype segmentation was proposed. Accurate segmentation of tomato fruit stem scars and locular structures was achieved, with significantly reduced computational cost by the proposed model. Finally, a Hybrid Depth Regression Model was designed to optimize the estimation of optimal depth. By fusing RGB and depth information, the framework enabled efficient detection of key phenotypic traits, including fruit longitudinal diameter, transverse diameter, mesocarp thickness, and depth and width of stem scar. Experimental results demonstrated a high correlation between the phenotypic parameters detected by the proposed model and the manually measured values, effectively validating the accuracy and feasibility of the model. Hence, we developed an equipment automatically phenotyping tomato fruits and the corresponding software system, providing reliable data support for precision tomato breeding and intelligent cultivation, as well as a reference methodology for phenotyping other fruit crops. tomato fruit phenotyping phenotypic recognition deep learning depth imaging phenotypic analysis Shandong Vegetable Research System SDAIT-05 Key Research and Development Program of Shandong Province 2022TZXD0025 This work was supported by the Shandong Vegetable Research System (SDAIT-05), and the Key Research and Development Program of Shandong Province (2022TZXD0025). pmc-status-qastatus 0 pmc-status-live yes pmc-status-embargo no pmc-status-released yes pmc-prop-open-access yes pmc-prop-olf no pmc-prop-manuscript no pmc-prop-legally-suppressed no pmc-prop-has-pdf yes pmc-prop-has-supplement no pmc-prop-pdf-only no pmc-prop-suppress-copyright no pmc-prop-is-real-version no pmc-prop-is-scanned-article no pmc-prop-preprint no pmc-prop-in-epmc yes 1. Introduction Tomato ( Solanum lycopersicum L.) is a globally significant horticultural crop with high economic and nutritional value, containing functional substances, such as vitamin C and lycopene [ 1 , 2 ]. Modern cultivated tomatoes originated from the red-fruited wild species ( Solanum pimpinellifolium ) through domestication and selection for traits such as fruit size and sugar accumulation [ 3 ]. In recent years, advances in breeding technologies have resulted in a diversification of tomato varieties, significantly enriching the available germplasm resources [ 4 , 5 ]. Phenotypic characteristics of tomato fruits, including shape, color and texture, directly influence their commercial grading, mechanized harvesting, and post-harvest quality [ 6 ]. For instance, traditional soft-textured tomato varieties are unsuitable for mechanical harvesting, prompting breeding efforts toward firmer textures [ 7 ]. The locular gel (a gelatinous tissue within fruit locules) in tomato fruits constitutes the second most abundant tissue after the pericarp, accounting for approximately 23% of the fruit&#8217;s fresh weight [ 8 ]. Research has demonstrated that the size and number of locules affect fruit weight, shape, and texture, and to some extent influence flavor and mouthfeel [ 9 , 10 ]. In tomato breeding, traits such as locule number, mesocarp thickness, transverse and longitudinal diameters, fruit shape index, and color are emphasized by breeders. Additionally, the depth and width of the stem scar in the fruit are identified as important factors affecting the appearance and commercial value of tomatoes. Underlying genetic regulatory mechanisms of tomato fruit traits, including size, shape, color, taste and nutritional content, have emerged as key research foci in plant science [ 11 , 12 , 13 , 14 ]. Modern tomato breeding strategies have transitioned from phenotypic selection to integrated genotype-phenotype prediction [ 15 ]. This shift has made the acquisition of high-throughput phenomics data a critical step in tomato breeding. Current phenotyping relies heavily on manual measurements, which are subjective, inefficient, and unscalable for high-throughput breeding. Through in-depth studies, researchers have achieved significant breakthroughs in understanding the genetic basis and regulatory mechanisms of tomato development [ 16 , 17 , 18 ]. However, the morphological diversity of tomato fruits, such as locule number ranging from 3 to 10, and their developmental dynamics pose substantial challenges. In this context, the development of high-precision and rapid techniques for identifying and measuring tomato fruit phenotypes is essential for the quantitative analysis of fruit traits. Such techniques also provide high-frequency dynamic phenomics inputs for genomic selection models, which are significant for enhancing the efficiency of tomato fruit improvement and establishing robust fruit evaluation models. In recent years, innovations in artificial intelligence technology have injected strong momentum into crop phenomics. Notably, the integration of computer vision and deep learning has significantly enhanced the automated parsing capabilities of phenotypic parameters [ 19 , 20 , 21 ], providing technical support for efficient breeding decisions. In the field of fruit detection, Zhang et al. [ 22 ] proposed a lightweight fruit-detection algorithm using Light-CSPNet as the backbone network. By incorporating improved feature extraction modules, downsampling methods, and feature fusion modules, they achieved real-time detection of tomato fruits on edge devices while maintaining detection accuracy. For the task of winter jujube detection, Yu et al. [ 23 ] introduced an MLG-YOLO model based on YOLOv8n, which achieves three-dimensional localization of winter jujubes by integrating an RGB-D camera. In the field of maturity assessment, Wan et al. [ 24 ] combined characteristic color values with backpropagation Neural Network (BPNN) technology to detect the maturity of commercially available tomatoes. They constructed a quantitative model for tomato fruit maturity based on threshold segmentation and concentric sub-region division strategies. In the field of commercial grading, Ireri et al. [ 25 ] proposed a machine vision system for tomato grading based on RGB images, which accurately identified abnormalities in calyx morphology and fruit scars. In the field of crop disease diagnosis, Deng et al. [ 26 ] proposed an image-based method for segmenting tomato leaf diseases, MC-UNet, which employs a multi-scale convolution module to capture multi-scale information of tomato diseases. By utilizing a cross-layer attention fusion mechanism with gating structures and fusion operations, they effectively improved the boundary consistency of leaf spot segmentation. Kang et al. [ 27 ] improved the deep learning network YOLO-TGI by integrating Ghost and CBAM modules to assess the health status of tomato leaves and simultaneously count tomatoes in video streams. These technologies collectively demonstrate the technical feasibility of automated extraction of fruit phenotypes. The key to accurate extraction of fruit phenotypic characteristics is the precise assessment and quantification of multidimensional data such as the transverse diameter, longitudinal diameter, and color of the fruit [ 28 ]. Zhu et al. [ 29 ] proposed an automatic detection method for tomato fruit phenotypes based on image recognition, using the Mask R-CNN model to train and test the structural indicators of tomato fruit locules. They extracted the color, transverse and longitudinal diameters, top and navel angles, locule number, and pericarp thickness of tomato fruits, achieving automated measurement of multiple phenotypic parameters. Xu et al. [ 30 ] successfully extracted 11 phenotypic traits, such as melon size, pedicel, and color, by constructing a deep learning algorithm framework, and R 2 values were above 0.94 for fruit transverse diameter and 0.698 for fruit longitudinal diameter. Xue et al. [ 31 ] proposed a cucumber fruit morphological trait recognition framework and software called CucumberAI, which integrates deep learning algorithms and can effectively identify 51 cucumber features, and achieved R 2 values greater than 0.9 for fruit diameter, neck length, and fruit length. These phenotype extraction methods, based on image recognition and deep learning, provide new technical approaches for the precise analysis of fruit phenotypic traits. When obtaining the size of tomato fruits, traditional methods often rely on introducing a reference object in the image and inferring the actual size of the fruit by comparing the size ratio of the fruit to the reference object in the image. However, this method has significant limitations: to ensure measurement accuracy, the reference object and the fruit should ideally be on the same plane. Considering that tomato fruits vary in size and grow in different positions, it is difficult to ensure that all fruits and the reference object are on the same plane, thus easily introducing measurement errors. With the rapid advancement of perceptual imaging technology and the widespread adoption of consumer-grade RGB-D cameras, real-time depth estimation combined with RGB imaging can be achieved at low cost. This significantly enhances remote non-contact sensing capabilities, continuously improves measurement accuracy, and greatly boosts environmental adaptability. These devices mostly use the time-of-flight (TOF) principle for ranging, which not only provides 2D information of the target object but also the depth value of each pixel in the image, providing rich data information for the study of crop morphological characteristics [ 32 , 33 , 34 ]. Due to their convenience and practicality, RGB-D cameras are increasingly recognized by researchers and agricultural practitioners, and are gradually becoming important tools for detecting and extracting crop morphological characteristics. For high-throughput automatic phenotypic analysis of tomato fruit traits, in this study, a more comprehensive and efficient intelligent phenotyping framework was developed. The contributions are summarized as follows: The framework analyzes 12 phenotypic traits, including fruit transverse and longitudinal diameters, shape index, stem scar structure in the fruit, as well as stem scar depth and width, locule structure, locule number, locule area, mesocarp thickness, mesocarp color, and locule color. Based on the SegFormer architecture [ 35 ], the MLLA linear attention mechanism was introduced to develop a SegFormer-MLLA model for tomato fruit phenotypic traits segmentation [ 36 ]. This model enhances computational efficiency while maintaining high segmentation accuracy, enabling precise segmentation of the locule and stem scar structures in tomato fruits. By integrating depth information, the dimensions of tomato fruit traits were measured. To address depth information errors caused by optical interference, such as specular reflections, a Hybrid Depth Regression Model (HDRM) was designed. This model captures the optimal depth distance of the tomato fruit images through modeling parameter errors, calculating residuals, and applying random forest-based residual correction. We designed an intelligent detection system for tomato fruit phenomics analysis, which integrates both software and hardware components. During the detection process, each sample was assigned a corresponding label to establish a mapping with its phenotypic data, enabling efficient and accurate detection and data storage of tomato fruit phenotypic traits. 2. Materials and Methods 2.1. Image Acquisition Tomato fruit samples used in this study were collected from Shandong Agricultural University Science and Technology Innovation Park (36.163&#176; N, 117.165&#176; E) and Taian Hengchang Ecological Agriculture Company (36.221&#176; N, 116.864&#176; E). The tomato varieties used in this study were previously collected materials in our laboratory. A total of 322 mature tomato fruits, representing multiple varieties and colors, were randomly selected. For longitudinal sections, the fruits were cut along the central axis passing through the stem scar. For transverse sections, the fruits were cut through the fruit center. The resulting sections were placed on a uniform white background, and high-resolution images of both longitudinal and transverse sections were captured using an Azure Kinect 3.0 depth camera under consistent illumination conditions. The depth camera was fixed using a top-view bracket, and images were captured at a resolution of 3840 &#215; 2160 pixels. Some examples of the tomato fruit images are shown in Figure 1 , illustrating detailed features of the stem scar and locules. Specifically, considerable variation was observed in the tomato for the number of locules (2&#8211;10 per fruit), along with the stem scar, and the shape and size of the locules. 2.2. Image Preprocessing To eliminate background noise interference in the tomato section images and unify the data scale, an image preprocessing workflow was designed, which consists of four main modules: binarization, image cropping, data annotation, and data partitioning. Binarization module The binarization process is shown in Figure 2 a. Tomato fruits were extracted based on the HSV color space, and noise interference was reduced using closing and opening operations to enhance image quality. Due to color differences in tomatoes and interference from the stem scar color domain, the extracted tomatoes exhibited some pixel loss. To address this issue, Canny edge detection [ 37 ] combined with contour extraction was employed to identify the edges of the tomato fruits. After removing noise through opening operations and multiple rounds of erosion, the image binarization process was completed. 2. Image cropping module The image cropping process is illustrated in Figure 2 b. To ensure consistency in the size of tomato section images and to meet the requirements for model training, all image samples were cropped and resized to 512 &#215; 512 pixels, resulting in individual tomato fruit section images. 3. Data annotation module The LabelMe tool was employed to annotate longitudinal and transverse sections of tomato fruits with distinct strategies: longitudinal sections were annotated along the stem scar contour, while transverse sections were marked along locule contours, including irregular locule structures. Annotated data were then converted into JSON files and formatted for model training. 4. Data partitioning module For the purpose of model training and validation, the dataset was randomly split into training, validation, and test subsets in a 7:2:1 ratio. To prevent potential data leakage, the training, validation, and test datasets were stored in separate directories. For data augmentation, the training set was subjected to a combination of cropping, scaling, rotation, and brightness adjustment to enhance sample diversity, while the validation and test sets retained only cropping, scaling, and rotation to preserve the original data characteristics. After data augmentation, a total of 8392 tomato section images were obtained. 2.3. SegFormer-MLLA Model SegFormer [ 35 ] is a semantic segmentation model based on Transformer [ 38 ], consisting of an encoder and a decoder. The encoder is constructed with four layers of transformer blocks, each stage employing downsampling rates of 4, 8, 16, and 32, respectively, to progressively extract multi-scale features. Each transformer block includes an efficient self-attention module, a Mix-FFN (mixed feed-forward network) module, and an overlapped patch merging module to efficiently capture both global and local features. The four feature maps of different resolutions from the encoder layers are fused in the decoder after passing through an MLP layer, and then the prediction mask is obtained after another MLP. Unlike traditional segmentation models with complex decoder architectures, SegFormer utilizes a lightweight all-MLP decoder, effectively reducing computational overhead and simplifying parameter tuning. The standard self-attention mechanism based on the Transformer architecture has a quadratic computational complexity of O( N 2 ), which poses bottlenecks in terms of computational resources and memory usage. SegFormer employs a hierarchically structured Transformer encoder architecture combined with efficient sequence reduction techniques, lowering the time complexity from O( N 2 ) to O( N 2 / R ). Nevertheless, as its core is still based on an inherently quadratic-complexity attention mechanism, the overall optimization is limited. Early linear attention mechanisms replaced the nonlinear Softmax function with linear normalization, reducing the computational complexity to O( N ). However, due to limitations in feature representation capability, their actual performance still lags behind traditional attention mechanisms. Recently, the Mamba architecture based on state space models (SSMs) has achieved significant development in the field of image segmentation [ 39 , 40 , 41 ], as it maintains linear computational complexity while establishing long-range dependencies. MLLA [ 36 ] combines the selective mechanism of Mamba with the advantages of linear attention, achieving parallel processing efficiency for attention and adaptive feature selection capability of SSM, thereby enabling efficient image processing with O( N ) complexity. MLLA Attention employs RoPE positional encoding [ 42 ] instead of a forget gate, providing necessary positional information while maintaining parallel computation and fast inference speed, thereby overcoming the limitations of recursive computation. By combining LePE positional encoding [ 43 ] with RoPE positional encoding, it can flexibly handle features at different scales. To achieve efficient and precise segmentation of tomato fruit stem scar and locule structures, we proposed the SegFormer-MLLA model for tomato fruit phenotyping, which optimizes the encoder layer based on SegFormer and introduces the MLLA linear attention mechanism. The overall architecture of SegFormer-MLLA is shown in Figure 3 a. To enhance the generalization ability of MLLA, a linear projection layer ( Proj ) is used to map features to a unified embedding dimension, thereby improving feature representation, and dropout is combined for regularization to reduce the risk of overfitting. The MLLA Attention module, which is the key feature extraction component of the model, has an overall architecture as shown in Figure 3 b and aims to capture long-range and local dependencies in images with linear complexity. The projections of the query ( Q ), key ( K ), and value ( V ) vectors are processed through activation functions and then realized via linear transformations. The formula for calculating the attention output of MLLA Attention is given in Equations (1) and (2): (1) Q = &#981; ( x W Q ) , &#160; K = &#981; ( x W K ) , &#160; V = x W V (2) y i = &#8721; j = 1 N Q i K j &#8868; &#8721; j = 1 N Q i K j &#8868; V j = Q i ( &#8721; j = 1 N K j &#8868; V j ) Q i ( &#8721; j = 1 N K j &#8868; ) where &#981; denotes the additional kernel function introduced, x denotes the input, and W Q , W K , and W V denote the learnable weight matrices for the Q , K , and V projections, respectively, with each Q aggregating information from all K and V . (3) y i = Q i S i Q i Z i , &#160; S i = &#8721; j = 1 i K j &#8868; V j , &#160; Z i = &#8721; j = 1 i K j &#8868; This further derives cyclic linear attention, as expressed in Equation (4). (4) S i = S i &#8722; 1 + K i &#8868; V i , &#160; Z i = Z i &#8722; 1 + K i &#8868; , &#160; y i = Q i S i Q i Z i RoPE [ 42 ] uses rotational position embeddings to provide global position information for Q and K, allowing the attention mechanism to capture relative positional dependencies. LePE [ 43 ] uses depthwise convolution to extract local spatial features for V. This mechanism acts like a forget gate, which enhances the model&#8217;s fine-grained spatial perception. MLLA Attention integrates RoPE and LePE to effectively fuse global and local information [ 40 ], as described below: (5) R o P E ( x m , &#952; i ) = x m &#8901; ( cos ( m &#952; i ) + sin ( m &#952; i ) ) (6) L e P E ( x ) = x + D W C o n v ( x ) W L (7) A t t n = ( R o P E ( Q ) , &#160; R o P E ( K ) , &#160; V + L e P E ( V ) ) where m denotes the dimensionality of the input x , &#952; i denotes the position-related angle, W L denotes the learnable weight matrix, and DWConv denotes a depthwise convolution with a kernel size of k . 2.4. Tomato Fruit Phenotypic Size Transformation Based on the acquired phenotypic parameters of tomato fruit sections, this study utilizes depth information to convert pixel distances into real-world physical distances. Specifically, RGB image pixels were remapped through distortion correction to generate an undistorted image. The depth image records the actual depth value d of each pixel from the camera. By integrating the camera&#8217;s intrinsic matrix K with the depth value d , a mapping relationship from pixel coordinates ( u , v ) to three-dimensional physical coordinates ( X , Y , Z ) was established, as given by Equations (8) and (9): (8) K = f x 0 c x 0 f y c y 0 0 1 (9) ( x , y , z ) = ( ( u &#8722; c x ) &#8901; d f x , ( v &#8722; c y ) &#8901; d f y , d ) where K denotes the intrinsic matrix, f x and f y represent the focal length parameters, ( c x , c y ) indicates the principal point coordinates, and d is the raw distance value obtained from the depth sensor. A preliminary analysis of the phenotypic data from tomato fruit sections revealed deviations in both fruit depth values and measured dimensions. The potential causes are hypothesized to include the following: (1) the specular reflection effect, where the smooth surface of the tomato fruit sections causes specular reflection of structured light, disrupting phase computation; (2) the light scattering effect due to tissue moisture, where water-rich tomato tissues and cellular structures induce multiple light scattering, resulting in distortion of light distribution and errors in depth estimation; (3) multipath errors, where positional variations in multiple tomatoes in the image lead to depth estimation errors. To address these issues, a Hybrid Depth Regression Model (HDRM) was developed to fit the optimal depth distance, with its core process depicted in Figure 4 . The key modules illustrated in Figure 4 are designed as follows: Parameterized Modeling for Error Correction. A nonlinear parametric model was established, and the optimal parameter solution was obtained by fitting the objective function using the least squares method. Let d c denote the depth value measured by the camera, d b denote the optimal depth value, which is obtained through multiple rounds of tuning and calibration, and d param denote the initial predicted depth value as given by Equation (10): (10) d p a r a m = ( 1 + &#945; ) d c + &#946; d c 2 + &#981; + &#947; d c where &#945; , &#946; , &#981; , and &#947; are parameters derived from data fitting. Residual Calculation. The residual error e , which denotes the deviation predicted by the parametric error model, was calculated for further correction using a random forest regression model, as defined below: (11) e ( d ) = d b &#8722; d p a r a m Feature Engineering. To further capture the nonlinear relationships within the residuals, an extended feature set X extended was constructed, including linear, quadratic, cubic, logarithmic, and reciprocal terms: (12) X e x t e n d e d = [ d c , d c 2 , d c 3 , ln ( d c + 1 ) , 1 d ] Standardization. To prevent feature scale discrepancies from affecting model training, the feature set was standardized to obtain X norm , ensuring consistency in the input to the random forest model. Here, &#956; denotes the mean of the feature vector, and &#963; denotes the standard deviation of the feature vector: (13) X n o r m = X e x t e n d e d &#8722; &#956; &#963; Random Forest Regressor for Residual Correction ( RF ). A random forest RF model was employed to predict the residual correction value e &#8743; . The RF model integrates the outputs of multiple decision trees, T k , and its predicted value is given by: (14) e &#8743; ( d ) = R F ( X n o r m ) Final Corrected Model Depth. The final corrected depth is the sum of the parametric model prediction and the random forest residual prediction: (15) d f i a n l = d p a r a m + e &#8743; ( d ) 2.5. Tomato Fruit Phenotype Recognition Process By integrating image processing techniques with deep learning algorithms, this study analyzed tomato fruits from both longitudinal and transverse sectional views and proposed a framework for the automated identification of phenotypic traits, as shown in Figure 5 . The framework enables high-throughput and precise extraction of multi-dimensional phenotypic traits from tomato fruits of various varieties, including transverse and longitudinal diameters, fruit shape index, stem scar structure, stem scar depth and width, locule structure, locule number, locule area, mesocarp thickness, mesocarp color, and locule color. The main modules were structured as follows: Figure 5 a illustrates the extraction of phenotypic features from longitudinal sections of tomato fruits, focusing on shape and stem scar features. To extract morphological features from tomato sections, this study used image processing and threshold segmentation algorithms to generate a binary mask for each tomato fruit. A minimum bounding rectangle was fitted to each tomato fruit in the image, with its height defined as the longitudinal diameter and its width as the transverse diameter. The fruit shape index was calculated as the ratio between the longitudinal and transverse diameters of the fruit. We utilized a SegFormer-MLLA model for tomato fruit phenotypic trait segmentation to achieve efficient and precise segmentation of the stem scar boundary. Based on the segmentation results, a minimum bounding rectangle was fitted to the stem scar, with its width and depth determined. Using the obtained data, we integrated RGB-D information from the depth camera and employed the HDRM model to optimize depth values, thereby converting pixel distances into physical dimensions and obtaining the actual values of the tomato fruit&#8217;s transverse diameter, longitudinal diameter, stem scar depth, and stem scar width. Figure 5 b illustrates the extraction of phenotypic features from transverse sections of tomato fruits, emphasizing locule features, locule area, and mesocarp thickness. Tomato fruit transverse section images were processed at 512 &#215; 512 resolution. The SegFormer-MLLA model was applied to segment the locule structure for quantitative analysis of locule number and area. To ensure systematic and traceable analysis, a numbering system was designed for tomato fruits and their internal locules, assigning unique identifiers to establish correspondence. Three rays were drawn from the centroid of each tomato fruit toward each locule. Experimental results showed that offsetting the two side rays by 12&#176; from the central ray provided optimal performance. The minimum Euclidean distance between the intersection points of rays with the locule contour and the tomato outer contour was calculated, and their average was used as an approximate estimate of mesocarp thickness. Using the depth information provided by the depth image and the HDRM model, pixel-based measurements of mesocarp thickness and locule area were converted into actual physical dimensions. Further color recognition analysis was conducted. By averaging the RGB values of each tomato locule, the representative color features of the locule were obtained. Additionally, based on a tomato flesh mask (generated by subtracting the locule mask from the overall tomato mask), a morphological erosion algorithm was employed to extract the pericarp region near the tomato&#8217;s outer edge, and its color features were identified. 3. Results 3.1. Experimental Environment The experiments were conducted on a system equipped with an NVIDIA GeForce RTX 4070 GPU and an Intel Core i5-13490F CPU, running the Windows 11 operating system. The integrated development environment was PyCharm 2024.2.2, and the compilation environment was Python 3.8. The MMSegmentation algorithm library was employed as the algorithmic framework. Input images were processed at a resolution of 512 &#215; 512 pixels, using the AdamW optimizer with a learning rate of 1 &#215; 10 &#8722;3 . The batch size was set to 4. The imaging parameters of the Azure Kinect 3.0 depth camera were maintained at fixed values during data acquisition to ensure consistent illumination and color characteristics. Specifically, the brightness, contrast, saturation, and sharpness were set to 20, 50, 64, and 24, respectively. These values were obtained through tuning and calibration to achieve optimal visual clarity and depth stability under the controlled lighting conditions of the imaging environment. Model training was conducted for 320,000 iterations for tomato stem scar segmentation and 240,000 iterations for tomato locule segmentation. The poly learning rate decay strategy was adopted, and the weight decay was 0.01. To address the class imbalance problem, particularly for small structures such as stem scars, a hybrid loss function combining Cross-Entropy Loss (weight = 0.7) and Dice Loss (weight = 0.3) was employed. 3.2. Evaluation Metrics The segmentation performance of the SegFormer-MLLA model was evaluated using Intersection over Union (IoU), Dice coefficient, Accuracy, Precision, and Recall. IoU denotes the overlap between predicted and ground-truth regions. The Dice coefficient quantifies the boundary matching accuracy. Precision denotes the proportion of correctly predicted positive regions among all predicted positive regions. Recall denotes the proportion of correctly identified target regions relative to all actual target regions. The formulas for these four metrics are presented below: (16) I o U = T P T P + F P + F N (17) D i c e &#160; c o e f f i c i e n t = 2 &#215; X &#8745; Y X + Y = 2 T P 2 T P + F P + F N (18) P r e c i s i o n = T P T P + F P (19) R e c a l l = T P T P + F N where TP , FP , and FN denote the number of true positives, false positives, and false negatives, respectively. X represents the segmented region predicted by the model, and Y indicates the ground-truth segmented region. We evaluated the Hybrid Depth Regression Model using Root Mean Square Error ( RMSE ) to quantify its performance. Phenotypic traits of tomato fruit sections, including transverse and longitudinal diameters, mesocarp thickness, and stem scar depth and width, were manually measured using a vernier caliper. The fruit shape index was calculated as the ratio of longitudinal diameter to transverse diameter. To evaluate the performance of image-based dimension measurements, RMSE , MAE , and R 2 were used as metrics: (20) R M S E = 1 N &#8721; i = 1 N y i &#8722; y &#8743; i 2 (21) M A E = 1 N &#8721; i = 1 N y i &#8722; y &#8743; i (22) R 2 = 1 &#8722; &#8721; i = 1 N ( y &#8743; i &#8722; y i ) 2 &#8721; i = 1 N y i &#8722; y &#175; 2 where y &#8743; i denotes the predicted dimension, y i represents the ground-truth dimension, and N denotes the sample size. 3.3. Evaluation of Segmentation Results To evaluate the performance of the SegFormer-MLLA model, comparative experiments were conducted under identical experimental conditions and test sets against several classical semantic segmentation algorithms, including UNet [ 44 ], DeepLabv3+ [ 45 ], PIDNet [ 46 ], Convnext [ 47 ], and Mask2Former [ 48 ]. The SegFormer model comprises multiple variants, such as B0 and B2, which differ in embedding dimensions and layer counts, representing lightweight and more complex architectures, respectively. In this study, SegFormer-MLLA-a and SegFormer-MLLA-b were proposed based, respectively, on the embedding dimensions and layer counts of the B0 and B2 models. Table 1 shows the evaluation results for tomato stem scar segmentation. The lightweight SegFormer-MLLA-a model, with only 3.06 M parameters, achieved an IoU of 77.86%, comparable to the Mask2Former model&#8217;s IoU of 77.64% with 44.00 M parameters. Furthermore, the SegFormer-MLLA-b model, an enhanced version of the SegFormer-B2 architecture, achieved an IoU of 78.36% with a 23.2% parameter reduction (from 24.72 M to 18.98 M). It slightly outperformed the baseline model while maintaining stability in the Dice coefficient (87.87%) and Recall (87.59%). These results demonstrate the significant performance advantages of the SegFormer-MLLA model optimized with the MLLA Attention module. Table 2 shows the evaluation results for tomato locules segmentation. As presented in Table 2 , the SegFormer-MLLA model exhibited outstanding performance. The SegFormer-MLLA-a model, with only 3.06 M parameters, attained an IoU of 85.00%, representing a 0.16% improvement over the baseline SegFormer-B0, and increased the Dice coefficient to 91.88%. The SegFormer-MLLA-b model, with 18.98 M parameters, achieved an IoU of 85.24%, surpassing the Mask2Former model (IoU 85.15%) with 2.32 times the parameters. These results indicate that the MLLA module provides exceptional performance in fine-structure segmentation while maintaining high computational efficiency, highlighting the model&#8217;s effective balance between performance and resource demands. 3.4. Tomato Fruit Size Phenotypic Information Extraction For the segmentation and dimension recognition tasks of tomato fruit section images, a strategy integrating preprocessing and depth information was employed. As original images contained multiple tomato targets with excessive background elements and small target sizes, training and prediction using unprocessed images led to reduced model segmentation accuracy. Therefore, an HSV color space segmentation combined with contour detection was initially applied to crop the original images into multiple 512 &#215; 512 pixel single-tomato images, while the positional information of each tomato in the original image was recorded. Subsequently, semantic segmentation was performed on the cropped single-tomato images, and the segmentation results were recombined into the original image layout using the retained positional information. Ultimately, Precise measurements of the actual physical dimensions of tomato fruit sections were achieved by integrating RGB images with depth information. This approach effectively reduces background interference on segmentation accuracy, providing reliable support for depth vision-based tomato phenotyping. The performance of the tomato fruit phenotyping intelligent detection framework was evaluated using 50 independent tomato samples imaged at two different heights, resulting in 100 independent sample sets in total. Benchmark values for fruit geometric parameters were obtained through manual measurements, and the fruit shape index was calculated. The phenotypic measurement results were compared with the corresponding predictions from the phenotypic detection model, depicted in Figure 6 , which shows high consistency in the model&#8217;s predictions for transverse diameter, longitudinal diameter, and fruit shape index of tomato fruits. The RMSE values were 1.09 mm, 0.87 mm, and 0.01, respectively. The MAE values were 0.87 mm, 0.68 mm, and 0.01, respectively. The R 2 values were 0.945, 0.956, and 0.920, respectively. For mesocarp thickness, the model achieved an RMSE of 0.52 mm, MAE of 0.42 mm, and R 2 of 0.907. Compared to the aforementioned parameters, the R 2 value for the tomato fruit stem scar was slightly lower, attributable to its morphological diversity and the influence of segmentation outcomes. The violin plots in Figure 7 , which illustrate the residual distributions for scar depth and width, provide evidence for this issue. In some varieties, the fruit stem scar area appears off-white or light yellow&#8212;a color similar to the placental tissue&#8212;resulting in unclear boundary recognition; hence, manual detection is recommended. Additionally, this study quantified color features by extracting RGB tri-channel values from the mesocarp and locules, illustrated in Figure 8 , enabling a new dimension for assessing fruit maturity and internal structural characteristics. The color differences observed between the mesocarp and the locules in tomatoes are not merely visual but are intrinsically linked to the spatial distribution of key biochemical traits, particularly lycopene content [ 49 ]. The inclusion of color data enhances the diversity of phenotypic parameters and provides a data foundation for correlations between fruit quality and phenotypic traits. Compared to traditional manual measurements, this automated identification method enables rapid phenotyping of tomato fruits and effectively supports variety selection and quality grading in high-throughput agricultural phenotyping applications, significantly improving breeding screening efficiency. 3.5. Ablation Experiment Building on the SegFormer-MLLA model for tomato fruit structure segmentation, this study extracted 10 key phenotypic parameters from RGB-D images of fruit sections. The precision issue in size measurement arises from depth value bias in depth cameras. A Hybrid Depth Regression Model (HDRM) was introduced to correct the depth values, effectively improving measurement accuracy. A total of 264 paired samples were used, divided into training and testing sets with a 9:1 ratio, and evaluated through ten-fold cross-validation to ensure model robustness. As shown in Figure 9 , the optimized depth measurements significantly reduced the RMSE from 18.754 mm (original) to 3.011 mm using the proposed HDRM, compared to 3.154 mm for the parameterized modeling approach and 3.500 mm for the Random Forest model. To evaluate the performance of different modeling strategies in predicting fruit morphological parameters, the predictive accuracy of the Random Forest model, the parametric model, and the HDRM (combining both approaches) was compared. The results in Table 3 show that the Random Forest model can capture nonlinear relationships but tends to exhibit bias when the dataset is small or lacks sufficient constraints. The parametric model provides good interpretability but has limited ability to fit systematic errors. In contrast, the proposed HDRM achieved the best performance across all metrics, with RMSE values for transverse diameter, longitudinal diameter reduced to 1.064 mm and 0.956 mm. Furthermore, the contribution of each component within the overall framework was evaluated through an ablation study, as presented in Table 4 . When employing the Segormer-MALL, the model achieved strong detection performance, with the introduction of the MLLA module enhancing its ability to represent structural details of tomato locules and stem scars. In the depth correction component, using the Random Forest model alone exhibited a certain degree of instability, whereas the parametric modeling approach effectively reduced systematic errors. By integrating both methods, the HDRM mitigated fitting bias and improved prediction stability. The complete framework achieved the lowest RMSE and MAE across most evaluation metrics. 3.6. Device Detection and Software Development To automate the extraction and quantitative analysis of tomato fruit phenotypic traits, we integrated multiple algorithms and techniques, including image processing, semantic segmentation, and regression models. Using these methods, we successfully designed and implemented an efficient automated detection equipment for tomato fruit phenotyping, along with its supporting software, as shown in Figure 10 . The equipment primarily consists of the following components: an Azure Kinect depth camera, a sample tray for the stable placement of fruits (capable of holding six tomatoes), LED light strips to provide a uniform and controllable lighting environment, and a sealed light-shielded imaging box to isolate ambient light. The accompanying software provides a user-friendly interface and integrates core functions, including real-time capture, processing, and storage of RGB-D images, automatic extraction and quantitative analysis of tomato fruit phenotypic parameters, and the creation of a phenotypic database for structured storage and management of tomato fruit data. This device serves as a laboratory tool designed for precise internal phenotyping of tomato fruits obtained from breeding and cultivation experiments. 4. Discussion Amid the rapid advancement of intelligent breeding technologies, efficiently and accurately extracting phenotypic information from tomato fruits remains a key challenge. Because traditional manual phenotyping measurement methods are time-consuming and labor-intensive, they are not suitable for the high-throughput, large-sample demands of modern breeding. In the field of automated tomato fruit analysis, there has been considerable research on external quality attributes [ 50 , 51 , 52 ], while studies on intelligent recognition of internal structures remain relatively limited. This study focuses on methodological research for the intelligent acquisition of internal phenotypic traits in tomato fruits. We obtained internal phenotypic traits such as locule number, mesocarp thickness, and stem scar morphology by performing both transverse and longitudinal sectioning of tomato fruits. These destructive measurements are necessary to access internal structures that cannot be observed non-invasively. Although the method is inherently destructive, it enables the acquisition of precise and detailed internal phenotypic data at a low cost. Furthermore, the enclosed imaging box ensures stable and uniform illumination, effectively minimizing ambient light interference and guaranteeing consistent imaging quality across samples. Accordingly, the accuracy reported in this study is specific to the conditions used: the analysis of sectioned fruits within an enclosed imaging system. The results are therefore not directly applicable to intact fruits in open environments. In tomato fruit phenotypic size detection, most methods typically rely on a ruler or black-and-white scale card as a reference for measuring fruit-related phenotypic traits [ 30 , 31 , 53 ], which require the reference object and the fruit to be positioned on the same focal plane and aligned with the fruit&#8217;s primary measurement axis; otherwise, substantial measurement errors may arise. In this study, a method that combined RGB images with depth information was employed for the accurate detection of tomato fruit phenotypic size, eliminating the need for a black-and-white scale card, and enabling high-throughput measurement across large sample sets. This approach can be extended to other crops with similar fruit characteristics, requiring minor fine-tuning and recalibration to accommodate differences in tissue structure and phenotypic traits. 4.1. The Feasibility and Practical Significance of SegFormer-MLLA in Tomato Fruit Trait Analysis With the increasing demand for automated analysis of tomato fruit traits, efficient utilization of computational resources in resource-constrained environments is critical for real-time or near-real-time applications [ 54 ]. To address the challenge of automated and precise phenotyping of complex tomato fruit traits, we propose a novel lightweight segmentation model, SegFormer-MLLA, for efficient locule and stem scar segmentation, meeting the demands of resource-constrained environments. The segmentation results generated by this model further enable the automatic extraction of multiple key phenotypic parameters, such as tomato mesocarp thickness and stem scar characteristics. Previous research [ 29 ] utilized the Mask R-CNN model to extract tomato fruit phenotypes, but it exhibited limitations in model efficiency. The model proposed in this study has only 3.06 M parameters, offering higher efficiency and greater suitability for scalable deployment. 4.2. Effect of HDRM Model on Size Detection During the experiment, we observed deviations in the restoration of fruit phenotypic dimensions using depth information. This deviation is likely due to light absorption by moisture in the tomato fruit&#8217;s cross-sectional tissue and light reflection caused by its smooth surface. To overcome this limitation, a Hybrid Depth Regression Model (HDRM) is used to optimize the captured depth values, which, together with the camera&#8217;s intrinsic matrix, enables conversion of pixel measurements in RGB images into the fruit&#8217;s actual physical dimensions. Evaluated using R 2 , RMSE, and MAE metrics, our method achieved high accuracy in measuring tomato phenotypic traits, including transverse diameter, longitudinal diameter, mesocarp thickness, and fruit shape index. 4.3. Phenotypic Research of Tomato Stem Scars Currently, significant progress has been made in rapid phenotyping of vegetables such as tomatoes, but research has primarily focused on external fruit traits, such as size and shape, while studies on internal structures and localized features, such as stem scars, remain scarce. The tomato stem scar is a wound formed when the stem separates from the fruit during harvesting. Its rapid healing forms a hydrophobic barrier, which helps reduce post-harvest water loss and microbial infection, thereby extending the storage period and thus its importance in tomato post-harvest handling [ 55 ]. Based on our method, the extraction and segmentation of stem scars were successfully achieved, with dimensional detection errors controlled at the sub-millimeter level, providing significant advantages for automated phenotypic analysis in breeding programs. 4.4. Benefits of the Automated Phenotyping System To apply our established models and methods more efficiently to the systematic analysis of tomato fruit phenotyping, we built on the intelligent detection framework and developed automated phenotyping equipment and software. This system effectively eliminates subjective errors in manual measurements, enhances detection convenience, significantly improves the consistency and reliability of phenotypic data, and lowers the operational threshold. Furthermore, we established a comprehensive tomato phenotyping database, enabling long-term storage, traceability, and reuse of detection data and images, which facilitates comparative analysis, model training, and data sharing, providing critical support for genotype-phenotype association studies. 4.5. Limitations and Future Work Although this study has made progress in the automated detection of tomato fruit phenotypic traits, certain limitations remain. During fruit size detection, slight angular deviations between the tomato fruit section plane and the camera may occur, even if visually undetectable. These deviations can lead to non-uniform depth value distribution across the plane, introducing measurement errors. As shown in Table 5 , our method demonstrates high accuracy in measuring tomato fruit phenotypic traits by comparing the true and detected values of multiple tomato samples at six equipment positions. Slight variations in the detection outcomes were primarily due to changes in orientation or visual perspective. For instance, a 5&#176; tilt in the tomato fruit section resulted in a deviation of approximately 2&#8211;3 mm in the depth value. To address these challenges, our research will focus on key directions to advance tomato phenomics. First, we will refine our model and expand training datasets to include a broader range of tomato cultivars, thereby enhancing the accuracy and robustness of detecting tomato fruit phenotypic traits. Second, we plan to explore the application of point cloud, spectral, and three-dimensional technologies in tomato phenotyping, aiming to develop innovative approaches to study more phenotypes, thereby enhancing the precision and scope of trait analysis in agricultural research. Third, we will implement equipment enhancements, such as replacing the fixed tray for holding tomato fruits with a conveyorized system to mitigate angular deviations between the fruit section plane and the camera. 5. Conclusions In this study, an intelligent detection framework for tomato fruit phenomics analysis was developed, which combines image processing techniques with deep learning algorithms to automate the extraction and quantitative analysis of 12 phenotypic traits. First, a dataset of tomato fruit section images was developed using a depth camera. Second, a lightweight SegFormer-MLLA model for tomato fruit phenotype segmentation was proposed. Accurate segmentation of tomato fruit stem scars and locular structures was achieved, with significantly reduced computational cost by the proposed model. Finally, an HDRM model was designed to optimize the estimation of optimal depth. Building on this, we developed an automated phenotyping system for tomato fruits, which provides a controlled and stable environment to enable precise trait detection. The results showed that the RMSEs were approximately 1 mm for the longitudinal diameter, transverse diameter, and stem scar width of the tomato fruit sections, and below 0.6 mm for the mesocarp thickness and stem scar depth. Disclaimer/Publisher&#8217;s Note: The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content. Author Contributions Conceptualization, J.L. and G.D.; methodology, J.L. and G.D.; software, G.D.; validation, H.Y., Z.X.; formal analysis, J.L., Y.Z. and Q.S.; investigation, G.D.; resources, Y.Z., W.N. and Q.S.; data curation, G.D. and Y.L.; writing&#8212;original draft preparation, G.D.; writing&#8212;review and editing, J.L., W.N. and Q.S.; visualization, G.D.; supervision, J.L.; project administration, J.L.; funding acquisition, Q.S. All authors have read and agreed to the published version of the manuscript. Data Availability Statement Some datasets, model weights, and code used in the present study are available at https://github.com/Snail-code-wq/Plants_Tomato_2025 (accessed on 5 November 2025). All self-developed datasets can be obtained by contacting the corresponding author. Conflicts of Interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. References 1. Kim M. Nguyen T.T.P. Ahn J.-H. Kim G.-J. Sim S.-C. Genome-wide association study identifies QTL for eight fruit traits in cultivated tomato ( Solanum lycopersicum L.) Hortic. Res. 2021 8 203 10.1038/s41438-021-00638-4 34465758 PMC8408251 2. Perveen R. Suleria H.A.R. Anjum F.M. Butt M.S. Pasha I. Ahmad S.J. Tomato ( Solanum lycopersicum ) carotenoids and lycopenes chemistry; metabolism, absorption, nutrition, and allied health claims&#8212;A comprehensive review Crit. Rev. Food Sci. Nutr. 2015 55 919 929 10.1080/10408398.2012.657809 24915375 3. Lin T. Zhu G. Zhang J. Xu X. Yu Q. Zheng Z. Zhang Z. Lun Y. Li S. Wang X. Genomic analyses provide insights into the history of tomato breeding Nat. Genet. 2014 46 1220 1226 10.1038/ng.3117 25305757 4. Zhu G. Wang S. Huang Z. Zhang S. Liao Q. Zhang C. Lin T. Qin M. Peng M. Yang C. Rewiring of the Fruit Metabolome in Tomato Breeding Cell 2018 172 249 261.e12 10.1016/j.cell.2017.12.019 29328914 5. Mata-Nicol&#225;s E. Montero-Pau J. Gimeno-Paez E. Garcia-Carpintero V. Ziarsolo P. Menda N. Mueller L.A. Blanca J. Ca&#241;izares J. van der Knaap E. Exploiting the diversity of tomato: The development of a phenotypically and genetically detailed germplasm collection Hortic. Res. 2020 7 66 10.1038/s41438-020-0291-7 32377357 PMC7192925 6. Oltman A.E. Jervis S.M. Drake M.A. Consumer Attitudes and Preferences for Fresh Market Tomatoes J. Food Sci. 2014 79 S2091 S2097 10.1111/1750-3841.12638 25219281 7. Tanksley S.D. The Genetic, Developmental, and Molecular Bases of Fruit Size and Shape Variation in Tomato Plant Cell. 2004 16 (Suppl. S1) S181 S189 10.1105/tpc.018119 15131251 PMC2643388 8. Mounet F. Moing A. Garcia V. Petit J. Maucourt M. Deborde C. Bernillon S. Le Gall G. Colquhoun I. Defernez M. Gene and Metabolite Regulatory Network Analysis of Early Developing Fruit Tissues Highlights New Candidate Genes for the Control of Tomato Fruit Composition and Development Plant Physiol. 2009 149 1505 1528 10.1104/pp.108.133967 19144766 PMC2649409 9. Barrero L.S. Tanksley S.D. Evaluating the genetic basis of multiple-locule fruit in a broad cross section of tomato cultivars Theor. Appl. Genet. 2004 109 669 679 10.1007/s00122-004-1676-y 15292992 10. van der Knaap E. Chakrabarti M. Chu Y.H. Clevenger J.P. Illa-Berenguer E. Huang Z. Keyhaninejad N. Mu Q. Sun L. Wang Y. What lies beyond the eye: The molecular mechanisms regulating tomato fruit weight and shape Front. Plant Sci. 2014 5 227 10.3389/fpls.2014.00227 24904622 PMC4034497 11. Yang J. Liu Y. Liang B. Yang Q. Li X. Chen J. Li H. Lyu Y. Lin T. Genomic basis of selective breeding from the closest wild relative of large-fruited tomato Hortic. Res. 2023 10 uhad142 10.1093/hr/uhad142 37564272 PMC10410300 12. Kumar P. Irfan M. Green ripe fruit in tomato: Unraveling the genetic tapestry from cultivated to wild varieties J. Exp. Bot. 2024 75 3203 3205 10.1093/jxb/erae149 38845353 PMC11156801 13. Zhang J. Lyu H. Chen J. Cao X. Du R. Ma L. Wang N. Zhu Z. Rao J. Wang J. Releasing a sugar brake generates sweeter tomato without yield penalty Nature 2024 635 647 656 10.1038/s41586-024-08186-2 39537922 PMC11578880 14. Yang T. Ali M. Lin L. Li P. He H. Zhu Q. Sun C. Wu N. Zhang X. Huang T. Recoloring tomato fruit by CRISPR/Cas9-mediated multiplex gene editing Hortic. Res. 2022 10 uhac214 10.1093/hr/uhac214 36643741 PMC9832834 15. Mansoor S. Karunathilake E.M.B.M. Tuan T.T. Chung Y.S. Genomics, phenomics, and machine learning in transforming plant research: Advancements and challenges Hortic. Plant J. 2025 11 486 503 10.1016/j.hpj.2023.09.005 16. Einspanier S. Tominello-Ramirez C. Hasler M. Barbacci A. Raffaele S. Stam R. High-Resolution Disease Phenotyping Reveals Distinct Resistance Mechanisms of Tomato Crop Wild Relatives against Sclerotinia sclerotiorum Plant Phenomics 2024 6 0214 10.34133/plantphenomics.0214 39105186 PMC11298253 17. Zhou Y. Zhang Z. Bao Z. Li H. Lyu Y. Zan Y. Wu Y. Cheng L. Fang Y. Wu K. Graph pangenome captures missing heritability and empowers tomato breeding Nature 2022 606 527 534 10.1038/s41586-022-04808-9 35676474 PMC9200638 18. Gan L. Song M. Wang X. Yang N. Li H. Liu X. Li Y. Cytokinins are involved in regulation of tomato pericarp thickness and fruit size Hortic. Res. 2022 9 uhab041 10.1093/hr/uhab041 35043193 PMC8968492 19. Fanourakis D. Papadakis V.M. Machado M. Psyllakis E. Nektarios P.A. Non-invasive leaf hydration status determination through convolutional neural networks based on multispectral images in chrysanthemum Plant Growth Regul. 2024 102 485 496 10.1007/s10725-023-01072-3 20. Jiang X. Wang J. Xie K. Cui C. Du A. Shi X. Yang W. Zhai R. PlantCaFo: An efficient few-shot plant disease recognition method based on foundation models Plant Phenomics 2025 7 100024 10.1016/j.plaphe.2025.100024 21. Zhang J. Xie J. Zhang F. Gao J. Yang C. Song C. Rao W. Zhang Y. Greenhouse tomato detection and pose classification algorithm based on improved YOLOv5 Comput. Electron. Agric. 2024 216 108519 10.1016/j.compag.2023.108519 22. Zhang W. Liu Y. Chen K. Li H. Duan Y. Wu W. Shi Y. Guo W. Lightweight fruit-detection algorithm for edge computing applications Front. Plant Sci. 2021 12 740936 10.3389/fpls.2021.740936 34721466 PMC8548576 23. Yu C. Shi X. Luo W. Feng J. Zheng Z. Yorozu A. Hu Y. Guo J. MLG-YOLO: A Model for Real-Time Accurate Detection and Localization of Winter Jujube in Complex Structured Orchard Environments Plant Phenomics 2024 6 0258 10.34133/plantphenomics.0258 39314991 PMC11418275 24. Wan P. Toudeshki A. Tan H. Ehsani R. A methodology for fresh tomato maturity detection using computer vision Comput. Electron. Agric. 2018 146 43 50 10.1016/j.compag.2018.01.011 25. Ireri D. Belal E. Okinda C. Makange N. Ji C. A computer vision system for defect discrimination and grading in tomatoes using machine learning and image processing Artif. Intell. Agric. 2019 2 28 37 10.1016/j.aiia.2019.06.001 26. Deng Y. Xi H. Zhou G. Chen A. Wang Y. Li L. Hu Y. An Effective Image-Based Tomato Leaf Disease Segmentation Method Using MC-UNet Plant Phenomics 2023 5 0049 10.34133/plantphenomics.0049 37228512 PMC10204749 27. Kang R. Huang J. Zhou X. Ren N. Sun S. Toward Real Scenery: A Lightweight Tomato Growth Inspection Algorithm for Leaf Disease Detection and Fruit Counting Plant Phenomics 2024 6 0174 10.34133/plantphenomics.0174 38629080 PMC11018486 28. Tsaniklidis G. Makraki T. Papadimitriou D. Nikoloudakis N. Taheri-Garavand A. Fanourakis D. Non-Destructive Estimation of Area and Greenness in Leaf and Seedling Scales: A Case Study in Cucumber Agronomy 2025 15 2294 10.3390/agronomy15102294 29. Zhu Y. Gu Q. Zhao Y. Wan H. Wang R. Zhang X. Cheng Y. Quantitative Extraction and Evaluation of Tomato Fruit Phenotypes Based on Image Recognition Front. Plant Sci. 2022 13 859290 10.3389/fpls.2022.859290 35498696 PMC9044966 30. Xu S. Shen J. Wei Y. Li Y. He Y. Hu H. Feng X. Automatic plant phenotyping analysis of Melon ( Cucumis melo L.) germplasm resources using deep learning methods and computer vision Plant Methods 2024 20 166 10.1186/s13007-024-01293-1 39472934 PMC11524006 31. Xue W. Ding H. Jin T. Meng J. Wang S. Liu Z. Ma X. Li J. CucumberAI: Cucumber Fruit Morphology Identification System Based on Artificial Intelligence Plant Phenomics 2024 6 0193 10.34133/plantphenomics.0193 39144674 PMC11324094 32. Park J. Kim H. Tai Y.-W. Brown M.S. Kweon I. High quality depth map upsampling for 3D-TOF cameras Proceedings of the 2011 International Conference on Computer Vision Barcelona, Spain 6&#8211;13 November 2011 IEEE New York, NY, USA 1623 1630 33. Mufti F. Mahony R. Statistical analysis of signal measurement in time-of-flight cameras ISPRS J. Photogramm. Remote. Sens. 2011 66 720 731 10.1016/j.isprsjprs.2011.06.004 34. Kang Z. Zhou B. Fei S. Wang N. Predicting the greenhouse crop morphological parameters based on RGB-D Computer Vision Smart Agric. Technol. 2025 11 100968 10.1016/j.atech.2025.100968 35. Xie E. Wang W. Yu Z. Anandkumar A. Alvarez J.M. Luo P. SegFormer: Simple and efficient design for semantic segmentation with transformers Adv. Neural Inf. Process. Syst. 2021 34 12077 12090 36. Han D. Wang Z. Xia Z. Han Y. Pu Y. Ge C. Song J. Song S. Zheng B. Huang G. Demystify mamba in vision: A linear attention perspective Adv. Neural Inf. Process. Syst. 2024 37 127181 127203 37. Canny J. A Computational Approach to Edge Detection IEEE Trans. Pattern Anal. Mach. Intell. 1986 PAMI-8 679 698 10.1109/TPAMI.1986.4767851 21869365 38. Vaswani A. Shazeer N. Parmar N. Uszkoreit J. Jones L. Gomez A.N. Kaiser &#321;. Polosukhin I. Attention is all you need arXiv 2017 1706.03762 10.48550/arXiv.1706.03762 39. Gu A. Dao T. Mamba: Linear-time sequence modeling with selective state spaces arXiv 2023 10.48550/arXiv.2312.00752 2312.00752 40. Jiang Y. Li Z. Chen X. Xie H. Cai J. Mlla-unet: Mamba-like linear attention in an efficient u-shape model for medical image segmentation arXiv 2024 2410.23738 41. He H. Zhang J. Cai Y. Chen H. Hu X. Gan Z. Wang Y. Wang C. Wu Y. Xie L. Mobilemamba: Lightweight multi-receptive visual mamba network Proceedings of the Computer Vision and Pattern Recognition Conference Nashville, TN, USA 11&#8211;15 June 2025 4497 4507 42. Su J. Ahmed M. Lu Y. Pan S. Bo W. Liu Y. RoFormer: Enhanced transformer with Rotary Position Embedding Neurocomputing 2024 568 127063 10.1016/j.neucom.2023.127063 43. Dong X. Bao J. Chen D. Zhang W. Yu N. Yuan L. Chen D. Guo B. Cswin transformer: A general vision transformer backbone with cross-shaped windows Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition New Orleans, LA, USA 18&#8211;24 June 2022 12124 12134 44. Ronneberger O. Fischer P. Brox T. In U-net: Convolutional networks for biomedical image segmentation Proceedings of the International Conference on Medical image Computing and Computer-Assisted Intervention Munich, Germany 9&#8211;15 October 2015 Springer Berlin/Heidelberg, Germany 2015 234 241 45. Chen L.-C. Zhu Y. Papandreou G. Schroff F. Adam H. Encoder-decoder with atrous separable convolution for semantic image segmentation Proceedings of the European Conference on Computer Vision (ECCV) Munich, Germany 8&#8211;14 September 2018 801 818 46. Xu J. Xiong Z. Bhattacharyya S.P. PIDNet: A real-time semantic segmentation network inspired by PID controllers Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Vancouver, BC, Canada 8&#8211;22 June 2023 19529 19539 47. Liu Z. Mao H. Wu C.Y. Feichtenhofer C. Darrell T. Xie S. A convnet for the 2020s Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition New Orleans, LA, USA 18&#8211;22 June 2022 11976 11986 48. Cheng B. Misra I. Schwing A.G. Kirillov A. Girdhar R. In Masked-attention mask transformer for universal image segmentation Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition New Orleans, LA, USA 18&#8211;22 June 2022 1290 1299 49. Assad T. Jabeen A. Roy S. Bhat N. Maqbool N. Yadav A. Aijaz T. Using an image processing technique, correlating the lycopene and moisture content in dried tomatoes Food Humanit. 2024 2 100186 10.1016/j.foohum.2023.11.013 50. Cardellicchio A. Solimani F. Dimauro G. Petrozza A. Summerer S. Cellini F. Ren&#242; V. Detection of tomato plant phenotyping traits using YOLOv5-based single stage detectors Comput. Electron. Agric. 2023 207 107757 10.1016/j.compag.2023.107757 51. Rong J. Zhou H. Zhang F. Yuan T. Wang P. Tomato cluster detection and counting using improved YOLOv5 based on RGB-D fusion Comput. Electron. Agric. 2023 207 107741 10.1016/j.compag.2023.107741 52. Wang X. Liu J. Zhu X. Early real-time detection algorithm of tomato diseases and pests in the natural environment Plant Methods 2021 17 43 10.1186/s13007-021-00745-2 33892765 PMC8067659 53. Rodr&#237;guez G.R. Moyseenko J.B. Robbins M.D. Huarachi Morej&#243;n N. Francis D.M. van der Knaap E. Tomato Analyzer: A Useful Software Application to Collect Accurate and Detailed Morphological and Colorimetric Data from Two-dimensional Objects J. Vis. Exp. 2010 37 1856 10.3791/1856 PMC3146067 20234339 54. Lei L. Yang Q. Yang L. Shen T. Wang R. Fu C. Deep learning implementation of image segmentation in agricultural applications: A comprehensive review Artif. Intell. Rev. 2024 57 149 10.1007/s10462-024-10775-6 55. Leide J. Hildebrandt U. Hartung W. Riederer M. Vogg G. Abscisic acid mediates the formation of a suberized stem scar tissue in tomato fruits New Phytol. 2012 194 402 415 10.1111/j.1469-8137.2011.04047.x 22296281 Figure 1 Examples of tomato fruit section images. ( a ) Tomato fruit longitudinal section images; ( b ) Tomato fruit transverse section images. Figure 2 Preprocessing workflow for tomato fruit section images. ( a ) Binary thresholding of tomato fruit images to remove background interference; ( b ) Cropping of tomato fruit images to 512 &#215; 512 pixels. Figure 3 Schematic diagram of the SegFormer-MLLA model structure. ( a ) Overall architecture of SegFormer-MLLA, incorporating MLLA blocks to replace transformer blocks for improved feature extraction efficiency; ( b ) MLLA attention module, designed to capture both global and local features, enhancing the precision of tomato phenotypic trait analysis. Figure 4 Schematic diagram of the HDRM model structure. The model is trained using captured depth information and optimal depth information to generate final prediction results. Figure 5 Workflow for detecting phenotypic traits of tomato fruit. ( a ) Phenotypic detection of longitudinal sections; ( b ) Phenotypic detection of transverse sections. Figure 6 Tomato fruit phenotypic trait detection performance evaluation. ( a &#8211; f ) Assessment of phenotypic traits, including transverse diameter, longitudinal diameter, fruit shape index, mesocarp thickness, stem scar width, and depth. Figure 7 Residual distributions of fruit stem scar width ( a ) and depth ( b ). Figure 8 Detection results for tomato fruit. ( a ) Segmentation results for stem scar structure; ( b ) Segmentation results for locule structure; ( c ) Detection results for locule and mesocarp color. Figure 9 HDRM model detection performance evaluation. ( a , b ) HDRM model assessment through residual scatter plot and comparison of predicted versus ground-truth depth values. Figure 10 Schematic diagram of the automated detection equipment and software for tomato fruit phenotyping. ( a ) Main functional modules of the detection system; ( b ) Structural diagram of the equipment; ( c ) Detection process for longitudinal and transverse sections of tomato fruit phenotypes; ( d ) Results of tomato fruit phenotype detection. plants-14-03434-t001_Table 1 Table 1 Evaluation results for tomato stem scar segmentation. Models Stem Scar IoU (%) Dice (%) Precision (%) Recall (%) Parameters (M) Unet 74.52 85.32 84.97 85.26 29.06 Deeplabv3+ 74.78 85.41 85.73 85.41 43.59 Pidnet 73.37 84.64 85.14 84.15 7.72 Convnext 76.95 86.97 87.96 86.01 59.28 Mask2former 77.64 89.12 85.76 89.12 44.00 SegFormer-b0 77.82 87.46 87.34 87.58 3.72 SegFormer-MLLA-a 77.86 87.55 87.59 87.51 3.06 SegFormer-b2 78.29 87.82 88.44 87.21 24.72 SegFormer-MLLA-b 78.36 87.87 88.15 87.59 18.98 plants-14-03434-t002_Table 2 Table 2 Evaluation results for tomato locules segmentation. Models Locule IoU (%) Dice (%) Precision (%) Recall (%) Parameters (M) Unet 84.26 91.47 92.02 90.93 29.06 Deeplabv3+ 84.43 91.56 92.03 91.10 43.59 Pidnet 84.33 91.50 92.27 90.74 7.72 Convnext 84.62 91.67 91.46 91.88 59.28 Mask2former 85.15 91.98 92.48 91.49 44.00 SegFormer-b0 84.84 91.80 92.33 91.27 3.72 SegFormer-MLLA-a 85.00 91.88 91.88 91.91 3.06 SegFormer-b2 85.04 91.92 92.57 91.27 24.72 SegFormer-MLLA-b 85.24 92.03 92.47 91.59 18.98 plants-14-03434-t003_Table 3 Table 3 Performance comparison of different modeling strategies for predicting fruit morphological parameters. HDRM Transverse Diameter (mm) Longitudinal Diameter (mm) Random Forest Parametric Model RMSE MAE RMSE MAE &#160; &#160; 2.312 2.176 2.824 2.600 &#8730; &#160; 1.153 0.946 0.991 0.818 &#160; &#8730; 1.072 0.891 0.970 0.808 &#8730; &#8730; 1.064 0.880 0.965 0.803 The symbol &#8730; indicates that the corresponding module was used plants-14-03434-t004_Table 4 Table 4 Ablation Study Results of the Intelligent Tomato Fruit Detection Framework. SegFormer MLLA HDRM Mesocarp&#160;Thickness Stem&#160;Scar&#160;Width Stem&#160;Scar&#160;Depth Random Forest Parametric Model RMSE MAE RMSE MAE RMSE MAE &#8730; &#160; &#160; &#160; 0.682 0.586 1.163 0.957 0.553 0.457 &#8730; &#8730; &#160; &#160; 0.686 0.527 1.147 0.944 0.473 0.371 &#8730; &#160; &#8730; &#160; 0.484 0.378 0.990 0.740 0.447 0.367 &#8730; &#8730; &#8730; &#160; 0.371 0.322 0.983 0.777 0.441 0.360 &#8730; &#160; &#160; &#8730; 0.463 0.355 0.998 0.780 0.449 0.367 &#8730; &#8730; &#160; &#8730; 0.348 0.304 0.940 0.735 0.399 0.319 &#8730; &#160; &#8730; &#8730; 0.458 0.353 0.986 0.772 0.447 0.367 &#8730; &#8730; &#8730; &#8730; 0.349 0.303 0.937 0.735 0.397 0.315 The symbol &#8730; indicates that the corresponding module was used plants-14-03434-t005_Table 5 Table 5 Comparison of Measured and Detected Phenotypes of Tomato Fruits Across Multiple Positions. Phenotypic Trait Measure Size Position 1 2 3 4 5 6 transverse diameter (mm) 74.91 74.61 73.36 75.17 74.28 73.20 74.48 longitudinal diameter (mm) 59.86 59.91 59.15 59.68 59.85 59.41 59.35 shape index 0.80 0.80 0.81 0.79 0.81 0.81 0.80 stem scar width (mm) 13.23 13.61 13.16 13.34 13.61 13.27 12.91 stem scar depth (mm) 4.67 4.64 5.13 4.99 5.28 5.32 5.31 mesocarp thickness (mm) 8.36 8.63 8.28 8.42 8.45 8.30 8.47 locule number 6 6 6 6 6 6 6"
}