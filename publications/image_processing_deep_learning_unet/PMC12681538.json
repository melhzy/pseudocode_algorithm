{
  "pmcid": "PMC12681538",
  "source": "PMC",
  "download_date": "2025-12-09T16:11:25.700910",
  "metadata": {
    "journal_title": "Journal of Cardiovascular Magnetic Resonance",
    "journal_nlm_ta": "J Cardiovasc Magn Reson",
    "journal_iso_abbrev": "J Cardiovasc Magn Reson",
    "journal": "Journal of Cardiovascular Magnetic Resonance",
    "pmcid": "PMC12681538",
    "pmid": "40846282",
    "doi": "10.1016/j.jocmr.2025.101945",
    "title": "ScarNet: a novel foundation model for automated myocardial scar quantification from late gadolinium-enhancement images",
    "year": "2025",
    "month": "8",
    "day": "20",
    "pub_date": {
      "year": "2025",
      "month": "8",
      "day": "20"
    },
    "authors": [
      "Tavakoli Neda",
      "Rahsepar Amir Ali",
      "Benefield Brandon C.",
      "Shen Daming",
      "López-Tapia Santiago",
      "Schiffers Florian",
      "Goldberger Jeffrey J.",
      "Albert Christine M.",
      "Wu Edwin",
      "Katsaggelos Aggelos K.",
      "Lee Daniel C.",
      "Kim Daniel"
    ],
    "abstract": "Background Late gadolinium enhancement (LGE) imaging remains the gold standard for assessing myocardial fibrosis and scarring, with left ventricular (LV) LGE presence and extent serving as a predictor of major adverse cardiac events (MACE). Despite its clinical significance, LGE-based LV scar quantification is not used routinely due to the labor-intensive manual segmentation and substantial inter-observer variability. Methods We developed ScarNet that synergistically combines a transformer-based encoder in medical segment anything model (MedSAM), which we fine-tuned with our dataset, and a convolution-based decoder in UNet with tailored attention blocks to automatically segment myocardial scar boundaries while maintaining anatomical context. This network was trained and fine-tuned on an existing database of 401 ischemic cardiomyopathy patients (4137 2D LGE images) with expert segmentation of myocardial and scar boundaries in LGE images, validated on 100 patients (1034 2D LGE images) during training, and tested on unseen set of 184 patients (1895 2D LGE images). Ablation studies were conducted to validate each architectural component's contribution. Results In 184 independent testing patients, ScarNet achieved accurate scar boundary segmentation (median DICE = 0.912 [interquartile range (IQR): 0.863–0.944], concordance correlation coefficient [CCC] = 0.963), significantly outperforming both MedSAM (median DICE = 0.046 [IQR: 0.043–0.047], CCC = 0.018) and nnU-Net (median DICE = 0.638 [IQR: 0.604–0.661], CCC = 0.734). For scar volume quantification, ScarNet demonstrated excellent agreement with manual analysis (CCC = 0.995, percent bias = −0.63%, CoV=4.3%) compared to MedSAM (CCC = 0.002, percent bias = −13.31%, CoV = 130.3%) and nnU-Net (CCC = 0.910, percent bias = −2.46%, CoV = 20.3%). Similar trends were observed in the Monte Carlo simulations with noise perturbations. The overall accuracy was highest for ScarNet (sensitivity=95.3% (163/171); specificity=92.3% (12/13)), followed by nnU-Net (sensitivity=74.9% (128/171); specificity=69.2% (9/13)) and MedSAM (sensitivity=15.2% (26/171); specificity=92.3% (12/13)). Conclusion ScarNet outperformed MedSAM and nnU-Net for predicting myocardial and scar boundaries in LGE images of patients with ischemic cardiomyopathy. The Monte Carlo simulations demonstrated that ScarNet is less sensitive to noise perturbations than other tested networks.",
    "keywords": [
      "Cardiac MRI",
      "Deep learning",
      "Foundation models",
      "Late gadolinium enhancement",
      "Medical image segmentation",
      "Myocardial scar quantification"
    ]
  },
  "xml": "<?xml version=\"1.0\"  ?><!DOCTYPE pmc-articleset PUBLIC \"-//NLM//DTD ARTICLE SET 2.0//EN\" \"https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd\"><pmc-articleset><article xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:ali=\"http://www.niso.org/schemas/ali/1.0/\" article-type=\"research-article\" xml:lang=\"en\" dtd-version=\"1.4\"><processing-meta base-tagset=\"archiving\" mathml-version=\"3.0\" table-model=\"xhtml\" tagset-family=\"jats\"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type=\"nlm-ta\">J Cardiovasc Magn Reson</journal-id><journal-id journal-id-type=\"iso-abbrev\">J Cardiovasc Magn Reson</journal-id><journal-id journal-id-type=\"pmc-domain-id\">574</journal-id><journal-id journal-id-type=\"pmc-domain\">jcardiomagnres</journal-id><journal-title-group><journal-title>Journal of Cardiovascular Magnetic Resonance</journal-title></journal-title-group><issn pub-type=\"ppub\">1097-6647</issn><issn pub-type=\"epub\">1532-429X</issn><publisher><publisher-name>Elsevier</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type=\"pmcid\">PMC12681538</article-id><article-id pub-id-type=\"pmcid-ver\">PMC12681538.1</article-id><article-id pub-id-type=\"pmcaid\">12681538</article-id><article-id pub-id-type=\"pmcaiid\">12681538</article-id><article-id pub-id-type=\"pmid\">40846282</article-id><article-id pub-id-type=\"doi\">10.1016/j.jocmr.2025.101945</article-id><article-id pub-id-type=\"pii\">S1097-6647(25)00107-3</article-id><article-id pub-id-type=\"publisher-id\">101945</article-id><article-version article-version-type=\"pmc-version\">1</article-version><article-categories><subj-group subj-group-type=\"heading\"><subject>Original Research</subject></subj-group></article-categories><title-group><article-title>ScarNet: a novel foundation model for automated myocardial scar quantification from late gadolinium-enhancement images</article-title></title-group><contrib-group><contrib contrib-type=\"author\" id=\"au0005\"><name name-style=\"western\"><surname>Tavakoli</surname><given-names initials=\"N\">Neda</given-names></name><email>neda.tavakoli@northwestern.edu</email><xref rid=\"aff0005\" ref-type=\"aff\">a</xref><xref rid=\"cor1\" ref-type=\"corresp\">&#8270;</xref></contrib><contrib contrib-type=\"author\" id=\"au0010\"><name name-style=\"western\"><surname>Rahsepar</surname><given-names initials=\"AA\">Amir Ali</given-names></name><xref rid=\"aff0005\" ref-type=\"aff\">a</xref></contrib><contrib contrib-type=\"author\" id=\"au0015\"><name name-style=\"western\"><surname>Benefield</surname><given-names initials=\"BC\">Brandon C.</given-names></name><xref rid=\"aff0010\" ref-type=\"aff\">b</xref></contrib><contrib contrib-type=\"author\" id=\"au0020\"><name name-style=\"western\"><surname>Shen</surname><given-names initials=\"D\">Daming</given-names></name><xref rid=\"aff0015\" ref-type=\"aff\">c</xref></contrib><contrib contrib-type=\"author\" id=\"au0025\"><name name-style=\"western\"><surname>L&#243;pez-Tapia</surname><given-names initials=\"S\">Santiago</given-names></name><xref rid=\"aff0020\" ref-type=\"aff\">d</xref></contrib><contrib contrib-type=\"author\" id=\"au0030\"><name name-style=\"western\"><surname>Schiffers</surname><given-names initials=\"F\">Florian</given-names></name><xref rid=\"aff0020\" ref-type=\"aff\">d</xref></contrib><contrib contrib-type=\"author\" id=\"au0035\"><name name-style=\"western\"><surname>Goldberger</surname><given-names initials=\"JJ\">Jeffrey J.</given-names></name><xref rid=\"aff0025\" ref-type=\"aff\">e</xref></contrib><contrib contrib-type=\"author\" id=\"au0040\"><name name-style=\"western\"><surname>Albert</surname><given-names initials=\"CM\">Christine M.</given-names></name><xref rid=\"aff0030\" ref-type=\"aff\">f</xref></contrib><contrib contrib-type=\"author\" id=\"au0045\"><name name-style=\"western\"><surname>Wu</surname><given-names initials=\"E\">Edwin</given-names></name><xref rid=\"aff0010\" ref-type=\"aff\">b</xref></contrib><contrib contrib-type=\"author\" id=\"au0050\"><name name-style=\"western\"><surname>Katsaggelos</surname><given-names initials=\"AK\">Aggelos K.</given-names></name><xref rid=\"aff0020\" ref-type=\"aff\">d</xref></contrib><contrib contrib-type=\"author\" id=\"au0055\"><name name-style=\"western\"><surname>Lee</surname><given-names initials=\"DC\">Daniel C.</given-names></name><xref rid=\"aff0010\" ref-type=\"aff\">b</xref></contrib><contrib contrib-type=\"author\" id=\"au0060\"><name name-style=\"western\"><surname>Kim</surname><given-names initials=\"D\">Daniel</given-names></name><xref rid=\"aff0005\" ref-type=\"aff\">a</xref></contrib><aff id=\"aff0005\"><label>a</label>Department of Radiology, Feinberg School of Medicine, Northwestern University, Chicago, Illinois, USA</aff><aff id=\"aff0010\"><label>b</label>Department of Medicine (Division of Cardiology), Northwestern University Feinberg School of Medicine, Chicago, Illinois, USA</aff><aff id=\"aff0015\"><label>c</label>Department of Biomedical Engineering, Northwestern University, Evanston, Illinois, USA</aff><aff id=\"aff0020\"><label>d</label>Department of Electrical and Computer Engineering, Northwestern University, Evanston, Illinois, USA</aff><aff id=\"aff0025\"><label>e</label>Cardiovascular Division, University of Miami Miller School of Medicine, Miami, Florida, USA</aff><aff id=\"aff0030\"><label>f</label>Smidt Heart Institute, Cedars-Sinai Medical Center, Los Angeles, California, USA</aff></contrib-group><author-notes><corresp id=\"cor1\"><label>&#8270;</label>Corresponding author.&#160;Department of Radiology, Feinberg School of Medicine, Northwestern University, 737 North Michigan Avenue, Chicago, Illinois 60611, USA. <email>neda.tavakoli@northwestern.edu</email></corresp></author-notes><pub-date pub-type=\"collection\"><season>Winter</season><year>2025</year></pub-date><pub-date pub-type=\"epub\"><day>20</day><month>8</month><year>2025</year></pub-date><volume>27</volume><issue>2</issue><issue-id pub-id-type=\"pmc-issue-id\">490964</issue-id><elocation-id>101945</elocation-id><history><date date-type=\"received\"><day>30</day><month>12</month><year>2024</year></date><date date-type=\"rev-recd\"><day>14</day><month>8</month><year>2025</year></date><date date-type=\"accepted\"><day>18</day><month>8</month><year>2025</year></date></history><pub-history><event event-type=\"pmc-release\"><date><day>20</day><month>08</month><year>2025</year></date></event><event event-type=\"pmc-live\"><date><day>08</day><month>12</month><year>2025</year></date></event><event event-type=\"pmc-last-change\"><date iso-8601-date=\"2025-12-08 09:25:14.293\"><day>08</day><month>12</month><year>2025</year></date></event></pub-history><permissions><copyright-statement>&#169; 2025 The Author(s)</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref specific-use=\"textmining\" content-type=\"ccbyncndlicense\">https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref><license-p>This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).</license-p></license></permissions><self-uri xmlns:xlink=\"http://www.w3.org/1999/xlink\" content-type=\"pmc-pdf\" xlink:href=\"main.pdf\"/><abstract id=\"ab0010\"><sec><title>Background</title><p>Late gadolinium enhancement (LGE) imaging remains the gold standard for assessing myocardial fibrosis and scarring, with left ventricular (LV) LGE presence and extent serving as a predictor of major adverse cardiac events (MACE). Despite its clinical significance, LGE-based LV scar quantification is not used routinely due to the labor-intensive manual segmentation and substantial inter-observer variability.</p></sec><sec><title>Methods</title><p>We developed ScarNet that synergistically combines a transformer-based encoder in medical segment anything model (MedSAM), which we fine-tuned with our dataset, and a convolution-based decoder in UNet with tailored attention blocks to automatically segment myocardial scar boundaries while maintaining anatomical context. This network was trained and fine-tuned on an existing database of 401 ischemic cardiomyopathy patients (4137 2D LGE images) with expert segmentation of myocardial and scar boundaries in LGE images, validated on 100 patients (1034 2D LGE images) during training, and tested on unseen set of 184 patients (1895 2D LGE images). Ablation studies were conducted to validate each architectural component's contribution.</p></sec><sec><title>Results</title><p>In 184 independent testing patients, ScarNet achieved accurate scar boundary segmentation (median DICE&#160;=&#160;0.912 [interquartile range (IQR): 0.863&#8211;0.944], concordance correlation coefficient [CCC]&#160;=&#160;0.963), significantly outperforming both MedSAM (median DICE&#160;=&#160;0.046 [IQR: 0.043&#8211;0.047], CCC&#160;=&#160;0.018) and nnU-Net (median DICE&#160;=&#160;0.638 [IQR: 0.604&#8211;0.661], CCC&#160;=&#160;0.734). For scar volume quantification, ScarNet demonstrated excellent agreement with manual analysis (CCC&#160;=&#160;0.995, percent bias&#160;=&#160;&#8722;0.63%, CoV=4.3%) compared to MedSAM (CCC&#160;=&#160;0.002, percent bias&#160;=&#160;&#8722;13.31%, CoV&#160;=&#160;130.3%) and nnU-Net (CCC&#160;=&#160;0.910, percent bias&#160;=&#160;&#8722;2.46%, CoV&#160;=&#160;20.3%). Similar trends were observed in the Monte Carlo simulations with noise perturbations. The overall accuracy was highest for ScarNet (sensitivity=95.3% (163/171); specificity=92.3% (12/13)), followed by nnU-Net (sensitivity=74.9% (128/171); specificity=69.2% (9/13)) and MedSAM (sensitivity=15.2% (26/171); specificity=92.3% (12/13)).</p></sec><sec><title>Conclusion</title><p>ScarNet outperformed MedSAM and nnU-Net for predicting myocardial and scar boundaries in LGE images of patients with ischemic cardiomyopathy. The Monte Carlo simulations demonstrated that ScarNet is less sensitive to noise perturbations than other tested networks.</p></sec></abstract><abstract abstract-type=\"graphical\" id=\"ab0015\"><title>Graphical abstract</title><p><fig id=\"fig0065\" position=\"anchor\" orientation=\"portrait\"><alt-text id=\"at0075\">ga1</alt-text><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"lk0065\" position=\"float\" orientation=\"portrait\" xlink:href=\"ga1.jpg\"/></fig></p></abstract><kwd-group id=\"keys0010\"><title>Keywords</title><kwd>Cardiac MRI</kwd><kwd>Deep learning</kwd><kwd>Foundation models</kwd><kwd>Late gadolinium enhancement</kwd><kwd>Medical image segmentation</kwd><kwd>Myocardial scar quantification</kwd></kwd-group><custom-meta-group><custom-meta><meta-name>pmc-status-qastatus</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>pmc-status-live</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-status-embargo</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-status-released</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-open-access</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-olf</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-manuscript</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-legally-suppressed</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-pdf</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-supplement</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-pdf-only</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-suppress-copyright</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-real-version</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-scanned-article</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-preprint</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-in-epmc</meta-name><meta-value>yes</meta-value></custom-meta></custom-meta-group></article-meta><def-list><title>Abbreviations</title><def-item><term id=\"key0010\">AI</term><def><p>artificial intelligence</p></def></def-item><def-item><term id=\"key0020\">CMR</term><def><p>cardiovascular magnetic resonance</p></def></def-item><def-item><term id=\"key0030\">CNN</term><def><p>convolutional neural networks</p></def></def-item><def-item><term id=\"key0040\">CoV</term><def><p>coefficient of variation</p></def></def-item><def-item><term id=\"key0050\">DL</term><def><p>DICE loss</p></def></def-item><def-item><term id=\"key0060\">GPU</term><def><p>graphics processing unit</p></def></def-item><def-item><term id=\"key0070\">LGE</term><def><p>late gadolinium enhancement magnetic resonance imaging</p></def></def-item><def-item><term id=\"key0080\">LV</term><def><p>left ventricle</p></def></def-item><def-item><term id=\"key0090\">MACE</term><def><p>major adverse cardiac events</p></def></def-item><def-item><term id=\"key0100\">MedSAM</term><def><p>medical segment anything model</p></def></def-item><def-item><term id=\"key0110\">MI</term><def><p>myocardial infarction</p></def></def-item><def-item><term id=\"key0120\">MRI</term><def><p>magnetic resonance imaging</p></def></def-item><def-item><term id=\"key0130\">SAM</term><def><p>segment anything model</p></def></def-item><def-item><term id=\"key0140\">SE</term><def><p>squeeze-and-excitation</p></def></def-item><def-item><term id=\"key0150\">ViT</term><def><p>vision transformer</p></def></def-item><def-item><term id=\"key0160\">CCC</term><def><p>concordance correlation coefficient</p></def></def-item><def-item><term id=\"key0170\">2D</term><def><p>two-dimensional</p></def></def-item><def-item><term id=\"key0180\">3D</term><def><p>three-dimensional</p></def></def-item><def-item><term id=\"key0190\">IQR</term><def><p>interquartile range</p></def></def-item><def-item><term id=\"key0200\">nnU-Net</term><def><p>no new U-net</p></def></def-item><def-item><term id=\"key0210\">FCNN</term><def><p>fully convolutional neural network</p></def></def-item><def-item><term id=\"key0220\">PSIR</term><def><p>phase-sensitive inversion recovery</p></def></def-item><def-item><term id=\"key0230\">ViTMAE</term><def><p>vision transformer masked auto encoder</p></def></def-item><def-item><term id=\"key0240\">FTL</term><def><p>focal Tversky loss</p></def></def-item><def-item><term id=\"key0250\">CE</term><def><p>cross entropy</p></def></def-item><def-item><term id=\"key0260\">DSC</term><def><p>DICE similarity coefficient</p></def></def-item><def-item><term id=\"key0270\">MPI</term><def><p>message passing interface</p></def></def-item></def-list></front><body><sec id=\"sec0005\"><label>1</label><title>Introduction</title><p id=\"p0010\">Late gadolinium enhancement (LGE) cardiovascular magnetic resonance (CMR) <xref rid=\"bib1\" ref-type=\"bibr\">[1]</xref> is the gold standard non-invasive test for myocardial fibrosis and scarring, providing essential information for risk stratification, treatment planning, and prognosis evaluation. Among LGE metrics, left ventricular (LV) scar volume is especially significant, as it has proven to be a predictor of major adverse cardiac events (MACE) and arrhythmic complications <xref rid=\"bib2\" ref-type=\"bibr\">[2]</xref>.</p><p id=\"p0015\">Despite its clinical importance, LGE-based LV scar quantification remains challenging to implement in practice due to several factors <xref rid=\"bib3\" ref-type=\"bibr\">[3]</xref>. Traditional manual segmentation requires several minutes per case and is highly user-dependent, with considerable inter-observer variability <xref rid=\"bib4\" ref-type=\"bibr\">[4]</xref>, <xref rid=\"bib5\" ref-type=\"bibr\">[5]</xref>, <xref rid=\"bib6\" ref-type=\"bibr\">[6]</xref>. This variability stems from the complex and heterogeneous appearance of scar tissue in LGE images, which often presents with diffuse boundaries, irregular shapes, and varying intensity patterns. Additionally, imaging artifacts such as motion blur, intensity inhomogeneity, ghosting artifacts arising from arrhythmia, and noise further complicate accurate scar delineation <xref rid=\"bib7\" ref-type=\"bibr\">[7]</xref>, making reliable manual segmentation both labor-intensive and inconsistent.</p><p id=\"p0020\">Recent advancements in deep learning have inspired efforts to automate LV scar segmentation in LGE <xref rid=\"bib8\" ref-type=\"bibr\">[8]</xref>. Traditional convolutional neural networks (CNNs), particularly U-Net-based architectures <xref rid=\"bib9\" ref-type=\"bibr\">[9]</xref>, <xref rid=\"bib10\" ref-type=\"bibr\">[10]</xref>, have shown promise in medical image segmentation tasks. Early work by Moccia et al. demonstrated the potential of fully convolutional neural networks (FCNNs) for scar segmentation on CMR-LGE images, achieving improved performance when limiting the search area to the myocardial region <xref rid=\"bib11\" ref-type=\"bibr\">[11]</xref>. However, these methods have encountered limitations in cardiac scar segmentation. A 2021 meta-analysis of 35 AI-based left ventricular scar quantification studies demonstrated mean DICE scores of only 0.616 and 0.633 for supervised and unsupervised methods, respectively <xref rid=\"bib12\" ref-type=\"bibr\">[12]</xref>. These limited performances are attributed to the inherent challenges of capturing long-range dependencies in cardiac anatomy, handling multi-scale variations in scar appearance <xref rid=\"bib13\" ref-type=\"bibr\">[13]</xref>, and accurately delineating poorly defined scar boundaries.</p><p id=\"p0025\">The recent development of transformer-based models <xref rid=\"bib14\" ref-type=\"bibr\">[14]</xref>, including the segment anything model (SAM) <xref rid=\"bib14\" ref-type=\"bibr\">[14]</xref>, <xref rid=\"bib15\" ref-type=\"bibr\">[15]</xref> and its medical variant, MedSAM <xref rid=\"bib16\" ref-type=\"bibr\">[16]</xref>, has introduced new possibilities for medical image segmentation. These models excel at capturing global context and handling diverse object appearances, presenting a unique opportunity to address the challenges of cardiac scar segmentation. However, their generalist nature and lack of domain-specific optimization limit their direct applicability to LGE analysis <xref rid=\"bib17\" ref-type=\"bibr\">[17]</xref>, <xref rid=\"bib18\" ref-type=\"bibr\">[18]</xref>.</p><p id=\"p0030\">To address these challenges, we propose ScarNet, a novel foundation model designed specifically for LV scar segmentation in LGE as illustrated in <xref rid=\"fig0005\" ref-type=\"fig\">Fig. 1</xref>. ScarNet integrates the global context-awareness of MedSAM's transformer-based encoder with the precise localization capabilities of a U-Net decoder through an adaptive fusion mechanism. This architecture is further strengthened by specialized attention mechanisms, including multi-scale feature extraction pathways enhanced by squeeze-and-excitation (SE) modules <xref rid=\"bib19\" ref-type=\"bibr\">[19]</xref> and novel ScarAttention blocks that dynamically focus on subtle scar regions while preserving anatomical context.<fig id=\"fig0005\" position=\"float\" orientation=\"portrait\"><label>Fig. 1</label><caption><p>Architecture of ScarNet: a&#160;hybrid model combining MedSAM's ViT-based encoder with U-Net's multi-scale decoder for LV scar segmentation in LGE. <bold>(A)</bold> The integration of MedSAM's embeddings, processed through ScarAttention and fused with U-Net outputs, to generate precise scar masks. <bold>(B)</bold> The UNet encoder-decoder, highlighting hierarchical feature extraction, skip connections, and spatial refinement for accurate segmentation. <italic toggle=\"yes\">LV</italic> left ventricular, <italic toggle=\"yes\">LGE</italic>&#160;late gadolinium enhancement, <italic toggle=\"yes\">MedSAM</italic> medical segment anything model, <italic toggle=\"yes\">ViT</italic> vision transformer.</p></caption><alt-text id=\"at0005\">Fig. 1</alt-text><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"lk0005\" position=\"float\" orientation=\"portrait\" xlink:href=\"gr1.jpg\"/></fig></p><p id=\"p0035\">To address the class imbalance inherent in cardiac scar segmentation, ScarNet incorporates a comprehensive multi-component loss function. This loss function combines DICE, Focal <xref rid=\"bib20\" ref-type=\"bibr\">[20]</xref>, and cross-entropy losses with class-specific optimization terms for scar and myocardium segmentation, supported by an adaptive weighting scheme to balance the contributions of each component throughout training.</p><p id=\"p0040\">Our novel ScarNet architecture addresses key challenges in cardiac scar segmentation through several innovative design elements. The hybrid structure combines global context understanding with precise local feature detection, while specialized attention mechanisms enhance the capture of heterogeneous scar patterns. Furthermore, an efficient inference pipeline supports seamless integration into clinical workflows, and the adaptive fusion design enables comprehensive multi-scale feature extraction. The purpose of this study was to implement ScarNet and compare its performance against MedSAM and nnU-Net on an existing database of LGE images of ischemic cardiomyopathy patients with expert segmentation of myocardial and scar boundaries as reference.</p></sec><sec id=\"sec0010\"><label>2</label><title>Methods</title><sec id=\"sec0015\"><label>2.1</label><title>Patient cohort</title><p id=\"p0045\">This is a retrospective study using de-identified LGE images from patients with coronary artery disease and left ventricular dysfunction enrolled in the DETERMINE registry (ClinicalTrials.gov ID <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"pmc:clinical-trial\" xlink:href=\"NCT00487279\">NCT00487279</ext-link>) and PRE-DETERMINE study (ClinicalTrials.gov ID <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"pmc:clinical-trial\" xlink:href=\"NCT01114269\">NCT01114269</ext-link>) <xref rid=\"bib21\" ref-type=\"bibr\">[21]</xref>. The DETERMINE and PRE-DETERMINE studies were conducted at 65 sites across the United States between 2008 and 2015, using vendor-specific LGE pulse sequences (Siemens, Philips, and GE scanners). The protocols included segmented breath-hold, single-shot, and 3D sequences. Of the images analyzed by the DETERMINE/PRE-DETERMINE studies,92.9% (739/795) were magnitude, while 7% (56/795) were phase-sensitive inversion recovery (PSIR). The study was approved by our Institutional Review Board with a waiver of informed consent.</p><p id=\"p0050\">From the original database of 795 patients, 58 patients with microvascular obstruction were removed, and 51 patients were removed due to either poor image quality or mismatch between the annotated contour files and the underlying image files. In total, we used 685 patients with 7066 analyzable 2D LGE images. The dataset was divided using a patient-level split to prevent data leakage: 401 patients (4137 2D LGE images) for training, 100 patients (1034 2D images) for validation, and 184 patients (1895 2D images) as an independent testing set. All patients included in the testing study exhibited confirmed ischemic cardiomyopathy with left ventricular ejection fraction below 50%. Additional clinical profiles were not available to the study team at the time of this study. LGE images were manually segmented using the full width at half maximum technique <xref rid=\"bib21\" ref-type=\"bibr\">[21]</xref> in QMass software (version 7.6, Medis Medical Imaging Systems, Leiden, The Netherlands), by two attending cardiologists with more than 10 years of clinical experience in CMR. The median pixel dimension was 1.74&#8201;mm&#8201;&#215;&#8201;1.91&#8201;mm (range: 0.95&#8201;mm&#8201;&#215;&#8201;1.04&#8201;mm to 2.81&#8201;mm&#8201;&#215;&#8201;3.75&#8201;mm). The median acquisition matrix was 224&#160;&#215;&#160;192 (range: 120&#160;&#215;&#160;72 to 384&#160;&#215;&#160;256). For additional details of the dataset and data preparation, please see Appendix in the <xref rid=\"sec0085\" ref-type=\"sec\">Supplementary Materials</xref>.</p></sec><sec id=\"sec0020\"><label>2.2</label><title>Model architecture</title><p id=\"p0055\">We include a literature review of related works to highlight their relative strengths and weaknesses, ultimately justifying the need for our study. Please see Appendix in <xref rid=\"sec0085\" ref-type=\"sec\">Supplementary Materials</xref> for this literature review.</p><p id=\"p0060\">The ScarNet architecture, shown in <xref rid=\"fig0005\" ref-type=\"fig\">Fig. 1</xref> and <xref rid=\"fig0010\" ref-type=\"fig\">Fig. 2</xref>, integrates global and local features by combining the pretrained MedSAM with a UNet pathway via an adaptive fusion mechanism, effectively capturing both anatomical context and spatial details necessary for precise LV scar segmentation in LGE. The MedSAM pathway uses a vision transformer (ViT) backbone, pretrained on large-scale general and medical datasets, to leverage global contextual information and subtle structural relationships in cardiac imaging. The complete segmentation pipeline is detailed in Algorithm 1, Algorithm 2, and Algorithm 3 included in <xref rid=\"sec0085\" ref-type=\"sec\">Supplementary Materials</xref>, which outlines the key steps of our approach from input processing to final mask generation. The feature fusion process between MedSAM and UNet pathways is elaborated in Algorithm 4 included in <xref rid=\"sec0085\" ref-type=\"sec\">Supplementary Materials</xref>. Additional algorithmic details can be found in the Appendix in <xref rid=\"sec0085\" ref-type=\"sec\">Supplementary Materials</xref>.<fig id=\"fig0010\" position=\"float\" orientation=\"portrait\"><label>Fig. 2</label><caption><p>Overview of the ScarNet encoder-decoder architecture with attention mechanisms: the image encoder leverages a ViTMAE-based vision transformer for comprehensive feature extraction. A prompt encoder generates segmentation prompts from automatically detected epicardial ROI expanded by two pixels in all directions (up, down, left, right), which feed into the mask decoder. Key components Channel Reducer, Scar Attention blocks, and SE layers, refine feature maps to highlight subtle scar regions while maintaining anatomical context. The final convolutional layers integrate multi-scale features to produce accurate scar segmentation masks, with the adaptive attention modules enabling dynamic focus on clinically relevant scar tissue in LGE. <italic toggle=\"yes\">ViTMAE</italic> vision transformer masked auto encoder, <italic toggle=\"yes\">ROI</italic> Region of Interest, <italic toggle=\"yes\">SE</italic> Squeeze-and-Excitation.</p></caption><alt-text id=\"at0010\">Fig. 2</alt-text><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"lk0010\" position=\"float\" orientation=\"portrait\" xlink:href=\"gr2.jpg\"/></fig></p><p id=\"p0065\">By dividing the input image into non-overlapping patches, each mapped into an embedding space, MedSAM processes these features through a multi-scale decoder that progressively reduces channel dimensions from 256 to 32, preserving essential spatial relationships. This pathway is further enhanced with squeeze-and-excitation (SE) blocks that recalibrate channels, highlighting scar-relevant regions while suppressing background features, thus maximizing the representational power of the pretrained MedSAM (<xref rid=\"eqn0015\" ref-type=\"disp-formula\">(3)</xref>, <xref rid=\"eqn0020\" ref-type=\"disp-formula\">(4)</xref>).</p><p id=\"p0070\">In parallel, the UNet pathway captures localized spatial details through a symmetric encoder-decoder architecture, progressively reducing spatial resolution while increasing feature depth with each encoding block (<xref rid=\"eqn0025\" ref-type=\"disp-formula\">Eq. 5</xref>). Skip connections preserve high-resolution features by linking corresponding encoder and decoder blocks, which enables accurate boundary delineation critical for scar segmentation (<xref rid=\"eqn0030\" ref-type=\"disp-formula\">Eq. 6</xref>). The adaptive fusion mechanism combines outputs from both pathways, balancing global and local context by aligning feature maps and applying an adaptive weighting mechanism. This fusion consolidates ScarNet&#8217;s learned representations into a single four-class segmentation map, distinguishing background, myocardium, blood pool, and scar regions, through a final 1&#160;&#215;&#160;1 convolutional layer.</p><sec id=\"sec0025\"><label>2.2.1</label><title>Ablation study design</title><p id=\"p0075\">To validate our architectural design choices, we conducted ablation experiments by systematically removing or modifying key components on the testing dataset. Four configurations were evaluated as follows: (1) MedSAM Pathway Removal&#8212;complete elimination of the transformer encoder, using only the UNet pathway; (2) Weight Freezing&#8212;MedSAM weights frozen during training to assess fine-tuning importance; (3) Attention removal&#8212;elimination of SE modules and ScarAttention blocks while maintaining fusion; and (4) Full ScarNet&#8212;complete architecture as baseline. All experiments used identical training protocols and hyperparameters.</p><sec id=\"sec0030\"><label>2.2.1.1</label><title>Attention mechanisms</title><p id=\"p0080\">ScarNet&#8217;s attention mechanisms focus on scar-relevant features, enhancing the model&#8217;s ability to generalize across diverse imaging conditions. SE modules, embedded within the MedSAM pathway, recalibrate channel-wise features by modeling interdependencies to boost sensitivity to scar tissue regions, while suppressing irrelevant background areas. Complementing this, the ScarAttention blocks, detailed in Algorithm 2, dynamically emphasize scar-specific features by reweighting spatial attention. These blocks use positional relationships and intensity variations unique to scars, improving the model's accuracy in highlighting subtle scar regions while preserving surrounding anatomical structures.</p></sec><sec id=\"sec0035\"><label>2.2.1.2</label><title>Training pipeline</title><p id=\"p0085\">ScarNet&#8217;s training pipeline, described in Algorithm 1, is structured to ensure optimal segmentation capabilities. Initially, input LGE images are normalized and fed into both MedSAM and U-Net pathways. The parallel processing of these pathways generates both global and local feature representations, which are then enhanced by SE and ScarAttention modules before being fused to yield a four-class segmentation map. Loss calculation follows, with <inline-formula><mml:math id=\"M1\" altimg=\"si0001.svg\"><mml:msub><mml:mrow><mml:mi mathvariant=\"script\">L</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant=\"italic\">ScarNet</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> computed based on the adaptive weighting of DICE, Focal, and Cross-Entropy losses, guiding the model to optimize for both global and local accuracy. Backpropagation is conducted using an Adam optimizer, with gradients calculated to minimize <inline-formula><mml:math id=\"M2\" altimg=\"si0001.svg\"><mml:msub><mml:mrow><mml:mi mathvariant=\"script\">L</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant=\"italic\">ScarNet</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> (Algorithm 1, Steps 13&#8211;15). Regularization techniques, such as dropout and data augmentation, are applied to improve generalization.</p><p id=\"p0090\">During inference, ScarNet processes unseen LGE images and generates segmentation maps for background, myocardium, blood pool, and scar regions, with the inference algorithm detailed in Algorithm 4 dynamically adjusting feature weighting for efficient predictions.</p></sec><sec id=\"sec0040\"><label>2.2.1.3</label><title>Mathematical model</title><p id=\"p0095\">The ScarNet model, denoted by <inline-formula><mml:math id=\"M3\" altimg=\"si0002.svg\"><mml:mi mathvariant=\"script\">H</mml:mi></mml:math></inline-formula>, combines a fine-tuned and enhanced MedSAM and U-Net architecture to achieve accurate segmentation of cardiac scar regions. The model&#8217;s core function can be expressed as:<disp-formula id=\"eqn0005\"><label>(1)</label><mml:math id=\"M4\" altimg=\"si0003.svg\"><mml:mrow><mml:mi mathvariant=\"script\">H</mml:mi><mml:mrow><mml:mfenced open=\"(\" close=\")\"><mml:mrow><mml:mi mathvariant=\"normal\">x</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mo>=</mml:mo><mml:mi mathvariant=\"script\">F</mml:mi><mml:mrow><mml:mfenced open=\"(\" close=\")\"><mml:mrow><mml:mtext>MedSAM</mml:mtext><mml:mrow><mml:mfenced open=\"(\" close=\")\"><mml:mrow><mml:mi mathvariant=\"normal\">x</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mo>,</mml:mo><mml:mspace width=\"1em\"/><mml:mtext>U</mml:mtext><mml:mo>&#8722;</mml:mo><mml:mtext>Net</mml:mtext><mml:mrow><mml:mfenced open=\"(\" close=\")\"><mml:mrow><mml:mi mathvariant=\"normal\">x</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id=\"M5\" altimg=\"si0004.svg\"><mml:mrow><mml:mi>x</mml:mi><mml:mo>&#8712;</mml:mo><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>H</mml:mi><mml:mo>&#215;</mml:mo><mml:mi>W</mml:mi><mml:mo>&#215;</mml:mo><mml:mn mathvariant=\"double-struck\">1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> represents a grayscale medical image, and <inline-formula><mml:math id=\"M6\" altimg=\"si0005.svg\"><mml:mrow><mml:mi mathvariant=\"script\">F</mml:mi><mml:mspace width=\"1em\"/></mml:mrow></mml:math></inline-formula>&#160;is a fusion function that combines the outputs of the MedSAM and U-Net branches. The fusion function <inline-formula><mml:math id=\"M7\" altimg=\"si0006.svg\"><mml:mrow><mml:mi mathvariant=\"script\">F</mml:mi><mml:mi mathvariant=\"normal\">ta</mml:mi></mml:mrow></mml:math></inline-formula>&#160;takes two feature maps, <inline-formula><mml:math id=\"M8\" altimg=\"si0007.svg\"><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mspace width=\"1em\"/></mml:mrow></mml:math></inline-formula>&#160;and <inline-formula><mml:math id=\"M9\" altimg=\"si0008.svg\"><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>, produced by MedSAM and U-Net, respectively, and combines them through concatenation and a 1&#160;&#215;&#160;1 convolution to produce the final segmentation output:<disp-formula id=\"eqn0010\"><label>(2)</label><mml:math id=\"M10\" altimg=\"si0009.svg\"><mml:mrow><mml:mi mathvariant=\"script\">F</mml:mi><mml:mrow><mml:mfenced open=\"(\" close=\")\"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant=\"normal\">f</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant=\"normal\">f</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mo>=</mml:mo><mml:mtext>Conv</mml:mtext><mml:mrow><mml:mfenced open=\"(\" close=\")\"><mml:mrow><mml:mtext>Concat</mml:mtext><mml:mrow><mml:mfenced open=\"[\" close=\"]\"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant=\"normal\">f</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant=\"normal\">f</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id=\"M11\" altimg=\"si0010.svg\"><mml:mtext>Conv</mml:mtext></mml:math></inline-formula> is a 1&#160;&#215;&#160;1 convolution that reduces the concatenated feature map to the desired number of classes, and <inline-formula><mml:math id=\"M12\" altimg=\"si0011.svg\"><mml:mrow><mml:mtext>Concat</mml:mtext><mml:mspace width=\"1em\"/></mml:mrow></mml:math></inline-formula>&#160;represents channel-wise concatenation.</p><sec id=\"sec0045\"><label>2.2.1.3.1</label><title>MedSAM pathway</title><p id=\"p0100\">The MedSAM component of ScarNet leverages a ViT backbone to capture global dependencies within the image, which is crucial for identifying subtle structures like scar tissue. MedSAM consists of patch embedding and position encoding stages, where the input image <inline-formula><mml:math id=\"M13\" altimg=\"si0012.svg\"><mml:mrow><mml:mi mathvariant=\"normal\">x</mml:mi><mml:mo>&#8712;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant=\"normal\">R</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant=\"normal\">H</mml:mi><mml:mo>&#215;</mml:mo><mml:mi mathvariant=\"normal\">W</mml:mi><mml:mo>&#215;</mml:mo><mml:mn mathvariant=\"double-struck\">1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> is divided into <inline-formula><mml:math id=\"M14\" altimg=\"si0013.svg\"><mml:mrow><mml:mi mathvariant=\"normal\">p</mml:mi><mml:mo>&#215;</mml:mo><mml:mi mathvariant=\"normal\">p</mml:mi></mml:mrow></mml:math></inline-formula> non-overlapping patches. Each patch is flattened and mapped to an embedding space, generating patch embeddings <inline-formula><mml:math id=\"M15\" altimg=\"si0014.svg\"><mml:mi>E</mml:mi></mml:math></inline-formula>:<disp-formula id=\"eqn0015\"><label>(3)</label><mml:math id=\"M16\" altimg=\"si0015.svg\"><mml:mrow><mml:mi mathvariant=\"normal\">E</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant=\"normal\">W</mml:mi></mml:mrow><mml:mrow><mml:mtext>embed</mml:mtext></mml:mrow></mml:msub><mml:mo>&#8901;</mml:mo><mml:mi mathvariant=\"normal\">P</mml:mi><mml:mrow><mml:mfenced open=\"(\" close=\")\"><mml:mrow><mml:mi mathvariant=\"normal\">x</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id=\"M17\" altimg=\"si0016.svg\"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mfenced open=\"(\" close=\")\"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mspace width=\"1em\"/></mml:mrow></mml:math></inline-formula>&#160;denotes the patches, and <inline-formula><mml:math id=\"M18\" altimg=\"si0017.svg\"><mml:mrow><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mtext>embed</mml:mtext></mml:mrow></mml:msub><mml:mspace width=\"1em\"/></mml:mrow></mml:math></inline-formula>&#160;is a learnable embedding matrix. The transformer operates on these patch embeddings, applying self-attention to learn relationships across the entire spatial dimension of the image. While the original MedSAM was designed for binary segmentation (one class + background), we adapted it for our multi-class cardiac segmentation task. Specifically, we modified the final decoder layer to output 4 channels instead of 1, enabling simultaneous segmentation of background, blood pool, myocardium, and scar tissue. The model was trained using multi-class cross-entropy loss rather than the original binary cross-entropy, allowing MedSAM to handle the four-class cardiac segmentation problem. This adaptation maintains the transformer's global context learning capabilities while extending its output functionality for comprehensive cardiac tissue classification. Despite modifying MedSAM's decoder for 4-class output and training with multi-class cross-entropy loss, the standalone model failed to learn meaningful scar representations without domain-specific fine-tuning, demonstrating that architectural adaptation alone is insufficient for specialized cardiac applications.</p><p id=\"p0105\">For query Q, key K, and value V matrices derived from E, self-attention is computed as:<disp-formula id=\"eqn0020\"><label>(4)</label><mml:math id=\"M19\" altimg=\"si0018.svg\"><mml:mrow><mml:mi mathvariant=\"italic\">Attention</mml:mi><mml:mo stretchy=\"false\">(</mml:mo><mml:mi>Q</mml:mi><mml:mo>,</mml:mo><mml:mspace width=\"1em\"/><mml:mi>K</mml:mi><mml:mo>,</mml:mo><mml:mspace width=\"1em\"/><mml:mi>V</mml:mi><mml:mo stretchy=\"false\">)</mml:mo><mml:mspace width=\"1em\"/><mml:mo>=</mml:mo><mml:mi mathvariant=\"italic\">softmax</mml:mi><mml:mrow><mml:mfenced open=\"(\" close=\")\"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>Q</mml:mi><mml:msup><mml:mrow><mml:mi>K</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:mrow><mml:mspace width=\"1em\"/><mml:mi>V</mml:mi></mml:mrow></mml:math></disp-formula>where d is the embedding dimension, enabling global context learning. The encoded features are passed through multiple attention blocks and SE layers in a multi-scale decoder. This process enhances the features relevant to scar regions. The detailed processing steps of the MedSAM branch are presented in Algorithm 2, highlighting the transformer-based processing and attention mechanisms.</p></sec><sec id=\"sec0050\"><label>2.2.1.3.2</label><title>UNet&#160;pathway</title><p id=\"p0110\">The UNet pathway captures local spatial details via a hierarchical encoder-decoder structure. The encoder consists of convolutional layers followed by downsampling steps, progressively reducing spatial resolution and increasing feature channels:<disp-formula id=\"eqn0025\"><label>(5)</label><mml:math id=\"M20\" altimg=\"si0019.svg\"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant=\"italic\">enc</mml:mi></mml:mrow><mml:mrow><mml:mspace width=\"1em\"/><mml:mi>l</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi mathvariant=\"italic\">Downsample</mml:mi><mml:mrow><mml:mfenced open=\"(\" close=\")\"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant=\"italic\">enc</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>&#8722;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula></p><p id=\"p0115\">Each level l extracts features at a smaller spatial scale, enabling the capture of localized features. The decoder restores spatial resolution by upsampling, integrating high-resolution features from the encoder via skip connections:<disp-formula id=\"eqn0030\"><label>(6)</label><mml:math id=\"M21\" altimg=\"si0020.svg\"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant=\"italic\">dec</mml:mi></mml:mrow><mml:mrow><mml:mspace width=\"1em\"/><mml:mi>l</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi mathvariant=\"italic\">Upsample</mml:mi><mml:mrow><mml:mfenced open=\"(\" close=\")\"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant=\"italic\">dec</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow><mml:mspace width=\"1em\"/><mml:mo>+</mml:mo><mml:mspace width=\"1em\"/><mml:msubsup><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant=\"italic\">enc</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></disp-formula></p><p id=\"p0120\">The final layer produces a feature map <inline-formula><mml:math id=\"M22\" altimg=\"si0021.svg\"><mml:msub><mml:mrow><mml:mi mathvariant=\"normal\">M</mml:mi></mml:mrow><mml:mrow><mml:mtext>UNet</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>&#160;in <inline-formula><mml:math id=\"M23\" altimg=\"si0022.svg\"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant=\"normal\">R</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant=\"normal\">H</mml:mi><mml:mo>&#215;</mml:mo><mml:mi mathvariant=\"normal\">W</mml:mi><mml:mo>&#215;</mml:mo><mml:mi mathvariant=\"normal\">C</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mspace width=\"0.25em\"/></mml:mrow></mml:math></inline-formula>&#160;where C is the number of classes. Algorithm 3 provides a detailed breakdown of the UNet branch operations, including the encoder-decoder pathway and skip connection enhancement steps.</p></sec><sec id=\"sec0055\"><label>2.2.1.3.3</label><title>Loss function</title><p id=\"p0125\">In ScarNet, the overall loss function <inline-formula><mml:math id=\"M24\" altimg=\"si0001.svg\"><mml:msub><mml:mrow><mml:mi mathvariant=\"script\">L</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant=\"italic\">ScarNet</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is designed to address class imbalance and to focus on achieving high segmentation accuracy, especially for challenging regions like cardiac scars. The ScarNet model aims to minimize the overall loss function with respect to the model parameters<inline-formula><mml:math id=\"M25\" altimg=\"si0023.svg\"><mml:mrow><mml:mspace width=\"1em\"/><mml:mi mathvariant=\"normal\">&#952;</mml:mi></mml:mrow></mml:math></inline-formula>, ensuring accurate segmentation across classes, with a particular emphasis on the scar class. This can be formulated as:<disp-formula id=\"eqn0035\"><label>(7)</label><mml:math id=\"M26\" altimg=\"si0024.svg\"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant=\"normal\">&#952;</mml:mi></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi mathvariant=\"normal\">arg</mml:mi><mml:munder><mml:mrow><mml:mi>min</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant=\"normal\">&#952;</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant=\"script\">L</mml:mi></mml:mrow><mml:mrow><mml:mtext>ScarNet</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mfenced open=\"(\" close=\")\"><mml:mrow><mml:mi mathvariant=\"normal\">&#952;</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id=\"M27\" altimg=\"si0025.svg\"><mml:msup><mml:mrow><mml:mi mathvariant=\"normal\">&#952;</mml:mi></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> represents the optimal parameters of the model, and <inline-formula><mml:math id=\"M28\" altimg=\"si0026.svg\"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant=\"script\">L</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant=\"italic\">ScarNet</mml:mi></mml:mrow></mml:msub><mml:mspace width=\"1em\"/></mml:mrow></mml:math></inline-formula>&#160;is the combined loss function defined as:<disp-formula id=\"eqn0040\"><label>(8)</label><mml:math id=\"M29\" altimg=\"si0027.svg\"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant=\"script\">L</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant=\"italic\">ScarNet</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>&#955;</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>.</mml:mo><mml:mi mathvariant=\"italic\">FTL</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>&#955;</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>.</mml:mo><mml:mi mathvariant=\"italic\">DL</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>&#955;</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>.</mml:mo><mml:mi mathvariant=\"italic\">CE</mml:mi></mml:mrow></mml:math></disp-formula>where, <inline-formula><mml:math id=\"M30\" altimg=\"si0028.svg\"><mml:mi mathvariant=\"italic\">FTL</mml:mi></mml:math></inline-formula> is the Focal Tversky Loss, which mitigates class imbalance by focusing more on the scar region,&#160;<inline-formula><mml:math id=\"M31\" altimg=\"si0029.svg\"><mml:mi mathvariant=\"italic\">DL</mml:mi></mml:math></inline-formula> is the DICE Loss, which measures spatial overlap between the predicted and ground truth masks, <inline-formula><mml:math id=\"M32\" altimg=\"si0030.svg\"><mml:mi mathvariant=\"italic\">CE</mml:mi></mml:math></inline-formula> is the cross-entropy loss, weighted by class-specific importance <inline-formula><mml:math id=\"M33\" altimg=\"si0031.svg\"><mml:msub><mml:mrow><mml:mi mathvariant=\"normal\">&#955;</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id=\"M34\" altimg=\"si0032.svg\"><mml:msub><mml:mrow><mml:mi mathvariant=\"normal\">&#955;</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>, and <inline-formula><mml:math id=\"M35\" altimg=\"si0033.svg\"><mml:msub><mml:mrow><mml:mi mathvariant=\"normal\">&#955;</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> are coefficients that control the contribution of each term. These parameters were objectively determined through systematic grid search over<inline-formula><mml:math id=\"M36\" altimg=\"si0034.svg\"><mml:mrow><mml:msub><mml:mrow><mml:mi>&#955;</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>&#8712;</mml:mo><mml:mspace width=\"0.25em\"/><mml:mrow><mml:mfenced open=\"[\" close=\"]\"><mml:mrow><mml:mn>0.3</mml:mn><mml:mo>,</mml:mo><mml:mspace width=\"0.25em\"/><mml:mn>0.5</mml:mn><mml:mo>,</mml:mo><mml:mspace width=\"0.25em\"/><mml:mn>0,7</mml:mn></mml:mrow></mml:mfenced></mml:mrow><mml:mo>,</mml:mo><mml:mspace width=\"0.25em\"/><mml:msub><mml:mrow><mml:mspace width=\"0.25em\"/><mml:mi>&#955;</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>&#8712;</mml:mo><mml:mspace width=\"0.25em\"/><mml:mrow><mml:mfenced open=\"[\" close=\"]\"><mml:mrow><mml:mn>0.2</mml:mn><mml:mo>,</mml:mo><mml:mspace width=\"0.25em\"/><mml:mn>0.4</mml:mn><mml:mo>,</mml:mo><mml:mspace width=\"0.25em\"/><mml:mn>0,6</mml:mn></mml:mrow></mml:mfenced></mml:mrow><mml:mo>,</mml:mo><mml:mspace width=\"0.25em\"/><mml:msub><mml:mrow><mml:mspace width=\"0.25em\"/><mml:mi>&#955;</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>&#8712;</mml:mo><mml:mspace width=\"0.25em\"/><mml:mrow><mml:mfenced open=\"[\" close=\"]\"><mml:mrow><mml:mn>0.1</mml:mn><mml:mo>,</mml:mo><mml:mspace width=\"0.25em\"/><mml:mn>0.2</mml:mn><mml:mo>,</mml:mo><mml:mspace width=\"0.25em\"/><mml:mn>0,3</mml:mn></mml:mrow></mml:mfenced></mml:mrow><mml:mspace width=\"1em\"/></mml:mrow></mml:math></inline-formula>&#160;using 5-fold cross-validation on the combined training-validation cohort (501 patients), with the testing set (184 patients) held out completely to prevent data leakage. This yielded optimal values <inline-formula><mml:math id=\"M37\" altimg=\"si0035.svg\"><mml:mrow><mml:msub><mml:mrow><mml:mi>&#955;</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn><mml:mo>,</mml:mo><mml:mspace width=\"0.25em\"/><mml:msub><mml:mrow><mml:mi>&#955;</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.4</mml:mn><mml:mo>,</mml:mo><mml:mspace width=\"0.25em\"/><mml:msub><mml:mrow><mml:mi>&#955;</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:math></inline-formula> (See <xref rid=\"fig0015\" ref-type=\"fig\">Fig. 3</xref>). The optimization is subject to constraints that guide the model&#8217;s focus:<list list-type=\"simple\" id=\"li0005\"><list-item id=\"u0005\"><label>1.</label><p id=\"p0130\">Class Imbalance Constraint: The scar class receives greater emphasis through heavier weighting of the Focal Tversky Loss term, enabling the model to manage class imbalances effectively. This constraint prioritizes reducing false negatives and false positives in scar segmentation, thus emphasizing the critical region of interest.</p></list-item><list-item id=\"u0010\"><label>2.</label><p id=\"p0135\">Spatial Accuracy Constraint: The DICE Loss <inline-formula><mml:math id=\"M38\" altimg=\"si0029.svg\"><mml:mi mathvariant=\"italic\">DL</mml:mi></mml:math></inline-formula> component ensures that the segmentation output maintains spatial alignment with the ground truth by maximizing overlap. This constraint encourages accurate boundary delineation, especially for small or complex structures.</p></list-item><list-item id=\"u0015\"><label>3.</label><p id=\"p0140\">Regional Priority Constraint: The cross-entropy loss <inline-formula><mml:math id=\"M39\" altimg=\"si0030.svg\"><mml:mi mathvariant=\"italic\">CE</mml:mi></mml:math></inline-formula>, with class-specific weights, further reinforces focus on critical regions, allowing flexibility in segmentation where non-scar regions may have less impact on the overall segmentation goal.</p></list-item></list><fig id=\"fig0015\" position=\"float\" orientation=\"portrait\"><label>Fig. 3</label><caption><p>Lambda parameter sensitivity analysis for objective parameter optimization. <bold>(A)</bold> Individual parameter sensitivity analysis: performance curves showing how each &#955; parameter individually affects DICE coefficient. Optimal values are marked with dashed vertical lines (&#955;1&#160;=&#160;0.5, &#955;2&#160;=&#160;0.4, &#955;3&#160;=&#160;0.1), with shaded regions indicating &#177;20% stability zones where performance remains within 2% of optimal. <bold>(B)</bold> Grid search results: heatmap visualization of DICE performance across &#955;1 and &#955;2 combinations with &#955;3 fixed at 0.1. The red box highlights the optimal combination (&#955;1&#160;=&#160;0.5, &#955;2&#160;=&#160;0.4), demonstrating systematic evaluation of the parameter space. <bold>(C)</bold> Top 5 parameter combinations: ranking of best-performing parameter sets from comprehensive grid search of 27 combinations. The optimal configuration (0.5, 0.4, 0.1) shown in red achieves peak performance while maintaining reasonable performance across nearby parameter values. <bold>(D)</bold> Performance comparison: multi-metric validation comparing optimal versus suboptimal parameters across DICE coefficient, sensitivity, and specificity. Consistent improvements across all metrics confirm the robustness of the optimization approach, with 2.6% DICE improvement, 2.9% sensitivity improvement, and 1.6% specificity improvement using optimal parameters</p></caption><alt-text id=\"at0015\">Fig. 3</alt-text><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"lk0015\" position=\"float\" orientation=\"portrait\" xlink:href=\"gr3.jpg\"/></fig></p><p id=\"p0145\">Focal Tversky Loss (FTL) is adapted from the Tversky Index, emphasizing false positives and false negatives to handle class imbalance effectively. FTL is defined as:<disp-formula id=\"eqn0045\"><label>(9)</label><mml:math id=\"M40\" altimg=\"si0036.svg\"><mml:mrow><mml:mi mathvariant=\"normal\">FTL</mml:mi><mml:mspace width=\".25em\"/><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo stretchy=\"true\">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mspace width=\".25em\"/><mml:mo>&#8722;</mml:mo><mml:mfrac><mml:mrow><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mo stretchy=\"true\">(</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>&#8901;</mml:mo><mml:mi>g</mml:mi></mml:mrow><mml:mo stretchy=\"true\">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>&#1013;</mml:mi></mml:mrow><mml:mrow><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mo stretchy=\"true\">(</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>&#8901;</mml:mo><mml:mi>g</mml:mi></mml:mrow><mml:mo stretchy=\"true\">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi mathvariant=\"normal\">&#945;</mml:mi><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mo stretchy=\"true\">(</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>&#8901;</mml:mo><mml:mrow><mml:mo stretchy=\"true\">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#8722;</mml:mo><mml:mi>g</mml:mi></mml:mrow><mml:mo stretchy=\"true\">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy=\"true\">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi mathvariant=\"normal\">&#946;</mml:mi><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mo stretchy=\"true\">(</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy=\"true\">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#8722;</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mo stretchy=\"true\">)</mml:mo></mml:mrow><mml:mo>.</mml:mo><mml:mi>g</mml:mi></mml:mrow><mml:mo stretchy=\"true\">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>&#1013;</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo stretchy=\"true\">)</mml:mo></mml:mrow><mml:mi mathvariant=\"normal\">&#947;</mml:mi></mml:msup></mml:mrow></mml:math></disp-formula></p><p id=\"p0150\">For predicted <inline-formula><mml:math id=\"M41\" altimg=\"si0037.svg\"><mml:mi>p</mml:mi></mml:math></inline-formula> and ground truth <inline-formula><mml:math id=\"M42\" altimg=\"si0038.svg\"><mml:mi>g</mml:mi></mml:math></inline-formula> masks, where the focusing parameter <inline-formula><mml:math id=\"M43\" altimg=\"si0039.svg\"><mml:mi mathvariant=\"normal\">&#947;</mml:mi></mml:math></inline-formula> controls the emphasis on hard-to-classify examples, set to <inline-formula><mml:math id=\"M44\" altimg=\"si0039.svg\"><mml:mi mathvariant=\"normal\">&#947;</mml:mi></mml:math></inline-formula> = 2.0 for balanced focusing on difficult cases, and <inline-formula><mml:math id=\"M45\" altimg=\"si0040.svg\"><mml:mi mathvariant=\"normal\">&#1013;</mml:mi></mml:math></inline-formula> is a smoothing constant (<inline-formula><mml:math id=\"M46\" altimg=\"si0041.svg\"><mml:mrow><mml:mi mathvariant=\"normal\">&#1013;</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mi mathvariant=\"normal\">e</mml:mi><mml:mo>&#8722;</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula>) added for numerical stability.</p><p id=\"p0155\">DICE loss (DL) helps maximize the overlap between predicted <inline-formula><mml:math id=\"M47\" altimg=\"si0037.svg\"><mml:mi>p</mml:mi></mml:math></inline-formula> and ground truth <inline-formula><mml:math id=\"M48\" altimg=\"si0038.svg\"><mml:mi>g</mml:mi></mml:math></inline-formula>, masks, improving spatial accuracy. The DL is calculated as:<disp-formula id=\"eqn0050\"><label>(10)</label><mml:math id=\"M49\" altimg=\"si0042.svg\"><mml:mrow><mml:mi>D</mml:mi><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>&#8722;</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo>&#8901;</mml:mo><mml:mrow><mml:mo stretchy=\"true\">|</mml:mo><mml:mrow><mml:mi mathvariant=\"normal\">p</mml:mi><mml:mo>&#8745;</mml:mo><mml:mi mathvariant=\"normal\">g</mml:mi></mml:mrow><mml:mo stretchy=\"true\">|</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>&#1013;</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy=\"true\">|</mml:mo><mml:mi mathvariant=\"normal\">p</mml:mi><mml:mo stretchy=\"true\">|</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo stretchy=\"true\">|</mml:mo><mml:mi mathvariant=\"normal\">g</mml:mi><mml:mo stretchy=\"true\">|</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>&#1013;</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>incorporating the smoothing parameter <inline-formula><mml:math id=\"M50\" altimg=\"si0040.svg\"><mml:mi mathvariant=\"normal\">&#1013;</mml:mi></mml:math></inline-formula> to ensure numerical stability. The parameter <inline-formula><mml:math id=\"M51\" altimg=\"si0043.svg\"><mml:mrow><mml:mi mathvariant=\"normal\">&#1013;</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>&#8722;</mml:mo><mml:mi mathvariant=\"normal\">e</mml:mi><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula> is used to prevent division by zero errors when the intersection between predicted and ground truth masks is zero, particularly during early training stages or for challenging segmentation cases.</p><p id=\"p0160\">Cross-entropy loss is calculated for each pixel, weighted by class to improve representation of the scar class over background regions:<disp-formula id=\"eqn0055\"><label>(11)</label><mml:math id=\"M52\" altimg=\"si0044.svg\"><mml:mrow><mml:mi mathvariant=\"normal\">CE</mml:mi><mml:mo>=</mml:mo><mml:mo>&#8722;</mml:mo><mml:munder><mml:mo>&#8721;</mml:mo><mml:mi>c</mml:mi></mml:munder><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>&#8901;</mml:mo><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mspace width=\".25em\"/><mml:mi>log</mml:mi><mml:mrow><mml:mo stretchy=\"true\">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy=\"true\">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id=\"M53\" altimg=\"si0045.svg\"><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mspace width=\"1em\"/></mml:mrow></mml:math></inline-formula>&#160;is the weight for class <inline-formula><mml:math id=\"M54\" altimg=\"si0046.svg\"><mml:mi mathvariant=\"italic\">c</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id=\"M55\" altimg=\"si0047.svg\"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id=\"M56\" altimg=\"si0048.svg\"><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> are the predicted and true probabilities for class c, respectively.</p><p id=\"p0165\">This loss formulation provides a balanced objective that aligns ScarNet to achieve high accuracy in cardiac scar segmentation by reducing errors across both global context (captured by MedSAM) and local detail (captured by UNet). The training process aims to minimize <inline-formula><mml:math id=\"M57\" altimg=\"si0001.svg\"><mml:msub><mml:mrow><mml:mi mathvariant=\"script\">L</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant=\"italic\">ScarNet</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> by updating the model weights to reduce misclassifications, particularly for the scar class. This is achieved by gradient descent optimization: using optimizers Adam, gradients of <inline-formula><mml:math id=\"M58\" altimg=\"si0001.svg\"><mml:msub><mml:mrow><mml:mi mathvariant=\"script\">L</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant=\"italic\">ScarNet</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> with respect to model parameters are computed. These gradients indicate the direction and magnitude of updates needed to minimize the loss. Regularization methods, i.e., dropout and data augmentation help the model generalize, while tuning the weights <inline-formula><mml:math id=\"M59\" altimg=\"si0031.svg\"><mml:msub><mml:mrow><mml:mi mathvariant=\"normal\">&#955;</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id=\"M60\" altimg=\"si0032.svg\"><mml:msub><mml:mrow><mml:mi mathvariant=\"normal\">&#955;</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>, and <inline-formula><mml:math id=\"M61\" altimg=\"si0033.svg\"><mml:msub><mml:mrow><mml:mi mathvariant=\"normal\">&#955;</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> in the combined loss function focuses the model on scar segmentation without overfitting.</p><p id=\"p0170\">ScarNet demonstrates superior performance in cardiac scar segmentation by effectively delineating scar boundaries, reducing false positives, and providing consistent segmentation quality across varying scar sizes, shapes, and image qualities. The use of attention mechanisms at multiple scales further enhances the model&#8217;s ability to focus on relevant features, resulting in reliable and precise segmentation outcomes. Additional implementation details of our network are available in <xref rid=\"sec0085\" ref-type=\"sec\">Supplementary Materials</xref>.</p></sec></sec></sec></sec><sec id=\"sec0060\"><label>2.3</label><title>Two secondary experiments to demonstrate robustness</title><p id=\"p0175\">First, to compare the performance of our model against other models as a function of training data size, we trained the models with combined training-validation cohorts ranging from 15 to 501 patients (with training comprising 80% and validation comprising 20% of each cohort at the patient level), with corresponding testing sets maintaining an approximately 4:1 training/validation-to-testing ratio. For example, the smallest experiment used 12 patients for training, 3 patients for validation, and 4 patients for testing, while the largest experiment used 401 patients for training, 100 patients for validation, and 184 patients for testing. This proportional scaling maintains consistent ratios across all experiments while ensuring patient-level separation to prevent data leakage between training, validation, and testing sets. Second, we conducted Monte Carlo simulations with 200 iterations by adding random noise (noise level 5%) (please see the Monte Carlo Simulation section in <xref rid=\"sec0085\" ref-type=\"sec\">Supplementary Materials</xref>).</p></sec><sec id=\"sec0065\"><label>2.4</label><title>Statistical analyses</title><p id=\"p0180\">We tested for variable normality using the Kolmogorov-Smirnov, Anderson-Darling, and Shapiro-Wilk tests. A variable was deemed normally distributed if it passes all three tests. Box plots are reported for each comparing DICE metric to visualize the distribution and central tendencies across methods. Bland-Altman analysis was performed on scar volumes to assess the level of agreement between measurements, and concordance correlation coefficient (CCC) was calculated for scar volume measurements to compare with ground truth (i.e., manual). CCC values are also computed for scar DICE to compare it with ground truth. The coefficient of variation (CoV) was defined as the standard deviation of the difference divided by the mean and is computed for both scar DICE and scar volume. One-way analysis of variance (Kruskal-Wallis if not normally distributed) with Bonferroni correction was conducted to detect any significant differences among groups. A p-value &lt;0.05 was considered statistically significant for all tests performed.</p></sec></sec><sec id=\"sec0070\"><label>3</label><title>Results</title><p id=\"p0185\">Overall, 685 patients (with 7066 analyzable 2D LGE images) retrospectively enrolled in this study had mean age of 57.82&#160;&#177;&#160;18.58&#160;years, 59.8% (410/685) males, and mean left ventricular ejection fraction of 40.3&#160;&#177;&#160;11.0%, as detailed in <xref rid=\"tbl0005\" ref-type=\"table\">Table 1</xref> and <xref rid=\"tbl0010\" ref-type=\"table\">Table 2</xref>.<table-wrap position=\"float\" id=\"tbl0005\" orientation=\"portrait\"><label>Table 1</label><caption><p>Participant demographics and characteristics.</p></caption><alt-text id=\"at0065\">Table 1</alt-text><table frame=\"hsides\" rules=\"groups\"><thead><tr><th colspan=\"1\" rowspan=\"1\">Characteristic</th><th colspan=\"1\" rowspan=\"1\">Training Set (n&#160;=&#160;401)</th><th colspan=\"1\" rowspan=\"1\">Validation Set (n&#160;=&#160;100)</th><th colspan=\"1\" rowspan=\"1\">Test Set (n&#160;=&#160;184)</th></tr></thead><tbody><tr><td colspan=\"1\" rowspan=\"1\">Sex</td><td colspan=\"1\" rowspan=\"1\">Male: 59.8% (240/401), Female: 40.1% (161/401)</td><td colspan=\"1\" rowspan=\"1\">Male: 60.0% (60/100), Female: 40.0% (40/100)</td><td colspan=\"1\" rowspan=\"1\">Male: 59.7% (110/184), Female: 40.2% (74/184)</td></tr><tr><td colspan=\"1\" rowspan=\"1\">Age (mean&#160;&#177;&#160;SD)</td><td colspan=\"1\" rowspan=\"1\">57.82&#160;&#177;&#160;18.58 years</td><td colspan=\"1\" rowspan=\"1\">57.82&#160;&#177;&#160;18.58 years</td><td colspan=\"1\" rowspan=\"1\">57.82&#160;&#177;&#160;18.58 years</td></tr><tr><td colspan=\"1\" rowspan=\"1\">Left ventricular ejection fraction</td><td colspan=\"1\" rowspan=\"1\">40.3&#160;&#177;&#160;11.0%</td><td colspan=\"1\" rowspan=\"1\">40.3&#160;&#177;&#160;11.0%</td><td colspan=\"1\" rowspan=\"1\">40.3&#160;&#177;&#160;11.0%</td></tr></tbody></table></table-wrap><table-wrap position=\"float\" id=\"tbl0010\" orientation=\"portrait\"><label>Table 2</label><caption><p>Dataset characteristics and ischemic scar distribution<bold>.</bold></p></caption><alt-text id=\"at0070\">Table 2</alt-text><table frame=\"hsides\" rules=\"groups\"><thead><tr><th colspan=\"1\" rowspan=\"1\">Characteristic</th><th colspan=\"1\" rowspan=\"1\">Training Set (n&#160;=&#160;401)</th><th colspan=\"1\" rowspan=\"1\">Validation Set (n&#160;=&#160;100)</th><th colspan=\"1\" rowspan=\"1\">Testing Set (n&#160;=&#160;184)</th><th colspan=\"1\" rowspan=\"1\">Total (n&#160;=&#160;685)</th></tr></thead><tbody><tr><td colspan=\"1\" rowspan=\"1\">Number of 2D LGE images</td><td colspan=\"1\" rowspan=\"1\">4137</td><td colspan=\"1\" rowspan=\"1\">1034</td><td colspan=\"1\" rowspan=\"1\">1895</td><td colspan=\"1\" rowspan=\"1\">7066</td></tr><tr><td colspan=\"1\" rowspan=\"1\"><italic toggle=\"yes\">LGE positive images</italic></td><td colspan=\"1\" rowspan=\"1\">3848</td><td colspan=\"1\" rowspan=\"1\">962</td><td colspan=\"1\" rowspan=\"1\">1761</td><td colspan=\"1\" rowspan=\"1\">6571</td></tr><tr><td colspan=\"1\" rowspan=\"1\"><italic toggle=\"yes\">LGE negative images</italic></td><td colspan=\"1\" rowspan=\"1\">289</td><td colspan=\"1\" rowspan=\"1\">72</td><td colspan=\"1\" rowspan=\"1\">134</td><td colspan=\"1\" rowspan=\"1\">495</td></tr><tr><td colspan=\"1\" rowspan=\"1\">Images per Patient</td><td colspan=\"1\" rowspan=\"1\">10.3&#160;&#177;&#160;3.1</td><td colspan=\"1\" rowspan=\"1\">10.3&#160;&#177;&#160;3.1</td><td colspan=\"1\" rowspan=\"1\">10.3&#160;&#177;&#160;3.1</td><td colspan=\"1\" rowspan=\"1\">10.3&#160;&#177;&#160;3.1</td></tr><tr><td colspan=\"1\" rowspan=\"1\">Scar Severity Categories (Patient-Level)</td><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/></tr><tr><td colspan=\"1\" rowspan=\"1\">No Scar</td><td colspan=\"1\" rowspan=\"1\">6.9% (28/401)</td><td colspan=\"1\" rowspan=\"1\">7.0% ( 7/100)</td><td colspan=\"1\" rowspan=\"1\">7.0% (13/184)</td><td colspan=\"1\" rowspan=\"1\">7.0% (48/685)</td></tr><tr><td colspan=\"1\" rowspan=\"1\">Mild Scar</td><td colspan=\"1\" rowspan=\"1\">27.9% (112/401)</td><td colspan=\"1\" rowspan=\"1\">28.00% (28/100)</td><td colspan=\"1\" rowspan=\"1\">28.2% (52/184)</td><td colspan=\"1\" rowspan=\"1\">28.0% (192/685)</td></tr><tr><td colspan=\"1\" rowspan=\"1\">Moderate Scar</td><td colspan=\"1\" rowspan=\"1\">50.1% (201/401)</td><td colspan=\"1\" rowspan=\"1\">50.00% (50/100)</td><td colspan=\"1\" rowspan=\"1\">50.0% (92/184)</td><td colspan=\"1\" rowspan=\"1\">50.0% (343/685)</td></tr><tr><td colspan=\"1\" rowspan=\"1\">Severe Scar</td><td colspan=\"1\" rowspan=\"1\">14.9% (60/401)</td><td colspan=\"1\" rowspan=\"1\">15.0% (15/100)</td><td colspan=\"1\" rowspan=\"1\">14.6% (27/184)</td><td colspan=\"1\" rowspan=\"1\">14.8% (102/685)</td></tr><tr><td colspan=\"1\" rowspan=\"1\">Scar Volume Statistics</td><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/></tr><tr><td colspan=\"1\" rowspan=\"1\">Mean&#177;SD (%)</td><td colspan=\"1\" rowspan=\"1\">14.95&#160;&#177;&#160;9.50</td><td colspan=\"1\" rowspan=\"1\">14.95&#160;&#177;&#160;9.50</td><td colspan=\"1\" rowspan=\"1\">13.37&#160;&#177;&#160;8.57</td><td colspan=\"1\" rowspan=\"1\">14.52&#160;&#177;&#160;9.29</td></tr><tr><td colspan=\"1\" rowspan=\"1\">Median (%)</td><td colspan=\"1\" rowspan=\"1\">14.52</td><td colspan=\"1\" rowspan=\"1\">14.52</td><td colspan=\"1\" rowspan=\"1\">12.80</td><td colspan=\"1\" rowspan=\"1\">14.06</td></tr><tr><td colspan=\"1\" rowspan=\"1\">Range (%)</td><td colspan=\"1\" rowspan=\"1\">00.00&#8211;59.52</td><td colspan=\"1\" rowspan=\"1\">00.00&#8211;55.23</td><td colspan=\"1\" rowspan=\"1\">0.00&#8211;41.93</td><td colspan=\"1\" rowspan=\"1\">0.00&#8211;59.52</td></tr></tbody></table><table-wrap-foot><fn><p>Data presented as n (%) or mean &#177; SD unless otherwise specified. No Scar (0%), Mild (&lt;10%), Moderate (10-30%), Severe (&gt;30%). <italic toggle=\"yes\">SD</italic> standard deviation, <italic toggle=\"yes\">LGE</italic> late gadolinium enhancement <xref rid=\"bib34\" ref-type=\"bibr\">[34]</xref>, <xref rid=\"bib35\" ref-type=\"bibr\">[35]</xref></p></fn></table-wrap-foot></table-wrap></p><p id=\"p0190\">Statistical analysis for myocardial segmentation showed that, compared against ScarNet (median DICE&#160;=&#160;0.961 [IQR: 0.920&#8211;0.999], CCC&#160;=&#160;0.978), nnU-Net (median DICE&#160;=&#160;0.878 [IQR: 0.838&#8211;0.915], CCC&#160;=&#160;0.892) and MedSAM (median DICE&#160;=&#160;0.242 [IQR: 0.116&#8211;0.342], CCC&#160;=&#160;0.156) were significantly different (p&lt;0.001). For scar segmentation, compared with ScarNet (median DICE&#160;=&#160;0.912 [IQR: 0.863&#8211;0.944], CCC&#160;=&#160;0.963), MedSAM (median DICE&#160;=&#160;0.046 [IQR: 0.043&#8211;0.047], CCC&#160;=&#160;0.018) and nnU-Net (median DICE&#160;=&#160;0.638 [IQR: 0.604&#8211;0.661], CCC&#160;=&#160;0.734) were significantly different (p&lt;0.001) (<xref rid=\"fig0020\" ref-type=\"fig\">Fig. 4</xref>).<fig id=\"fig0020\" position=\"float\" orientation=\"portrait\"><label>Fig. 4</label><caption><p>Comparative performance metrics across different segmentation models. (Left) Box plots showing myocardium DICE scores for ScarNet, MedSAM, and nnU-Net. (Right) Scar DICE scores across models</p></caption><alt-text id=\"at0020\">Fig. 4</alt-text><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"lk0020\" position=\"float\" orientation=\"portrait\" xlink:href=\"gr4.jpg\"/></fig></p><p id=\"p0195\">A representative sample for one patient comparing segmentation performance between MedSAM and ScarNet and their corresponding feature logits and probability maps is shown in <xref rid=\"fig0025\" ref-type=\"fig\">Fig. 5</xref>, illustrating superior scar DICE and myocardium DICE for ScarNet compared to other networks.<fig id=\"fig0025\" position=\"float\" orientation=\"portrait\"><label>Fig. 5</label><caption><p>Comparative visualization of ScarNet, MedSAM, and nnU-Net for cardiac LV LGE segmentation on a representative test sample. <bold>(A)</bold> Raw LGE image; <bold>(B)</bold> Multi-class segmentation showing myocardium (blue), blood pool (pink), and scar tissue (yellow) serving as ground truth (reference); <bold>(C)</bold> Predicted segmentation by MedSAM (myocardium DICE&#160;=&#160;0.11, scar DICE&#160;=&#160;0.00); <bold>(D)</bold> Predicted segmentation by nnU-Net (myocardium DICE&#160;=&#160;0.84, scar DICE&#160;=&#160;0.61); <bold>(E)</bold> Predicted segmentation by ScarNet (myocardium DICE&#160;=&#160;0.95, scar DICE&#160;=&#160;0.91). Left panel (MedSAM): <bold>(F)</bold> Logit map for the background; <bold>(G)</bold> Logit map for the blood pool; <bold>(H)</bold> Logit map for the myocardium ([red indicates high positive values, blue indicates high negative values]);<bold>(I&#8211;K)</bold> Corresponding probability maps for the background, blood pool, and myocardium, respectively [(bright colors indicate high probability, dark colors indicate low probability)]. Right panel (ScarNet): <bold>(L)</bold> Logit map for the background; <bold>(M)</bold> Logit map for the blood pool; <bold>(N)</bold> Logit map for the scar tissue [(red indicates high positive values, blue indicates high negative values)]; <bold>(O)</bold> Logit map for the myocardium; <bold>(P&#8211;S)</bold> Corresponding probability maps for the background, blood pool, scar tissue, and myocardium, respectively [(bright colors indicate high probability, dark colors indicate low probability)]. Despite 4-class architectural adaptation, MedSAM shows absence of scar-specific activation, demonstrating the necessity of specialized training for cardiac applications. Note that probability maps represent post-softmax outputs without thresholding; ScarNet's binary-appearing probabilities reflect high model confidence with values clustering near 0 or 1, while MedSAM shows greater uncertainty with values distributed across the full probability range. This figure does not include nnU-Net feature maps, because it does not provide feature maps.&#160;<italic toggle=\"yes\">LV</italic>&#160;left ventricular,&#160;<italic toggle=\"yes\">LGE</italic>&#160;late gadolinium enhancement, <italic toggle=\"yes\">MedSAM</italic> medical segment anything</p></caption><alt-text id=\"at0025\">Fig. 5</alt-text><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"lk0025\" position=\"float\" orientation=\"portrait\" xlink:href=\"gr5.jpg\"/></fig></p><p id=\"p0200\">The performance of MedSAM, nnU-Net, and ScarNet as a function of training data size is shown in <xref rid=\"fig0030\" ref-type=\"fig\">Fig. 6</xref>. For both myocardium and scar segmentations, ScarNet achieved higher accuracy throughout and hit the plateau faster, with scar segmentation performance stabilizing at approximately 120 training patients (median scar DICE &#8764;0.912 [IQR: 0.885&#8211;0.917]) and myocardium segmentation plateauing at approximately 200 training patients (median myocardium DICE &#8764;0.948 [IQR: 0.873&#8211;0.952]). Since <xref rid=\"fig0030\" ref-type=\"fig\">Fig. 6</xref> demonstrates that ScarNet achieves plateau performance with relatively small training cohorts, we conducted additional experiments with alternative dataset splits. Using an alternative three-way split of 200 patients for training, 50 for validation, and 435 for independent testing (to cover all the 685 patients), ScarNet maintained consistent performance with a median scar DICE of 0.908 [IQR: 0.882&#8211;0.925]. Additionally, 5-fold cross-validation across the complete dataset demonstrated stable performance with a median scar DICE of 0.911 [IQR: 0.894&#8211;0.923], confirming model generalizability across different patient subsets. Both alternative splitting strategies consistently showed the same performance ranking: ScarNet &gt; nnU-Net &gt; MedSAM, validating the robustness of our architectural approach. <xref rid=\"fig0035\" ref-type=\"fig\">Fig. 7</xref> compares segmentation performance between MedSAM, nnU-Net, and ScarNet in four representative patients, where ScarNet consistently outperformed the other networks.<fig id=\"fig0030\" position=\"float\" orientation=\"portrait\"><label>Fig. 6</label><caption><p>Comparative analysis of segmentation performance across varying training dataset sizes. <bold>(A)</bold> Mean myocardium DICE scores for ScarNet, MedSAM, and nnU-Net with increasing training cohort sizes from 15 to 501 patients (actual training: 12 to 401 patients, validation: 3 to 100 patients), maintaining an 80/20 training-validation split and approximately 4:1 training/validation-to-testing ratio for each experiment. The proportional scaling of validation sets ensures adequate statistical power for performance monitoring and early stopping at each training size. <bold>(B)</bold> Mean scar DICE score progression for all models with increasing training cohort sizes from 15 to 501 patients (actual training: 12 to 401 patients), with validation sets scaled proportionally to maintain representative performance monitoring. <italic toggle=\"yes\">MedSAM</italic> medical segment anything</p></caption><alt-text id=\"at0030\">Fig. 6</alt-text><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"lk0030\" position=\"float\" orientation=\"portrait\" xlink:href=\"gr6.jpg\"/></fig><fig id=\"fig0035\" position=\"float\" orientation=\"portrait\"><label>Fig. 7</label><caption><p>Comparative analysis of CMR segmentation performance across different deep learning architectures. From left to right: Original CMR scans, Reference (ground truth) segmentations, MedSAM (without fine-tuning), nnU-Net, and proposed ScarNet. Representative test cases demonstrate the segmentation results across multiple cardiac slices at different anatomical levels. <italic toggle=\"yes\">CMR</italic> cardiovascular magnetic resonance, <italic toggle=\"yes\">MedSAM</italic> medical segment anyth</p></caption><alt-text id=\"at0035\">Fig. 7</alt-text><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"lk0035\" position=\"float\" orientation=\"portrait\" xlink:href=\"gr7.jpg\"/></fig></p><p id=\"p0205\"><xref rid=\"fig0040\" ref-type=\"fig\">Fig. 8</xref> compares scar volume quantification by different segmentation methods, where manual is the reference. Compared against manual (median scar volume&#160;=&#160;0.114 [IQR: 0.094&#8211;0.180]), MedSAM (median scar volume&#160;=&#160;0.000 [IQR: 0.000&#8211;0.001], CCC&#160;=&#160;0.000, bias&#160;=&#160;&#8722;13.31% [198.8% of mean], CoV&#160;=&#160;130.3%) and nnU-Net (median scar volume&#160;=&#160;0.095 [IQR: 0.068&#8211;0.150], CCC&#160;=&#160;0.910, bias&#160;=&#160;&#8722;2.46% [20.31% of mean], CoV&#160;=&#160;20.3%) were significantly different (p&lt;0.001), whereas ScarNet (median scar volume&#160;=&#160;0.109 [IQR: 0.087&#8211;0.173], CCC&#160;=&#160;0.995, bias&#160;=&#160;&#8722;0.63% [4.82% of mean], CoV&#160;=&#160;4.3%) was not significantly different (p&#160;=&#160;0.192).<fig id=\"fig0040\" position=\"float\" orientation=\"portrait\"><label>Fig. 8</label><caption><p>Bland-Altman and correlation analyses comparing automated and manual scar quantification methods. Left column <bold>(A, C, E)</bold>: Bland-Altman plots showing differences between automated and manual scar volume measurements. <bold>(A)</bold> MedSAM vs Manual (CoV&#160;=&#160;130.3%, bias&#160;=&#160;&#8722;13.31%); <bold>(C)</bold> nnU-Net vs Manual (CoV&#160;=&#160;20.3%, bias&#160;=&#160;&#8722;2.46%); <bold>(E)</bold> ScarNet vs Manual (CoV&#160;=&#160;4.3%, bias&#160;=&#160;&#8722;0.63%). Right column <bold>(B, D, F)</bold>: Correlation plots between automated and manual measurements. <bold>(B)</bold> MedSAM shows poor correlation (CCC&#160;=&#160;0.002); <bold>(D)</bold> nnU-Net demonstrates good correlation (CCC&#160;=&#160;0.910); <bold>(F)</bold> ScarNet achieves near-perfect correlation (CCC&#160;=&#160;0.995 with manual measurements. Dotted lines in Bland-Altman plots represent 95% confidence intervals, and solid black lines show mean bias. <italic toggle=\"yes\">CoV</italic>&#160;coefficient of variation, <italic toggle=\"yes\">MedSAM</italic> medical segment anything</p></caption><alt-text id=\"at0040\">Fig. 8</alt-text><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"lk0040\" position=\"float\" orientation=\"portrait\" xlink:href=\"gr8.jpg\"/></fig><fig id=\"fig0045\" position=\"float\" orientation=\"portrait\"><label>Fig. 9</label><caption><p>Robustness analysis of segmentation models under noise conditions. Top row: <bold>(A)</bold> Original cardiac LGE image; <bold>(B)</bold> Reference segmentation with myocardium (blue) and scar tissue (pink); <bold>(C)</bold> Image with added Gaussian noise; <bold>(D)</bold> Noise difference map.Middle row - Original image segmentation: <bold>(E)</bold> MedSAM (Scar DSC: 0.0000), <bold>(F)</bold> nnU-Net (Scar DSC: 0.5636), and <bold>(G)</bold> ScarNet (Scar DSC: 0.9723), with zoomed insets showing detailed segmentation boundaries.Bottom row - Noisy image segmentation: <bold>(H)</bold> MedSAM (Scar DSC: 0.0000), <bold>(I)</bold> nnU-Net (Scar DSC: 0.5634), and <bold>(J)</bold> ScarNet (Scar DSC: 0.9720), demonstrating segmentation performance under noise conditions.&#160;<italic toggle=\"yes\">LGE</italic>&#160;late gadolinium enhancement, MedSAM medical segment anything, <italic toggle=\"yes\">DSC</italic> DICE similarity coe</p></caption><alt-text id=\"at0045\">Fig. 9</alt-text><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"lk0045\" position=\"float\" orientation=\"portrait\" xlink:href=\"gr9.jpg\"/></fig></p><p id=\"p0210\"><xref rid=\"fig0050\" ref-type=\"fig\">Fig. 10</xref> shows three no-scar cases with false positives predicted by each network. <xref rid=\"fig0055\" ref-type=\"fig\">Fig. 11</xref> shows three scar cases with false negatives predicted by each network. As shown in <xref rid=\"fig0060\" ref-type=\"fig\">Fig. 12</xref>, the overall accuracy was highest for ScarNet (sensitivity=95.3% (163/171); specificity=92.3% (12/13)), followed by nnU-Net (sensitivity=74.9% (128/171); specificity=69.2% (9/13)) and MedSAM (sensitivity=15.2% (26/171); specificity=92.3% (12/13)).<fig id=\"fig0050\" position=\"float\" orientation=\"portrait\"><label>Fig. 10</label><caption><p>Three example no-scar cases with false positives predicted by each network. (Top row): One of four false positives predicted by nnU-Net. (Middle row): The lone false positive predicted by ScarNet. (Bottom row): The lone false positive predicted by MedSAM. <italic toggle=\"yes\">MedSAM</italic> medical segment anything</p></caption><alt-text id=\"at0050\">Fig. 10</alt-text><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"lk0050\" position=\"float\" orientation=\"portrait\" xlink:href=\"gr10.jpg\"/></fig><fig id=\"fig0055\" position=\"float\" orientation=\"portrait\"><label>Fig. 11</label><caption><p>Three example scar cases with false negatives predicted by each network. (Top row): One of forty-three false negatives predicted by nnU-Net. (Middle row): One of eight false negatives predicted by ScarNet. (Bottom row): One of one hundred forty-five false negatives predicted by MedSAM</p></caption><alt-text id=\"at0055\">Fig. 11</alt-text><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"lk0055\" position=\"float\" orientation=\"portrait\" xlink:href=\"gr11.jpg\"/></fig><fig id=\"fig0060\" position=\"float\" orientation=\"portrait\"><label>Fig. 12</label><caption><p>A confusion matrix for scar vs. no-scar classifications predicted by the three networks. (Left) ScarNet produced very high specificity 92.3% (12/13) and sensitivity 95.3% (163/171) with only 1 false positive and 8 false negative cases out of 184 total cases. (Middle) nnU-Net produced moderate specificity 69.2% (9/13 and sensitivity 74.9% (128/171), resulting in 4 false positives and 43 false negatives. (Right) MedSAM produced very high specificity 92.3% (12/13) but very low sensitivity 15.2% (26/171), resulting in only 1 false positive but 145 false negatives. <italic toggle=\"yes\">MedSAM</italic> medical segment anything model.</p></caption><alt-text id=\"at0060\">Fig. 12</alt-text><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"lk0060\" position=\"float\" orientation=\"portrait\" xlink:href=\"gr12.jpg\"/></fig></p><p id=\"p0215\">In Monte Carlo simulations with noise perturbations, for myocardial segmentation, ScarNet (median DICE&#160;=&#160;0.925 [IQR: 0.895&#8211;0.955], CCC&#160;=&#160;0.965; CoV&#160;=&#160;4.8%) was significantly higher (p&lt;0.001) than MedSAM (median DICE&#160;=&#160;0.185 [IQR: 0.089&#8211;0.281], CCC&#160;=&#160;0.089; CoV&#160;=&#160;76.8%) and nnU-Net (median DICE&#160;=&#160;0.795 [IQR: 0.731&#8211;0.859], CCC&#160;=&#160;0.825; CoV&#160;=&#160;18.5%). For scar segmentation, ScarNet (median DICE&#160;=&#160;0.892 [IQR: 0.856&#8211;0.928], CCC&#160;=&#160;0.946; CoV&#160;=&#160;5.9%) produced significantly higher performance (p&lt;0.001) than MedSAM (median DICE&#160;=&#160;0.048 [IQR: 0.000&#8211;0.124], CCC&#160;=&#160;0.012; CoV&#160;=&#160;233.3%) and nnU-Net (median DICE&#160;=&#160;0.615 [IQR: 0.253&#8211;0.977], CCC&#160;=&#160;0.698; CoV&#160;=&#160;28.7%). For scar volume quantification with noise perturbations, ScarNet maintained superior accuracy (CCC&#160;=&#160;0.988, percent bias: &#8722;1.2&#160;&#177;&#160;2.8%, CoV&#160;=&#160;6.1%) compared to MedSAM (CCC&lt;0.001, percent bias: &#8722;15.3&#160;&#177;&#160;18.7%, CoV&#160;=&#160;142.8%) and nnU-Net (CCC&#160;=&#160;0.892, percent bias: &#8722;3.2&#160;&#177;&#160;8.1%, CoV&#160;=&#160;24.5%) (all p&lt;0.001). <xref rid=\"fig0045\" ref-type=\"fig\">Fig. 9</xref> shows representative Monte Carlo simulation results with noise perturbations.</p><sec id=\"sec0075\"><label>3.1</label><title>Ablation study results</title><p id=\"p0220\">Ablation studies systematically validated each component's contribution to the hybrid architecture's performance. Removing the MedSAM pathway resulted in the largest performance decrease (median myocardium DICE&#160;=&#160;0.961 [IQR: 0.920&#8211;0.999], CCC&#160;=&#160;0.978 to median myocardium DICE&#160;=&#160;0.934 [IQR: 0.892&#8211;0.967], CCC&#160;=&#160;0.945; median scar DICE&#160;=&#160;0.912 [IQR: 0.863&#8211;0.944], CCC&#160;=&#160;0.963 to median scar DICE&#160;=&#160;0.847 [IQR: 0.801&#8211;0.891], CCC&#160;=&#160;0.891, &#916;&#160;=&#160;&#8722;0.065), followed by attention mechanisms (median myocardium DICE&#160;=&#160;0.945 [IQR: 0.901&#8211;0.978], CCC&#160;=&#160;0.961; median scar DICE&#160;=&#160;0.872 [IQR: 0.819&#8211;0.908], CCC&#160;=&#160;0.924, &#916;&#160;=&#160;&#8722;0.040) and frozen MedSAM weights (median myocardium DICE&#160;=&#160;0.948 [IQR: 0.905&#8211;0.981], CCC&#160;=&#160;0.967; median scar DICE&#160;=&#160;0.883 [IQR: 0.834&#8211;0.923], CCC&#160;=&#160;0.938, &#916;&#160;=&#160;&#8722;0.029) (all p&lt;0.001). Notably, scar volume quantification accuracy also deteriorated substantially without MedSAM (error increased from &#8722;0.63&#160;&#177;&#160;4.82%, CCC&#160;=&#160;0.995, p&lt;0.001 to &#8722;2.14&#160;&#177;&#160;8.91%, CCC&#160;=&#160;0.976, p&lt;0.001), with frozen weights showing intermediate degradation (&#8722;1.28&#160;&#177;&#160;6.45%, CCC&#160;=&#160;0.987, p&lt;0.001) and attention removal also showing decreased accuracy (&#8722;1.87&#160;&#177;&#160;7.23%, CCC&#160;=&#160;0.981, p&lt;0.001).</p></sec><sec id=\"sec0080\"><label>3.2</label><title>Regional performance analysis</title><p id=\"p0225\">Regional performance analysis across 1895 slices from 184 patients demonstrated consistent ScarNet superiority across all cardiac regions. For basal regions (632 slices), ScarNet achieved median scar DICE&#160;=&#160;0.925 [IQR: 0.887&#8211;0.962], CCC&#160;=&#160;0.971 compared to nnU-Net (median scar DICE&#160;=&#160;0.651 [IQR: 0.612&#8211;0.688], CCC&#160;=&#160;0.748) and MedSAM (median scar DICE&#160;=&#160;0.048 [IQR: 0.044&#8211;0.051], CCC&#160;=&#160;0.021). In mid-ventricular regions (631 slices), ScarNet maintained high performance with median scar DICE&#160;=&#160;0.904 [IQR: 0.847&#8211;0.928], CCC&#160;=&#160;0.958 versus nnU-Net (median scar DICE&#160;=&#160;0.627 [IQR: 0.592&#8211;0.648], CCC&#160;=&#160;0.722) and MedSAM (median scar DICE&#160;=&#160;0.044 [IQR: 0.040&#8211;0.047], CCC&#160;=&#160;0.016). Apical regions (632 slices) showed similar patterns with ScarNet achieving median scar DICE&#160;=&#160;0.898 [IQR: 0.841&#8211;0.931], CCC&#160;=&#160;0.952 compared to nnU-Net (median scar DICE&#160;=&#160;0.625 [IQR: 0.588&#8211;0.654], CCC&#160;=&#160;0.715) and MedSAM (median scar DICE&#160;=&#160;0.044 [IQR: 0.041&#8211;0.046], CCC&#160;=&#160;0.015). Overall performance across all 1895 slices confirmed ScarNet's superiority (median scar DICE&#160;=&#160;0.912 [IQR: 0.863&#8211;0.944], CCC&#160;=&#160;0.963) over nnU-Net (median scar DICE&#160;=&#160;0.638 [IQR: 0.604&#8211;0.661], CCC&#160;=&#160;0.734) and MedSAM (median scar DICE&#160;=&#160;0.046 [IQR: 0.043&#8211;0.047], CCC&#160;=&#160;0.018) (all comparisons p&lt;0.001).</p></sec></sec><sec id=\"sec0085\"><label>4</label><title>Discussion</title><p id=\"p0230\">In this study, we developed ScarNet, a novel deep learning model that combines a complete MedSAM pathway with a parallel UNet pathway through an adaptive fusion mechanism for automated myocardial scar segmentation in LGE images. After training the model using 401 patients and validating on 100 patients, and evaluating on 184 test patients, ScarNet achieved superior segmentation accuracy for both myocardium (median DICE&#160;=&#160;0.961) and scar tissue (median DICE&#160;=&#160;0.912), significantly outperforming both MedSAM and nnU-Net. Using Monte Carlo simulations with 5% Gaussian noise perturbation, the model demonstrated exceptional robustness with minimal percent bias (&#8722;0.63%) and coefficient of variation (4.3%) in scar volume quantification, while maintaining consistently high DICE scores for both myocardium (0.912&#160;&#177;&#160;0.063; CoV&#160;=&#160;6.9%) and scar tissue (0.892&#160;&#177;&#160;0.053; CoV&#160;=&#160;5.9%). Ablation studies validated the critical contribution of each architectural component, particularly the MedSAM pathway integration.</p><p id=\"p0235\">Our approach differs from previous deep learning methods by addressing several key limitations in automated scar segmentation. Traditional CNN-based approaches <xref rid=\"bib8\" ref-type=\"bibr\">[8]</xref>, <xref rid=\"bib9\" ref-type=\"bibr\">[9]</xref>, <xref rid=\"bib10\" ref-type=\"bibr\">[10]</xref>, while effective for general medical segmentation, struggle with the inherent challenges of LGE imaging, achieving limited DICE scores of only 0.616 and 0.633 for supervised and unsupervised methods, respectively <xref rid=\"bib12\" ref-type=\"bibr\">[12]</xref>. Earlier efforts by Zabihollahy et al. <xref rid=\"bib22\" ref-type=\"bibr\">[22]</xref> and Bai et al. <xref rid=\"bib23\" ref-type=\"bibr\">[23]</xref> demonstrated the potential of CNNs for scar segmentation, but faced challenges in capturing complex scar patterns. A significant advancement came from Fahmy et al. <xref rid=\"bib10\" ref-type=\"bibr\">[10]</xref>, who introduced a deep learning-based image fusion approach that improved scar quantification accuracy by combining multiple image features. While their method showed promise in handling varying contrast patterns, it still faced challenges with complex scar morphologies and required careful parameter tuning. Subsequent developments by Xiong et al. <xref rid=\"bib24\" ref-type=\"bibr\">[24]</xref> with dual fully convolutional networks and Zhuang et al. <xref rid=\"bib25\" ref-type=\"bibr\">[25]</xref> with multi-scale patch-based approaches improved performance but still struggled with consistent accuracy.</p><p id=\"p0240\">Recent work on unsupervised domain adaptation <xref rid=\"bib26\" ref-type=\"bibr\">[26]</xref> demonstrated promising results in handling multi-center variability by adapting the network to different scanner characteristics without requiring additional annotations, though the method still showed limitations in capturing fine scar details. Similarly, comparative studies of dark- and bright-blood LGE imaging techniques <xref rid=\"bib27\" ref-type=\"bibr\">[27]</xref> showed improved visualization of subendocardial scars across different myocardial pathologies, particularly in cases where traditional bright-blood LGE faced challenges in distinguishing scar tissue from adjacent blood pool. While these approaches advanced our understanding of scar imaging and quantification, they still relied heavily on manual intervention or faced challenges with consistent automated analysis.</p><p id=\"p0245\">Recent transformer-based models like SAM <xref rid=\"bib14\" ref-type=\"bibr\">[14]</xref>, <xref rid=\"bib15\" ref-type=\"bibr\">[15]</xref> and MedSAM <xref rid=\"bib16\" ref-type=\"bibr\">[16]</xref>, despite leveraging pretraining on a vast dataset of over 50,000 medical images and SAM's foundation of 1 billion masked image segments lack the domain-specific optimization necessary for accurate scar delineation <xref rid=\"bib17\" ref-type=\"bibr\">[17]</xref>, <xref rid=\"bib18\" ref-type=\"bibr\">[18]</xref>. ScarNet's hybrid architecture overcomes these limitations by combining the global context awareness of transformers with the precise localization capabilities of CNNs, enhanced by specialized attention mechanisms that specifically target scar features while preserving anatomical context.</p><p id=\"p0250\">Several findings from our study have important implications for clinical practice. First, ScarNet's ability to achieve near-manual-level accuracy (CCC&#160;=&#160;0.995, percent bias&#160;=&#160;&#8722;0.63%, CoV&#160;=&#160;4.3%) in scar volume quantification suggests its potential for reliable automated analysis in clinical workflows. The incorporation of transformer architecture and specialized attention mechanisms proved particularly effective in identifying irregular scar patterns and heterogeneous enhancement, challenges that have traditionally limited automated approaches. The model's robust performance across varying training data sizes indicates its effectiveness even with limited datasets, a crucial advantage for clinical implementation. Furthermore, the stability demonstrated in noise perturbation experiments (5% Gaussian noise level, empirically determined as an upper limit in clinical practice) resulted in consistently high performance (scar DICE&#160;=&#160;0.892&#160;&#177;&#160;0.053, CoV&#160;=&#160;5.9%), suggesting reliable performance against clinically relevant noise. These findings confirm that: (1) MedSAM's global context modeling is essential despite poor standalone performance, (2) domain-specific fine-tuning of pretrained weights is crucial, and (3) specialized attention mechanisms provide meaningful improvements for scar detection. The overall accuracy was highest for ScarNet, followed by nnU-Net and MedSAM, where only ScarNet had sensitivity and specificity greater than 90%. Notably, ScarNet demonstrated the highest performance in basal regions, with slight but consistent decreases toward the apex, while maintaining substantial advantages over both comparison methods across all cardiac regions.</p></sec><sec id=\"sec0090\"><label>5</label><title>Limitations</title><p id=\"p0255\">This study has several limitations that should be acknowledged. First, while our dataset included 685 patients with 7066 2D LGE images, it was derived from specific clinical trials (DETERMINE and PRE-DETERMINE), potentially limiting generalizability to broader patient populations. Second, our ground truth annotations were created using the full width at half maximum technique, which, although widely accepted, may not capture all patterns of enhancement. Third, as a foundation model, ScarNet requires a graphics processing unit (GPU) for optimal performance, which may impact deployment in some clinical settings. While recent advances in GPU computing <xref rid=\"bib28\" ref-type=\"bibr\">[28]</xref>, <xref rid=\"bib29\" ref-type=\"bibr\">[29]</xref>, <xref rid=\"bib30\" ref-type=\"bibr\">[30]</xref>, <xref rid=\"bib31\" ref-type=\"bibr\">[31]</xref> and memory management, such as improved collective message passing interface (MPI) libraries for Intel GPUs <xref rid=\"bib32\" ref-type=\"bibr\">[32]</xref>, offer promising solutions for optimizing foundation model deployment, GPU requirements remain a consideration for clinical implementation. Fourth, our dataset includes images with varying spatial resolution parameters, with median pixel dimension of 1.74&#8201;mm&#8201;&#215;&#8201;1.91&#8201;mm. While most LGE scans align with the spatial resolution recommended (1.4&#8211;1.8&#8201;mm) by the SCMR protocol first published in 2013 <xref rid=\"bib33\" ref-type=\"bibr\">[33]</xref>, some LGE scans were below the recommended resolution. This limitation of our retrospective study stems from the fact that the majority of CMR scans in DETERMINE studies were conducted between 2008 and 2015, prior to the 2013 SCMR protocol recommendation. Nevertheless, despite the slightly suboptimal spatial resolution, ScarNet achieved high accuracy in detecting myocardial scar volume. Fifth, while the model shows robust performance on varying scar patterns, its effectiveness on rare or atypical presentations requires further validation. Sixth, the current loss function parameters (<inline-formula><mml:math id=\"M62\" altimg=\"si0049.svg\"><mml:mrow><mml:msub><mml:mrow><mml:mi>&#955;</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>&#955;</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>&#955;</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo stretchy=\"false\">)</mml:mo></mml:mrow></mml:math></inline-formula> were optimized for ischemic scar patterns and would likely require retuning for non-ischemic cardiomyopathies due to different enhancement characteristics and morphological patterns. Seventh, although we demonstrated stability under simulated noise (5% Gaussian) real-world testing on low-quality or artifact-laden images remains necessary. Eighth, the current validation focused on 2D slice-based analysis; extension to true 3D volume segmentation could potentially improve spatial consistency. Ninth, the two cardiologists involved in the image processing did not analyze the same datasets or perform an inter-rater variability analysis. As such, we are unable to evaluate the influence of label uncertainly due to inter-rater variability on our model performance. Future studies should validate ScarNet's performance against multiple expert annotations using various quantification techniques and explore its performance in non-ischemic cardiomyopathies, where scar patterns can be less well-defined and challenging to quantify.</p><p id=\"p0260\">In conclusion, we present ScarNet, a novel foundation model specifically designed for automated left ventricular scar quantification in LGE, distinguishing itself from existing cardiac foundation models that focus on general cardiac structure analysis rather than specific scar assessment. While other foundation models have advanced cardiac imaging analysis broadly, ScarNet's focused approach to scar quantification fills a crucial gap in automated cardiac tissue analysis. Its successful implementation could facilitate routine quantitative assessment of myocardial scar, potentially improving risk stratification and treatment planning in patients with ischemic cardiomyopathy. Future work should focus on validation across different cardiac pathologies, integration with clinical decision support systems, and exploration of applications beyond cardiac imaging.</p></sec><sec id=\"sec0095\"><title>Funding</title><p id=\"p0265\"><funding-source id=\"gs1\">The National Institutes of Health</funding-source> (<award-id award-type=\"grant\" rid=\"gs1\">R01HL116895, R01HL151079, R01HL167148, R01HL168859</award-id>), <funding-source id=\"gs2\">the Radiological Society of North America</funding-source> (<award-id award-type=\"grant\" rid=\"gs2\">EILTC2302</award-id>), and <funding-source id=\"gs3\">the American Heart Association</funding-source> (<award-id award-type=\"grant\" rid=\"gs3\">949899</award-id>).</p></sec><sec id=\"sec0100\"><title>Author contributions</title><p id=\"p0270\"><bold>Neda&#160;Tavakoli:</bold>&#160;Writing &#8211; review &amp; editing, writing &#8211; original draft, visualization, validation, software, project administration, methodology, formal analysis, data curation, conceptualizationa.&#160;<bold>Amir Ali&#160;Rahsepar:</bold> Writing &#8211; review &amp; editing, writing &#8211; original draft, visualization, validation, supervision, software, resources, methodology, data curation, conceptualization.&#160;<bold>Brandon C.&#160;Benefield:</bold> Writing &#8211; review &amp; editing, writing &#8211; original draft, validation, supervision, resources, methodology, data curation, conceptualization.&#160;<bold>Daming&#160;Shen:</bold> Writing &#8211; review &amp; editing, supervision, methodology, investigation, data curation, conceptualization.&#160;<bold>Santiago&#160;L&#243;pez-Tapia:</bold> Writing &#8211; review &amp; editing, validation, supervision, methodology, conceptualization. <bold>Florian Schiffers:</bold> Writing &#8211; review &amp; editing, validation, methodology, conceptualization.&#160;<bold>Jeffrey J.&#160;Goldberger:</bold> Writing &#8211; review &amp; editing, validation, supervision.&#160;<bold>Christine M.&#160;Albert:</bold> Writing &#8211; review &amp; editing, validation, supervision.&#160;<bold>Edwin&#160;Wu:</bold> Writing &#8211; review &amp; editing, validation, supervision.&#160;<bold>Aggelos K.&#160;Katsaggelos:</bold> Writing &#8211; review &amp; editing, validation, supervision, methodology, formal analysis, conceptualization. <bold>Daniel C.&#160;Lee:</bold> Writing &#8211; review &amp; editing, writing &#8211; original draft, visualization, validation, supervision, software, resources, project administration, methodology, investigation, data curation, conceptualization. <bold>Daniel&#160;Kim:</bold> Writing &#8211; review &amp; editing, writing &#8211; original draft, visualization, validation, supervision, software, resources, project administration, methodology, investigation, funding acquisition, formal analysis, data curation, conceptualization.</p></sec><sec id=\"sec0105\"><title>Declaration of generative AI and AI-assisted technologies in the writing process</title><p id=\"p0275\">During the preparation of this work, the author(s) used ChatGPT in order to check the grammar. After using this tool/service, the author(s) reviewed and edited the content as needed and take(s) full responsibility for the content of the publication.</p></sec><sec sec-type=\"COI-statement\" id=\"coi0005\"><title>Declaration of competing interests</title><p id=\"p0280\">The authors declare the following financial interests/personal relationships which may be considered as potential competing interests:&#160;Neda Tavakoli reports that financial support was provided by National Institutes of Health, Radiological Society of North America, American Heart Association. The other authors&#160;declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.</p></sec></body><back><ref-list id=\"bibliog0005\"><title>References</title><ref id=\"bib1\"><label>1</label><element-citation publication-type=\"journal\" id=\"sbref1\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Kim</surname><given-names>R.J.</given-names></name><name name-style=\"western\"><surname>Chen</surname><given-names>E.L.</given-names></name><name name-style=\"western\"><surname>Lima</surname><given-names>J.A.</given-names></name><name name-style=\"western\"><surname>Judd</surname><given-names>R.M.</given-names></name></person-group><article-title>Myocardial Gd-DTPA kinetics determine MRI contrast enhancement and reflect the extent and severity of myocardial injury after acute reperfused infarction</article-title><source>Circulation</source><volume>94</volume><year>1996</year><fpage>3318</fpage><lpage>3326</lpage><pub-id pub-id-type=\"pmid\">8989146</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1161/01.cir.94.12.3318</pub-id></element-citation></ref><ref id=\"bib2\"><label>2</label><element-citation publication-type=\"journal\" id=\"sbref2\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Kwong</surname><given-names>R.Y.</given-names></name><name name-style=\"western\"><surname>Chan</surname><given-names>A.K.</given-names></name><name name-style=\"western\"><surname>Brown</surname><given-names>K.A.</given-names></name><name name-style=\"western\"><surname>Chan</surname><given-names>C.W.</given-names></name><name name-style=\"western\"><surname>Reynolds</surname><given-names>H.G.</given-names></name><name name-style=\"western\"><surname>Tsang</surname><given-names>S.</given-names></name><etal/></person-group><article-title>Impact of unrecognized myocardial scar detected by cardiac magnetic resonance imaging on event-free survival in patients presenting with signs or symptoms of coronary artery disease</article-title><source>Circulation</source><volume>113</volume><year>2006</year><fpage>2733</fpage><lpage>2743</lpage><pub-id pub-id-type=\"pmid\">16754804</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1161/CIRCULATIONAHA.105.570648</pub-id></element-citation></ref><ref id=\"bib3\"><label>3</label><element-citation publication-type=\"journal\" id=\"sbref3\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Karim</surname><given-names>R.</given-names></name><name name-style=\"western\"><surname>Bhagirath</surname><given-names>P.</given-names></name><name name-style=\"western\"><surname>Claus</surname><given-names>P.</given-names></name><name name-style=\"western\"><surname>Housden</surname><given-names>R.J.</given-names></name><name name-style=\"western\"><surname>Chen</surname><given-names>Z.</given-names></name><name name-style=\"western\"><surname>Karimaghaloo</surname><given-names>Z.</given-names></name><etal/></person-group><article-title>Evaluation of state-of-the-art segmentation algorithms for left ventricle infarct from late Gadolinium enhancement MR images</article-title><source>Med Image Anal</source><volume>30</volume><year>2016</year><fpage>95</fpage><lpage>107</lpage><pub-id pub-id-type=\"pmid\">26891066</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1016/j.media.2016.01.004</pub-id></element-citation></ref><ref id=\"bib4\"><label>4</label><element-citation publication-type=\"journal\" id=\"sbref4\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Flett</surname><given-names>A.S.</given-names></name><name name-style=\"western\"><surname>Hasleton</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>Cook</surname><given-names>C.</given-names></name><name name-style=\"western\"><surname>Hausenloy</surname><given-names>D.</given-names></name><name name-style=\"western\"><surname>Quarta</surname><given-names>G.</given-names></name><name name-style=\"western\"><surname>Ariti</surname><given-names>C.</given-names></name><etal/></person-group><article-title>Evaluation of techniques for the quantification of myocardial scar of differing etiology using cardiac magnetic resonance</article-title><source>JACC Cardiovasc Imaging</source><volume>4</volume><year>2011</year><fpage>150</fpage><lpage>156</lpage><pub-id pub-id-type=\"pmid\">21329899</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1016/j.jcmg.2010.11.015</pub-id></element-citation></ref><ref id=\"bib5\"><label>5</label><element-citation publication-type=\"journal\" id=\"sbref5\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Rahsepar</surname><given-names>A.A.</given-names></name><name name-style=\"western\"><surname>Ghasemiesfe</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Suwa</surname><given-names>K.</given-names></name><name name-style=\"western\"><surname>Dolan</surname><given-names>R.S.</given-names></name><name name-style=\"western\"><surname>Shehata</surname><given-names>M.L.</given-names></name><name name-style=\"western\"><surname>Korell</surname><given-names>M.J.</given-names></name><etal/></person-group><article-title>Comprehensive evaluation of macroscopic and microscopic myocardial fibrosis by cardiac MR: intra-individual comparison of gadobutrol versus gadoterate meglumine</article-title><source>Eur Radiol</source><volume>29</volume><year>2019</year><fpage>4357</fpage><lpage>4367</lpage><pub-id pub-id-type=\"pmid\">30617490</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1007/s00330-018-5956-3</pub-id></element-citation></ref><ref id=\"bib6\"><label>6</label><mixed-citation publication-type=\"other\" id=\"othref0005\">Mehrnia M, Kholmovski E, Katsaggelos A, Kim D, Passman R, Elbaz MSM. Novel self-calibrated threshold-free probabilistic fibrosis signature technique for 3D late gadolinium enhancement MRI. (PP)IEEE. Trans Biomed Eng. 2024.(PP).<pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1109/TBME.2024.3476930</pub-id><pub-id pub-id-type=\"pmcid\">PMC11875924</pub-id><pub-id pub-id-type=\"pmid\">39383069</pub-id></mixed-citation></ref><ref id=\"bib7\"><label>7</label><element-citation publication-type=\"journal\" id=\"sbref6\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Ferreira</surname><given-names>P.F.</given-names></name><name name-style=\"western\"><surname>Gatehouse</surname><given-names>P.D.</given-names></name><name name-style=\"western\"><surname>Mohiaddin</surname><given-names>R.H.</given-names></name><name name-style=\"western\"><surname>Firmin</surname><given-names>D.N.</given-names></name></person-group><article-title>Cardiovascular magnetic resonance artefacts</article-title><source>J Cardiovasc Magn R</source><volume>15</volume><year>2013</year><fpage>41</fpage><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1186/1532-429X-15-41</pub-id><pub-id pub-id-type=\"pmcid\">PMC3674921</pub-id><pub-id pub-id-type=\"pmid\">23697969</pub-id></element-citation></ref><ref id=\"bib8\"><label>8</label><element-citation publication-type=\"journal\" id=\"sbref7\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Bernard</surname><given-names>O.</given-names></name><name name-style=\"western\"><surname>Lalande</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Zotti</surname><given-names>C.</given-names></name><name name-style=\"western\"><surname>Cervenansky</surname><given-names>F.</given-names></name><name name-style=\"western\"><surname>Yang</surname><given-names>X.</given-names></name><name name-style=\"western\"><surname>Heng</surname><given-names>P.-A.</given-names></name><etal/></person-group><article-title>Deep learning techniques for automatic MRI cardiac multi-structures segmentation and diagnosis: is the problem solved?</article-title><source>IEEE Trans Med Imaging</source><volume>37</volume><year>2018</year><fpage>2514</fpage><lpage>2525</lpage><pub-id pub-id-type=\"pmid\">29994302</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1109/TMI.2018.2837502</pub-id></element-citation></ref><ref id=\"bib9\"><label>9</label><element-citation publication-type=\"book\" id=\"sbref8\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Ronneberger</surname><given-names>O.</given-names></name><name name-style=\"western\"><surname>Fischer</surname><given-names>P.</given-names></name><name name-style=\"western\"><surname>Brox</surname><given-names>T.</given-names></name></person-group><part-title>U-net: convolutional networks for biomedical image segmentation</part-title><comment>proceedings, part III 18</comment><series>Medical image computing and computer-assisted intervention&#8211;MICCAI 2015: 18th international conference</series><volume>2015</volume><year>2015</year><publisher-name>Springer,</publisher-name><publisher-loc>Munich, Germany</publisher-loc><fpage>234</fpage><lpage>241</lpage><comment>proceedings, part III 18</comment></element-citation></ref><ref id=\"bib10\"><label>10</label><element-citation publication-type=\"journal\" id=\"sbref9\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Fahmy</surname><given-names>A.S.</given-names></name><name name-style=\"western\"><surname>Rowin</surname><given-names>E.J.</given-names></name><name name-style=\"western\"><surname>Chan</surname><given-names>R.H.</given-names></name><name name-style=\"western\"><surname>Manning</surname><given-names>W.J.</given-names></name><name name-style=\"western\"><surname>Maron</surname><given-names>M.S.</given-names></name><name name-style=\"western\"><surname>Nezafat</surname><given-names>R.</given-names></name></person-group><article-title>Improved quantification of myocardium scar in late gadolinium enhancement images: deep learning based image fusion approach</article-title><source>J Magn Reson Imaging</source><volume>54</volume><year>2021</year><fpage>303</fpage><lpage>312</lpage><pub-id pub-id-type=\"pmid\">33599043</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1002/jmri.27555</pub-id><pub-id pub-id-type=\"pmcid\">PMC8359184</pub-id></element-citation></ref><ref id=\"bib11\"><label>11</label><element-citation publication-type=\"journal\" id=\"sbref10\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Moccia</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Banali</surname><given-names>R.</given-names></name><name name-style=\"western\"><surname>Martini</surname><given-names>C.</given-names></name><name name-style=\"western\"><surname>Muscogiuri</surname><given-names>G.</given-names></name><name name-style=\"western\"><surname>Pontone</surname><given-names>G.</given-names></name><name name-style=\"western\"><surname>Pepi</surname><given-names>M.</given-names></name><etal/></person-group><article-title>Development and testing of a deep learning-based strategy for scar segmentation on CMR-LGE images</article-title><source>Magn Reson Mater Phys Biol Med</source><volume>32</volume><year>2019</year><fpage>187</fpage><lpage>195</lpage><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1007/s10334-018-0718-4</pub-id><pub-id pub-id-type=\"pmid\">30460430</pub-id></element-citation></ref><ref id=\"bib12\"><label>12</label><element-citation publication-type=\"journal\" id=\"sbref11\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Jathanna</surname><given-names>N.</given-names></name><name name-style=\"western\"><surname>Podlasek</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Sokol</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Auer</surname><given-names>D.</given-names></name><name name-style=\"western\"><surname>Chen</surname><given-names>X.</given-names></name><name name-style=\"western\"><surname>Jamil-Copley</surname><given-names>S.</given-names></name></person-group><article-title>Diagnostic utility of artificial intelligence for left ventricular scar identification using cardiac magnetic resonance imaging-a&#160;systematic review</article-title><source>Cardiovasc Digit Health J</source><volume>2</volume><year>2021</year><fpage>S21</fpage><lpage>s29</lpage><pub-id pub-id-type=\"pmid\">35265922</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1016/j.cvdhj.2021.11.005</pub-id><pub-id pub-id-type=\"pmcid\">PMC8890335</pub-id></element-citation></ref><ref id=\"bib13\"><label>13</label><element-citation publication-type=\"journal\" id=\"sbref12\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Chen</surname><given-names>C.</given-names></name><name name-style=\"western\"><surname>Qin</surname><given-names>C.</given-names></name><name name-style=\"western\"><surname>Qiu</surname><given-names>H.</given-names></name><name name-style=\"western\"><surname>Tarroni</surname><given-names>G.</given-names></name><name name-style=\"western\"><surname>Duan</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>Bai</surname><given-names>W.</given-names></name><etal/></person-group><article-title>Deep learning for cardiac image segmentation: a review</article-title><source>Front Cardiovasc Med</source><volume>7</volume><year>2020</year><fpage>25</fpage><pub-id pub-id-type=\"pmid\">32195270</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.3389/fcvm.2020.00025</pub-id><pub-id pub-id-type=\"pmcid\">PMC7066212</pub-id></element-citation></ref><ref id=\"bib14\"><label>14</label><mixed-citation publication-type=\"other\" id=\"othref0010\">Vaswani A. Attention is all you need. Advances in Neural Information Processing Systems. 2017.</mixed-citation></ref><ref id=\"bib15\"><label>15</label><mixed-citation publication-type=\"other\" id=\"othref0015\">Kirillov A, Mintun E, Ravi N, Mao H, Rolland C, Gustafson L,&#160;et al. Segment anything, in: Proceedings of IEEE/CVF International Conference on Computer Vision.&#160;2023, 4015&#8211;4026.</mixed-citation></ref><ref id=\"bib16\"><label>16</label><element-citation publication-type=\"journal\" id=\"sbref13\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Ma</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>He</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>Li</surname><given-names>F.</given-names></name><name name-style=\"western\"><surname>Han</surname><given-names>L.</given-names></name><name name-style=\"western\"><surname>You</surname><given-names>C.</given-names></name><name name-style=\"western\"><surname>Wang</surname><given-names>B.</given-names></name></person-group><article-title>Segment anything in medical images</article-title><source>Nat Commun</source><volume>15</volume><year>2024</year><fpage>654</fpage><pub-id pub-id-type=\"pmid\">38253604</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1038/s41467-024-44824-z</pub-id><pub-id pub-id-type=\"pmcid\">PMC10803759</pub-id></element-citation></ref><ref id=\"bib17\"><label>17</label><mixed-citation publication-type=\"other\" id=\"othref0020\">Mehrnia M, Elbayumi M, Elbaz MS. Assessing foundational medical'segment anything'(Med-SAM1, Med-SAM2) deep learning models for left atrial segmentation&#160;in 3D LGE MRI. arXiv Prepr arXiv2411: 05963, 2024.</mixed-citation></ref><ref id=\"bib18\"><label>18</label><element-citation publication-type=\"journal\" id=\"sbref14\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Hatamizadeh</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Tang</surname><given-names>Y.</given-names></name><name name-style=\"western\"><surname>Nath</surname><given-names>V.</given-names></name><name name-style=\"western\"><surname>Yang</surname><given-names>D.</given-names></name><name name-style=\"western\"><surname>Myronenko</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Landman</surname><given-names>B.</given-names></name><etal/></person-group><article-title>Unetr: transformers for 3d medical image segmentation, in: Proceedings of</article-title><source>IEEE/CVF Winter Conf Appl Comput Vis</source><year>2022</year><fpage>574</fpage><lpage>584</lpage></element-citation></ref><ref id=\"bib19\"><label>19</label><element-citation publication-type=\"book\" id=\"sbref15\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Hu</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>Shen</surname><given-names>L.</given-names></name><name name-style=\"western\"><surname>Sun</surname><given-names>G.</given-names></name></person-group><part-title>Squeeze-and-excitation networks</part-title><source>Proceedings of the IEEE conference on computer vision and pattern recognition</source><year>2018</year><fpage>7132</fpage><lpage>7141</lpage></element-citation></ref><ref id=\"bib20\"><label>20</label><element-citation publication-type=\"journal\" id=\"sbref16\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Ross</surname><given-names>T.-Y.</given-names></name><name name-style=\"western\"><surname>Doll&#225;r</surname><given-names>G.</given-names></name></person-group><article-title>Focal loss for dense object detection</article-title><source>Proc IEEE Conf Comput Vis Pattern Recognit</source><year>2017</year><fpage>2980</fpage><lpage>2988</lpage></element-citation></ref><ref id=\"bib21\"><label>21</label><element-citation publication-type=\"journal\" id=\"sbref17\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Flett</surname><given-names>A.S.</given-names></name><name name-style=\"western\"><surname>Hasleton</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>Cook</surname><given-names>C.</given-names></name><name name-style=\"western\"><surname>Hausenloy</surname><given-names>D.</given-names></name><name name-style=\"western\"><surname>Quarta</surname><given-names>G.</given-names></name><name name-style=\"western\"><surname>Ariti</surname><given-names>C.</given-names></name><etal/></person-group><article-title>Evaluation of techniques for the quantification of myocardial scar of differing etiology using cardiac magnetic resonance</article-title><source>JACC Cardiovasc Imaging</source><volume>4</volume><year>2011</year><fpage>150</fpage><lpage>156</lpage><pub-id pub-id-type=\"pmid\">21329899</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1016/j.jcmg.2010.11.015</pub-id></element-citation></ref><ref id=\"bib22\"><label>22</label><element-citation publication-type=\"journal\" id=\"sbref18\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Zabihollahy</surname><given-names>F.</given-names></name><name name-style=\"western\"><surname>White</surname><given-names>J.A.</given-names></name><name name-style=\"western\"><surname>Ukwatta</surname><given-names>E.</given-names></name></person-group><article-title>Convolutional neural network-based approach for segmentation of left ventricle myocardial scar from 3D late gadolinium enhancement MR images</article-title><source>Med Phys</source><volume>46</volume><year>2019</year><fpage>1740</fpage><lpage>1751</lpage><pub-id pub-id-type=\"pmid\">30734937</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1002/mp.13436</pub-id></element-citation></ref><ref id=\"bib23\"><label>23</label><element-citation publication-type=\"journal\" id=\"sbref19\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Bai</surname><given-names>W.</given-names></name><name name-style=\"western\"><surname>Sinclair</surname><given-names>M.</given-names></name><name name-style=\"western\"><surname>Tarroni</surname><given-names>G.</given-names></name><name name-style=\"western\"><surname>Oktay</surname><given-names>O.</given-names></name><name name-style=\"western\"><surname>Rajchl</surname><given-names>M.</given-names></name><name name-style=\"western\"><surname>Vaillant</surname><given-names>G.</given-names></name><etal/></person-group><article-title>Automated cardiovascular magnetic resonance image analysis with fully convolutional networks</article-title><source>J Cardiovasc Magn R</source><volume>20</volume><year>2018</year><fpage>65</fpage><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1186/s12968-018-0471-x</pub-id><pub-id pub-id-type=\"pmcid\">PMC6138894</pub-id><pub-id pub-id-type=\"pmid\">30217194</pub-id></element-citation></ref><ref id=\"bib24\"><label>24</label><element-citation publication-type=\"journal\" id=\"sbref20\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Xiong</surname><given-names>Z.H.</given-names></name><name name-style=\"western\"><surname>Xia</surname><given-names>Q.</given-names></name><name name-style=\"western\"><surname>Hu</surname><given-names>Z.Q.</given-names></name><name name-style=\"western\"><surname>Huang</surname><given-names>N.</given-names></name><name name-style=\"western\"><surname>Bian</surname><given-names>C.</given-names></name><name name-style=\"western\"><surname>Zheng</surname><given-names>Y.F.</given-names></name><etal/></person-group><article-title>A global benchmark of algorithms for segmenting the left atrium from late gadolinium-enhanced cardiac magnetic resonance imaging</article-title><source>Med Image Anal</source><volume>67</volume><year>2021</year><object-id pub-id-type=\"publisher-id\">101832</object-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1016/j.media.2020.101832</pub-id><pub-id pub-id-type=\"pmid\">33166776</pub-id></element-citation></ref><ref id=\"bib25\"><label>25</label><element-citation publication-type=\"journal\" id=\"sbref21\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Zhuang</surname><given-names>X.H.</given-names></name><name name-style=\"western\"><surname>Shen</surname><given-names>J.</given-names></name></person-group><article-title>Multi-scale patch and multi-modality atlases for whole heart segmentation of MRI</article-title><source>Med Image Anal</source><volume>31</volume><year>2016</year><fpage>77</fpage><lpage>87</lpage><pub-id pub-id-type=\"pmid\">26999615</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1016/j.media.2016.02.006</pub-id></element-citation></ref><ref id=\"bib26\"><label>26</label><element-citation publication-type=\"journal\" id=\"sbref22\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Crawley</surname><given-names>R.</given-names></name><name name-style=\"western\"><surname>Amirrajab</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Lustermans</surname><given-names>D.</given-names></name><name name-style=\"western\"><surname>Holtackers</surname><given-names>R.J.</given-names></name><name name-style=\"western\"><surname>Plein</surname><given-names>S.</given-names></name><name name-style=\"western\"><surname>Veta</surname><given-names>M.</given-names></name><etal/></person-group><article-title>Automated cardiovascular MR myocardial scar quantification with unsupervised domain adaptation</article-title><source>Eur Radio Exp</source><volume>8</volume><year>2024</year><fpage>93</fpage><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1186/s41747-024-00497-3</pub-id><pub-id pub-id-type=\"pmcid\">PMC11324636</pub-id><pub-id pub-id-type=\"pmid\">39143405</pub-id></element-citation></ref><ref id=\"bib27\"><label>27</label><element-citation publication-type=\"journal\" id=\"sbref23\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Jada</surname><given-names>L.</given-names></name><name name-style=\"western\"><surname>Holtackers</surname><given-names>R.J.</given-names></name><name name-style=\"western\"><surname>Martens</surname><given-names>B.</given-names></name><name name-style=\"western\"><surname>Nies</surname><given-names>H.</given-names></name><name name-style=\"western\"><surname>Van De Heyning</surname><given-names>C.M.</given-names></name><name name-style=\"western\"><surname>Botnar</surname><given-names>R.M.</given-names></name><etal/></person-group><article-title>Quantification of myocardial scar of different etiology using dark- and bright-blood late gadolinium enhancement cardiovascular magnetic resonance</article-title><source>Sci Rep</source><volume>14</volume><year>2024</year><fpage>5395</fpage><pub-id pub-id-type=\"pmid\">38443457</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1038/s41598-024-52058-8</pub-id><pub-id pub-id-type=\"pmcid\">PMC10914833</pub-id></element-citation></ref><ref id=\"bib28\"><label>28</label><mixed-citation publication-type=\"other\" id=\"othref0025\">Kousha Des P. Conversational AI Enabled Services and Performance Analysis Tools&#160;for High-Performance Computing, in, The Ohio State University. 2024.</mixed-citation></ref><ref id=\"bib29\"><label>29</label><element-citation publication-type=\"book\" id=\"sbref24\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Kousha</surname><given-names>P.</given-names></name><name name-style=\"western\"><surname>Zhou</surname><given-names>Q.</given-names></name><name name-style=\"western\"><surname>Subramoni</surname><given-names>H.</given-names></name><name name-style=\"western\"><surname>Panda</surname><given-names>D.K.</given-names></name></person-group><part-title>Benchmarking modern databases for storing and profiling very large scale HPC communication data</part-title><source>in: International Symposium on Benchmarking, Measuring and Optimization</source><year>2023</year><publisher-name>Springer,</publisher-name><fpage>104</fpage><lpage>119</lpage></element-citation></ref><ref id=\"bib30\"><label>30</label><element-citation publication-type=\"book\" id=\"sbref25\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Kousha</surname><given-names>P.</given-names></name><name name-style=\"western\"><surname>Jain</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Kolli</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Lieber</surname><given-names>M.</given-names></name><name name-style=\"western\"><surname>Han</surname><given-names>M.</given-names></name><name name-style=\"western\"><surname>Contini</surname><given-names>N.</given-names></name><etal/></person-group><part-title>SAI: AI-enabled speech assistant interface for science gateways in HPC</part-title><source>in: International Conference on</source><series>High Performance Computing</series><year>2023</year><publisher-name>Springer,</publisher-name><fpage>402</fpage><lpage>424</lpage></element-citation></ref><ref id=\"bib31\"><label>31</label><element-citation publication-type=\"journal\" id=\"sbref26\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Kousha</surname><given-names>P.</given-names></name><name name-style=\"western\"><surname>Sankarapandian Dayala Ganesh Ram</surname><given-names>K.R.</given-names></name><name name-style=\"western\"><surname>Kedia</surname><given-names>M.</given-names></name><name name-style=\"western\"><surname>Subramoni</surname><given-names>H.</given-names></name><name name-style=\"western\"><surname>Jain</surname><given-names>A.</given-names></name><name name-style=\"western\"><surname>Shafi</surname><given-names>A.</given-names></name><etal/></person-group><article-title>INAM: cross-stack profiling and analysis of communication in MPI-based applications</article-title><source>Pract Exp Adv Res Comput</source><year>2021</year><fpage>1</fpage><lpage>11</lpage></element-citation></ref><ref id=\"bib32\"><label>32</label><element-citation publication-type=\"journal\" id=\"sbref27\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Chen</surname><given-names>C.-C.</given-names></name><name name-style=\"western\"><surname>Kuncham</surname><given-names>G.K.R.</given-names></name><name name-style=\"western\"><surname>Kousha</surname><given-names>P.</given-names></name><name name-style=\"western\"><surname>Subramoni</surname><given-names>H.</given-names></name><name name-style=\"western\"><surname>Panda</surname><given-names>D.K.</given-names></name></person-group><article-title>Design and implementation of an IPC-based collective MPI library for intel GPUs</article-title><source>Pract Exp Adv Res Comput 2024 Hum Power Comput</source><year>2024</year><fpage>1</fpage><lpage>9</lpage></element-citation></ref><ref id=\"bib33\"><label>33</label><element-citation publication-type=\"journal\" id=\"sbref28\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Kramer</surname><given-names>C.M.</given-names></name><name name-style=\"western\"><surname>Barkhausen</surname><given-names>J.</given-names></name><name name-style=\"western\"><surname>Flamm</surname><given-names>S.D.</given-names></name><name name-style=\"western\"><surname>Kim</surname><given-names>R.J.</given-names></name><name name-style=\"western\"><surname>Nagel, P</surname><given-names>E.</given-names></name></person-group><article-title>Society for cardiovascular magnetic resonance board of trustees task force on standardized, standardized cardiovascular magnetic resonance (CMR) protocols 2013 update</article-title><source>J Cardiovasc Magn Reson</source><volume>15</volume><year>2013</year><object-id pub-id-type=\"publisher-id\">91</object-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1186/1532-429X-10-35</pub-id><pub-id pub-id-type=\"pmcid\">PMC2467420</pub-id><pub-id pub-id-type=\"pmid\">18605997</pub-id></element-citation></ref><ref id=\"bib34\"><label>34</label><element-citation publication-type=\"journal\" id=\"sbref29\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Kwon</surname><given-names>D.H.</given-names></name><name name-style=\"western\"><surname>Halley</surname><given-names>C.M.</given-names></name><name name-style=\"western\"><surname>Carrigan</surname><given-names>T.P.</given-names></name><name name-style=\"western\"><surname>Zysek</surname><given-names>V.</given-names></name><name name-style=\"western\"><surname>Popovic</surname><given-names>Z.B.</given-names></name><name name-style=\"western\"><surname>Setser</surname><given-names>R.</given-names></name><etal/></person-group><article-title>Extent of left ventricular scar predicts outcomes in ischemic cardiomyopathy patients with significantly reduced systolic function: a delayed hyperenhancement cardiac magnetic resonance study</article-title><source>JACC Cardiovasc Imaging</source><volume>2</volume><year>2009</year><fpage>34</fpage><lpage>44</lpage><pub-id pub-id-type=\"pmid\">19356530</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1016/j.jcmg.2008.09.010</pub-id></element-citation></ref><ref id=\"bib35\"><label>35</label><element-citation publication-type=\"journal\" id=\"sbref30\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Klem</surname><given-names>I.</given-names></name><name name-style=\"western\"><surname>Weinsaft</surname><given-names>J.W.</given-names></name><name name-style=\"western\"><surname>Bahnson</surname><given-names>T.D.</given-names></name><name name-style=\"western\"><surname>Hegland</surname><given-names>D.</given-names></name><name name-style=\"western\"><surname>Kim</surname><given-names>H.W.</given-names></name><name name-style=\"western\"><surname>Hayes</surname><given-names>B.</given-names></name><etal/></person-group><article-title>Assessment of myocardial scarring improves risk stratification in patients evaluated for cardiac defibrillator implantation</article-title><source>J Am Coll Cardiol</source><volume>60</volume><year>2012</year><fpage>408</fpage><lpage>420</lpage><pub-id pub-id-type=\"pmid\">22835669</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1016/j.jacc.2012.02.070</pub-id><pub-id pub-id-type=\"pmcid\">PMC3424733</pub-id></element-citation></ref></ref-list><sec id=\"sec0115\" sec-type=\"supplementary-material\"><label>Appendix A</label><title>Supplementary material</title><p id=\"p0295\"><supplementary-material content-type=\"local-data\" id=\"ec0005\" position=\"float\" orientation=\"portrait\"><caption><p>Supplementary material</p></caption><media xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"mmc1.docx\" position=\"float\" orientation=\"portrait\"/></supplementary-material>.</p></sec><sec sec-type=\"data-availability\" id=\"da0005\"><title>Availability of data and materials</title><p id=\"p0005\">The ScarNet implementation and associated code in Python are available at: <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://github.com/NedaTavakoli/ScarNet\" id=\"ir0005\">https://github.com/NedaTavakoli/ScarNet</ext-link>. For inquiries regarding LGE datasets, please contact the PRE-DETERMINE and DETERMINE study steering committee.</p></sec><ack id=\"ack0005\"><title>Acknowledgements</title><p id=\"p0285\">This work was partially supported by funding from the National Institutes of Health (R01HL116895, R01HL151079, R01HL167148, R01HL168859), Radiological Society of North America (EILTC2302), and American Heart Association (949899).</p></ack><fn-group><fn id=\"sec0110\" fn-type=\"supplementary-material\"><label>Appendix A</label><p id=\"p0290\">Supplementary data associated with this article can be found in the online version at <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://doi.org/10.1016/j.jocmr.2025.101945\" id=\"ir0010\">doi:10.1016/j.jocmr.2025.101945</ext-link>.</p></fn></fn-group></back></article></pmc-articleset>",
  "text": "pmc J Cardiovasc Magn Reson J Cardiovasc Magn Reson 574 jcardiomagnres Journal of Cardiovascular Magnetic Resonance 1097-6647 1532-429X Elsevier PMC12681538 PMC12681538.1 12681538 12681538 40846282 10.1016/j.jocmr.2025.101945 S1097-6647(25)00107-3 101945 1 Original Research ScarNet: a novel foundation model for automated myocardial scar quantification from late gadolinium-enhancement images Tavakoli Neda neda.tavakoli@northwestern.edu a &#8270; Rahsepar Amir Ali a Benefield Brandon C. b Shen Daming c L&#243;pez-Tapia Santiago d Schiffers Florian d Goldberger Jeffrey J. e Albert Christine M. f Wu Edwin b Katsaggelos Aggelos K. d Lee Daniel C. b Kim Daniel a a Department of Radiology, Feinberg School of Medicine, Northwestern University, Chicago, Illinois, USA b Department of Medicine (Division of Cardiology), Northwestern University Feinberg School of Medicine, Chicago, Illinois, USA c Department of Biomedical Engineering, Northwestern University, Evanston, Illinois, USA d Department of Electrical and Computer Engineering, Northwestern University, Evanston, Illinois, USA e Cardiovascular Division, University of Miami Miller School of Medicine, Miami, Florida, USA f Smidt Heart Institute, Cedars-Sinai Medical Center, Los Angeles, California, USA &#8270; Corresponding author.&#160;Department of Radiology, Feinberg School of Medicine, Northwestern University, 737 North Michigan Avenue, Chicago, Illinois 60611, USA. neda.tavakoli@northwestern.edu Winter 2025 20 8 2025 27 2 490964 101945 30 12 2024 14 8 2025 18 8 2025 20 08 2025 08 12 2025 08 12 2025 &#169; 2025 The Author(s) 2025 https://creativecommons.org/licenses/by-nc-nd/4.0/ This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/). Background Late gadolinium enhancement (LGE) imaging remains the gold standard for assessing myocardial fibrosis and scarring, with left ventricular (LV) LGE presence and extent serving as a predictor of major adverse cardiac events (MACE). Despite its clinical significance, LGE-based LV scar quantification is not used routinely due to the labor-intensive manual segmentation and substantial inter-observer variability. Methods We developed ScarNet that synergistically combines a transformer-based encoder in medical segment anything model (MedSAM), which we fine-tuned with our dataset, and a convolution-based decoder in UNet with tailored attention blocks to automatically segment myocardial scar boundaries while maintaining anatomical context. This network was trained and fine-tuned on an existing database of 401 ischemic cardiomyopathy patients (4137 2D LGE images) with expert segmentation of myocardial and scar boundaries in LGE images, validated on 100 patients (1034 2D LGE images) during training, and tested on unseen set of 184 patients (1895 2D LGE images). Ablation studies were conducted to validate each architectural component's contribution. Results In 184 independent testing patients, ScarNet achieved accurate scar boundary segmentation (median DICE&#160;=&#160;0.912 [interquartile range (IQR): 0.863&#8211;0.944], concordance correlation coefficient [CCC]&#160;=&#160;0.963), significantly outperforming both MedSAM (median DICE&#160;=&#160;0.046 [IQR: 0.043&#8211;0.047], CCC&#160;=&#160;0.018) and nnU-Net (median DICE&#160;=&#160;0.638 [IQR: 0.604&#8211;0.661], CCC&#160;=&#160;0.734). For scar volume quantification, ScarNet demonstrated excellent agreement with manual analysis (CCC&#160;=&#160;0.995, percent bias&#160;=&#160;&#8722;0.63%, CoV=4.3%) compared to MedSAM (CCC&#160;=&#160;0.002, percent bias&#160;=&#160;&#8722;13.31%, CoV&#160;=&#160;130.3%) and nnU-Net (CCC&#160;=&#160;0.910, percent bias&#160;=&#160;&#8722;2.46%, CoV&#160;=&#160;20.3%). Similar trends were observed in the Monte Carlo simulations with noise perturbations. The overall accuracy was highest for ScarNet (sensitivity=95.3% (163/171); specificity=92.3% (12/13)), followed by nnU-Net (sensitivity=74.9% (128/171); specificity=69.2% (9/13)) and MedSAM (sensitivity=15.2% (26/171); specificity=92.3% (12/13)). Conclusion ScarNet outperformed MedSAM and nnU-Net for predicting myocardial and scar boundaries in LGE images of patients with ischemic cardiomyopathy. The Monte Carlo simulations demonstrated that ScarNet is less sensitive to noise perturbations than other tested networks. Graphical abstract ga1 Keywords Cardiac MRI Deep learning Foundation models Late gadolinium enhancement Medical image segmentation Myocardial scar quantification pmc-status-qastatus 0 pmc-status-live yes pmc-status-embargo no pmc-status-released yes pmc-prop-open-access yes pmc-prop-olf no pmc-prop-manuscript no pmc-prop-legally-suppressed no pmc-prop-has-pdf yes pmc-prop-has-supplement yes pmc-prop-pdf-only no pmc-prop-suppress-copyright no pmc-prop-is-real-version no pmc-prop-is-scanned-article no pmc-prop-preprint no pmc-prop-in-epmc yes Abbreviations AI artificial intelligence CMR cardiovascular magnetic resonance CNN convolutional neural networks CoV coefficient of variation DL DICE loss GPU graphics processing unit LGE late gadolinium enhancement magnetic resonance imaging LV left ventricle MACE major adverse cardiac events MedSAM medical segment anything model MI myocardial infarction MRI magnetic resonance imaging SAM segment anything model SE squeeze-and-excitation ViT vision transformer CCC concordance correlation coefficient 2D two-dimensional 3D three-dimensional IQR interquartile range nnU-Net no new U-net FCNN fully convolutional neural network PSIR phase-sensitive inversion recovery ViTMAE vision transformer masked auto encoder FTL focal Tversky loss CE cross entropy DSC DICE similarity coefficient MPI message passing interface 1 Introduction Late gadolinium enhancement (LGE) cardiovascular magnetic resonance (CMR) [1] is the gold standard non-invasive test for myocardial fibrosis and scarring, providing essential information for risk stratification, treatment planning, and prognosis evaluation. Among LGE metrics, left ventricular (LV) scar volume is especially significant, as it has proven to be a predictor of major adverse cardiac events (MACE) and arrhythmic complications [2] . Despite its clinical importance, LGE-based LV scar quantification remains challenging to implement in practice due to several factors [3] . Traditional manual segmentation requires several minutes per case and is highly user-dependent, with considerable inter-observer variability [4] , [5] , [6] . This variability stems from the complex and heterogeneous appearance of scar tissue in LGE images, which often presents with diffuse boundaries, irregular shapes, and varying intensity patterns. Additionally, imaging artifacts such as motion blur, intensity inhomogeneity, ghosting artifacts arising from arrhythmia, and noise further complicate accurate scar delineation [7] , making reliable manual segmentation both labor-intensive and inconsistent. Recent advancements in deep learning have inspired efforts to automate LV scar segmentation in LGE [8] . Traditional convolutional neural networks (CNNs), particularly U-Net-based architectures [9] , [10] , have shown promise in medical image segmentation tasks. Early work by Moccia et al. demonstrated the potential of fully convolutional neural networks (FCNNs) for scar segmentation on CMR-LGE images, achieving improved performance when limiting the search area to the myocardial region [11] . However, these methods have encountered limitations in cardiac scar segmentation. A 2021 meta-analysis of 35 AI-based left ventricular scar quantification studies demonstrated mean DICE scores of only 0.616 and 0.633 for supervised and unsupervised methods, respectively [12] . These limited performances are attributed to the inherent challenges of capturing long-range dependencies in cardiac anatomy, handling multi-scale variations in scar appearance [13] , and accurately delineating poorly defined scar boundaries. The recent development of transformer-based models [14] , including the segment anything model (SAM) [14] , [15] and its medical variant, MedSAM [16] , has introduced new possibilities for medical image segmentation. These models excel at capturing global context and handling diverse object appearances, presenting a unique opportunity to address the challenges of cardiac scar segmentation. However, their generalist nature and lack of domain-specific optimization limit their direct applicability to LGE analysis [17] , [18] . To address these challenges, we propose ScarNet, a novel foundation model designed specifically for LV scar segmentation in LGE as illustrated in Fig. 1 . ScarNet integrates the global context-awareness of MedSAM's transformer-based encoder with the precise localization capabilities of a U-Net decoder through an adaptive fusion mechanism. This architecture is further strengthened by specialized attention mechanisms, including multi-scale feature extraction pathways enhanced by squeeze-and-excitation (SE) modules [19] and novel ScarAttention blocks that dynamically focus on subtle scar regions while preserving anatomical context. Fig. 1 Architecture of ScarNet: a&#160;hybrid model combining MedSAM's ViT-based encoder with U-Net's multi-scale decoder for LV scar segmentation in LGE. (A) The integration of MedSAM's embeddings, processed through ScarAttention and fused with U-Net outputs, to generate precise scar masks. (B) The UNet encoder-decoder, highlighting hierarchical feature extraction, skip connections, and spatial refinement for accurate segmentation. LV left ventricular, LGE &#160;late gadolinium enhancement, MedSAM medical segment anything model, ViT vision transformer. Fig. 1 To address the class imbalance inherent in cardiac scar segmentation, ScarNet incorporates a comprehensive multi-component loss function. This loss function combines DICE, Focal [20] , and cross-entropy losses with class-specific optimization terms for scar and myocardium segmentation, supported by an adaptive weighting scheme to balance the contributions of each component throughout training. Our novel ScarNet architecture addresses key challenges in cardiac scar segmentation through several innovative design elements. The hybrid structure combines global context understanding with precise local feature detection, while specialized attention mechanisms enhance the capture of heterogeneous scar patterns. Furthermore, an efficient inference pipeline supports seamless integration into clinical workflows, and the adaptive fusion design enables comprehensive multi-scale feature extraction. The purpose of this study was to implement ScarNet and compare its performance against MedSAM and nnU-Net on an existing database of LGE images of ischemic cardiomyopathy patients with expert segmentation of myocardial and scar boundaries as reference. 2 Methods 2.1 Patient cohort This is a retrospective study using de-identified LGE images from patients with coronary artery disease and left ventricular dysfunction enrolled in the DETERMINE registry (ClinicalTrials.gov ID NCT00487279 ) and PRE-DETERMINE study (ClinicalTrials.gov ID NCT01114269 ) [21] . The DETERMINE and PRE-DETERMINE studies were conducted at 65 sites across the United States between 2008 and 2015, using vendor-specific LGE pulse sequences (Siemens, Philips, and GE scanners). The protocols included segmented breath-hold, single-shot, and 3D sequences. Of the images analyzed by the DETERMINE/PRE-DETERMINE studies,92.9% (739/795) were magnitude, while 7% (56/795) were phase-sensitive inversion recovery (PSIR). The study was approved by our Institutional Review Board with a waiver of informed consent. From the original database of 795 patients, 58 patients with microvascular obstruction were removed, and 51 patients were removed due to either poor image quality or mismatch between the annotated contour files and the underlying image files. In total, we used 685 patients with 7066 analyzable 2D LGE images. The dataset was divided using a patient-level split to prevent data leakage: 401 patients (4137 2D LGE images) for training, 100 patients (1034 2D images) for validation, and 184 patients (1895 2D images) as an independent testing set. All patients included in the testing study exhibited confirmed ischemic cardiomyopathy with left ventricular ejection fraction below 50%. Additional clinical profiles were not available to the study team at the time of this study. LGE images were manually segmented using the full width at half maximum technique [21] in QMass software (version 7.6, Medis Medical Imaging Systems, Leiden, The Netherlands), by two attending cardiologists with more than 10 years of clinical experience in CMR. The median pixel dimension was 1.74&#8201;mm&#8201;&#215;&#8201;1.91&#8201;mm (range: 0.95&#8201;mm&#8201;&#215;&#8201;1.04&#8201;mm to 2.81&#8201;mm&#8201;&#215;&#8201;3.75&#8201;mm). The median acquisition matrix was 224&#160;&#215;&#160;192 (range: 120&#160;&#215;&#160;72 to 384&#160;&#215;&#160;256). For additional details of the dataset and data preparation, please see Appendix in the Supplementary Materials . 2.2 Model architecture We include a literature review of related works to highlight their relative strengths and weaknesses, ultimately justifying the need for our study. Please see Appendix in Supplementary Materials for this literature review. The ScarNet architecture, shown in Fig. 1 and Fig. 2 , integrates global and local features by combining the pretrained MedSAM with a UNet pathway via an adaptive fusion mechanism, effectively capturing both anatomical context and spatial details necessary for precise LV scar segmentation in LGE. The MedSAM pathway uses a vision transformer (ViT) backbone, pretrained on large-scale general and medical datasets, to leverage global contextual information and subtle structural relationships in cardiac imaging. The complete segmentation pipeline is detailed in Algorithm 1, Algorithm 2, and Algorithm 3 included in Supplementary Materials , which outlines the key steps of our approach from input processing to final mask generation. The feature fusion process between MedSAM and UNet pathways is elaborated in Algorithm 4 included in Supplementary Materials . Additional algorithmic details can be found in the Appendix in Supplementary Materials . Fig. 2 Overview of the ScarNet encoder-decoder architecture with attention mechanisms: the image encoder leverages a ViTMAE-based vision transformer for comprehensive feature extraction. A prompt encoder generates segmentation prompts from automatically detected epicardial ROI expanded by two pixels in all directions (up, down, left, right), which feed into the mask decoder. Key components Channel Reducer, Scar Attention blocks, and SE layers, refine feature maps to highlight subtle scar regions while maintaining anatomical context. The final convolutional layers integrate multi-scale features to produce accurate scar segmentation masks, with the adaptive attention modules enabling dynamic focus on clinically relevant scar tissue in LGE. ViTMAE vision transformer masked auto encoder, ROI Region of Interest, SE Squeeze-and-Excitation. Fig. 2 By dividing the input image into non-overlapping patches, each mapped into an embedding space, MedSAM processes these features through a multi-scale decoder that progressively reduces channel dimensions from 256 to 32, preserving essential spatial relationships. This pathway is further enhanced with squeeze-and-excitation (SE) blocks that recalibrate channels, highlighting scar-relevant regions while suppressing background features, thus maximizing the representational power of the pretrained MedSAM ( (3) , (4) ). In parallel, the UNet pathway captures localized spatial details through a symmetric encoder-decoder architecture, progressively reducing spatial resolution while increasing feature depth with each encoding block ( Eq. 5 ). Skip connections preserve high-resolution features by linking corresponding encoder and decoder blocks, which enables accurate boundary delineation critical for scar segmentation ( Eq. 6 ). The adaptive fusion mechanism combines outputs from both pathways, balancing global and local context by aligning feature maps and applying an adaptive weighting mechanism. This fusion consolidates ScarNet&#8217;s learned representations into a single four-class segmentation map, distinguishing background, myocardium, blood pool, and scar regions, through a final 1&#160;&#215;&#160;1 convolutional layer. 2.2.1 Ablation study design To validate our architectural design choices, we conducted ablation experiments by systematically removing or modifying key components on the testing dataset. Four configurations were evaluated as follows: (1) MedSAM Pathway Removal&#8212;complete elimination of the transformer encoder, using only the UNet pathway; (2) Weight Freezing&#8212;MedSAM weights frozen during training to assess fine-tuning importance; (3) Attention removal&#8212;elimination of SE modules and ScarAttention blocks while maintaining fusion; and (4) Full ScarNet&#8212;complete architecture as baseline. All experiments used identical training protocols and hyperparameters. 2.2.1.1 Attention mechanisms ScarNet&#8217;s attention mechanisms focus on scar-relevant features, enhancing the model&#8217;s ability to generalize across diverse imaging conditions. SE modules, embedded within the MedSAM pathway, recalibrate channel-wise features by modeling interdependencies to boost sensitivity to scar tissue regions, while suppressing irrelevant background areas. Complementing this, the ScarAttention blocks, detailed in Algorithm 2, dynamically emphasize scar-specific features by reweighting spatial attention. These blocks use positional relationships and intensity variations unique to scars, improving the model's accuracy in highlighting subtle scar regions while preserving surrounding anatomical structures. 2.2.1.2 Training pipeline ScarNet&#8217;s training pipeline, described in Algorithm 1, is structured to ensure optimal segmentation capabilities. Initially, input LGE images are normalized and fed into both MedSAM and U-Net pathways. The parallel processing of these pathways generates both global and local feature representations, which are then enhanced by SE and ScarAttention modules before being fused to yield a four-class segmentation map. Loss calculation follows, with L ScarNet computed based on the adaptive weighting of DICE, Focal, and Cross-Entropy losses, guiding the model to optimize for both global and local accuracy. Backpropagation is conducted using an Adam optimizer, with gradients calculated to minimize L ScarNet (Algorithm 1, Steps 13&#8211;15). Regularization techniques, such as dropout and data augmentation, are applied to improve generalization. During inference, ScarNet processes unseen LGE images and generates segmentation maps for background, myocardium, blood pool, and scar regions, with the inference algorithm detailed in Algorithm 4 dynamically adjusting feature weighting for efficient predictions. 2.2.1.3 Mathematical model The ScarNet model, denoted by H , combines a fine-tuned and enhanced MedSAM and U-Net architecture to achieve accurate segmentation of cardiac scar regions. The model&#8217;s core function can be expressed as: (1) H x = F MedSAM x , U &#8722; Net x where x &#8712; R H &#215; W &#215; 1 represents a grayscale medical image, and F &#160;is a fusion function that combines the outputs of the MedSAM and U-Net branches. The fusion function F ta &#160;takes two feature maps, f 1 &#160;and f 2 , produced by MedSAM and U-Net, respectively, and combines them through concatenation and a 1&#160;&#215;&#160;1 convolution to produce the final segmentation output: (2) F f 1 , f 2 = Conv Concat f 1 , f 2 where Conv is a 1&#160;&#215;&#160;1 convolution that reduces the concatenated feature map to the desired number of classes, and Concat &#160;represents channel-wise concatenation. 2.2.1.3.1 MedSAM pathway The MedSAM component of ScarNet leverages a ViT backbone to capture global dependencies within the image, which is crucial for identifying subtle structures like scar tissue. MedSAM consists of patch embedding and position encoding stages, where the input image x &#8712; R H &#215; W &#215; 1 is divided into p &#215; p non-overlapping patches. Each patch is flattened and mapped to an embedding space, generating patch embeddings E : (3) E = W embed &#8901; P x where P x &#160;denotes the patches, and W embed &#160;is a learnable embedding matrix. The transformer operates on these patch embeddings, applying self-attention to learn relationships across the entire spatial dimension of the image. While the original MedSAM was designed for binary segmentation (one class + background), we adapted it for our multi-class cardiac segmentation task. Specifically, we modified the final decoder layer to output 4 channels instead of 1, enabling simultaneous segmentation of background, blood pool, myocardium, and scar tissue. The model was trained using multi-class cross-entropy loss rather than the original binary cross-entropy, allowing MedSAM to handle the four-class cardiac segmentation problem. This adaptation maintains the transformer's global context learning capabilities while extending its output functionality for comprehensive cardiac tissue classification. Despite modifying MedSAM's decoder for 4-class output and training with multi-class cross-entropy loss, the standalone model failed to learn meaningful scar representations without domain-specific fine-tuning, demonstrating that architectural adaptation alone is insufficient for specialized cardiac applications. For query Q, key K, and value V matrices derived from E, self-attention is computed as: (4) Attention ( Q , K , V ) = softmax Q K T d V where d is the embedding dimension, enabling global context learning. The encoded features are passed through multiple attention blocks and SE layers in a multi-scale decoder. This process enhances the features relevant to scar regions. The detailed processing steps of the MedSAM branch are presented in Algorithm 2, highlighting the transformer-based processing and attention mechanisms. 2.2.1.3.2 UNet&#160;pathway The UNet pathway captures local spatial details via a hierarchical encoder-decoder structure. The encoder consists of convolutional layers followed by downsampling steps, progressively reducing spatial resolution and increasing feature channels: (5) F enc l = Downsample F enc l &#8722; 1 Each level l extracts features at a smaller spatial scale, enabling the capture of localized features. The decoder restores spatial resolution by upsampling, integrating high-resolution features from the encoder via skip connections: (6) F dec l = Upsample F dec l + 1 + F enc l The final layer produces a feature map M UNet &#160;in R H &#215; W &#215; C , &#160;where C is the number of classes. Algorithm 3 provides a detailed breakdown of the UNet branch operations, including the encoder-decoder pathway and skip connection enhancement steps. 2.2.1.3.3 Loss function In ScarNet, the overall loss function L ScarNet is designed to address class imbalance and to focus on achieving high segmentation accuracy, especially for challenging regions like cardiac scars. The ScarNet model aims to minimize the overall loss function with respect to the model parameters &#952; , ensuring accurate segmentation across classes, with a particular emphasis on the scar class. This can be formulated as: (7) &#952; * = arg min &#952; L ScarNet &#952; where &#952; * represents the optimal parameters of the model, and L ScarNet &#160;is the combined loss function defined as: (8) L ScarNet = &#955; 1 . FTL + &#955; 2 . DL + &#955; 3 . CE where, FTL is the Focal Tversky Loss, which mitigates class imbalance by focusing more on the scar region,&#160; DL is the DICE Loss, which measures spatial overlap between the predicted and ground truth masks, CE is the cross-entropy loss, weighted by class-specific importance &#955; 1 , &#955; 2 , and &#955; 3 are coefficients that control the contribution of each term. These parameters were objectively determined through systematic grid search over &#955; 1 &#8712; 0.3 , 0.5 , 0,7 , &#955; 2 &#8712; 0.2 , 0.4 , 0,6 , &#955; 3 &#8712; 0.1 , 0.2 , 0,3 &#160;using 5-fold cross-validation on the combined training-validation cohort (501 patients), with the testing set (184 patients) held out completely to prevent data leakage. This yielded optimal values &#955; 1 = 0.5 , &#955; 2 = 0.4 , &#955; 3 = 0.1 (See Fig. 3 ). The optimization is subject to constraints that guide the model&#8217;s focus: 1. Class Imbalance Constraint: The scar class receives greater emphasis through heavier weighting of the Focal Tversky Loss term, enabling the model to manage class imbalances effectively. This constraint prioritizes reducing false negatives and false positives in scar segmentation, thus emphasizing the critical region of interest. 2. Spatial Accuracy Constraint: The DICE Loss DL component ensures that the segmentation output maintains spatial alignment with the ground truth by maximizing overlap. This constraint encourages accurate boundary delineation, especially for small or complex structures. 3. Regional Priority Constraint: The cross-entropy loss CE , with class-specific weights, further reinforces focus on critical regions, allowing flexibility in segmentation where non-scar regions may have less impact on the overall segmentation goal. Fig. 3 Lambda parameter sensitivity analysis for objective parameter optimization. (A) Individual parameter sensitivity analysis: performance curves showing how each &#955; parameter individually affects DICE coefficient. Optimal values are marked with dashed vertical lines (&#955;1&#160;=&#160;0.5, &#955;2&#160;=&#160;0.4, &#955;3&#160;=&#160;0.1), with shaded regions indicating &#177;20% stability zones where performance remains within 2% of optimal. (B) Grid search results: heatmap visualization of DICE performance across &#955;1 and &#955;2 combinations with &#955;3 fixed at 0.1. The red box highlights the optimal combination (&#955;1&#160;=&#160;0.5, &#955;2&#160;=&#160;0.4), demonstrating systematic evaluation of the parameter space. (C) Top 5 parameter combinations: ranking of best-performing parameter sets from comprehensive grid search of 27 combinations. The optimal configuration (0.5, 0.4, 0.1) shown in red achieves peak performance while maintaining reasonable performance across nearby parameter values. (D) Performance comparison: multi-metric validation comparing optimal versus suboptimal parameters across DICE coefficient, sensitivity, and specificity. Consistent improvements across all metrics confirm the robustness of the optimization approach, with 2.6% DICE improvement, 2.9% sensitivity improvement, and 1.6% specificity improvement using optimal parameters Fig. 3 Focal Tversky Loss (FTL) is adapted from the Tversky Index, emphasizing false positives and false negatives to handle class imbalance effectively. FTL is defined as: (9) FTL = ( 1 &#8722; &#8721; ( p &#8901; g ) + &#1013; &#8721; ( p &#8901; g ) + &#945; &#8721; ( p &#8901; ( 1 &#8722; g ) ) + &#946; &#8721; ( ( 1 &#8722; p ) . g ) + &#1013; ) &#947; For predicted p and ground truth g masks, where the focusing parameter &#947; controls the emphasis on hard-to-classify examples, set to &#947; = 2.0 for balanced focusing on difficult cases, and &#1013; is a smoothing constant ( &#1013; = 1 e &#8722; 5 ) added for numerical stability. DICE loss (DL) helps maximize the overlap between predicted p and ground truth g , masks, improving spatial accuracy. The DL is calculated as: (10) D L = 1 &#8722; 2 &#8901; | p &#8745; g | + &#1013; | p | + | g | + &#1013; incorporating the smoothing parameter &#1013; to ensure numerical stability. The parameter &#1013; = 1 &#8722; e 5 is used to prevent division by zero errors when the intersection between predicted and ground truth masks is zero, particularly during early training stages or for challenging segmentation cases. Cross-entropy loss is calculated for each pixel, weighted by class to improve representation of the scar class over background regions: (11) CE = &#8722; &#8721; c w c &#8901; g c log ( p c ) where w c &#160;is the weight for class c and p c and g c are the predicted and true probabilities for class c, respectively. This loss formulation provides a balanced objective that aligns ScarNet to achieve high accuracy in cardiac scar segmentation by reducing errors across both global context (captured by MedSAM) and local detail (captured by UNet). The training process aims to minimize L ScarNet by updating the model weights to reduce misclassifications, particularly for the scar class. This is achieved by gradient descent optimization: using optimizers Adam, gradients of L ScarNet with respect to model parameters are computed. These gradients indicate the direction and magnitude of updates needed to minimize the loss. Regularization methods, i.e., dropout and data augmentation help the model generalize, while tuning the weights &#955; 1 , &#955; 2 , and &#955; 3 in the combined loss function focuses the model on scar segmentation without overfitting. ScarNet demonstrates superior performance in cardiac scar segmentation by effectively delineating scar boundaries, reducing false positives, and providing consistent segmentation quality across varying scar sizes, shapes, and image qualities. The use of attention mechanisms at multiple scales further enhances the model&#8217;s ability to focus on relevant features, resulting in reliable and precise segmentation outcomes. Additional implementation details of our network are available in Supplementary Materials . 2.3 Two secondary experiments to demonstrate robustness First, to compare the performance of our model against other models as a function of training data size, we trained the models with combined training-validation cohorts ranging from 15 to 501 patients (with training comprising 80% and validation comprising 20% of each cohort at the patient level), with corresponding testing sets maintaining an approximately 4:1 training/validation-to-testing ratio. For example, the smallest experiment used 12 patients for training, 3 patients for validation, and 4 patients for testing, while the largest experiment used 401 patients for training, 100 patients for validation, and 184 patients for testing. This proportional scaling maintains consistent ratios across all experiments while ensuring patient-level separation to prevent data leakage between training, validation, and testing sets. Second, we conducted Monte Carlo simulations with 200 iterations by adding random noise (noise level 5%) (please see the Monte Carlo Simulation section in Supplementary Materials ). 2.4 Statistical analyses We tested for variable normality using the Kolmogorov-Smirnov, Anderson-Darling, and Shapiro-Wilk tests. A variable was deemed normally distributed if it passes all three tests. Box plots are reported for each comparing DICE metric to visualize the distribution and central tendencies across methods. Bland-Altman analysis was performed on scar volumes to assess the level of agreement between measurements, and concordance correlation coefficient (CCC) was calculated for scar volume measurements to compare with ground truth (i.e., manual). CCC values are also computed for scar DICE to compare it with ground truth. The coefficient of variation (CoV) was defined as the standard deviation of the difference divided by the mean and is computed for both scar DICE and scar volume. One-way analysis of variance (Kruskal-Wallis if not normally distributed) with Bonferroni correction was conducted to detect any significant differences among groups. A p-value &lt;0.05 was considered statistically significant for all tests performed. 3 Results Overall, 685 patients (with 7066 analyzable 2D LGE images) retrospectively enrolled in this study had mean age of 57.82&#160;&#177;&#160;18.58&#160;years, 59.8% (410/685) males, and mean left ventricular ejection fraction of 40.3&#160;&#177;&#160;11.0%, as detailed in Table 1 and Table 2 . Table 1 Participant demographics and characteristics. Table 1 Characteristic Training Set (n&#160;=&#160;401) Validation Set (n&#160;=&#160;100) Test Set (n&#160;=&#160;184) Sex Male: 59.8% (240/401), Female: 40.1% (161/401) Male: 60.0% (60/100), Female: 40.0% (40/100) Male: 59.7% (110/184), Female: 40.2% (74/184) Age (mean&#160;&#177;&#160;SD) 57.82&#160;&#177;&#160;18.58 years 57.82&#160;&#177;&#160;18.58 years 57.82&#160;&#177;&#160;18.58 years Left ventricular ejection fraction 40.3&#160;&#177;&#160;11.0% 40.3&#160;&#177;&#160;11.0% 40.3&#160;&#177;&#160;11.0% Table 2 Dataset characteristics and ischemic scar distribution . Table 2 Characteristic Training Set (n&#160;=&#160;401) Validation Set (n&#160;=&#160;100) Testing Set (n&#160;=&#160;184) Total (n&#160;=&#160;685) Number of 2D LGE images 4137 1034 1895 7066 LGE positive images 3848 962 1761 6571 LGE negative images 289 72 134 495 Images per Patient 10.3&#160;&#177;&#160;3.1 10.3&#160;&#177;&#160;3.1 10.3&#160;&#177;&#160;3.1 10.3&#160;&#177;&#160;3.1 Scar Severity Categories (Patient-Level) No Scar 6.9% (28/401) 7.0% ( 7/100) 7.0% (13/184) 7.0% (48/685) Mild Scar 27.9% (112/401) 28.00% (28/100) 28.2% (52/184) 28.0% (192/685) Moderate Scar 50.1% (201/401) 50.00% (50/100) 50.0% (92/184) 50.0% (343/685) Severe Scar 14.9% (60/401) 15.0% (15/100) 14.6% (27/184) 14.8% (102/685) Scar Volume Statistics Mean&#177;SD (%) 14.95&#160;&#177;&#160;9.50 14.95&#160;&#177;&#160;9.50 13.37&#160;&#177;&#160;8.57 14.52&#160;&#177;&#160;9.29 Median (%) 14.52 14.52 12.80 14.06 Range (%) 00.00&#8211;59.52 00.00&#8211;55.23 0.00&#8211;41.93 0.00&#8211;59.52 Data presented as n (%) or mean &#177; SD unless otherwise specified. No Scar (0%), Mild (&lt;10%), Moderate (10-30%), Severe (&gt;30%). SD standard deviation, LGE late gadolinium enhancement [34] , [35] Statistical analysis for myocardial segmentation showed that, compared against ScarNet (median DICE&#160;=&#160;0.961 [IQR: 0.920&#8211;0.999], CCC&#160;=&#160;0.978), nnU-Net (median DICE&#160;=&#160;0.878 [IQR: 0.838&#8211;0.915], CCC&#160;=&#160;0.892) and MedSAM (median DICE&#160;=&#160;0.242 [IQR: 0.116&#8211;0.342], CCC&#160;=&#160;0.156) were significantly different (p&lt;0.001). For scar segmentation, compared with ScarNet (median DICE&#160;=&#160;0.912 [IQR: 0.863&#8211;0.944], CCC&#160;=&#160;0.963), MedSAM (median DICE&#160;=&#160;0.046 [IQR: 0.043&#8211;0.047], CCC&#160;=&#160;0.018) and nnU-Net (median DICE&#160;=&#160;0.638 [IQR: 0.604&#8211;0.661], CCC&#160;=&#160;0.734) were significantly different (p&lt;0.001) ( Fig. 4 ). Fig. 4 Comparative performance metrics across different segmentation models. (Left) Box plots showing myocardium DICE scores for ScarNet, MedSAM, and nnU-Net. (Right) Scar DICE scores across models Fig. 4 A representative sample for one patient comparing segmentation performance between MedSAM and ScarNet and their corresponding feature logits and probability maps is shown in Fig. 5 , illustrating superior scar DICE and myocardium DICE for ScarNet compared to other networks. Fig. 5 Comparative visualization of ScarNet, MedSAM, and nnU-Net for cardiac LV LGE segmentation on a representative test sample. (A) Raw LGE image; (B) Multi-class segmentation showing myocardium (blue), blood pool (pink), and scar tissue (yellow) serving as ground truth (reference); (C) Predicted segmentation by MedSAM (myocardium DICE&#160;=&#160;0.11, scar DICE&#160;=&#160;0.00); (D) Predicted segmentation by nnU-Net (myocardium DICE&#160;=&#160;0.84, scar DICE&#160;=&#160;0.61); (E) Predicted segmentation by ScarNet (myocardium DICE&#160;=&#160;0.95, scar DICE&#160;=&#160;0.91). Left panel (MedSAM): (F) Logit map for the background; (G) Logit map for the blood pool; (H) Logit map for the myocardium ([red indicates high positive values, blue indicates high negative values]); (I&#8211;K) Corresponding probability maps for the background, blood pool, and myocardium, respectively [(bright colors indicate high probability, dark colors indicate low probability)]. Right panel (ScarNet): (L) Logit map for the background; (M) Logit map for the blood pool; (N) Logit map for the scar tissue [(red indicates high positive values, blue indicates high negative values)]; (O) Logit map for the myocardium; (P&#8211;S) Corresponding probability maps for the background, blood pool, scar tissue, and myocardium, respectively [(bright colors indicate high probability, dark colors indicate low probability)]. Despite 4-class architectural adaptation, MedSAM shows absence of scar-specific activation, demonstrating the necessity of specialized training for cardiac applications. Note that probability maps represent post-softmax outputs without thresholding; ScarNet's binary-appearing probabilities reflect high model confidence with values clustering near 0 or 1, while MedSAM shows greater uncertainty with values distributed across the full probability range. This figure does not include nnU-Net feature maps, because it does not provide feature maps.&#160; LV &#160;left ventricular,&#160; LGE &#160;late gadolinium enhancement, MedSAM medical segment anything Fig. 5 The performance of MedSAM, nnU-Net, and ScarNet as a function of training data size is shown in Fig. 6 . For both myocardium and scar segmentations, ScarNet achieved higher accuracy throughout and hit the plateau faster, with scar segmentation performance stabilizing at approximately 120 training patients (median scar DICE &#8764;0.912 [IQR: 0.885&#8211;0.917]) and myocardium segmentation plateauing at approximately 200 training patients (median myocardium DICE &#8764;0.948 [IQR: 0.873&#8211;0.952]). Since Fig. 6 demonstrates that ScarNet achieves plateau performance with relatively small training cohorts, we conducted additional experiments with alternative dataset splits. Using an alternative three-way split of 200 patients for training, 50 for validation, and 435 for independent testing (to cover all the 685 patients), ScarNet maintained consistent performance with a median scar DICE of 0.908 [IQR: 0.882&#8211;0.925]. Additionally, 5-fold cross-validation across the complete dataset demonstrated stable performance with a median scar DICE of 0.911 [IQR: 0.894&#8211;0.923], confirming model generalizability across different patient subsets. Both alternative splitting strategies consistently showed the same performance ranking: ScarNet &gt; nnU-Net &gt; MedSAM, validating the robustness of our architectural approach. Fig. 7 compares segmentation performance between MedSAM, nnU-Net, and ScarNet in four representative patients, where ScarNet consistently outperformed the other networks. Fig. 6 Comparative analysis of segmentation performance across varying training dataset sizes. (A) Mean myocardium DICE scores for ScarNet, MedSAM, and nnU-Net with increasing training cohort sizes from 15 to 501 patients (actual training: 12 to 401 patients, validation: 3 to 100 patients), maintaining an 80/20 training-validation split and approximately 4:1 training/validation-to-testing ratio for each experiment. The proportional scaling of validation sets ensures adequate statistical power for performance monitoring and early stopping at each training size. (B) Mean scar DICE score progression for all models with increasing training cohort sizes from 15 to 501 patients (actual training: 12 to 401 patients), with validation sets scaled proportionally to maintain representative performance monitoring. MedSAM medical segment anything Fig. 6 Fig. 7 Comparative analysis of CMR segmentation performance across different deep learning architectures. From left to right: Original CMR scans, Reference (ground truth) segmentations, MedSAM (without fine-tuning), nnU-Net, and proposed ScarNet. Representative test cases demonstrate the segmentation results across multiple cardiac slices at different anatomical levels. CMR cardiovascular magnetic resonance, MedSAM medical segment anyth Fig. 7 Fig. 8 compares scar volume quantification by different segmentation methods, where manual is the reference. Compared against manual (median scar volume&#160;=&#160;0.114 [IQR: 0.094&#8211;0.180]), MedSAM (median scar volume&#160;=&#160;0.000 [IQR: 0.000&#8211;0.001], CCC&#160;=&#160;0.000, bias&#160;=&#160;&#8722;13.31% [198.8% of mean], CoV&#160;=&#160;130.3%) and nnU-Net (median scar volume&#160;=&#160;0.095 [IQR: 0.068&#8211;0.150], CCC&#160;=&#160;0.910, bias&#160;=&#160;&#8722;2.46% [20.31% of mean], CoV&#160;=&#160;20.3%) were significantly different (p&lt;0.001), whereas ScarNet (median scar volume&#160;=&#160;0.109 [IQR: 0.087&#8211;0.173], CCC&#160;=&#160;0.995, bias&#160;=&#160;&#8722;0.63% [4.82% of mean], CoV&#160;=&#160;4.3%) was not significantly different (p&#160;=&#160;0.192). Fig. 8 Bland-Altman and correlation analyses comparing automated and manual scar quantification methods. Left column (A, C, E) : Bland-Altman plots showing differences between automated and manual scar volume measurements. (A) MedSAM vs Manual (CoV&#160;=&#160;130.3%, bias&#160;=&#160;&#8722;13.31%); (C) nnU-Net vs Manual (CoV&#160;=&#160;20.3%, bias&#160;=&#160;&#8722;2.46%); (E) ScarNet vs Manual (CoV&#160;=&#160;4.3%, bias&#160;=&#160;&#8722;0.63%). Right column (B, D, F) : Correlation plots between automated and manual measurements. (B) MedSAM shows poor correlation (CCC&#160;=&#160;0.002); (D) nnU-Net demonstrates good correlation (CCC&#160;=&#160;0.910); (F) ScarNet achieves near-perfect correlation (CCC&#160;=&#160;0.995 with manual measurements. Dotted lines in Bland-Altman plots represent 95% confidence intervals, and solid black lines show mean bias. CoV &#160;coefficient of variation, MedSAM medical segment anything Fig. 8 Fig. 9 Robustness analysis of segmentation models under noise conditions. Top row: (A) Original cardiac LGE image; (B) Reference segmentation with myocardium (blue) and scar tissue (pink); (C) Image with added Gaussian noise; (D) Noise difference map.Middle row - Original image segmentation: (E) MedSAM (Scar DSC: 0.0000), (F) nnU-Net (Scar DSC: 0.5636), and (G) ScarNet (Scar DSC: 0.9723), with zoomed insets showing detailed segmentation boundaries.Bottom row - Noisy image segmentation: (H) MedSAM (Scar DSC: 0.0000), (I) nnU-Net (Scar DSC: 0.5634), and (J) ScarNet (Scar DSC: 0.9720), demonstrating segmentation performance under noise conditions.&#160; LGE &#160;late gadolinium enhancement, MedSAM medical segment anything, DSC DICE similarity coe Fig. 9 Fig. 10 shows three no-scar cases with false positives predicted by each network. Fig. 11 shows three scar cases with false negatives predicted by each network. As shown in Fig. 12 , the overall accuracy was highest for ScarNet (sensitivity=95.3% (163/171); specificity=92.3% (12/13)), followed by nnU-Net (sensitivity=74.9% (128/171); specificity=69.2% (9/13)) and MedSAM (sensitivity=15.2% (26/171); specificity=92.3% (12/13)). Fig. 10 Three example no-scar cases with false positives predicted by each network. (Top row): One of four false positives predicted by nnU-Net. (Middle row): The lone false positive predicted by ScarNet. (Bottom row): The lone false positive predicted by MedSAM. MedSAM medical segment anything Fig. 10 Fig. 11 Three example scar cases with false negatives predicted by each network. (Top row): One of forty-three false negatives predicted by nnU-Net. (Middle row): One of eight false negatives predicted by ScarNet. (Bottom row): One of one hundred forty-five false negatives predicted by MedSAM Fig. 11 Fig. 12 A confusion matrix for scar vs. no-scar classifications predicted by the three networks. (Left) ScarNet produced very high specificity 92.3% (12/13) and sensitivity 95.3% (163/171) with only 1 false positive and 8 false negative cases out of 184 total cases. (Middle) nnU-Net produced moderate specificity 69.2% (9/13 and sensitivity 74.9% (128/171), resulting in 4 false positives and 43 false negatives. (Right) MedSAM produced very high specificity 92.3% (12/13) but very low sensitivity 15.2% (26/171), resulting in only 1 false positive but 145 false negatives. MedSAM medical segment anything model. Fig. 12 In Monte Carlo simulations with noise perturbations, for myocardial segmentation, ScarNet (median DICE&#160;=&#160;0.925 [IQR: 0.895&#8211;0.955], CCC&#160;=&#160;0.965; CoV&#160;=&#160;4.8%) was significantly higher (p&lt;0.001) than MedSAM (median DICE&#160;=&#160;0.185 [IQR: 0.089&#8211;0.281], CCC&#160;=&#160;0.089; CoV&#160;=&#160;76.8%) and nnU-Net (median DICE&#160;=&#160;0.795 [IQR: 0.731&#8211;0.859], CCC&#160;=&#160;0.825; CoV&#160;=&#160;18.5%). For scar segmentation, ScarNet (median DICE&#160;=&#160;0.892 [IQR: 0.856&#8211;0.928], CCC&#160;=&#160;0.946; CoV&#160;=&#160;5.9%) produced significantly higher performance (p&lt;0.001) than MedSAM (median DICE&#160;=&#160;0.048 [IQR: 0.000&#8211;0.124], CCC&#160;=&#160;0.012; CoV&#160;=&#160;233.3%) and nnU-Net (median DICE&#160;=&#160;0.615 [IQR: 0.253&#8211;0.977], CCC&#160;=&#160;0.698; CoV&#160;=&#160;28.7%). For scar volume quantification with noise perturbations, ScarNet maintained superior accuracy (CCC&#160;=&#160;0.988, percent bias: &#8722;1.2&#160;&#177;&#160;2.8%, CoV&#160;=&#160;6.1%) compared to MedSAM (CCC&lt;0.001, percent bias: &#8722;15.3&#160;&#177;&#160;18.7%, CoV&#160;=&#160;142.8%) and nnU-Net (CCC&#160;=&#160;0.892, percent bias: &#8722;3.2&#160;&#177;&#160;8.1%, CoV&#160;=&#160;24.5%) (all p&lt;0.001). Fig. 9 shows representative Monte Carlo simulation results with noise perturbations. 3.1 Ablation study results Ablation studies systematically validated each component's contribution to the hybrid architecture's performance. Removing the MedSAM pathway resulted in the largest performance decrease (median myocardium DICE&#160;=&#160;0.961 [IQR: 0.920&#8211;0.999], CCC&#160;=&#160;0.978 to median myocardium DICE&#160;=&#160;0.934 [IQR: 0.892&#8211;0.967], CCC&#160;=&#160;0.945; median scar DICE&#160;=&#160;0.912 [IQR: 0.863&#8211;0.944], CCC&#160;=&#160;0.963 to median scar DICE&#160;=&#160;0.847 [IQR: 0.801&#8211;0.891], CCC&#160;=&#160;0.891, &#916;&#160;=&#160;&#8722;0.065), followed by attention mechanisms (median myocardium DICE&#160;=&#160;0.945 [IQR: 0.901&#8211;0.978], CCC&#160;=&#160;0.961; median scar DICE&#160;=&#160;0.872 [IQR: 0.819&#8211;0.908], CCC&#160;=&#160;0.924, &#916;&#160;=&#160;&#8722;0.040) and frozen MedSAM weights (median myocardium DICE&#160;=&#160;0.948 [IQR: 0.905&#8211;0.981], CCC&#160;=&#160;0.967; median scar DICE&#160;=&#160;0.883 [IQR: 0.834&#8211;0.923], CCC&#160;=&#160;0.938, &#916;&#160;=&#160;&#8722;0.029) (all p&lt;0.001). Notably, scar volume quantification accuracy also deteriorated substantially without MedSAM (error increased from &#8722;0.63&#160;&#177;&#160;4.82%, CCC&#160;=&#160;0.995, p&lt;0.001 to &#8722;2.14&#160;&#177;&#160;8.91%, CCC&#160;=&#160;0.976, p&lt;0.001), with frozen weights showing intermediate degradation (&#8722;1.28&#160;&#177;&#160;6.45%, CCC&#160;=&#160;0.987, p&lt;0.001) and attention removal also showing decreased accuracy (&#8722;1.87&#160;&#177;&#160;7.23%, CCC&#160;=&#160;0.981, p&lt;0.001). 3.2 Regional performance analysis Regional performance analysis across 1895 slices from 184 patients demonstrated consistent ScarNet superiority across all cardiac regions. For basal regions (632 slices), ScarNet achieved median scar DICE&#160;=&#160;0.925 [IQR: 0.887&#8211;0.962], CCC&#160;=&#160;0.971 compared to nnU-Net (median scar DICE&#160;=&#160;0.651 [IQR: 0.612&#8211;0.688], CCC&#160;=&#160;0.748) and MedSAM (median scar DICE&#160;=&#160;0.048 [IQR: 0.044&#8211;0.051], CCC&#160;=&#160;0.021). In mid-ventricular regions (631 slices), ScarNet maintained high performance with median scar DICE&#160;=&#160;0.904 [IQR: 0.847&#8211;0.928], CCC&#160;=&#160;0.958 versus nnU-Net (median scar DICE&#160;=&#160;0.627 [IQR: 0.592&#8211;0.648], CCC&#160;=&#160;0.722) and MedSAM (median scar DICE&#160;=&#160;0.044 [IQR: 0.040&#8211;0.047], CCC&#160;=&#160;0.016). Apical regions (632 slices) showed similar patterns with ScarNet achieving median scar DICE&#160;=&#160;0.898 [IQR: 0.841&#8211;0.931], CCC&#160;=&#160;0.952 compared to nnU-Net (median scar DICE&#160;=&#160;0.625 [IQR: 0.588&#8211;0.654], CCC&#160;=&#160;0.715) and MedSAM (median scar DICE&#160;=&#160;0.044 [IQR: 0.041&#8211;0.046], CCC&#160;=&#160;0.015). Overall performance across all 1895 slices confirmed ScarNet's superiority (median scar DICE&#160;=&#160;0.912 [IQR: 0.863&#8211;0.944], CCC&#160;=&#160;0.963) over nnU-Net (median scar DICE&#160;=&#160;0.638 [IQR: 0.604&#8211;0.661], CCC&#160;=&#160;0.734) and MedSAM (median scar DICE&#160;=&#160;0.046 [IQR: 0.043&#8211;0.047], CCC&#160;=&#160;0.018) (all comparisons p&lt;0.001). 4 Discussion In this study, we developed ScarNet, a novel deep learning model that combines a complete MedSAM pathway with a parallel UNet pathway through an adaptive fusion mechanism for automated myocardial scar segmentation in LGE images. After training the model using 401 patients and validating on 100 patients, and evaluating on 184 test patients, ScarNet achieved superior segmentation accuracy for both myocardium (median DICE&#160;=&#160;0.961) and scar tissue (median DICE&#160;=&#160;0.912), significantly outperforming both MedSAM and nnU-Net. Using Monte Carlo simulations with 5% Gaussian noise perturbation, the model demonstrated exceptional robustness with minimal percent bias (&#8722;0.63%) and coefficient of variation (4.3%) in scar volume quantification, while maintaining consistently high DICE scores for both myocardium (0.912&#160;&#177;&#160;0.063; CoV&#160;=&#160;6.9%) and scar tissue (0.892&#160;&#177;&#160;0.053; CoV&#160;=&#160;5.9%). Ablation studies validated the critical contribution of each architectural component, particularly the MedSAM pathway integration. Our approach differs from previous deep learning methods by addressing several key limitations in automated scar segmentation. Traditional CNN-based approaches [8] , [9] , [10] , while effective for general medical segmentation, struggle with the inherent challenges of LGE imaging, achieving limited DICE scores of only 0.616 and 0.633 for supervised and unsupervised methods, respectively [12] . Earlier efforts by Zabihollahy et al. [22] and Bai et al. [23] demonstrated the potential of CNNs for scar segmentation, but faced challenges in capturing complex scar patterns. A significant advancement came from Fahmy et al. [10] , who introduced a deep learning-based image fusion approach that improved scar quantification accuracy by combining multiple image features. While their method showed promise in handling varying contrast patterns, it still faced challenges with complex scar morphologies and required careful parameter tuning. Subsequent developments by Xiong et al. [24] with dual fully convolutional networks and Zhuang et al. [25] with multi-scale patch-based approaches improved performance but still struggled with consistent accuracy. Recent work on unsupervised domain adaptation [26] demonstrated promising results in handling multi-center variability by adapting the network to different scanner characteristics without requiring additional annotations, though the method still showed limitations in capturing fine scar details. Similarly, comparative studies of dark- and bright-blood LGE imaging techniques [27] showed improved visualization of subendocardial scars across different myocardial pathologies, particularly in cases where traditional bright-blood LGE faced challenges in distinguishing scar tissue from adjacent blood pool. While these approaches advanced our understanding of scar imaging and quantification, they still relied heavily on manual intervention or faced challenges with consistent automated analysis. Recent transformer-based models like SAM [14] , [15] and MedSAM [16] , despite leveraging pretraining on a vast dataset of over 50,000 medical images and SAM's foundation of 1 billion masked image segments lack the domain-specific optimization necessary for accurate scar delineation [17] , [18] . ScarNet's hybrid architecture overcomes these limitations by combining the global context awareness of transformers with the precise localization capabilities of CNNs, enhanced by specialized attention mechanisms that specifically target scar features while preserving anatomical context. Several findings from our study have important implications for clinical practice. First, ScarNet's ability to achieve near-manual-level accuracy (CCC&#160;=&#160;0.995, percent bias&#160;=&#160;&#8722;0.63%, CoV&#160;=&#160;4.3%) in scar volume quantification suggests its potential for reliable automated analysis in clinical workflows. The incorporation of transformer architecture and specialized attention mechanisms proved particularly effective in identifying irregular scar patterns and heterogeneous enhancement, challenges that have traditionally limited automated approaches. The model's robust performance across varying training data sizes indicates its effectiveness even with limited datasets, a crucial advantage for clinical implementation. Furthermore, the stability demonstrated in noise perturbation experiments (5% Gaussian noise level, empirically determined as an upper limit in clinical practice) resulted in consistently high performance (scar DICE&#160;=&#160;0.892&#160;&#177;&#160;0.053, CoV&#160;=&#160;5.9%), suggesting reliable performance against clinically relevant noise. These findings confirm that: (1) MedSAM's global context modeling is essential despite poor standalone performance, (2) domain-specific fine-tuning of pretrained weights is crucial, and (3) specialized attention mechanisms provide meaningful improvements for scar detection. The overall accuracy was highest for ScarNet, followed by nnU-Net and MedSAM, where only ScarNet had sensitivity and specificity greater than 90%. Notably, ScarNet demonstrated the highest performance in basal regions, with slight but consistent decreases toward the apex, while maintaining substantial advantages over both comparison methods across all cardiac regions. 5 Limitations This study has several limitations that should be acknowledged. First, while our dataset included 685 patients with 7066 2D LGE images, it was derived from specific clinical trials (DETERMINE and PRE-DETERMINE), potentially limiting generalizability to broader patient populations. Second, our ground truth annotations were created using the full width at half maximum technique, which, although widely accepted, may not capture all patterns of enhancement. Third, as a foundation model, ScarNet requires a graphics processing unit (GPU) for optimal performance, which may impact deployment in some clinical settings. While recent advances in GPU computing [28] , [29] , [30] , [31] and memory management, such as improved collective message passing interface (MPI) libraries for Intel GPUs [32] , offer promising solutions for optimizing foundation model deployment, GPU requirements remain a consideration for clinical implementation. Fourth, our dataset includes images with varying spatial resolution parameters, with median pixel dimension of 1.74&#8201;mm&#8201;&#215;&#8201;1.91&#8201;mm. While most LGE scans align with the spatial resolution recommended (1.4&#8211;1.8&#8201;mm) by the SCMR protocol first published in 2013 [33] , some LGE scans were below the recommended resolution. This limitation of our retrospective study stems from the fact that the majority of CMR scans in DETERMINE studies were conducted between 2008 and 2015, prior to the 2013 SCMR protocol recommendation. Nevertheless, despite the slightly suboptimal spatial resolution, ScarNet achieved high accuracy in detecting myocardial scar volume. Fifth, while the model shows robust performance on varying scar patterns, its effectiveness on rare or atypical presentations requires further validation. Sixth, the current loss function parameters ( &#955; 1 , &#955; 2 , &#955; 3 ) were optimized for ischemic scar patterns and would likely require retuning for non-ischemic cardiomyopathies due to different enhancement characteristics and morphological patterns. Seventh, although we demonstrated stability under simulated noise (5% Gaussian) real-world testing on low-quality or artifact-laden images remains necessary. Eighth, the current validation focused on 2D slice-based analysis; extension to true 3D volume segmentation could potentially improve spatial consistency. Ninth, the two cardiologists involved in the image processing did not analyze the same datasets or perform an inter-rater variability analysis. As such, we are unable to evaluate the influence of label uncertainly due to inter-rater variability on our model performance. Future studies should validate ScarNet's performance against multiple expert annotations using various quantification techniques and explore its performance in non-ischemic cardiomyopathies, where scar patterns can be less well-defined and challenging to quantify. In conclusion, we present ScarNet, a novel foundation model specifically designed for automated left ventricular scar quantification in LGE, distinguishing itself from existing cardiac foundation models that focus on general cardiac structure analysis rather than specific scar assessment. While other foundation models have advanced cardiac imaging analysis broadly, ScarNet's focused approach to scar quantification fills a crucial gap in automated cardiac tissue analysis. Its successful implementation could facilitate routine quantitative assessment of myocardial scar, potentially improving risk stratification and treatment planning in patients with ischemic cardiomyopathy. Future work should focus on validation across different cardiac pathologies, integration with clinical decision support systems, and exploration of applications beyond cardiac imaging. Funding The National Institutes of Health ( R01HL116895, R01HL151079, R01HL167148, R01HL168859 ), the Radiological Society of North America ( EILTC2302 ), and the American Heart Association ( 949899 ). Author contributions Neda&#160;Tavakoli: &#160;Writing &#8211; review &amp; editing, writing &#8211; original draft, visualization, validation, software, project administration, methodology, formal analysis, data curation, conceptualizationa.&#160; Amir Ali&#160;Rahsepar: Writing &#8211; review &amp; editing, writing &#8211; original draft, visualization, validation, supervision, software, resources, methodology, data curation, conceptualization.&#160; Brandon C.&#160;Benefield: Writing &#8211; review &amp; editing, writing &#8211; original draft, validation, supervision, resources, methodology, data curation, conceptualization.&#160; Daming&#160;Shen: Writing &#8211; review &amp; editing, supervision, methodology, investigation, data curation, conceptualization.&#160; Santiago&#160;L&#243;pez-Tapia: Writing &#8211; review &amp; editing, validation, supervision, methodology, conceptualization. Florian Schiffers: Writing &#8211; review &amp; editing, validation, methodology, conceptualization.&#160; Jeffrey J.&#160;Goldberger: Writing &#8211; review &amp; editing, validation, supervision.&#160; Christine M.&#160;Albert: Writing &#8211; review &amp; editing, validation, supervision.&#160; Edwin&#160;Wu: Writing &#8211; review &amp; editing, validation, supervision.&#160; Aggelos K.&#160;Katsaggelos: Writing &#8211; review &amp; editing, validation, supervision, methodology, formal analysis, conceptualization. Daniel C.&#160;Lee: Writing &#8211; review &amp; editing, writing &#8211; original draft, visualization, validation, supervision, software, resources, project administration, methodology, investigation, data curation, conceptualization. Daniel&#160;Kim: Writing &#8211; review &amp; editing, writing &#8211; original draft, visualization, validation, supervision, software, resources, project administration, methodology, investigation, funding acquisition, formal analysis, data curation, conceptualization. Declaration of generative AI and AI-assisted technologies in the writing process During the preparation of this work, the author(s) used ChatGPT in order to check the grammar. After using this tool/service, the author(s) reviewed and edited the content as needed and take(s) full responsibility for the content of the publication. Declaration of competing interests The authors declare the following financial interests/personal relationships which may be considered as potential competing interests:&#160;Neda Tavakoli reports that financial support was provided by National Institutes of Health, Radiological Society of North America, American Heart Association. The other authors&#160;declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. References 1 Kim R.J. Chen E.L. Lima J.A. Judd R.M. Myocardial Gd-DTPA kinetics determine MRI contrast enhancement and reflect the extent and severity of myocardial injury after acute reperfused infarction Circulation 94 1996 3318 3326 8989146 10.1161/01.cir.94.12.3318 2 Kwong R.Y. Chan A.K. Brown K.A. Chan C.W. Reynolds H.G. Tsang S. Impact of unrecognized myocardial scar detected by cardiac magnetic resonance imaging on event-free survival in patients presenting with signs or symptoms of coronary artery disease Circulation 113 2006 2733 2743 16754804 10.1161/CIRCULATIONAHA.105.570648 3 Karim R. Bhagirath P. Claus P. Housden R.J. Chen Z. Karimaghaloo Z. Evaluation of state-of-the-art segmentation algorithms for left ventricle infarct from late Gadolinium enhancement MR images Med Image Anal 30 2016 95 107 26891066 10.1016/j.media.2016.01.004 4 Flett A.S. Hasleton J. Cook C. Hausenloy D. Quarta G. Ariti C. Evaluation of techniques for the quantification of myocardial scar of differing etiology using cardiac magnetic resonance JACC Cardiovasc Imaging 4 2011 150 156 21329899 10.1016/j.jcmg.2010.11.015 5 Rahsepar A.A. Ghasemiesfe A. Suwa K. Dolan R.S. Shehata M.L. Korell M.J. Comprehensive evaluation of macroscopic and microscopic myocardial fibrosis by cardiac MR: intra-individual comparison of gadobutrol versus gadoterate meglumine Eur Radiol 29 2019 4357 4367 30617490 10.1007/s00330-018-5956-3 6 Mehrnia M, Kholmovski E, Katsaggelos A, Kim D, Passman R, Elbaz MSM. Novel self-calibrated threshold-free probabilistic fibrosis signature technique for 3D late gadolinium enhancement MRI. (PP)IEEE. Trans Biomed Eng. 2024.(PP). 10.1109/TBME.2024.3476930 PMC11875924 39383069 7 Ferreira P.F. Gatehouse P.D. Mohiaddin R.H. Firmin D.N. Cardiovascular magnetic resonance artefacts J Cardiovasc Magn R 15 2013 41 10.1186/1532-429X-15-41 PMC3674921 23697969 8 Bernard O. Lalande A. Zotti C. Cervenansky F. Yang X. Heng P.-A. Deep learning techniques for automatic MRI cardiac multi-structures segmentation and diagnosis: is the problem solved? IEEE Trans Med Imaging 37 2018 2514 2525 29994302 10.1109/TMI.2018.2837502 9 Ronneberger O. Fischer P. Brox T. U-net: convolutional networks for biomedical image segmentation proceedings, part III 18 Medical image computing and computer-assisted intervention&#8211;MICCAI 2015: 18th international conference 2015 2015 Springer, Munich, Germany 234 241 proceedings, part III 18 10 Fahmy A.S. Rowin E.J. Chan R.H. Manning W.J. Maron M.S. Nezafat R. Improved quantification of myocardium scar in late gadolinium enhancement images: deep learning based image fusion approach J Magn Reson Imaging 54 2021 303 312 33599043 10.1002/jmri.27555 PMC8359184 11 Moccia S. Banali R. Martini C. Muscogiuri G. Pontone G. Pepi M. Development and testing of a deep learning-based strategy for scar segmentation on CMR-LGE images Magn Reson Mater Phys Biol Med 32 2019 187 195 10.1007/s10334-018-0718-4 30460430 12 Jathanna N. Podlasek A. Sokol A. Auer D. Chen X. Jamil-Copley S. Diagnostic utility of artificial intelligence for left ventricular scar identification using cardiac magnetic resonance imaging-a&#160;systematic review Cardiovasc Digit Health J 2 2021 S21 s29 35265922 10.1016/j.cvdhj.2021.11.005 PMC8890335 13 Chen C. Qin C. Qiu H. Tarroni G. Duan J. Bai W. Deep learning for cardiac image segmentation: a review Front Cardiovasc Med 7 2020 25 32195270 10.3389/fcvm.2020.00025 PMC7066212 14 Vaswani A. Attention is all you need. Advances in Neural Information Processing Systems. 2017. 15 Kirillov A, Mintun E, Ravi N, Mao H, Rolland C, Gustafson L,&#160;et al. Segment anything, in: Proceedings of IEEE/CVF International Conference on Computer Vision.&#160;2023, 4015&#8211;4026. 16 Ma J. He Y. Li F. Han L. You C. Wang B. Segment anything in medical images Nat Commun 15 2024 654 38253604 10.1038/s41467-024-44824-z PMC10803759 17 Mehrnia M, Elbayumi M, Elbaz MS. Assessing foundational medical'segment anything'(Med-SAM1, Med-SAM2) deep learning models for left atrial segmentation&#160;in 3D LGE MRI. arXiv Prepr arXiv2411: 05963, 2024. 18 Hatamizadeh A. Tang Y. Nath V. Yang D. Myronenko A. Landman B. Unetr: transformers for 3d medical image segmentation, in: Proceedings of IEEE/CVF Winter Conf Appl Comput Vis 2022 574 584 19 Hu J. Shen L. Sun G. Squeeze-and-excitation networks Proceedings of the IEEE conference on computer vision and pattern recognition 2018 7132 7141 20 Ross T.-Y. Doll&#225;r G. Focal loss for dense object detection Proc IEEE Conf Comput Vis Pattern Recognit 2017 2980 2988 21 Flett A.S. Hasleton J. Cook C. Hausenloy D. Quarta G. Ariti C. Evaluation of techniques for the quantification of myocardial scar of differing etiology using cardiac magnetic resonance JACC Cardiovasc Imaging 4 2011 150 156 21329899 10.1016/j.jcmg.2010.11.015 22 Zabihollahy F. White J.A. Ukwatta E. Convolutional neural network-based approach for segmentation of left ventricle myocardial scar from 3D late gadolinium enhancement MR images Med Phys 46 2019 1740 1751 30734937 10.1002/mp.13436 23 Bai W. Sinclair M. Tarroni G. Oktay O. Rajchl M. Vaillant G. Automated cardiovascular magnetic resonance image analysis with fully convolutional networks J Cardiovasc Magn R 20 2018 65 10.1186/s12968-018-0471-x PMC6138894 30217194 24 Xiong Z.H. Xia Q. Hu Z.Q. Huang N. Bian C. Zheng Y.F. A global benchmark of algorithms for segmenting the left atrium from late gadolinium-enhanced cardiac magnetic resonance imaging Med Image Anal 67 2021 101832 10.1016/j.media.2020.101832 33166776 25 Zhuang X.H. Shen J. Multi-scale patch and multi-modality atlases for whole heart segmentation of MRI Med Image Anal 31 2016 77 87 26999615 10.1016/j.media.2016.02.006 26 Crawley R. Amirrajab S. Lustermans D. Holtackers R.J. Plein S. Veta M. Automated cardiovascular MR myocardial scar quantification with unsupervised domain adaptation Eur Radio Exp 8 2024 93 10.1186/s41747-024-00497-3 PMC11324636 39143405 27 Jada L. Holtackers R.J. Martens B. Nies H. Van De Heyning C.M. Botnar R.M. Quantification of myocardial scar of different etiology using dark- and bright-blood late gadolinium enhancement cardiovascular magnetic resonance Sci Rep 14 2024 5395 38443457 10.1038/s41598-024-52058-8 PMC10914833 28 Kousha Des P. Conversational AI Enabled Services and Performance Analysis Tools&#160;for High-Performance Computing, in, The Ohio State University. 2024. 29 Kousha P. Zhou Q. Subramoni H. Panda D.K. Benchmarking modern databases for storing and profiling very large scale HPC communication data in: International Symposium on Benchmarking, Measuring and Optimization 2023 Springer, 104 119 30 Kousha P. Jain A. Kolli A. Lieber M. Han M. Contini N. SAI: AI-enabled speech assistant interface for science gateways in HPC in: International Conference on High Performance Computing 2023 Springer, 402 424 31 Kousha P. Sankarapandian Dayala Ganesh Ram K.R. Kedia M. Subramoni H. Jain A. Shafi A. INAM: cross-stack profiling and analysis of communication in MPI-based applications Pract Exp Adv Res Comput 2021 1 11 32 Chen C.-C. Kuncham G.K.R. Kousha P. Subramoni H. Panda D.K. Design and implementation of an IPC-based collective MPI library for intel GPUs Pract Exp Adv Res Comput 2024 Hum Power Comput 2024 1 9 33 Kramer C.M. Barkhausen J. Flamm S.D. Kim R.J. Nagel, P E. Society for cardiovascular magnetic resonance board of trustees task force on standardized, standardized cardiovascular magnetic resonance (CMR) protocols 2013 update J Cardiovasc Magn Reson 15 2013 91 10.1186/1532-429X-10-35 PMC2467420 18605997 34 Kwon D.H. Halley C.M. Carrigan T.P. Zysek V. Popovic Z.B. Setser R. Extent of left ventricular scar predicts outcomes in ischemic cardiomyopathy patients with significantly reduced systolic function: a delayed hyperenhancement cardiac magnetic resonance study JACC Cardiovasc Imaging 2 2009 34 44 19356530 10.1016/j.jcmg.2008.09.010 35 Klem I. Weinsaft J.W. Bahnson T.D. Hegland D. Kim H.W. Hayes B. Assessment of myocardial scarring improves risk stratification in patients evaluated for cardiac defibrillator implantation J Am Coll Cardiol 60 2012 408 420 22835669 10.1016/j.jacc.2012.02.070 PMC3424733 Appendix A Supplementary material Supplementary material . Availability of data and materials The ScarNet implementation and associated code in Python are available at: https://github.com/NedaTavakoli/ScarNet . For inquiries regarding LGE datasets, please contact the PRE-DETERMINE and DETERMINE study steering committee. Acknowledgements This work was partially supported by funding from the National Institutes of Health (R01HL116895, R01HL151079, R01HL167148, R01HL168859), Radiological Society of North America (EILTC2302), and American Heart Association (949899). Appendix A Supplementary data associated with this article can be found in the online version at doi:10.1016/j.jocmr.2025.101945 ."
}