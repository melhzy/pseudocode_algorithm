{
  "pmcid": "PMC12672381",
  "source": "PMC",
  "download_date": "2025-12-09T16:37:24.667670",
  "metadata": {
    "journal_title": "Findings of ACL. EMNLP. Conference on Empirical Methods in Natural Language Processing",
    "journal_nlm_ta": "Find ACL EMNLP",
    "journal": "Findings of ACL. EMNLP. Conference on Empirical Methods in Natural Language Processing",
    "pmcid": "PMC12672381",
    "pmid": "41346454",
    "doi": "10.18653/v1/2024.findings-emnlp.505",
    "title": "Variational Language Concepts for Interpreting Foundation Language Models",
    "authors": [
      "Wang Hengyi",
      "Tan Shiwei",
      "Hong Zhqing",
      "Zhang Desheng",
      "Wang Hao"
    ],
    "abstract": "Foundation Language Models (FLMs) such as BERT and its variants have achieved remarkable success in natural language processing. To date, the interpretability of FLMs has primarily relied on the attention weights in their self-attention layers. However, these attention weights only provide word-level interpretations, failing to capture higher-level structures, and are therefore lacking in readability and intuitiveness. To address this challenge, we first provide a formal definition of  conceptual interpretation  and then propose a variational Bayesian framework, dubbed VAriational Language Concept (VALC), to go beyond word-level interpretations and provide concept-level interpretations. Our theoretical analysis shows that our VALC finds the optimal language concepts to interpret FLM predictions. Empirical results on several real-world datasets show that our method can successfully provide conceptual interpretation for FLMs."
  },
  "xml": "<?xml version=\"1.0\"  ?><!DOCTYPE pmc-articleset PUBLIC \"-//NLM//DTD ARTICLE SET 2.0//EN\" \"https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd\"><pmc-articleset><article xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:ali=\"http://www.niso.org/schemas/ali/1.0/\" xml:lang=\"en\" article-type=\"research-article\" dtd-version=\"1.4\"><!--The publisher of this article does not allow downloading of the full text in XML form.--><front><journal-meta><journal-id journal-id-type=\"nlm-ta\">Find ACL EMNLP</journal-id><journal-id journal-id-type=\"pmc-domain-id\">319</journal-id><journal-id journal-id-type=\"pmc-domain\">nihpa</journal-id><journal-title-group><journal-title>Findings of ACL. EMNLP. Conference on Empirical Methods in Natural Language Processing</journal-title></journal-title-group><custom-meta-group><custom-meta><meta-name>pmc-is-collection-domain</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-collection-title</meta-name><meta-value>NIHPA Author Manuscripts</meta-value></custom-meta></custom-meta-group></journal-meta><article-meta><article-id pub-id-type=\"pmcid\">PMC12672381</article-id><article-id pub-id-type=\"pmcid-ver\">PMC12672381.1</article-id><article-id pub-id-type=\"pmcaid\">12672381</article-id><article-id pub-id-type=\"pmcaiid\">12672381</article-id><article-id pub-id-type=\"manuscript-id\">NIHMS2061524</article-id><article-id pub-id-type=\"pmid\">41346454</article-id><article-id pub-id-type=\"doi\">10.18653/v1/2024.findings-emnlp.505</article-id><article-id pub-id-type=\"manuscript-id-alternative\">NIHMS2061524</article-id><article-id pub-id-type=\"manuscript-id-alternative\">NIHPA2061524</article-id><article-version article-version-type=\"pmc-version\">1</article-version><article-categories><subj-group subj-group-type=\"heading\"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Variational Language Concepts for Interpreting Foundation Language Models</article-title></title-group><contrib-group><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Wang</surname><given-names initials=\"H\">Hengyi</given-names></name><xref rid=\"CR1\" ref-type=\"corresp\">*</xref></contrib><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Tan</surname><given-names initials=\"S\">Shiwei</given-names></name></contrib><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Hong</surname><given-names initials=\"Z\">Zhqing</given-names></name></contrib><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Zhang</surname><given-names initials=\"D\">Desheng</given-names></name></contrib><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Wang</surname><given-names initials=\"H\">Hao</given-names></name></contrib><aff id=\"A1\">Department of Computer Science, Rutgers University</aff></contrib-group><author-notes><corresp id=\"CR1\"><label>*</label>Correspondence to: Hengyi Wang &lt;<email>hengyi.wang@rutgers.edu</email>&gt;</corresp></author-notes><pub-date pub-type=\"ppub\"><month>11</month><year>2024</year></pub-date><volume>2024</volume><issue-id pub-id-type=\"pmc-issue-id\">501735</issue-id><fpage>8645</fpage><lpage>8671</lpage><pub-history><event event-type=\"nihms-submitted\"><date><day>24</day><month>11</month><year>2025</year></date></event><event event-type=\"pmc-release\"><date><day>04</day><month>12</month><year>2025</year></date></event><event event-type=\"pmc-live\"><date><day>04</day><month>12</month><year>2025</year></date></event><event event-type=\"pmc-last-change\"><date iso-8601-date=\"2025-12-06 05:25:13.350\"><day>06</day><month>12</month><year>2025</year></date></event></pub-history><self-uri xmlns:xlink=\"http://www.w3.org/1999/xlink\" content-type=\"pmc-pdf\" xlink:href=\"nihms-2061524.pdf\"/><abstract id=\"ABS1\"><p id=\"P1\">Foundation Language Models (FLMs) such as BERT and its variants have achieved remarkable success in natural language processing. To date, the interpretability of FLMs has primarily relied on the attention weights in their self-attention layers. However, these attention weights only provide word-level interpretations, failing to capture higher-level structures, and are therefore lacking in readability and intuitiveness. To address this challenge, we first provide a formal definition of <italic toggle=\"yes\">conceptual interpretation</italic> and then propose a variational Bayesian framework, dubbed VAriational Language Concept (VALC), to go beyond word-level interpretations and provide concept-level interpretations. Our theoretical analysis shows that our VALC finds the optimal language concepts to interpret FLM predictions. Empirical results on several real-world datasets show that our method can successfully provide conceptual interpretation for FLMs.</p></abstract><custom-meta-group><custom-meta><meta-name>pmc-status-qastatus</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>pmc-status-live</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-status-embargo</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-status-released</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-open-access</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-olf</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-manuscript</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-legally-suppressed</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-pdf</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-supplement</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-pdf-only</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-suppress-copyright</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-real-version</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-scanned-article</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-preprint</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-in-epmc</meta-name><meta-value>yes</meta-value></custom-meta></custom-meta-group></article-meta></front></article></pmc-articleset>",
  "text": "Find ACL EMNLP 319 nihpa Findings of ACL. EMNLP. Conference on Empirical Methods in Natural Language Processing pmc-is-collection-domain yes pmc-collection-title NIHPA Author Manuscripts PMC12672381 PMC12672381.1 12672381 12672381 NIHMS2061524 41346454 10.18653/v1/2024.findings-emnlp.505 NIHMS2061524 NIHPA2061524 1 Article Variational Language Concepts for Interpreting Foundation Language Models Wang Hengyi * Tan Shiwei Hong Zhqing Zhang Desheng Wang Hao Department of Computer Science, Rutgers University * Correspondence to: Hengyi Wang &lt; hengyi.wang@rutgers.edu &gt; 11 2024 2024 501735 8645 8671 24 11 2025 04 12 2025 04 12 2025 06 12 2025 Foundation Language Models (FLMs) such as BERT and its variants have achieved remarkable success in natural language processing. To date, the interpretability of FLMs has primarily relied on the attention weights in their self-attention layers. However, these attention weights only provide word-level interpretations, failing to capture higher-level structures, and are therefore lacking in readability and intuitiveness. To address this challenge, we first provide a formal definition of conceptual interpretation and then propose a variational Bayesian framework, dubbed VAriational Language Concept (VALC), to go beyond word-level interpretations and provide concept-level interpretations. Our theoretical analysis shows that our VALC finds the optimal language concepts to interpret FLM predictions. Empirical results on several real-world datasets show that our method can successfully provide conceptual interpretation for FLMs. pmc-status-qastatus 0 pmc-status-live yes pmc-status-embargo no pmc-status-released yes pmc-prop-open-access no pmc-prop-olf no pmc-prop-manuscript yes pmc-prop-legally-suppressed no pmc-prop-has-pdf yes pmc-prop-has-supplement yes pmc-prop-pdf-only no pmc-prop-suppress-copyright no pmc-prop-is-real-version no pmc-prop-is-scanned-article no pmc-prop-preprint no pmc-prop-in-epmc yes"
}