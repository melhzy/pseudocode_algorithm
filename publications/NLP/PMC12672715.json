{
  "pmcid": "PMC12672715",
  "source": "PMC",
  "download_date": "2025-12-09T16:37:24.261456",
  "metadata": {
    "journal_title": "NPJ Mental Health Research",
    "journal_nlm_ta": "Npj Ment Health Res",
    "journal_iso_abbrev": "Npj Ment Health Res",
    "journal": "NPJ Mental Health Research",
    "pmcid": "PMC12672715",
    "pmid": "41331078",
    "doi": "10.1038/s44184-025-00175-1",
    "title": "Identifying psychiatric manifestations in outpatients with depression and anxiety: a large language model-based approach",
    "year": "2025",
    "month": "12",
    "day": "2",
    "pub_date": {
      "year": "2025",
      "month": "12",
      "day": "2"
    },
    "authors": [
      "Xu Shihao",
      "Yan Yiming",
      "Ding Yanli",
      "Li Feng",
      "Zhang Shu",
      "Tang Haoyun",
      "Luo Chao",
      "Li Yan",
      "Liu Hao",
      "Mei Yu",
      "Gu Wenjie",
      "Qiu Hong",
      "Wang Yong",
      "Qiu Jianyin",
      "Yang Tao",
      "Wang Zike",
      "Zhang Qing",
      "Geng Haiyang",
      "Han Yunyun",
      "Shao Jun",
      "Opel Nils",
      "Bing Lidong",
      "Zhao Min",
      "Xu Yifeng",
      "Jiang Xun",
      "Chen Jianhua"
    ],
    "abstract": "Accurate psychiatric diagnosis and assessment are crucial for effective treatment. However, current diagnostic approaches heavily rely on subjective observations constrained by time and clinical resources. This study investigates the potential of using Large Language Models (LLMs) to identify the symptoms in psychiatrist-patient dialogues and use them as intermediate features to predict the diagnostic labels. We collected audio recordings of 1160 outpatients with depressive disorder and anxiety disorder. LLMs were trained and utilized to identify clinical symptoms, rate assessment scales, and an ensemble learning pipeline was designed to classify diagnostic results and symptoms with 10-fold cross-validation. The system achieved 86.9% accuracy for identifying the appearance of clinical annotations and 74.7% (77.2%) accuracy for identifying symptoms of anxiety (depression). In addition, analysis of LLM-generated features shows that depression cases exhibited prominent markers of anhedonia and decreased volition, whereas anxiety disorders were characterized by tension and an inability to relax.",
    "keywords": [
      "Predictive markers",
      "Anxiety",
      "Depression",
      "Human behaviour"
    ]
  },
  "xml": "<?xml version=\"1.0\"  ?><!DOCTYPE pmc-articleset PUBLIC \"-//NLM//DTD ARTICLE SET 2.0//EN\" \"https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd\"><pmc-articleset><article xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:ali=\"http://www.niso.org/schemas/ali/1.0/\" article-type=\"research-article\" xml:lang=\"en\" dtd-version=\"1.4\"><processing-meta base-tagset=\"archiving\" mathml-version=\"3.0\" table-model=\"xhtml\" tagset-family=\"jats\"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type=\"nlm-ta\">Npj Ment Health Res</journal-id><journal-id journal-id-type=\"iso-abbrev\">Npj Ment Health Res</journal-id><journal-id journal-id-type=\"pmc-domain-id\">4551</journal-id><journal-id journal-id-type=\"pmc-domain\">npjmhres</journal-id><journal-title-group><journal-title>NPJ Mental Health Research</journal-title></journal-title-group><issn pub-type=\"epub\">2731-4251</issn><publisher><publisher-name>Nature Publishing Group</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type=\"pmcid\">PMC12672715</article-id><article-id pub-id-type=\"pmcid-ver\">PMC12672715.1</article-id><article-id pub-id-type=\"pmcaid\">12672715</article-id><article-id pub-id-type=\"pmcaiid\">12672715</article-id><article-id pub-id-type=\"pmid\">41331078</article-id><article-id pub-id-type=\"doi\">10.1038/s44184-025-00175-1</article-id><article-id pub-id-type=\"publisher-id\">175</article-id><article-version article-version-type=\"pmc-version\">1</article-version><article-categories><subj-group subj-group-type=\"heading\"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Identifying psychiatric manifestations in outpatients with depression and anxiety: a large language model-based approach</article-title></title-group><contrib-group><contrib contrib-type=\"author\" equal-contrib=\"yes\"><name name-style=\"western\"><surname>Xu</surname><given-names initials=\"S\">Shihao</given-names></name><xref ref-type=\"aff\" rid=\"Aff1\">1</xref><xref ref-type=\"aff\" rid=\"Aff2\">2</xref><xref ref-type=\"aff\" rid=\"Aff3\">3</xref></contrib><contrib contrib-type=\"author\" equal-contrib=\"yes\"><name name-style=\"western\"><surname>Yan</surname><given-names initials=\"Y\">Yiming</given-names></name><xref ref-type=\"aff\" rid=\"Aff1\">1</xref><xref ref-type=\"aff\" rid=\"Aff4\">4</xref></contrib><contrib contrib-type=\"author\" equal-contrib=\"yes\"><name name-style=\"western\"><surname>Ding</surname><given-names initials=\"Y\">Yanli</given-names></name><xref ref-type=\"aff\" rid=\"Aff1\">1</xref><xref ref-type=\"aff\" rid=\"Aff4\">4</xref></contrib><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Li</surname><given-names initials=\"F\">Feng</given-names></name><xref ref-type=\"aff\" rid=\"Aff2\">2</xref></contrib><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Zhang</surname><given-names initials=\"S\">Shu</given-names></name><xref ref-type=\"aff\" rid=\"Aff2\">2</xref></contrib><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Tang</surname><given-names initials=\"H\">Haoyun</given-names></name><xref ref-type=\"aff\" rid=\"Aff1\">1</xref><xref ref-type=\"aff\" rid=\"Aff4\">4</xref></contrib><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Luo</surname><given-names initials=\"C\">Chao</given-names></name><xref ref-type=\"aff\" rid=\"Aff1\">1</xref><xref ref-type=\"aff\" rid=\"Aff4\">4</xref></contrib><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Li</surname><given-names initials=\"Y\">Yan</given-names></name><xref ref-type=\"aff\" rid=\"Aff1\">1</xref><xref ref-type=\"aff\" rid=\"Aff4\">4</xref></contrib><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Liu</surname><given-names initials=\"H\">Hao</given-names></name><xref ref-type=\"aff\" rid=\"Aff1\">1</xref></contrib><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Mei</surname><given-names initials=\"Y\">Yu</given-names></name><xref ref-type=\"aff\" rid=\"Aff1\">1</xref></contrib><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Gu</surname><given-names initials=\"W\">Wenjie</given-names></name><xref ref-type=\"aff\" rid=\"Aff1\">1</xref></contrib><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Qiu</surname><given-names initials=\"H\">Hong</given-names></name><xref ref-type=\"aff\" rid=\"Aff1\">1</xref></contrib><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Wang</surname><given-names initials=\"Y\">Yong</given-names></name><xref ref-type=\"aff\" rid=\"Aff1\">1</xref><xref ref-type=\"aff\" rid=\"Aff4\">4</xref></contrib><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Qiu</surname><given-names initials=\"J\">Jianyin</given-names></name><xref ref-type=\"aff\" rid=\"Aff1\">1</xref><xref ref-type=\"aff\" rid=\"Aff4\">4</xref></contrib><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Yang</surname><given-names initials=\"T\">Tao</given-names></name><xref ref-type=\"aff\" rid=\"Aff3\">3</xref></contrib><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Wang</surname><given-names initials=\"Z\">Zike</given-names></name><xref ref-type=\"aff\" rid=\"Aff2\">2</xref></contrib><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Zhang</surname><given-names initials=\"Q\">Qing</given-names></name><xref ref-type=\"aff\" rid=\"Aff1\">1</xref><xref ref-type=\"aff\" rid=\"Aff4\">4</xref><xref ref-type=\"aff\" rid=\"Aff5\">5</xref></contrib><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Geng</surname><given-names initials=\"H\">Haiyang</given-names></name><xref ref-type=\"aff\" rid=\"Aff3\">3</xref></contrib><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Han</surname><given-names initials=\"Y\">Yunyun</given-names></name><xref ref-type=\"aff\" rid=\"Aff3\">3</xref></contrib><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Shao</surname><given-names initials=\"J\">Jun</given-names></name><xref ref-type=\"aff\" rid=\"Aff2\">2</xref></contrib><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Opel</surname><given-names initials=\"N\">Nils</given-names></name><xref ref-type=\"aff\" rid=\"Aff6\">6</xref><xref ref-type=\"aff\" rid=\"Aff7\">7</xref></contrib><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Bing</surname><given-names initials=\"L\">Lidong</given-names></name><xref ref-type=\"aff\" rid=\"Aff3\">3</xref></contrib><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Zhao</surname><given-names initials=\"M\">Min</given-names></name><xref ref-type=\"aff\" rid=\"Aff1\">1</xref><xref ref-type=\"aff\" rid=\"Aff4\">4</xref><xref ref-type=\"aff\" rid=\"Aff5\">5</xref></contrib><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Xu</surname><given-names initials=\"Y\">Yifeng</given-names></name><xref ref-type=\"aff\" rid=\"Aff1\">1</xref><xref ref-type=\"aff\" rid=\"Aff4\">4</xref><xref ref-type=\"aff\" rid=\"Aff5\">5</xref></contrib><contrib contrib-type=\"author\" corresp=\"yes\"><name name-style=\"western\"><surname>Jiang</surname><given-names initials=\"X\">Xun</given-names></name><address><email>xun.jiang@thetahealth.ai</email></address><xref ref-type=\"aff\" rid=\"Aff2\">2</xref><xref ref-type=\"aff\" rid=\"Aff3\">3</xref></contrib><contrib contrib-type=\"author\" corresp=\"yes\"><name name-style=\"western\"><surname>Chen</surname><given-names initials=\"J\">Jianhua</given-names></name><address><email>jianhua.chen@smhc.org.cn</email></address><xref ref-type=\"aff\" rid=\"Aff1\">1</xref><xref ref-type=\"aff\" rid=\"Aff3\">3</xref><xref ref-type=\"aff\" rid=\"Aff4\">4</xref><xref ref-type=\"aff\" rid=\"Aff5\">5</xref></contrib><aff id=\"Aff1\"><label>1</label><institution-wrap><institution-id institution-id-type=\"ROR\">https://ror.org/0220qvk04</institution-id><institution-id institution-id-type=\"GRID\">grid.16821.3c</institution-id><institution-id institution-id-type=\"ISNI\">0000 0004 0368 8293</institution-id><institution>Shanghai Mental Health Center, </institution><institution>Shanghai Jiao Tong University School of Medicine, </institution></institution-wrap>Shanghai, China </aff><aff id=\"Aff2\"><label>2</label>Theta Health Inc., Redwood City, CA USA </aff><aff id=\"Aff3\"><label>3</label>Tianqiao and Chrissy Chen Institute, Shanghai, China </aff><aff id=\"Aff4\"><label>4</label><institution-wrap><institution-id institution-id-type=\"ROR\">https://ror.org/057tkkm33</institution-id><institution-id institution-id-type=\"GRID\">grid.452344.0</institution-id><institution>Shanghai Clinical Research Center for Mental Health, </institution></institution-wrap>Shanghai, China </aff><aff id=\"Aff5\"><label>5</label><institution-wrap><institution-id institution-id-type=\"ROR\">https://ror.org/05bd2wa15</institution-id><institution-id institution-id-type=\"GRID\">grid.415630.5</institution-id><institution-id institution-id-type=\"ISNI\">0000 0004 1782 6212</institution-id><institution>Shanghai Key Laboratory of Psychotic Disorder, </institution></institution-wrap>Shanghai, China </aff><aff id=\"Aff6\"><label>6</label><institution-wrap><institution-id institution-id-type=\"ROR\">https://ror.org/035rzkx15</institution-id><institution-id institution-id-type=\"GRID\">grid.275559.9</institution-id><institution-id institution-id-type=\"ISNI\">0000 0000 8517 6224</institution-id><institution>University Hospital Jena Department of Psychiatry and Psychotherapy, </institution></institution-wrap>Jena, Germany </aff><aff id=\"Aff7\"><label>7</label>German Centre for Mental Health (DZPG), Berlin, Germany </aff></contrib-group><pub-date pub-type=\"epub\"><day>2</day><month>12</month><year>2025</year></pub-date><pub-date pub-type=\"collection\"><year>2025</year></pub-date><volume>4</volume><issue-id pub-id-type=\"pmc-issue-id\">479056</issue-id><elocation-id>63</elocation-id><history><date date-type=\"received\"><day>24</day><month>1</month><year>2025</year></date><date date-type=\"accepted\"><day>10</day><month>11</month><year>2025</year></date></history><pub-history><event event-type=\"pmc-release\"><date><day>02</day><month>12</month><year>2025</year></date></event><event event-type=\"pmc-live\"><date><day>04</day><month>12</month><year>2025</year></date></event><event event-type=\"pmc-last-change\"><date iso-8601-date=\"2025-12-04 00:25:12.810\"><day>04</day><month>12</month><year>2025</year></date></event></pub-history><permissions><copyright-statement>&#169; The Author(s) 2025</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref specific-use=\"textmining\" content-type=\"ccbyncndlicense\">https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License, which permits any non-commercial use, sharing, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if you modified the licensed material. You do not have permission under this licence to share adapted material derived from this article or parts of it. The images or other third party material in this article are included in the article&#8217;s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article&#8217;s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://creativecommons.org/licenses/by-nc-nd/4.0/\">http://creativecommons.org/licenses/by-nc-nd/4.0/</ext-link>.</license-p></license></permissions><self-uri xmlns:xlink=\"http://www.w3.org/1999/xlink\" content-type=\"pmc-pdf\" xlink:href=\"44184_2025_Article_175.pdf\"/><abstract id=\"Abs1\"><p id=\"Par1\">Accurate psychiatric diagnosis and assessment are crucial for effective treatment. However, current diagnostic approaches heavily rely on subjective observations constrained by time and clinical resources. This study investigates the potential of using Large Language Models (LLMs) to identify the symptoms in psychiatrist-patient dialogues and use them as intermediate features to predict the diagnostic labels. We collected audio recordings of 1160 outpatients with depressive disorder and anxiety disorder. LLMs were trained and utilized to identify clinical symptoms, rate assessment scales, and an ensemble learning pipeline was designed to classify diagnostic results and symptoms with 10-fold cross-validation. The system achieved 86.9% accuracy for identifying the appearance of clinical annotations and 74.7% (77.2%) accuracy for identifying symptoms of anxiety (depression). In addition, analysis of LLM-generated features shows that depression cases exhibited prominent markers of anhedonia and decreased volition, whereas anxiety disorders were characterized by tension and an inability to relax.</p></abstract><kwd-group kwd-group-type=\"npg-subject\"><title>Subject terms</title><kwd>Predictive markers</kwd><kwd>Anxiety</kwd><kwd>Depression</kwd><kwd>Human behaviour</kwd></kwd-group><funding-group><award-group><funding-source><institution>Tianqiao and Chrissy Chen Institute</institution></funding-source><award-id>2023-TX-018</award-id><award-id>2023-TX-018</award-id><award-id>2023-TX-018</award-id><award-id>2023-TX-018</award-id><award-id>2023-TX-018</award-id><award-id>2023-TX-018</award-id></award-group></funding-group><funding-group><award-group><funding-source><institution>National Natural Science Foundation of China</institution></funding-source><award-id>82071500</award-id><award-id>82071500</award-id><award-id>82071500</award-id><award-id>82071500</award-id><award-id>82071500</award-id><award-id>82071500</award-id></award-group></funding-group><funding-group><award-group><funding-source><institution>Program of Shanghai Academic/Technology Research Leader</institution></funding-source><award-id>21XD1423300</award-id><award-id>21XD1423300</award-id><award-id>21XD1423300</award-id><award-id>21XD1423300</award-id><award-id>21XD1423300</award-id><award-id>21XD1423300</award-id></award-group></funding-group><custom-meta-group><custom-meta><meta-name>pmc-status-qastatus</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>pmc-status-live</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-status-embargo</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-status-released</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-open-access</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-olf</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-manuscript</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-legally-suppressed</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-pdf</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-supplement</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-pdf-only</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-suppress-copyright</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-real-version</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-scanned-article</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-preprint</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-in-epmc</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#169; Springer Nature Limited 2025</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id=\"Sec1\" sec-type=\"introduction\"><title>Introduction</title><p id=\"Par2\">Depression and anxiety disorders represent two of the most prevalent mental health conditions globally. Globally, it is estimated that over 300 million people suffer from major depressive disorders, which is equivalent to 4.4% of the world&#8217;s population. A similar number of people suffer from anxiety disorders, often with co-occurring depression<sup><xref ref-type=\"bibr\" rid=\"CR1\">1</xref></sup>. The emerging field of digital phenotyping, which involves the nuanced quantification of human phenotypic expression at the individual level through digital device data, offers a quantitative approach to longitudinal observation<sup><xref ref-type=\"bibr\" rid=\"CR2\">2</xref></sup>.</p><p id=\"Par3\">The emerging field of digital phenotyping, characterized by continuous and nuanced quantification of human phenotypic expression at the individual level by leveraging digital device data, provides a quantitative approach for longitudinal observation<sup><xref ref-type=\"bibr\" rid=\"CR2\">2</xref></sup>. Researchers have demonstrated that social signals (e.g., linguistics, speech, etc.) play a crucial role in the diagnosis and assessment of patients with depression and anxiety<sup><xref ref-type=\"bibr\" rid=\"CR3\">3</xref>,<xref ref-type=\"bibr\" rid=\"CR4\">4</xref></sup>. In particular, the content of a patient&#8217;s speech provides rich information about their mental state, cognitive patterns, and emotional experiences<sup><xref ref-type=\"bibr\" rid=\"CR5\">5</xref>,<xref ref-type=\"bibr\" rid=\"CR6\">6</xref></sup>. The linguistic features, topic choices, and narrative structures employed by individuals can offer valuable insights into their psychological well-being<sup><xref ref-type=\"bibr\" rid=\"CR6\">6</xref></sup>.</p><p id=\"Par4\">Recent advances in NLP, particularly in LLMs such as GPT<sup><xref ref-type=\"bibr\" rid=\"CR7\">7</xref></sup>, Gemini<sup><xref ref-type=\"bibr\" rid=\"CR8\">8</xref></sup>, and Qwen<sup><xref ref-type=\"bibr\" rid=\"CR9\">9</xref></sup>, demonstrate diverse capabilities in clinical reasoning, social media analysis, and psychiatric education<sup><xref ref-type=\"bibr\" rid=\"CR10\">10</xref></sup>, which could potentially provide objective, data-driven insights in psychiatry. Moreover, LLMs are able to process, generate, and respond to natural language inputs, which fit naturally into the NIMH&#8217;s Research Domain Criteria (RDoC) framework, which suggests new ways of classifying mental disorders based on dimensions of observable behaviors<sup><xref ref-type=\"bibr\" rid=\"CR11\">11</xref></sup>. In recent psychiatric studies, these LLMs excel at understanding and generating complex linguistic patterns with human-like performance, making them widely explored for social media content analysis<sup><xref ref-type=\"bibr\" rid=\"CR12\">12</xref>,<xref ref-type=\"bibr\" rid=\"CR13\">13</xref></sup>, treatment performance enhancement<sup><xref ref-type=\"bibr\" rid=\"CR14\">14</xref>&#8211;<xref ref-type=\"bibr\" rid=\"CR16\">16</xref></sup>, chat counselor<sup><xref ref-type=\"bibr\" rid=\"CR17\">17</xref>,<xref ref-type=\"bibr\" rid=\"CR18\">18</xref></sup>, and supporting clinical decision-making<sup><xref ref-type=\"bibr\" rid=\"CR19\">19</xref>,<xref ref-type=\"bibr\" rid=\"CR20\">20</xref></sup> from an evidence-based practice perspective. Although LLMs demonstrate linguistic understanding and generation, they remain relatively scarce in producing objective digital biomarkers in psychiatry<sup><xref ref-type=\"bibr\" rid=\"CR21\">21</xref></sup>. Studies have shown that the speech of patients with depression and anxiety contains distinctive quantitative verbal and nonverbal digital markers compared to healthy controls<sup><xref ref-type=\"bibr\" rid=\"CR4\">4</xref>,<xref ref-type=\"bibr\" rid=\"CR6\">6</xref></sup>, but these characteristics often remain too subtle for humans to perceive actionable insights, making their practical application and improvement challenging<sup><xref ref-type=\"bibr\" rid=\"CR22\">22</xref></sup>. LLM is able to generate diagnostic results and provide reasoning steps, benefiting from a large amount of pre-training data. However, the interpretation and alignment of answers or decisions generated by LLM remain challenging<sup><xref ref-type=\"bibr\" rid=\"CR23\">23</xref></sup>. Moreover, most studies on depression and anxiety rely primarily on two data sources: social media and structured clinical reports, and are often constrained by limited data availability<sup><xref ref-type=\"bibr\" rid=\"CR3\">3</xref></sup>. Distinguishing between depression and anxiety in clinical settings remains challenging due to the overlap of symptoms and the high comorbidity rate, with limited research on the discovery of objective biomarkers for both conditions<sup><xref ref-type=\"bibr\" rid=\"CR21\">21</xref></sup>. In addition, during clinical interviews, psychiatrists translate patients&#8217; informal symptom descriptions into professional diagnostic terminology; however, there remains a lack of approaches to automatically and effectively bridge this &#8220;semantic gap\" between patients and clinicians.</p><p id=\"Par5\">To address these gaps in existing research, we collected a comprehensive dataset of psychiatric interviews at the Shanghai Mental Health Center (SMHC) in China, comprising over 15,000&#8201;min of speech recordings from 1160 individual outpatients with 25 different diagnoses. These recordings, primarily featuring patients diagnosed with depression and anxiety disorders, were collected in unstructured real-world environments to ensure ecological validity. To mimic the characteristics of clinical diagnosis, we designed a corpus of clinical indicators that incorporates diagnostic criteria, main complaints, mental status evaluations, and components from assessment scales using the Electronic Medical Records (EMRs) in the SMHC and widely-used assessment scales. Subsequently, we employed the pre-trained LLM to indicate the appearance of a corpus of clinical-related symptoms, rate the components of several assessment scales, and further fine-tuned the LLM with clinical annotations from professional psychiatrists to enhance its understanding of clinical-related concepts. In parallel, we extracted linguistic usage patterns and acoustic features to broaden the spectrum of biomarkers. Through the fusion of these modalities, we constructed an ensemble machine-learning pipeline capable of predicting both outpatient diagnostic groups and symptoms with moderately high accuracies. Moreover, we conducted an in-depth analysis of salient patterns between different diagnostic groups to enhance clinical interpretability. Our results demonstrate that objective cues extracted by the LLM, combined with other behavioral markers, can serve as valuable features for differentiating diagnostic groups and identifying symptom disclosure, potentially enhancing both the efficiency and effectiveness of psychiatric diagnosis and assessment in clinical practice.</p></sec><sec id=\"Sec2\"><title>Methods</title><p id=\"Par6\">This study collected the audio recording of 1160 participants between August 2023 and January 2024, in collaboration with the SMHC. The overall pipeline is shown in Fig. <xref rid=\"Fig1\" ref-type=\"fig\">1</xref>. Data collection was conducted using the Scientific Speech Transcription Pen M1 (Iflytek Co., Ltd.) with a sampling rate of 44100&#8201;Hz. Firstly, the protocol involved three primary stages: preprocessing of audio samples, anonymization of personally identifiable information, and subsequent transcription via automated speech recognition systems followed by meticulous manual verification to ensure transcriptional accuracy. Secondly, we collaborated with professional psychiatrists to design a set of clinical entities and leveraged the LLM to identify these concepts using the transcripts as input, enhancing the LLM based on the psychiatrists&#8217; annotations through supervised fine-tuning (SFT). Linguistic and acoustic features were extracted from both the transcripts and the speech. Finally, we utilized different modalities to train an ensemble machine learning pipeline to differentiate diagnostic groups and the major symptoms.<fig id=\"Fig1\" position=\"float\" orientation=\"portrait\"><label>Fig. 1</label><caption><title>Diagram of the analysis pipeline.</title><p>The audio recordings were collected during the diagnosis interview for outpatients. We extracted four types of feature sets from the recordings, two of which utilized LLM. These feature sets were utilized to classify different groups of participants and predict the appearance of depression and anxiety symptoms.</p></caption><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"d33e490\" position=\"float\" orientation=\"portrait\" xlink:href=\"44184_2025_175_Fig1_HTML.jpg\"/></fig></p><sec id=\"Sec3\"><title>Participants</title><p id=\"Par7\">The study sample comprised outpatients from the SMHC who attended clinical diagnostic interviews. Participants were aged 12 to 80 years and were fluent in Mandarin. Informed consent to participate in the study was obtained from all participants or their legal guardians, as appropriate. All diagnoses were established using the Chinese version of WHO International Classification of Diseases, Tenth Revision (ICD-10)<sup><xref ref-type=\"bibr\" rid=\"CR24\">24</xref></sup>. The study protocol was approved by the Ethics Committee of the SMHC institutional review board (IRB) to ensure compliance with ethical research standards. Specifically, the recording setup consisted of a microphone placed between the psychiatrist and the participant, connected to a computer. At the beginning of each interview, participants were asked to read a standardized 30-second text passage, followed by the standard diagnostic procedure. All clinical information was documented in the EMR system by the psychiatrists. To protect the privacy of participants, all audio recordings and associated meta-information underwent a thorough manual de-identification process.</p></sec><sec id=\"Sec4\"><title>Feature extraction</title><p id=\"Par8\">We extracted a comprehensive clinical entity set to cover the intermediate features that assist psychiatrists in the diagnosis and assessment process: clinical observations and standardized assessment scales, which we designate as clinical-related and assessment-related feature sets. A clinical entity, in the context of our pipeline, is a structured representation of a psychiatric symptom or construct, developed from both clinical observations and standardized assessment scales. It encompasses key terms, expressions, and severity indicators related to specific diagnostic features, and serves as a unified unit for symptom detection and classification in our system. As compensation, we measured the linguistic usage and acoustic characteristics and form as individual feature sets. In the following paragraphs, we will introduce how we build and extract these feature sets in detail.</p><p id=\"Par9\">The clinical-related feature set encompasses essential depression and anxiety indicators extracted from EMRs with comprehensive descriptions (shown in Supplementary Table <xref rid=\"MOESM1\" ref-type=\"media\">1</xref>). This feature set was developed through a collaborative approach involving both psychiatrists and LLM analysis. Firstly, the process began with extracting 218 clinical entities from three sections in the EMR system: chief complaint, personal medical history, and psychiatric examination. These entities represent predefined features within the documentation framework of the SMHC EMR system based on psychiatric diagnostic systems, textbooks, and experts&#8217; opinions. Then, we included a supplementary of 44 additional symptoms identified through clinical expertise and diagnostic criteria (e.g., DSM-5 and ICD-10) suggested by psychiatrists. We then utilized the Gemini 1.5 Pro<sup><xref ref-type=\"bibr\" rid=\"CR8\">8</xref></sup> to generate descriptions for all clinical entities, using the Chinese version of the DSM-5 guidance<sup><xref ref-type=\"bibr\" rid=\"CR25\">25</xref></sup> as a reference, leveraging the model&#8217;s strong extended context window capability. Through iterative psychiatric review, redundant and irrelevant items specific to depression and anxiety were eliminated, resulting in a refined set of 138 validated clinical-related features.</p><p id=\"Par10\">After rigorously defining the clinical-related features, we leveraged large language models to extract symptom information from diagnostic conversations. We employed Qwen2-72B-Instruct<sup><xref ref-type=\"bibr\" rid=\"CR26\">26</xref></sup> as our foundational model due to its advanced Chinese language processing capabilities and suitability for offline deployment within secure hospital environments. To enhance domain-specific performance, we implemented SFT using psychiatrists&#8217; annotations from electronic medical records EMRs. This approach adapted the base model to better recognize specialized medical terminology and clinical reasoning patterns specific to psychiatric assessment contexts. The fine-tuning methodology treated symptom identification as an autoregressive task, where the model learns to predict token probabilities based on previous context, ultimately generating binary judgments (&#8220;yes&#8221; or &#8220;no&#8221;) regarding specific symptom presence. The training data comprised individual samples where dialogue content, patient demographics (age, gender), and symptom categories were incorporated into prompt templates alongside corresponding symptom occurrence labels extracted from EMRs. For each clinical conversation, we systematically extracted all documented symptoms to create comprehensive training instances. The fine-tuning implementation utilized LLaMA-Factory (<ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://github.com/hiyouga/LLaMA-Factory\">https://github.com/hiyouga/LLaMA-Factory</ext-link>), while inference processes were facilitated through vLLM (<ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://github.com/vllm-project/vllm\">https://github.com/vllm-project/vllm</ext-link>). All computational procedures were executed on a high-performance computing infrastructure consisting of four A100 GPUs. Table <xref rid=\"Tab1\" ref-type=\"table\">1</xref> presents the prompt architecture used both for clinical feature generation and model fine-tuning (Supplementary Table <xref rid=\"MOESM1\" ref-type=\"media\">4</xref> for the Chinese version), demonstrating our structured approach to symptom extraction within extended clinical dialogues.<table-wrap id=\"Tab1\" position=\"float\" orientation=\"portrait\"><label>Table 1</label><caption><p>Prompt template for clinical-related feature generation</p></caption><table frame=\"hsides\" rules=\"groups\"><tbody><tr><td colspan=\"1\" rowspan=\"1\"><inline-graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"d33e550\" xlink:href=\"44184_2025_175_Tab1_HTML.gif\"/></td><td colspan=\"1\" rowspan=\"1\"/></tr></tbody></table><table-wrap-foot><p>The content within the curly braces is the demographic, symptom descriptions, and dialogue information that form the prompt.</p></table-wrap-foot></table-wrap></p><p id=\"Par11\">We first began with structuring EMR data to create reliable training labels for the SFT. Since EMRs contain unstructured text fields where psychiatrists document patient information, we employed the LLM to analyze these 1160 EMRs. For each EMR, we leveraged LLM to evaluate the presence of above mentioned 138 predefined clinical features, including similar expressions and synonyms, generating a boolean value list (yes/no) for each record. The prompt for querying the LLM to generate labels from EMRs is shown in Supplementary Table <xref rid=\"MOESM1\" ref-type=\"media\">3</xref> (Supplementary Table <xref rid=\"MOESM1\" ref-type=\"media\">6</xref> for the Chinese version).</p><p id=\"Par12\">Secondly, we implemented a rigorous filtering process for choosing high-quality data for SFT. We first leverage LLM to verify whether the information recorded in EMRs was adequately reflected in the interview dialogue transcripts, yielding 877 valid examples. Then, we collaborated with specialist psychiatrists to establish comprehensive evaluation criteria, encompassing five standards for psychiatric examination, one for chief complaints, and five for present illness history assessment. By using these criteria as the prompt (shown in Supplementary Table <xref rid=\"MOESM1\" ref-type=\"media\">3</xref>), we employed the LLM to evaluate each case and select the top 60% (527 examples) as high-quality cases based on the total score. From these high-quality cases, we allocated 477 cases for the SFT and 50 cases for the high-quality test set. The 50 high-quality test cases and 633 lower-quality cases are combined as a completed test set to evaluate the accuracy of clinical-related feature extraction.</p><p id=\"Par13\">Subsequently, we fine-tuned the Qwen2-72B-Instruct model with Low-Rank Adaptation (LoRA)<sup><xref ref-type=\"bibr\" rid=\"CR27\">27</xref></sup>. The LLM SFT involves training a pre-trained model on datasets with explicit input-output pairs to optimize the model&#8217;s performance on specific downstream tasks. LoRA is a parameter-efficient fine-tuning technique that adds small, trainable rank decomposition matrices to the LLM&#8217;s existing weights, allowing for efficient model adaptation while keeping most of the original model parameters frozen. The model was trained using the following hyperparameters: LoRA rank of 8, LoRA alpha of 16, batch size of 8, and an initial learning rate of 1e-4 for 7000 steps. During inference using the vLLM framework, we restricted the model&#8217;s output to a single token &#8220;Yes\" or &#8220;No\" as the binary output, while we also extracted the probability output for these two tokens from the whole vocabulary. After normalization of the probabilities, along with the binary outputs, we formed 276 features in the clinical-related feature set.</p><p id=\"Par14\">The assessment-related feature set incorporates data from six validated psychiatric rating scales, combining self-rating and peer-rating instruments. Self-rating scales include SCL-90<sup><xref ref-type=\"bibr\" rid=\"CR28\">28</xref></sup>, SDS<sup><xref ref-type=\"bibr\" rid=\"CR29\">29</xref></sup>, and SAS<sup><xref ref-type=\"bibr\" rid=\"CR30\">30</xref></sup>, while peer-rating scales comprise HAMD<sup><xref ref-type=\"bibr\" rid=\"CR31\">31</xref></sup>, HAMA<sup><xref ref-type=\"bibr\" rid=\"CR32\">32</xref></sup>, and MADRS<sup><xref ref-type=\"bibr\" rid=\"CR33\">33</xref></sup>, totaling 177 items in all. These scales were selected for their proven reliability in clinical practice and research, offering comprehensive symptom coverage.</p><p id=\"Par15\">We designed two meta-prompts to enable the LLM to mimic both psychiatrists and patients in rating assessment scales in a zero-shot manner, as illustrated in Supplementary Table <xref rid=\"MOESM1\" ref-type=\"media\">2</xref> and (Supplementary Table <xref rid=\"MOESM1\" ref-type=\"media\">5</xref> for the Chinese version). The scales&#8217; content and rating guidelines were integrated into the prompts for LLM to generate the features. For instance, when extracting features related to the first item of the HAMD, which measures depressed mood, we use the peer-rating meta-prompt to instruct the LLM to evaluate the severity of the patient&#8217;s depressed mood on a 0&#8211;4 scale based on age, gender, and conversation content, where 0 indicates the absence of depression and 4 represents severe depression. When the conversation lacks sufficient information about the depressed mood, the LLM is prompted to return &#8220;NULL\". Similar to the clinical-related feature extraction, we extracted and normalized the logits of related tokens from the last layer of LLM and served as the features for classification and prediction tasks, resulting in a total of 1199 features. We did not SFT the LLM for assessment-related feature extraction, since we do not have sufficient assessment scale labels.</p><p id=\"Par16\">In addition to the features generated by LLM, we extracted verbal features through two bag-of-words approaches: LIWC<sup><xref ref-type=\"bibr\" rid=\"CR34\">34</xref></sup> and TF-IDF<sup><xref ref-type=\"bibr\" rid=\"CR35\">35</xref></sup>, both of which measure the frequency of word occurrence within a document. The LIWC tool is specifically designed to provide rich insights into psychological states, including emotions, thinking styles, and social concerns. Notably, since our transcripts are in Mandarin, we used the Simplified Chinese version of LIWC<sup><xref ref-type=\"bibr\" rid=\"CR36\">36</xref></sup>. It comprises word counts for 63 categories, including 52 categories related to linguistic counts (e.g., function words, common verbs, numbers, etc.), psychological processes (e.g., affect, sociality, cognition, perception, drive, etc.), and personal concern (e.g., work, home, religion, etc.), as well as 7 emotional categories (e.g., happy, sad, fear, etc.) and 4 general text metrics (e.g., the number of unique words, words in LIWC dictionary, etc.). We normalized the LIWC category counts by the total number of words.</p><p id=\"Par17\">The TF-IDF algorithm, which stands for Term Frequency-Inverse Document Frequency, is a popular technique used in text analysis to determine the importance of words within a document or collection of documents. Unlike simple word counting, TF-IDF considers both how often a word appears in a specific document and how common or rare that word is across all documents. This approach helps identify words that are particularly characteristic or important to specific documents. In this study, TF-IDF was applied alongside LIWC to provide a more comprehensive analysis of the verbal features in the documents, offering insights into both the frequency and relevance of words used by the subjects. We applied Jieba (<ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://github.com/fxsjy/jieba\">https://github.com/fxsjy/jieba</ext-link>) for Chinese character segmentation, resulting in a total of 27,000 features.</p><p id=\"Par18\">In addition to examining the verbal aspects of participants&#8217; speech, we preprocessed the audio and extracted low-level acoustic and prosodic features using the OpenSMILE toolkits<sup><xref ref-type=\"bibr\" rid=\"CR37\">37</xref></sup>. The audio recordings were manually edited to obscure names, addresses, and personally identifiable information before analysis. To reduce the impact of environmental noise and the varying distance from the microphone to the participant on recording quality, we used the pyAudacity toolkit (<ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://github.com/asweigart/pyaudacity\">https://github.com/asweigart/pyaudacity</ext-link>) and the FFmpeg-normalized toolkit (<ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://github.com/slhck/ffmpeg-normalize\">https://github.com/slhck/ffmpeg-normalize</ext-link>) to reduce the noise with a parameter of 12&#8201;dB and normalize the volume to &#8722;23&#8201;dB respectively. OpenSMILE is a versatile, customizable suite of acoustic features for signal processing and machine learning applications. We utilized OpenSMILE&#8217;s emobase_live4 configuration to extract the following LLDs (Low-Level Descriptors): intensity, loudness, 12 MFCCs, pitch (F0), voicing probability (VoiceProb), F0 envelope (F0env), 8 line spectral frequencies (LSF), and Zero-Crossing Rate (ZCR). Next, we applied various functions to these LLDs and their delta coefficients, including minimum and maximum values with their relative positions (minPos and maxPos), range, mean, linear regression coefficients (linregc1-2), linear and quadratic error, standard deviation (STD), skewness, kurtosis, quartile values (quartile1-3), and interquartile ranges (iqr1-2, iqr2-3, iqr1-3). This process yielded 988 features to represent each speech utterance. Before LLD computation, pauses and silences were eliminated from the speech to create a continuous signal. We then extracted 988 emotion-based prosodic features using a 100 ms sliding window over the entire speech sample. Lastly, we calculated these emotion-based features&#8217; maximum, minimum, mean, and standard deviation to compose the final set of OpenSMILE features, totaling 3952 features.</p></sec><sec id=\"Sec5\"><title>Classification method</title><p id=\"Par19\">As explained in previous sections, we extracted five feature sets using LLM and existing toolkits: clinical-related, assessment-related, LIWC, TF-IDF, and OpenSMILE features. Subsequently, we built a machine learning pipeline to fuse the outputs from multiple feature sets to predict the appearance of the symptom and classify diagnostic groups, which was implemented using Scikit-learn 1.2.0 in Python 3.10. Notably, as detailed in explaining the clinical feature extraction, we fine-tuned the LLM using 138 high-quality clinical annotations to improve its ability to identify clinical concepts. We excluded diagnostic labels from this process to prevent data leakage.</p><p id=\"Par20\">To ensure robust validation, we employed 10-fold cross-validation (10-fold CV). This method involves dividing the data into 10 subsets, iteratively training the model on 9 subsets, and testing it on the remaining subset. The process is repeated 10 times, with each subset serving as the test set once, and the model&#8217;s performance is averaged across all iterations. We implemented the random forest classifier for all feature sets as it constantly achieved better performance than other types of classifiers. To address the challenge of class imbalance, we applied the Synthetic Minority Oversampling Technique (SMOTE)<sup><xref ref-type=\"bibr\" rid=\"CR38\">38</xref></sup>, which generates synthetic data for minority classes. Furthermore, we performed z-score standardization on all features, resulting in standardized features with a mean of 0 and a standard deviation of 1. This step ensures that all features are on a comparable scale, preventing any single feature from dominating the analysis due to its magnitude.</p><p id=\"Par21\">We also implemented probability calibration to standardize predictions from each feature set. This process involved an internal CV on the training set of the outer CV to obtain the probability distribution on training data, which were then used to calibrate test set predictions<sup><xref ref-type=\"bibr\" rid=\"CR6\">6</xref></sup>. Moreover, based on the feature importance ranked by the classifier on training data, we filtered out features whose importance values fell below the mean to reduce unimportant features. For the final prediction, we employed a late fusion technique, a multi-modal machine learning approach that involved averaging the standardized prediction outputs from all feature sets to produce the final output. This method allows for the integration of diverse information sources while maintaining the integrity of each feature set&#8217;s contribution to the final prediction.</p></sec><sec id=\"Sec6\"><title>Performance metrics</title><p id=\"Par22\">To evaluate the performance of the LLM in extracting clinical features from interview dialogues, we employed standard information extraction metrics: precision and recall. Precision measures the proportion of correctly identified symptoms among all symptoms extracted by the LLM, while recall measures the proportion of symptoms correctly extracted from the EMR annotations. Given that psychiatrists may not document every symptom mentioned during interviews in the EMRs, recall serves as a particularly valuable metric in our evaluation framework. Precision and recall are calculated as follows: Precision&#8201;=&#8201;TP/(TP&#8201;+&#8201;FP); Recall&#8201;=&#8201;TP/(TP&#8201;+&#8201;FN), where TP (True Positives) represents symptoms correctly identified by both the LLM, FP (False Positives) represents symptoms incorrectly extracted by the LLM, and FN (False Negatives) represents symptoms present in the EMR but missed by the LLM.</p><p id=\"Par23\">For classification and prediction tasks, we utilize a comprehensive set of standard metrics. Our analysis primarily focuses on balanced accuracy (BAC), which is particularly effective for imbalanced datasets by averaging sensitivity (SEN) and specificity (SPE). This metric provides a robust measure of overall performance, accounting for both true positive and true negative rates. In addition to BAC, we also employed AUPRC and weighted F1 score offering valuable insights into model performance across various classification thresholds, which are well-suited for machine learning tasks involving imbalanced data.</p><p id=\"Par24\">Understanding the key distinguishing features among various mental health conditions is crucial for improving diagnostic accuracy, developing targeted interventions, and enhancing our overall comprehension of these disorders. To address this critical need, we employed a comprehensive approach to identify the most important features distinguishing between different mental health conditions. We utilized various feature sets, including LLM-generated clinical and assessment-related features, LIWC categories, and TF-IDF terms, and applied the Mann-Whitney U test with FDR correction across all feature sets to calculate p-values and measure feature importance. Features are ranked by their p-values, with those below 0.05 indicating a statistically significant difference between the two groups.</p></sec><sec id=\"Sec7\"><title>Baseline experiment setup</title><p id=\"Par25\">Excepted the LIWC and TF-IDF, we incorporated both traditional transformer-based language models and LLM-based methods as the baselines for mental health dialogue classification. We established a comprehensive methodological framework encompassing three distinct classification paradigms: pre-trained language models, zero-shot LLM classification, SFT LLM classification, and our proposed pipeline.</p><p id=\"Par26\">We implemented two established pre-trained language models as baseline classifiers: BERT (Bidirectional Encoder Representations from Transformers)<sup><xref ref-type=\"bibr\" rid=\"CR39\">39</xref></sup> and RoBERTa (Robustly Optimized BERT Pretraining)<sup><xref ref-type=\"bibr\" rid=\"CR40\">40</xref></sup>. We utilized the &#8220;bert-base-chinese\" model<sup><xref ref-type=\"bibr\" rid=\"CR39\">39</xref></sup>, which consists of 12 transformer layers with 768 hidden dimensions and 12 attention heads, totaling approximately 110 million parameters. BERT&#8217;s bidirectional contextual representations enable effective capture of semantic nuances within clinical dialogues. For RoBERTa, we employed the &#8220;chinese-roberta-wwm-ext-large\" variant<sup><xref ref-type=\"bibr\" rid=\"CR41\">41</xref></sup>, featuring 24 transformer layers, 1024 hidden dimensions, and 16 attention heads (approximately 325 million parameters). This model incorporates the whole word masking technique specifically optimized for Chinese language understanding. RoBERTa&#8217;s enhanced training methodology and larger parameter space potentially offer improved representation capabilities for complex clinical narratives. Both BERT and RoBERTa were fine-tuned on the ANX vs. DP classification task using addition random initialed linear layer with softmax.</p><p id=\"Par27\">For the LLM-based baseline method, we implemented both zero-shot and SFT manner. (1) Zero-shot Classification: We implemented direct classification using Qwen2.5-72B-Instruct through carefully designed prompts (as shown in Supplementary Table <xref rid=\"MOESM1\" ref-type=\"media\">7</xref>) that incorporated dialogue content and diagnostic ground truth. The model was constrained to output binary classifications (depression/anxiety), with token probabilities extracted to calculate performance metrics. (2) SFT: We augmented the zero-shot approach through parameter-efficient fine-tuning using LoRA.</p><p id=\"Par28\">All methodologies underwent rigorous evaluation using consistent data partitioning and performance metrics. We implemented stratified sampling to allocate 60% of samples for training, 20% for validation, and 20% for testing across both depression and anxiety classes. Hyperparameter optimization was conducted using the validation set, while final performance evaluation utilized the held-out test set exclusively. Specifically, models exhibiting the lowest validation loss during the training process were preserved and subsequently employed for final performance evaluation on the held-out test set. This ensured methodological consistency and facilitated direct comparative analysis of classification paradigms.</p></sec></sec><sec id=\"Sec8\" sec-type=\"results\"><title>Results</title><sec id=\"Sec9\"><title>Sample</title><p id=\"Par29\">The study included 1160 individuals, yielding about 15,000 minutes of speech data. All participants received diagnoses based on the ICD-10<sup><xref ref-type=\"bibr\" rid=\"CR24\">24</xref></sup>. The sample comprised 553 participants diagnosed with &#8220;Depressive Episode\" or &#8220;Depressive Disorder\" (DP), 426 diagnosed with &#8220;Anxiety Disorder\" or &#8220;Anxiety State\" (ANX), and 181 classified as &#8220;Others\" (patients not diagnosed with DP or ANX). Table <xref rid=\"Tab2\" ref-type=\"table\">2</xref> presents the demographic characteristics of the participants. Moreover, based on the clinical annotations of symptom episodes in the EMRs, we categorized the participants into four groups: patients who experienced/presented anxiety symptoms (A), participants who experienced/presented depressive symptoms (D), participants who experienced/presented mixed depressive and anxiety symptoms (M), and participants without experienced/presented depressive and anxiety symptoms (N).<table-wrap id=\"Tab2\" position=\"float\" orientation=\"portrait\"><label>Table 2</label><caption><p>Demographics of all participants</p></caption><table frame=\"hsides\" rules=\"groups\"><thead><tr><th colspan=\"1\" rowspan=\"1\"/><th colspan=\"1\" rowspan=\"1\">DP (N = 553)</th><th colspan=\"1\" rowspan=\"1\">ANX (N = 426)</th><th colspan=\"1\" rowspan=\"1\">Others (N = 181)</th></tr></thead><tbody><tr><td colspan=\"1\" rowspan=\"1\">Age</td><td colspan=\"1\" rowspan=\"1\">29.2&#8201;&#177;&#8201;10.0</td><td colspan=\"1\" rowspan=\"1\">34.0&#8201;&#177;&#8201;12.0</td><td colspan=\"1\" rowspan=\"1\">27.5&#8201;&#177;&#8201;11.1</td></tr><tr><td colspan=\"1\" rowspan=\"1\">Gender</td><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/></tr><tr><td colspan=\"1\" rowspan=\"1\">&#8195;Female</td><td colspan=\"1\" rowspan=\"1\">377 (68.2%)</td><td colspan=\"1\" rowspan=\"1\">288 (67.6%)</td><td colspan=\"1\" rowspan=\"1\">104 (57.5%)</td></tr><tr><td colspan=\"1\" rowspan=\"1\">&#8195;Male</td><td colspan=\"1\" rowspan=\"1\">176 (31.8%)</td><td colspan=\"1\" rowspan=\"1\">138 (32.4%)</td><td colspan=\"1\" rowspan=\"1\">77 (42.5%)</td></tr><tr><td colspan=\"1\" rowspan=\"1\">Occupation</td><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/></tr><tr><td colspan=\"1\" rowspan=\"1\">&#8195;Employed</td><td colspan=\"1\" rowspan=\"1\">266 (48.1%)</td><td colspan=\"1\" rowspan=\"1\">250 (58.7%)</td><td colspan=\"1\" rowspan=\"1\">74 (40.9%)</td></tr><tr><td colspan=\"1\" rowspan=\"1\">&#8195;Student</td><td colspan=\"1\" rowspan=\"1\">201 (36.3%)</td><td colspan=\"1\" rowspan=\"1\">98 (23.0%)</td><td colspan=\"1\" rowspan=\"1\">81 (44.8%)</td></tr><tr><td colspan=\"1\" rowspan=\"1\">&#8195;Unemployed</td><td colspan=\"1\" rowspan=\"1\">46 (8.3%)</td><td colspan=\"1\" rowspan=\"1\">44 (10.3%)</td><td colspan=\"1\" rowspan=\"1\">14 (7.7%)</td></tr><tr><td colspan=\"1\" rowspan=\"1\">&#8195;Unknown</td><td colspan=\"1\" rowspan=\"1\">23 (4.2%)</td><td colspan=\"1\" rowspan=\"1\">15 (3.5%)</td><td colspan=\"1\" rowspan=\"1\">7 (3.9%)</td></tr><tr><td colspan=\"1\" rowspan=\"1\">&#8195;Retired</td><td colspan=\"1\" rowspan=\"1\">9 (1.6%)</td><td colspan=\"1\" rowspan=\"1\">19 (4.5%)</td><td colspan=\"1\" rowspan=\"1\">4 (2.2%)</td></tr><tr><td colspan=\"1\" rowspan=\"1\">&#8195;Dropped out</td><td colspan=\"1\" rowspan=\"1\">8 (1.4%)</td><td colspan=\"1\" rowspan=\"1\">NaN</td><td colspan=\"1\" rowspan=\"1\">1 (0.6%)</td></tr><tr><td colspan=\"1\" rowspan=\"1\">Personality</td><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/></tr><tr><td colspan=\"1\" rowspan=\"1\">&#8195;Introvert</td><td colspan=\"1\" rowspan=\"1\">274 (49.5%)</td><td colspan=\"1\" rowspan=\"1\">198 (46.5%)</td><td colspan=\"1\" rowspan=\"1\">106 (58.6%)</td></tr><tr><td colspan=\"1\" rowspan=\"1\">&#8195;Extrovert</td><td colspan=\"1\" rowspan=\"1\">148 (26.8%)</td><td colspan=\"1\" rowspan=\"1\">114 (26.8%)</td><td colspan=\"1\" rowspan=\"1\">34 (18.8%)</td></tr><tr><td colspan=\"1\" rowspan=\"1\">&#8195;Gentle</td><td colspan=\"1\" rowspan=\"1\">46 (8.3%)</td><td colspan=\"1\" rowspan=\"1\">38 (8.9%)</td><td colspan=\"1\" rowspan=\"1\">13 (7.2%)</td></tr><tr><td colspan=\"1\" rowspan=\"1\">&#8195;Sensitive</td><td colspan=\"1\" rowspan=\"1\">29 (5.2%)</td><td colspan=\"1\" rowspan=\"1\">22 (5.2%)</td><td colspan=\"1\" rowspan=\"1\">4 (2.2%)</td></tr><tr><td colspan=\"1\" rowspan=\"1\">&#8195;Strong welling</td><td colspan=\"1\" rowspan=\"1\">12 (2.2%)</td><td colspan=\"1\" rowspan=\"1\">14 (3.3%)</td><td colspan=\"1\" rowspan=\"1\">8 (4.4%)</td></tr><tr><td colspan=\"1\" rowspan=\"1\">&#8195;Others</td><td colspan=\"1\" rowspan=\"1\">44 (8.0%)</td><td colspan=\"1\" rowspan=\"1\">40 (9.4%)</td><td colspan=\"1\" rowspan=\"1\">16 (8.8%)</td></tr></tbody></table></table-wrap></p></sec><sec id=\"Sec10\"><title>LLM-generated clinical-related features evaluation</title><p id=\"Par30\">We evaluated the performance of LLM-generated clinical symptoms on the entire test samples and those with high-quality EMR, as shown in Table <xref rid=\"Tab3\" ref-type=\"table\">3</xref>. Our evaluation of LLM-based clinical symptom extraction demonstrated a significant performance improvement after the SFT, with the accuracy increased from 81.2 to 86.9% on the test set and 83.7 to 89.1% on the high-quality test set (<italic toggle=\"yes\">p</italic>&#8201;&lt;&#8201;0.01 in McNemar&#8217;s test). The recall metric showed substantial improvements, increasing from 66.1 to 81.1% on the whole test set and from 74.0 to 86.1% on the high-quality test set, indicating enhanced capability in identifying symptoms documented by psychiatrists in the EMR. Meanwhile, precision improved from 81.2 to 87.4% on the test set and from 84.2 to 89.5% on the high-quality test set. This precision increase, coupled with recall improvement, suggests that the fine-tuned model became more comprehensive in detecting symptoms from clinical dialogues.<table-wrap id=\"Tab3\" position=\"float\" orientation=\"portrait\"><label>Table 3</label><caption><p>Performance comparison of LLM-generated clinical-related features between Zero-shot and SFT approaches</p></caption><table frame=\"hsides\" rules=\"groups\"><thead><tr><th colspan=\"1\" rowspan=\"1\"/><th colspan=\"3\" rowspan=\"1\">Test set</th><th colspan=\"3\" rowspan=\"1\">High-quality test set</th></tr><tr><th colspan=\"1\" rowspan=\"1\"/><th colspan=\"1\" rowspan=\"1\">Precision</th><th colspan=\"1\" rowspan=\"1\">Recall</th><th colspan=\"1\" rowspan=\"1\">Accuracy</th><th colspan=\"1\" rowspan=\"1\">Precision</th><th colspan=\"1\" rowspan=\"1\">Recall</th><th colspan=\"1\" rowspan=\"1\">Accuracy</th></tr></thead><tbody><tr><td colspan=\"1\" rowspan=\"1\">Zero-shot</td><td colspan=\"1\" rowspan=\"1\">81.2%</td><td colspan=\"1\" rowspan=\"1\">66.1%</td><td colspan=\"1\" rowspan=\"1\">81.2%</td><td colspan=\"1\" rowspan=\"1\">84.2%</td><td colspan=\"1\" rowspan=\"1\">74.0%</td><td colspan=\"1\" rowspan=\"1\">83.7%</td></tr><tr><td colspan=\"1\" rowspan=\"1\">the SFT</td><td colspan=\"1\" rowspan=\"1\">87.4%</td><td colspan=\"1\" rowspan=\"1\">81.1%</td><td colspan=\"1\" rowspan=\"1\">86.9%</td><td colspan=\"1\" rowspan=\"1\">89.5%</td><td colspan=\"1\" rowspan=\"1\">86.1%</td><td colspan=\"1\" rowspan=\"1\">89.1%</td></tr></tbody></table></table-wrap></p><p id=\"Par31\">We present a comparative analysis of classification performance using clinical-related features extracted by the LLM in Fig. <xref rid=\"Fig2\" ref-type=\"fig\">2</xref>, comparing three feature sets: features extracted in a zero-shot manner, features extracted from the fine-tuned LLM, and psychiatrists&#8217; annotations derived from EMRs. Across all classification tasks, features from the fine-tuned LLM consistently demonstrate superior performance. For instance, in distinguishing between depression and anxiety diagnoses (A vs. D), the fine-tuned LLM achieves a BAC of 74.8%. In identifying depression (D vs. N) and anxiety symptoms (A vs. N), the BAC reaches 79.8% and 72.2% respectively. These results underscore the potential of fine-tuned LLMs for accurate and automated clinical manifestation extraction.<fig id=\"Fig2\" position=\"float\" orientation=\"portrait\"><label>Fig. 2</label><caption><title>Comparative analysis of classification performance using the clinical-related features extracted by LLM in zero-shot, the SFT, and the annotations from EMRs across different classification tasks.</title><p>&#8220;ANX\" represents Anxiety Disorder, &#8220;DP\" represents depression Disorder, &#8220;A\" represents participants with anxiety symptoms, &#8220;D\" represents participants with depressive symptoms, &#8220;M\" represents participants with mixed anxiety and depressive symptoms, and &#8220;N\" represents participants without anxiety and depressive symptoms.</p></caption><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"d33e970\" position=\"float\" orientation=\"portrait\" xlink:href=\"44184_2025_175_Fig2_HTML.jpg\"/></fig></p></sec><sec id=\"Sec11\"><title>Classification of diagnostic groups</title><p id=\"Par32\">The results of automated classification tasks for distinguishing between ANX, DP, and Others groups (not diagnosed with ANX or DP) using various linguistic and LLM-generated features are shown in Table <xref rid=\"Tab4\" ref-type=\"table\">4</xref>. For the binary classification task (ANX vs. DP), the model achieved a BAC of 75.5%, an F1 score of 0.762, and an AUPRC of 0.824, indicating good overall performance (permutation test <italic toggle=\"yes\">p</italic>&#8201;&lt;&#8201;0.01, same for other tasks). In the three-way classification task (ANX vs. DP vs. Other), the model&#8217;s performance was achieved with a BAC of 65.6% and an F1 score of 0.656, presenting a significant gain compared to the majority baseline (47.7%).<table-wrap id=\"Tab4\" position=\"float\" orientation=\"portrait\"><label>Table 4</label><caption><p>Results for classification of ANX, DP, and Others groups</p></caption><table frame=\"hsides\" rules=\"groups\"><thead><tr><th colspan=\"1\" rowspan=\"1\">Task</th><th colspan=\"1\" rowspan=\"1\">Feature Set</th><th colspan=\"4\" rowspan=\"1\">Confusion Matrix</th><th colspan=\"1\" rowspan=\"1\">SEN</th><th colspan=\"1\" rowspan=\"1\">SPE</th><th colspan=\"1\" rowspan=\"1\">F1</th><th colspan=\"1\" rowspan=\"1\">AUPRC</th><th colspan=\"1\" rowspan=\"1\">BAC</th><th colspan=\"1\" rowspan=\"1\">MB</th></tr><tr><th colspan=\"1\" rowspan=\"1\"/><th colspan=\"1\" rowspan=\"1\"/><th colspan=\"1\" rowspan=\"1\"/><th colspan=\"3\" rowspan=\"1\">Predicted Class</th><th colspan=\"1\" rowspan=\"1\"/><th colspan=\"1\" rowspan=\"1\"/><th colspan=\"1\" rowspan=\"1\"/><th colspan=\"1\" rowspan=\"1\"/><th colspan=\"1\" rowspan=\"1\"/><th colspan=\"1\" rowspan=\"1\"/></tr><tr><th colspan=\"1\" rowspan=\"1\"/><th colspan=\"1\" rowspan=\"1\"/><th colspan=\"1\" rowspan=\"1\"/><th colspan=\"1\" rowspan=\"1\"/><th colspan=\"1\" rowspan=\"1\">A</th><th colspan=\"1\" rowspan=\"1\">D</th><th colspan=\"1\" rowspan=\"1\"/><th colspan=\"1\" rowspan=\"1\"/><th colspan=\"1\" rowspan=\"1\"/><th colspan=\"1\" rowspan=\"1\"/><th colspan=\"1\" rowspan=\"1\"/><th colspan=\"1\" rowspan=\"1\"/></tr></thead><tbody><tr><td colspan=\"1\" rowspan=\"1\">ANX vs. DP</td><td colspan=\"1\" rowspan=\"1\">AssRel + CliRel + LIWC + TF-IDF</td><td colspan=\"2\" rowspan=\"1\"><bold>A</bold></td><td colspan=\"1\" rowspan=\"1\">294</td><td colspan=\"1\" rowspan=\"1\">132</td><td colspan=\"1\" rowspan=\"1\">0.690</td><td colspan=\"1\" rowspan=\"1\">0.819</td><td colspan=\"1\" rowspan=\"1\">0.762</td><td colspan=\"1\" rowspan=\"1\">0.824</td><td colspan=\"1\" rowspan=\"1\">0.755</td><td colspan=\"1\" rowspan=\"1\">0.565</td></tr><tr><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"2\" rowspan=\"1\"><bold>D</bold></td><td colspan=\"1\" rowspan=\"1\">100</td><td colspan=\"1\" rowspan=\"1\">453</td><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/></tr><tr><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"><bold>A</bold></td><td colspan=\"1\" rowspan=\"1\"><bold>D</bold></td><td colspan=\"1\" rowspan=\"1\"><bold>O</bold></td><td colspan=\"1\" rowspan=\"1\"><bold>SEN</bold></td><td colspan=\"1\" rowspan=\"1\"><bold>SPE</bold></td><td colspan=\"1\" rowspan=\"1\"><bold>F1</bold></td><td colspan=\"1\" rowspan=\"1\"><bold>AUPRC</bold></td><td colspan=\"1\" rowspan=\"1\"><bold>BAC</bold></td><td colspan=\"1\" rowspan=\"1\"><bold>MB</bold></td></tr><tr><td colspan=\"1\" rowspan=\"1\">ANX vs. DP vs. Others</td><td colspan=\"1\" rowspan=\"1\">AssRel + CliRel + LIWC + TF-IDF</td><td colspan=\"1\" rowspan=\"1\"><bold>A</bold></td><td colspan=\"1\" rowspan=\"1\">271</td><td colspan=\"1\" rowspan=\"1\">91</td><td colspan=\"1\" rowspan=\"1\">64</td><td colspan=\"1\" rowspan=\"1\">0.636</td><td colspan=\"1\" rowspan=\"1\">0.838</td><td colspan=\"1\" rowspan=\"1\">0.656</td><td colspan=\"1\" rowspan=\"1\">0.715</td><td colspan=\"1\" rowspan=\"1\">0.656</td><td colspan=\"1\" rowspan=\"1\">0.477</td></tr><tr><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"><bold>D</bold></td><td colspan=\"1\" rowspan=\"1\">92</td><td colspan=\"1\" rowspan=\"1\">357</td><td colspan=\"1\" rowspan=\"1\">104</td><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/></tr><tr><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"><bold>O</bold></td><td colspan=\"1\" rowspan=\"1\">27</td><td colspan=\"1\" rowspan=\"1\">30</td><td colspan=\"1\" rowspan=\"1\">124</td><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/></tr></tbody></table><table-wrap-foot><p><italic toggle=\"yes\">AssRel</italic> Assessment-related, <italic toggle=\"yes\">CliRel</italic> Clinical-related, <italic toggle=\"yes\">F1</italic> F1-score, <italic toggle=\"yes\">SEN</italic> Sensitivity, <italic toggle=\"yes\">SPE</italic> Specificity, <italic toggle=\"yes\">AUPRC</italic> Area under precision-recall curve, <italic toggle=\"yes\">BAC</italic> Balanced Accuracy, <italic toggle=\"yes\">MB</italic> Majority Baseline.</p></table-wrap-foot></table-wrap></p></sec><sec id=\"Sec12\"><title>Prediction of depression and anxiety symptoms</title><p id=\"Par33\">In addition to identifying diagnostic results by ICD-10 code, we predicted whether participants exhibited symptoms of depression, anxiety, mixed depression/anxiety, or no symptoms at all, as shown in Table <xref rid=\"Tab5\" ref-type=\"table\">5</xref>. In the anxiety vs. no anxiety (A vs. N) classification task, the model achieved a sensitivity of 0.683 and specificity of 0.810 for detecting anxiety, with an overall F1 score of 0.754 and BAC of 74.7%. For the depression vs. no depression (D vs. N) task, the model performed slightly better, with a sensitivity of 0.806 and specificity of 0.737 for detecting depression, resulting in an F1 score of 0.783 and a BAC of 77.2%. When distinguishing between anxiety, depression, mixed symptoms, and no depression and anxiety symptoms (A vs. D vs. M vs. N), we achieved an AUPRC of 0.606 and a BAC of 60.7%, which achieved a significant improvement of about 30% compared to the majority baseline.<table-wrap id=\"Tab5\" position=\"float\" orientation=\"portrait\"><label>Table 5</label><caption><p>Results for classification of participants with depression (D), anxiety (A), mixed depression and anxiety (M), and no depression and anxiety symptoms (N)</p></caption><table frame=\"hsides\" rules=\"groups\"><thead><tr><th colspan=\"1\" rowspan=\"1\">Task</th><th colspan=\"1\" rowspan=\"1\">Features</th><th colspan=\"5\" rowspan=\"1\">Confusion Matrix</th><th colspan=\"1\" rowspan=\"1\">SEN</th><th colspan=\"1\" rowspan=\"1\">SPE</th><th colspan=\"1\" rowspan=\"1\">F1</th><th colspan=\"1\" rowspan=\"1\">AUPRC</th><th colspan=\"1\" rowspan=\"1\">BAC</th><th colspan=\"1\" rowspan=\"1\">MB</th></tr><tr><th colspan=\"1\" rowspan=\"1\"/><th colspan=\"1\" rowspan=\"1\"/><th colspan=\"1\" rowspan=\"1\"/><th colspan=\"4\" rowspan=\"1\">Predicted Class</th><th colspan=\"1\" rowspan=\"1\"/><th colspan=\"1\" rowspan=\"1\"/><th colspan=\"1\" rowspan=\"1\"/><th colspan=\"1\" rowspan=\"1\"/><th colspan=\"1\" rowspan=\"1\"/><th colspan=\"1\" rowspan=\"1\"/></tr><tr><th colspan=\"1\" rowspan=\"1\"/><th colspan=\"1\" rowspan=\"1\"/><th colspan=\"1\" rowspan=\"1\"/><th colspan=\"2\" rowspan=\"1\">A</th><th colspan=\"2\" rowspan=\"1\">N</th><th colspan=\"1\" rowspan=\"1\"/><th colspan=\"1\" rowspan=\"1\"/><th colspan=\"1\" rowspan=\"1\"/><th colspan=\"1\" rowspan=\"1\"/><th colspan=\"1\" rowspan=\"1\"/><th colspan=\"1\" rowspan=\"1\"/></tr></thead><tbody><tr><td colspan=\"1\" rowspan=\"1\">A vs. N</td><td colspan=\"1\" rowspan=\"1\">AssRel + CliRel + LIWC + TF-IDF</td><td colspan=\"1\" rowspan=\"1\"><bold>A</bold></td><td colspan=\"2\" rowspan=\"1\">285</td><td colspan=\"2\" rowspan=\"1\">135</td><td colspan=\"1\" rowspan=\"1\">0.683</td><td colspan=\"1\" rowspan=\"1\">0.810</td><td colspan=\"1\" rowspan=\"1\">0.754</td><td colspan=\"1\" rowspan=\"1\">0.813</td><td colspan=\"1\" rowspan=\"1\">0.747</td><td colspan=\"1\" rowspan=\"1\">0.565</td></tr><tr><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"><bold>N</bold></td><td colspan=\"2\" rowspan=\"1\">176</td><td colspan=\"2\" rowspan=\"1\">564</td><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/></tr><tr><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"2\" rowspan=\"1\"><bold>D</bold></td><td colspan=\"2\" rowspan=\"1\"><bold>N</bold></td><td colspan=\"1\" rowspan=\"1\"><bold>SEN</bold></td><td colspan=\"1\" rowspan=\"1\"><bold>SPE</bold></td><td colspan=\"1\" rowspan=\"1\"><bold>F1</bold></td><td colspan=\"1\" rowspan=\"1\"><bold>AUPRC</bold></td><td colspan=\"1\" rowspan=\"1\"><bold>BAC</bold></td><td colspan=\"1\" rowspan=\"1\"><bold>MB</bold></td></tr><tr><td colspan=\"1\" rowspan=\"1\">D vs. N</td><td colspan=\"1\" rowspan=\"1\">AssRel + CliRel + LIWC + TF-IDF</td><td colspan=\"1\" rowspan=\"1\"><bold>D</bold></td><td colspan=\"2\" rowspan=\"1\">595</td><td colspan=\"2\" rowspan=\"1\">143</td><td colspan=\"1\" rowspan=\"1\">0.806</td><td colspan=\"1\" rowspan=\"1\">0.737</td><td colspan=\"1\" rowspan=\"1\">0.783</td><td colspan=\"1\" rowspan=\"1\">0.866</td><td colspan=\"1\" rowspan=\"1\">0.772</td><td colspan=\"1\" rowspan=\"1\">0.636</td></tr><tr><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"><bold>N</bold></td><td colspan=\"2\" rowspan=\"1\">111</td><td colspan=\"2\" rowspan=\"1\">311</td><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/></tr><tr><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"><bold>A</bold></td><td colspan=\"1\" rowspan=\"1\"><bold>D</bold></td><td colspan=\"1\" rowspan=\"1\"><bold>M</bold></td><td colspan=\"1\" rowspan=\"1\"><bold>N</bold></td><td colspan=\"1\" rowspan=\"1\"><bold>SEN</bold></td><td colspan=\"1\" rowspan=\"1\"><bold>SPE</bold></td><td colspan=\"1\" rowspan=\"1\"><bold>F1</bold></td><td colspan=\"1\" rowspan=\"1\"><bold>AUPRC</bold></td><td colspan=\"1\" rowspan=\"1\"><bold>BAC</bold></td><td colspan=\"1\" rowspan=\"1\"><bold>MB</bold></td></tr><tr><td colspan=\"1\" rowspan=\"1\">A vs. D vs. M vs. N</td><td colspan=\"1\" rowspan=\"1\">AssRel + CliRel + LIWC + TF-IDF</td><td colspan=\"1\" rowspan=\"1\"><bold>A</bold></td><td colspan=\"1\" rowspan=\"1\">114</td><td colspan=\"1\" rowspan=\"1\">2</td><td colspan=\"1\" rowspan=\"1\">17</td><td colspan=\"1\" rowspan=\"1\">12</td><td colspan=\"1\" rowspan=\"1\">0.786</td><td colspan=\"1\" rowspan=\"1\">0.865</td><td colspan=\"1\" rowspan=\"1\">0.586</td><td colspan=\"1\" rowspan=\"1\">0.606</td><td colspan=\"1\" rowspan=\"1\">0.607</td><td colspan=\"1\" rowspan=\"1\">0.399</td></tr><tr><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"><bold>D</bold></td><td colspan=\"1\" rowspan=\"1\">22</td><td colspan=\"1\" rowspan=\"1\">272</td><td colspan=\"1\" rowspan=\"1\">98</td><td colspan=\"1\" rowspan=\"1\">71</td><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/></tr><tr><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"><bold>M</bold></td><td colspan=\"1\" rowspan=\"1\">55</td><td colspan=\"1\" rowspan=\"1\">58</td><td colspan=\"1\" rowspan=\"1\">123</td><td colspan=\"1\" rowspan=\"1\">39</td><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/></tr><tr><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"><bold>N</bold></td><td colspan=\"1\" rowspan=\"1\">60</td><td colspan=\"1\" rowspan=\"1\">30</td><td colspan=\"1\" rowspan=\"1\">19</td><td colspan=\"1\" rowspan=\"1\">168</td><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/><td colspan=\"1\" rowspan=\"1\"/></tr></tbody></table><table-wrap-foot><p><italic toggle=\"yes\">AssRel</italic> Assessment-related; CliRel Clinical-related, <italic toggle=\"yes\">F1</italic> F1-score, <italic toggle=\"yes\">SEN</italic> Sensitivity, <italic toggle=\"yes\">SPE</italic> Specificity, <italic toggle=\"yes\">AUPRC</italic> Area under precision-recall curve, <italic toggle=\"yes\">BAC</italic> Balanced Accuracy, <italic toggle=\"yes\">MB</italic> Majority Baseline.</p></table-wrap-foot></table-wrap></p></sec><sec id=\"Sec13\"><title>Interpretability</title><p id=\"Par34\">The analysis revealed distinctive patterns across different mental health conditions and feature sets (Table <xref rid=\"Tab6\" ref-type=\"table\">6</xref>). In differentiating ANX from DP, clinical-related features emphasized anxiety-specific symptoms such as &#8220;Unable to relax\", &#8220;Uncontrollable restlessness\", and &#8220;Anxiety\", contrasting with depressive symptoms like &#8220;Sadness\" and &#8220;Anhedonia\". Assessment measures showed a mixed profile, with both anxiety indicators (HAMD_Somatic anxiety) and depression markers (HAMD_Depressed mood). LIWC analysis revealed heightened use of anxiety and fear-related language, and TF-IDF identified anxiety-related terms. For depression detection, clinical-related features highlighted core depressive symptoms, with &#8220;Depressed mood\", &#8220;Loss of interest\", and &#8220;Anhedonia\" emerging as primary indicators of depression. The assessment-related features showed strong signals from SCL-90 scales, particularly in items related to feelings of sadness and loss of interest. LIWC analysis identified significant usage patterns in sadness-related words and negative emotions, while TF-IDF analysis captured depression-specific terms and notably, negation patterns (e.g., &#8220;Don&#8217;t want\", &#8220;No\", etc.). For anxiety identification, clinical-related features strongly centered on anxiety manifestations, such as &#8220;Unable to relax\", &#8220;Anxiety\", and &#8220;Worry.\" The assessment-related features prominently featured inner tension and somatic anxiety, along with various SCL-90 anxiety-related items. Both LIWC and TF-IDF analyses consistently identified anxiety-specific language patterns, with LIWC showing &#8220;Anxiety\" and &#8220;Fear\" as top features, and TF-IDF highlighting terms related to physical symptoms (e.g., &#8220;Palpitations\", &#8220;Heartbeat\", etc.) and worry.<table-wrap id=\"Tab6\" position=\"float\" orientation=\"portrait\"><label>Table 6</label><caption><p>Top ten salient features for each feature set in paired classification tasks</p></caption><table frame=\"hsides\" rules=\"groups\"><thead><tr><th colspan=\"1\" rowspan=\"1\">Task</th><th colspan=\"1\" rowspan=\"1\">Clinical-related</th><th colspan=\"1\" rowspan=\"1\">Assessment-related</th><th colspan=\"1\" rowspan=\"1\">LIWC</th><th colspan=\"1\" rowspan=\"1\">TF-IDF</th></tr></thead><tbody><tr><td colspan=\"1\" rowspan=\"1\">ANX vs. DP</td><td colspan=\"1\" rowspan=\"1\"><p>Sadness</p><p>Perturbed and uneasy</p><p>Unable to relax</p><p>Uncontrollable</p><p>-restlessness</p><p>Negativism</p><p><bold>Anxiety</bold></p><p>Anhedonia</p><p>Anxiety and unease</p><p>Negative ideation</p><p> Anhedonia</p></td><td colspan=\"1\" rowspan=\"1\"><p><bold>SCL-90_Feeling blue_2</bold></p><p><bold>SCL-90_Feeling no interest in things_2</bold></p><p>HAMD_Depressed mood_4</p><p><bold>HAMD_Somatic anxiety_3</bold></p><p>MADRS_Inner tension_NULL</p><p><bold>SCL-90_Thoughts of ending your life_1</bold></p><p><bold>SCL-90_Feeling future hopeless_1</bold></p><p><bold>MADRS_Suicidal ideation_0</bold></p><p><bold>HAMD_A sense of hopelessness_0</bold></p><p><bold>SCL-90_Never feeling close to others_1</bold></p></td><td colspan=\"1\" rowspan=\"1\"><p><bold>Anxiety</bold></p><p><bold>Fear</bold></p><p><bold>Biological Processes</bold></p><p>Death</p><p>Sad</p><p><bold>Health</bold></p><p><bold>Body</bold></p><p><bold>Motion</bold></p><p><bold>Perfect tense</bold></p><p>Anger</p></td><td colspan=\"1\" rowspan=\"1\"><p><bold>Anxiety</bold></p><p>Ideas</p><p>Emotion</p><p><bold>Palpitations</bold></p><p><bold>Anxious</bold></p><p><bold>Worried</bold></p><p><bold>Terrified</bold></p><p><bold>Heartbeat</bold></p><p><bold>Excited</bold></p><p><bold>Behavior</bold></p></td></tr><tr><td colspan=\"1\" rowspan=\"1\">A vs. N</td><td colspan=\"1\" rowspan=\"1\"><p><bold>Unable to relax</bold></p><p><bold>Anxiety</bold></p><p><bold>Uncontrollable</bold></p><p><bold>-restlessness</bold></p><p><bold>Anxiety and unease</bold></p><p><bold>Feeling of tension</bold></p><p><bold>Somatic anxiety</bold></p><p><bold>Excessive worrying</bold></p><p><bold>with anxious</bold></p><p><bold>Worry</bold></p><p>Delusion of Guilt</p><p><bold>Palpitations</bold></p></td><td colspan=\"1\" rowspan=\"1\"><p><bold>MADRS_Inner tension_4</bold></p><p>\n<bold>HAMD_Somatic anxiety_3</bold></p><p>SCL-90_Feeling tense or keyed up_NULL</p><p><bold>HAMD_Psychiatric anxiety_3</bold></p><p><bold>HAMA_Autonomic symptoms_2</bold></p><p>SCL-90_Worrying too much about things_NULL</p><p>SCL-90_Nervousness or shakiness inside_NULL </p><p>SAS_Anxiety_NULL</p><p><bold>HAMA_Cardiovascular symptoms_2</bold></p><p>SCL-90_Feeling restless_NULL</p></td><td colspan=\"1\" rowspan=\"1\"><p><bold>Anxiety</bold></p><p><bold>Fear</bold></p><p><bold>Body</bold></p><p><bold>Biological Processes</bold></p><p>Good Social</p><p><bold>Perfect tense</bold></p><p><bold>Health</bold></p><p><bold>Motion</bold></p><p>Death</p></td><td colspan=\"1\" rowspan=\"1\"><p><bold>Anxiety</bold></p><p><bold>Anxious</bold></p><p><bold>Palpitations</bold></p><p><bold>Worried</bold></p><p>Ideas</p><p><bold>Heartbeat</bold></p><p><bold>Anxiety disorders</bold></p><p><bold>Chest tightness</bold></p><p><bold>Behavior</bold></p><p><bold>Comfortable</bold></p></td></tr><tr><td colspan=\"1\" rowspan=\"1\">D vs. N</td><td colspan=\"1\" rowspan=\"1\"><p><bold>Feeling Down</bold></p><p><bold>Perturbed and Uneasy</bold></p><p><bold>Sadness</bold></p><p><bold>Loss of interests</bold></p><p><bold>Anhedonia</bold></p><p><bold>Negativism</bold></p><p><bold>Hypobulia</bold></p><p><bold>Low self-evaluation</bold></p><p><bold>Helplessness</bold></p><p><bold>Abulia</bold></p></td><td colspan=\"1\" rowspan=\"1\"><p>SCL-90_Feeling blue_NULL</p><p>SCL-90_Feeling no interest in things_NULL</p><p>SCL-90_Feeling hopeless about the future_NULL</p><p>SCL-90_Feeling everything is an effort_NULL</p><p><bold>HAMD_Depressed mood_3</bold></p><p><bold>HAMD_Work and interests_3</bold></p><p>SCL-90_Feeling low in energy</p><p>-or slowed down_NULL</p><p>SCL-90_Feelings of worthlessness_NULL</p><p><bold>SDS_Depression_4</bold></p><p>MADRS_Apparent sadness_0</p></td><td colspan=\"1\" rowspan=\"1\"><p><bold>Sad</bold></p><p><bold>Affect</bold></p><p>Health</p><p><bold>Death</bold></p><p><bold>Humans</bold></p><p>Biological processes</p><p><bold>Anger</bold></p><p><bold>Achievement</bold></p><p><bold>Negative emotion</bold></p><p>Anxiety</p></td><td colspan=\"1\" rowspan=\"1\"><p><bold>No</bold></p><p><bold>Depression</bold></p><p><bold>Interests</bold></p><p><bold>Emotion</bold></p><p><bold>Yes</bold></p><p><bold>Obstacle</bold></p><p><bold>Don&#8217;t</bold></p><p><bold>Contrary</bold></p><p><bold>Ideas</bold></p><p><bold>Anger</bold></p></td></tr></tbody></table><table-wrap-foot><p>All features in the table have <italic toggle=\"yes\">p</italic>&#8201;&lt;&#8201;0.01.</p><p>For Assessment-related features, the feature nomenclature follows the format: Scale_Symptom-Name_Rating, where a &#8216;NULL&#8217; rating indicates the absence of symptom in dialogue identified by LLM.</p><p>The <bold>bold</bold> feature name represents that the <underline>underlined</underline> class has a higher mean value.</p></table-wrap-foot></table-wrap></p></sec><sec id=\"Sec14\"><title>Baseline experiment results</title><p id=\"Par35\">We conducted a systematic investigation of diagnostic efficacy in clinical dialogue classification utilizing multiple model architectures. The conventional transformer models demonstrated variable performance: BERT achieved modest results with 88.1% sensitivity but only 39.5% specificity and 64.3% F1 score, while RoBERTa exhibited superior sensitivity (96.3%) but similarly limited specificity (37.2%). When examining LLM-based approaches, Qwen2.5-72B-Instruct demonstrated substantial improvements in balanced performance, achieving 75.0% balanced accuracy in zero-shot configuration and 76.7% after SFT. Our proposed methodology, leveraging LLM-generated feature sets with ensemble random forest classifiers, outperformed all other approaches across most metrics, most notably achieving 79.1% balanced accuracy and 88.1% AUPRC, demonstrating the efficacy of feature extraction over direct classification when utilizing large language models for clinical diagnostic tasks.</p></sec></sec><sec id=\"Sec15\" sec-type=\"discussion\"><title>Discussion</title><p id=\"Par36\">Inspired by promising early research on digital phenotypes for diagnosing and classifying symptoms in psychiatric patients, we investigated using signal processing and state-of-the-art LLM to capture symptom-related expression cues in outpatient conversations. We developed an ensemble classification pipeline to automatically differentiate between clinical diagnostic outcomes and the presence of symptoms.</p><p id=\"Par37\">Although recent studies have demonstrated promising capabilities of utilizing LLMs in medical diagnosis<sup><xref ref-type=\"bibr\" rid=\"CR42\">42</xref></sup>, applications in mental health have predominantly centered on developing conversational agents<sup><xref ref-type=\"bibr\" rid=\"CR43\">43</xref></sup>, while the potential of extracting precise symptoms from psychiatric conversations for evidence-based diagnosis has not been fully explored. In this study, we investigated the efficacy of LLM in detecting clinical and assessment-related symptoms. Our investigation revealed that without any additional training, the model achieved a recall rate of 77.3% on high-quality dialogue-case pairs, and increased to 86.1% by fine-tuning the LLM using clinical annotations. This aligns with recent observations regarding LLMs&#8217; strong zero-shot performance in healthcare domains and the fine-tuning could further boost LLM performance<sup><xref ref-type=\"bibr\" rid=\"CR23\">23</xref></sup>. Furthermore, this enhanced base capability led to substantial improvements across all downstream classification and prediction tasks (e.g., the classification accuracy for ANX and DP increased from 72 to 75%). Current approaches to automated symptom detection predominantly rely on traditional natural language processing methods with predefined linguistic categories or rule-based systems<sup><xref ref-type=\"bibr\" rid=\"CR6\">6</xref>,<xref ref-type=\"bibr\" rid=\"CR44\">44</xref></sup>, which often struggle to capture the complex presentation of psychiatric symptoms in natural conversation. Some researchers have explored the use of LLMs to assist in medical information retrieval<sup><xref ref-type=\"bibr\" rid=\"CR45\">45</xref></sup>. We further investigated the information extraction capabilities in clinical dialogues and enhanced them through SFT.</p><p id=\"Par38\">Our study demonstrated moderate to high performance in anxiety symptom detection (BAC&#8201;=&#8201;74.7%, AUPRC&#8201;=&#8201;0.813), depression symptoms detection (BAC&#8201;=&#8201;77.2%, AUPRC&#8201;=&#8201;0.866), and a four-class classification of patients with anxiety/depression/mixed/none symptoms (BAC=60.7%, AUPRC&#8201;=&#8201;0.606). As shown in the summarization of existing literature (Supplementary Table <xref rid=\"MOESM1\" ref-type=\"media\">8</xref>), while anxiety detection in social media text has demonstrated promising results with high accuracy<sup><xref ref-type=\"bibr\" rid=\"CR46\">46</xref></sup>, the performance of similar methods on spoken language data, such as interview transcripts and therapy dialogues, remains limited with accuracy rates below 65%. Recent advances combining LLM embedding with acoustic features have shown improved results, reaching 75% accuracy in a small cohort of 65 patients<sup><xref ref-type=\"bibr\" rid=\"CR4\">4</xref></sup>; however, in our experiments, incorporating acoustic features did not yield improvements in overall classification performance as shown in Supplementary Fig. <xref rid=\"MOESM1\" ref-type=\"media\">1</xref>. This might be attributed to the noisy hospital environment and the limitations of our recording equipment, which resulted in suboptimal audio quality. While depression detection studies have reported wide-ranging accuracy rates (65&#8722;95%), some results should be interpreted with caution due to several methodological limitations: small sample sizes<sup><xref ref-type=\"bibr\" rid=\"CR44\">44</xref></sup>, reliance on PHQ screening tools rather than clinical diagnoses<sup><xref ref-type=\"bibr\" rid=\"CR47\">47</xref></sup>, data collection in structured experimental settings<sup><xref ref-type=\"bibr\" rid=\"CR48\">48</xref></sup>, and not studied the first-episode outpatients in real-world, unstructured clinical environments. Our study leverages clinical diagnoses from psychiatrists of first-episode outpatients in real-world clinical environments, achieving moderate to high accuracy despite the inherent challenges and variability of unstructured, naturalistic settings representing a significant advancement over controlled laboratory conditions. This success particularly highlights the potential of LLMs in extracting and analyzing clinical symptoms for predicting anxiety and depression in outpatient populations, offering a more ecologically valid and scalable solution for mental health screening and monitoring.</p><p id=\"Par39\">DP and ANX present significant assessment challenges due to their high prevalence, frequent comorbidity, and overlapping symptomatology<sup><xref ref-type=\"bibr\" rid=\"CR49\">49</xref></sup>. By leveraging LLM-generated features, our approach achieved robust performance in distinguishing these disorders, with a BAC of 75.5% and AUPRC of 0.824 for binary classification between DP and ANX, and the performance outperformed the directly using LLMs as classifiers (see Table <xref rid=\"Tab7\" ref-type=\"table\">7</xref>). In the more challenging multi-class scenario (ANX vs. DP vs. Others), the model maintained reasonable performance with a BAC of 65.6% and AUPRC of 0.715. Prior approaches to differentiating depression and anxiety disorders, such as cognitive tasks<sup><xref ref-type=\"bibr\" rid=\"CR50\">50</xref></sup> and structured questionnaires<sup><xref ref-type=\"bibr\" rid=\"CR51\">51</xref></sup>, have achieved accuracy rates of 70&#8211;80%. In addition, we tested the classification performance of each assessment scale as the feature set, where the results are presented in Supplementary Fig. <xref rid=\"MOESM1\" ref-type=\"media\">2</xref>. We observed that assessment-related features, particularly from scales like SCL-90, HAMD, and MADRS, showed strong discriminatory power across all comparisons, and early fusion and late fusion present similar classification performance. A potential reason is that these scales contain sufficient depression-related symptoms, which are key components for differentiating different groups. To our knowledge, no study has explored the objective diagnosis of DP and ANX using speech data from clinical interviews, potentially due to a lack of data and inherent subjectivity. Our study addresses a critical gap by analyzing the linguistic and symptom-related markers in various participant groups, providing objective cues to assist psychiatrists.<table-wrap id=\"Tab7\" position=\"float\" orientation=\"portrait\"><label>Table 7</label><caption><p>Comparison of classification performance using Qwen2-72B-Instruct (Zero-shot and SFT) and Ours (LLM-generated feature sets with ensemble random forest classifiers) for DP/ANX classification</p></caption><table frame=\"hsides\" rules=\"groups\"><thead><tr><th colspan=\"1\" rowspan=\"1\"/><th colspan=\"1\" rowspan=\"1\">SEN</th><th colspan=\"1\" rowspan=\"1\">SPE</th><th colspan=\"1\" rowspan=\"1\">F1</th><th colspan=\"1\" rowspan=\"1\">AUPRC</th><th colspan=\"1\" rowspan=\"1\">BAC</th><th colspan=\"1\" rowspan=\"1\">MB</th></tr></thead><tbody><tr><td colspan=\"1\" rowspan=\"1\">BERT</td><td colspan=\"1\" rowspan=\"1\">0.881</td><td colspan=\"1\" rowspan=\"1\">0.395</td><td colspan=\"1\" rowspan=\"1\">0.643</td><td colspan=\"1\" rowspan=\"1\">0.735</td><td colspan=\"1\" rowspan=\"1\">63.8%</td><td colspan=\"1\" rowspan=\"1\">0.566</td></tr><tr><td colspan=\"1\" rowspan=\"1\">RoBERTa</td><td colspan=\"1\" rowspan=\"1\"><bold>0.963</bold></td><td colspan=\"1\" rowspan=\"1\">0.372</td><td colspan=\"1\" rowspan=\"1\">0.669</td><td colspan=\"1\" rowspan=\"1\">0.708</td><td colspan=\"1\" rowspan=\"1\">66.8%</td><td colspan=\"1\" rowspan=\"1\">0.566</td></tr><tr><td colspan=\"1\" rowspan=\"1\">Qwen2.5-72B-Instruct (Zero-shot)</td><td colspan=\"1\" rowspan=\"1\">0.748</td><td colspan=\"1\" rowspan=\"1\">0.753</td><td colspan=\"1\" rowspan=\"1\">0.751</td><td colspan=\"1\" rowspan=\"1\">0.842</td><td colspan=\"1\" rowspan=\"1\">75.0%</td><td colspan=\"1\" rowspan=\"1\">0.566</td></tr><tr><td colspan=\"1\" rowspan=\"1\">Qwen2.5-72B-Instruct (SFT)</td><td colspan=\"1\" rowspan=\"1\">0.757</td><td colspan=\"1\" rowspan=\"1\">0.776</td><td colspan=\"1\" rowspan=\"1\">0.766</td><td colspan=\"1\" rowspan=\"1\">0.828</td><td colspan=\"1\" rowspan=\"1\">76.7%</td><td colspan=\"1\" rowspan=\"1\">0.566</td></tr><tr><td colspan=\"1\" rowspan=\"1\">Ours</td><td colspan=\"1\" rowspan=\"1\">0.788</td><td colspan=\"1\" rowspan=\"1\"><bold>0.793</bold></td><td colspan=\"1\" rowspan=\"1\"><bold>0.791</bold></td><td colspan=\"1\" rowspan=\"1\"><bold>0.881</bold></td><td colspan=\"1\" rowspan=\"1\"><bold>79.1%</bold></td><td colspan=\"1\" rowspan=\"1\">0.566</td></tr></tbody></table><table-wrap-foot><p>The bold numbers indicate the highest performance within each metric column.</p></table-wrap-foot></table-wrap></p><p id=\"Par40\">The feature analysis provides several key insights into the differential characteristics of different groups of participants, as shown in Table <xref rid=\"Tab6\" ref-type=\"table\">6</xref>. We illustrate the distribution of clinical and assessment-related features for each group of participants in Supplementary Figs. <xref rid=\"MOESM1\" ref-type=\"media\">3</xref> and <xref rid=\"MOESM1\" ref-type=\"media\">4</xref>. The clinical-related features demonstrate clear condition-specific patterns: features that show more importance in patients with depression cluster around mood (sadness and disappointment) and motivational disturbances (anhedonia, reduced volition), while anxiety features predominantly reflect an inability to relax and worry. The observation for depression is in line with previous studies which also observed that patients with depression presented blunted facial affect and increased sadness in language<sup><xref ref-type=\"bibr\" rid=\"CR4\">4</xref>,<xref ref-type=\"bibr\" rid=\"CR13\">13</xref></sup> and anhedonia is specific to depression<sup><xref ref-type=\"bibr\" rid=\"CR52\">52</xref></sup>. For anxiety recognition, the consistency of findings across different feature sets strengthens the reliability of these discriminators. For instance, the prominence of somatic symptoms in anxiety, captured in both assessment-related features and TF-IDF terms, suggests this could be a robust marker. Similarly, the persistent appearance of mood-related terms in depression across multiple feature sets reinforces their diagnostic utility. It is worth noting that acoustic features extracted using OpenSmile were not included in our feature importance analysis, as they did not demonstrate statistical significance in discriminating between the participant groups.</p><p id=\"Par41\">Real-world implementation of this LLM pipeline demands careful consideration of practical and clinical factors. Our approach, leveraging LLMs on conversational data to derive symptom insights and classifications, underscores the need for stringent data privacy protocols and computationally capable infrastructure. Furthermore, the pipeline&#8217;s interpretability, stemming from its focus on clinically relevant features, must be clearly presented within EMR workflows to foster clinician trust. Beyond these pipeline-specific needs, seamless integration and clinician training are critical for usability. Building trust also requires ongoing validation, performance monitoring to detect model drift, and transparent ethical protocols, including patient consent and equity audits, ensuring the tool responsibly supports clinical decision-making.</p><p id=\"Par42\">Our study has several limitations that should be addressed in future research. The absence of detailed symptom severity measures during the experiment limits our ability to correlate speech patterns with specific symptom intensities. Additionally, the study&#8217;s focus on specific disorders and potential biases in data collection may affect the generalizability of the results. Future work should prioritize the inclusion of comprehensive symptom severity assessments and explore the application of this approach to a broader range of mental health conditions. Besides, in the future, we will collect more data to perform longitudinal analysis, as it could provide insights into how linguistic patterns evolve with symptom progression or treatment response. Furthermore, expanding the use of more advanced LLMs in this context could potentially enhance the extraction of nuanced clinical concepts and provide even more detailed, interpretable insights for clinicians. Validating the model&#8217;s performance in diverse clinical settings and with larger, more diverse patient populations will be crucial to ensure its practical utility and generalizability. These advancements could significantly contribute to improving the efficiency and objectivity of consultations for depression, anxiety, and potentially other mental health disorders.</p><p id=\"Par43\">In summary, this study demonstrates the potential of using LLM to analyze digital biomarkers in speech for automatic assistance in psychosis diagnosis and assessment. Our model achieved promising accuracy in identifying individuals with anxiety and depression symptoms, as well as differentiating between DP and ANX groups. Using LLMs to extract clinically relevant features and rate assessment scales improved the interpretability of the results, offering a novel approach to bridging the gap between automated analysis and clinical practice. While further research is needed, our findings suggest that well-developed LLMs could potentially serve as valuable tools in standardizing psychiatric evaluation and decision-making.</p></sec><sec id=\"Sec16\" sec-type=\"supplementary-material\"><title>Supplementary information</title><p>\n<supplementary-material content-type=\"local-data\" id=\"MOESM1\" position=\"float\" orientation=\"portrait\"><media xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"44184_2025_175_MOESM1_ESM.pdf\" position=\"float\" orientation=\"portrait\"><caption><p>Supplementary Information</p></caption></media></supplementary-material>\n</p></sec></body><back><fn-group><fn><p><bold>Publisher&#8217;s note</bold> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn><fn><p>These authors contributed equally: Shihao Xu, Yiming Yan, Yanli Ding.</p></fn></fn-group><sec><title>Supplementary information</title><p>The online version contains supplementary material available at 10.1038/s44184-025-00175-1.</p></sec><ack><title>Acknowledgements</title><p>This work was supported by Tianqiao and Chrissy Chen Institute (TCCI) with the Program of Chen Frontier Lab for AI and Mental Health - Shanghai Mental Health Center (2023-TX-018), the National Natural Science Foundation of China (82071500), the Natural Science Foundation of Shanghai, China (23ZR1454600), the Program of Shanghai Academic/Technology Research Leader (21XD1423300), Shanghai Shen-Kang Hospital Development Center (SHDC12025118, SHDC22025303) to J.C.; the National Social Science Foundation of China (25BKX030) to Q.Z. and the Integrated Innovation Team Project of Shanghai Mental Health Center. We deeply appreciate every participant involved in this study and all the efforts made by TCCI and SMHC colleagues who are not on the author list.</p></ack><notes notes-type=\"author-contribution\"><title>Author contributions</title><p>J.C. was the overall principal investigators for the study who conceived the study and obtained financial support, and was responsible for study design and supervised the entire study. S.X., Y.Y. and Y.D. participated in the study design. S.X. developed the large language model methodology, designed the machine learning pipeline, conducted the experiments, and wrote the original draft. Y.Y. and Y.D. performed clinical concept verification, analyzed the data and finalized the manuscript. F.L. and S.Z. developed the large language model methodology, performed data processing, and conducted the experiments. Z.W., T.Y. and H.G. provided technical support and data resources. J.S., X.J., Y.H., Q.Z., M.Z., Y.X. and J.C. supervised the project, acquired funding, and reviewed the final manuscript. N.O., L.B., reviewed the final manuscript. H.T., C.L., Y.L., H.L., Y.M., W.G., H.Q., Y.W. and J.Q. contributed to the participant recruitment and clinical data collection. All authors contributed to the manuscript revision and approved the submitted version.</p></notes><notes notes-type=\"data-availability\"><title>Data availability</title><p>The research data cannot be publicly shared due to privacy concerns, but the code and instructions for requesting local access to the data are available at <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://github.com/Shanda-Group-Ltd/SMHC_llm_psychiatry_study\">https://github.com/Shanda-Group-Ltd/SMHC_llm_psychiatry_study</ext-link>, with qualified researchers able to apply for on-site data access through this repository.</p></notes><notes id=\"FPar1\" notes-type=\"COI-statement\"><title>Competing interests</title><p id=\"Par44\">The authors declare no competing interests.</p></notes><ref-list id=\"Bib1\"><title>References</title><ref id=\"CR1\"><label>1.</label><citation-alternatives><element-citation id=\"ec-CR1\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Chodavadia</surname><given-names>P</given-names></name><name name-style=\"western\"><surname>Teo</surname><given-names>I</given-names></name><name name-style=\"western\"><surname>Poremski</surname><given-names>D</given-names></name><name name-style=\"western\"><surname>Fung</surname><given-names>DSS</given-names></name><name name-style=\"western\"><surname>Finkelstein</surname><given-names>EA</given-names></name></person-group><article-title>Prevalence and economic burden of depression and anxiety symptoms among Singaporean adults: Results from a 2022 web panel</article-title><source>BMC Psychiatry</source><year>2023</year><volume>23</volume><fpage>104</fpage><pub-id pub-id-type=\"doi\">10.1186/s12888-023-04581-7</pub-id><pub-id pub-id-type=\"pmid\">36782116</pub-id><pub-id pub-id-type=\"pmcid\">PMC9925363</pub-id></element-citation><mixed-citation id=\"mc-CR1\" publication-type=\"journal\">Chodavadia, P., Teo, I., Poremski, D., Fung, D. S. S. &amp; Finkelstein, E. A. Prevalence and economic burden of depression and anxiety symptoms among Singaporean adults: Results from a 2022 web panel. <italic toggle=\"yes\">BMC Psychiatry</italic><bold>23</bold>, 104 (2023).<pub-id pub-id-type=\"pmid\">36782116</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1186/s12888-023-04581-7</pub-id><pub-id pub-id-type=\"pmcid\">PMC9925363</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR2\"><label>2.</label><citation-alternatives><element-citation id=\"ec-CR2\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Althubaiti</surname><given-names>A</given-names></name></person-group><article-title>Information bias in health research: definition, pitfalls, and adjustment methods</article-title><source>J. Multidiscip. Healthc.</source><year>2016</year><volume>9</volume><fpage>211</fpage><lpage>217</lpage><pub-id pub-id-type=\"doi\">10.2147/JMDH.S104807</pub-id><pub-id pub-id-type=\"pmid\">27217764</pub-id><pub-id pub-id-type=\"pmcid\">PMC4862344</pub-id></element-citation><mixed-citation id=\"mc-CR2\" publication-type=\"journal\">Althubaiti, A. Information bias in health research: definition, pitfalls, and adjustment methods. <italic toggle=\"yes\">J. Multidiscip. Healthc.</italic><bold>9</bold>, 211&#8211;217 (2016).<pub-id pub-id-type=\"pmid\">27217764</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.2147/JMDH.S104807</pub-id><pub-id pub-id-type=\"pmcid\">PMC4862344</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR3\"><label>3.</label><citation-alternatives><element-citation id=\"ec-CR3\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Sharma</surname><given-names>CM</given-names></name><name name-style=\"western\"><surname>Damani</surname><given-names>D</given-names></name><name name-style=\"western\"><surname>Chariar</surname><given-names>VM</given-names></name></person-group><article-title>Review and content analysis of textual expressions as a marker for depressive and anxiety disorders (DAD) detection using machine learning</article-title><source>Discov. Artif. Intell.</source><year>2023</year><volume>3</volume><fpage>38</fpage><pub-id pub-id-type=\"doi\">10.1007/s44163-023-00090-4</pub-id></element-citation><mixed-citation id=\"mc-CR3\" publication-type=\"journal\">Sharma, C. M., Damani, D. &amp; Chariar, V. M. Review and content analysis of textual expressions as a marker for depressive and anxiety disorders (DAD) detection using machine learning. <italic toggle=\"yes\">Discov. Artif. Intell.</italic><bold>3</bold>, 38 (2023).</mixed-citation></citation-alternatives></ref><ref id=\"CR4\"><label>4.</label><citation-alternatives><element-citation id=\"ec-CR4\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Jiang</surname><given-names>Z</given-names></name><etal/></person-group><article-title>Multimodal mental health digital biomarker analysis from remote interviews using facial, vocal, linguistic, and cardiovascular patterns</article-title><source>IEEE J. Biomed. Health Inform.</source><year>2024</year><volume>28</volume><fpage>1680</fpage><lpage>1691</lpage><pub-id pub-id-type=\"doi\">10.1109/JBHI.2024.3352075</pub-id><pub-id pub-id-type=\"pmid\">38198249</pub-id><pub-id pub-id-type=\"pmcid\">PMC10986761</pub-id></element-citation><mixed-citation id=\"mc-CR4\" publication-type=\"journal\">Jiang, Z. et al. Multimodal mental health digital biomarker analysis from remote interviews using facial, vocal, linguistic, and cardiovascular patterns. <italic toggle=\"yes\">IEEE J. Biomed. Health Inform.</italic><bold>28</bold>, 1680&#8211;1691 (2024).<pub-id pub-id-type=\"pmid\">38198249</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1109/JBHI.2024.3352075</pub-id><pub-id pub-id-type=\"pmcid\">PMC10986761</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR5\"><label>5.</label><citation-alternatives><element-citation id=\"ec-CR5\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Low</surname><given-names>DM</given-names></name><name name-style=\"western\"><surname>Bentley</surname><given-names>KH</given-names></name><name name-style=\"western\"><surname>Ghosh</surname><given-names>SS</given-names></name></person-group><article-title>Automated assessment of psychiatric disorders using speech: a systematic review</article-title><source>Laryngoscope Investig. Otolaryngol.</source><year>2020</year><volume>5</volume><fpage>96</fpage><lpage>116</lpage><pub-id pub-id-type=\"doi\">10.1002/lio2.354</pub-id><pub-id pub-id-type=\"pmid\">32128436</pub-id><pub-id pub-id-type=\"pmcid\">PMC7042657</pub-id></element-citation><mixed-citation id=\"mc-CR5\" publication-type=\"journal\">Low, D. M., Bentley, K. H. &amp; Ghosh, S. S. Automated assessment of psychiatric disorders using speech: a systematic review. <italic toggle=\"yes\">Laryngoscope Investig. Otolaryngol.</italic><bold>5</bold>, 96&#8211;116 (2020).<pub-id pub-id-type=\"pmid\">32128436</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1002/lio2.354</pub-id><pub-id pub-id-type=\"pmcid\">PMC7042657</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR6\"><label>6.</label><citation-alternatives><element-citation id=\"ec-CR6\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Xu</surname><given-names>S</given-names></name><etal/></person-group><article-title>Identifying psychiatric manifestations in schizophrenia and depression from audio-visual behavioural indicators through a machine-learning approach</article-title><source>Schizophrenia</source><year>2022</year><volume>8</volume><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type=\"doi\">10.1038/s41537-022-00287-z</pub-id><pub-id pub-id-type=\"pmid\">36344515</pub-id><pub-id pub-id-type=\"pmcid\">PMC9640655</pub-id></element-citation><mixed-citation id=\"mc-CR6\" publication-type=\"journal\">Xu, S. et al. Identifying psychiatric manifestations in schizophrenia and depression from audio-visual behavioural indicators through a machine-learning approach. <italic toggle=\"yes\">Schizophrenia</italic><bold>8</bold>, 1&#8211;13 (2022).<pub-id pub-id-type=\"pmid\">36344515</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1038/s41537-022-00287-z</pub-id><pub-id pub-id-type=\"pmcid\">PMC9640655</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR7\"><label>7.</label><mixed-citation publication-type=\"other\">Openai. ChatGPT. <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://chatgpt.com/chat\">https://chatgpt.com/chat</ext-link> (2024).</mixed-citation></ref><ref id=\"CR8\"><label>8.</label><mixed-citation publication-type=\"other\">Team, G. et al. Gemini 1.5: unlocking multimodal understanding across millions of tokens of context. Preprint at 10.48550/arXiv.2403.05530 (2024).</mixed-citation></ref><ref id=\"CR9\"><label>9.</label><mixed-citation publication-type=\"other\">Team, Q. Qwen2.5: a party of foundation models. <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://qwenlm.github.io/blog/qwen2.5/\">https://qwenlm.github.io/blog/qwen2.5/</ext-link> (2024).</mixed-citation></ref><ref id=\"CR10\"><label>10.</label><mixed-citation publication-type=\"other\">Omar, M. et al. Applications of large language models in psychiatry: a systematic review. <italic toggle=\"yes\">Front. Psychiatry</italic><bold>15</bold>, 1422807 (2024).<pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.3389/fpsyt.2024.1422807</pub-id><pub-id pub-id-type=\"pmcid\">PMC11228775</pub-id><pub-id pub-id-type=\"pmid\">38979501</pub-id></mixed-citation></ref><ref id=\"CR11\"><label>11.</label><citation-alternatives><element-citation id=\"ec-CR11\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Marzano</surname><given-names>L</given-names></name><etal/></person-group><article-title>The application of mHealth to mental health: opportunities and challenges</article-title><source>Lancet Psychiatry</source><year>2015</year><volume>2</volume><fpage>942</fpage><lpage>948</lpage><pub-id pub-id-type=\"doi\">10.1016/S2215-0366(15)00268-0</pub-id><pub-id pub-id-type=\"pmid\">26462228</pub-id></element-citation><mixed-citation id=\"mc-CR11\" publication-type=\"journal\">Marzano, L. et al. The application of mHealth to mental health: opportunities and challenges. <italic toggle=\"yes\">Lancet Psychiatry</italic><bold>2</bold>, 942&#8211;948 (2015).<pub-id pub-id-type=\"pmid\">26462228</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1016/S2215-0366(15)00268-0</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR12\"><label>12.</label><mixed-citation publication-type=\"other\">Lan, X., Cheng, Y., Sheng, L., Gao, C. &amp; Li, Y. Depression detection on social media with large language models. In <italic toggle=\"yes\">Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing: Industry Track</italic> (2025).</mixed-citation></ref><ref id=\"CR13\"><label>13.</label><mixed-citation publication-type=\"other\">Wang, Y., Inkpen, D. &amp; Kirinde Gamaarachchige, P. Explainable depression detection using large language models on social media data. In <italic toggle=\"yes\">Proc. 9th Workshop on Computational Linguistics and Clinical Psychology (CLPsych 2024)</italic>, 108-126 (Association for Computational Linguistics, 2024).</mixed-citation></ref><ref id=\"CR14\"><label>14.</label><mixed-citation publication-type=\"other\">Wang, X., Liu, K. &amp; Wang, C. Knowledge-enhanced Pre-training large language model for depression diagnosis and treatment. In <italic toggle=\"yes\">2023 IEEE 9th International Conference on Cloud Computing and Intelligent Systems (CCIS)</italic>, 532-536 (IEEE, 2023).</mixed-citation></ref><ref id=\"CR15\"><label>15.</label><mixed-citation publication-type=\"other\">Agrawal, A. Illuminate: a novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering. Preprint at 10.48550/arXiv.2402.05127 (2024).</mixed-citation></ref><ref id=\"CR16\"><label>16.</label><mixed-citation publication-type=\"other\">Chen, Z., Lu, Y. &amp; Wang, W. Y. Empowering psychotherapy with large language models: cognitive distortion detection through diagnosis of thought prompting. In <italic toggle=\"yes\">Findings of the Association for Computational Linguistics: EMNLP 2023</italic>, 4295&#8211;4304 (Association for Computational Linguistics, 2023).</mixed-citation></ref><ref id=\"CR17\"><label>17.</label><mixed-citation publication-type=\"other\">Liu, J. M. et al. ChatCounselor: a large language models for mental health support. Preprint at10.48550/arXiv.2309.15461 (2023).</mixed-citation></ref><ref id=\"CR18\"><label>18.</label><mixed-citation publication-type=\"other\">Li, J. et al. Agent hospital: a simulacrum of hospital with evolvable medical agents. Preprint at 10.48550/arXiv.2405.02957 (2024).</mixed-citation></ref><ref id=\"CR19\"><label>19.</label><mixed-citation publication-type=\"other\">Xin, A. W. et al. Using large language models to detect outcomes in qualitative studies on adolescent depression. <italic toggle=\"yes\">J. Am. Med. Inform. Assoc.</italic> ocae298, 10.1093/jamia/ocae298 (2024).<pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1093/jamia/ocae298</pub-id><pub-id pub-id-type=\"pmid\">39661754</pub-id></mixed-citation></ref><ref id=\"CR20\"><label>20.</label><citation-alternatives><element-citation id=\"ec-CR20\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Elyoseph</surname><given-names>Z</given-names></name><name name-style=\"western\"><surname>Levkovich</surname><given-names>I</given-names></name><name name-style=\"western\"><surname>Shinan-Altman</surname><given-names>S</given-names></name></person-group><article-title>Assessing prognosis in depression: Comparing perspectives of AI models, mental health professionals and the general public</article-title><source>Fam. Med. Community Health</source><year>2024</year><volume>12</volume><fpage>e002583</fpage><pub-id pub-id-type=\"doi\">10.1136/fmch-2023-002583</pub-id><pub-id pub-id-type=\"pmid\">38199604</pub-id><pub-id pub-id-type=\"pmcid\">PMC10806564</pub-id></element-citation><mixed-citation id=\"mc-CR20\" publication-type=\"journal\">Elyoseph, Z., Levkovich, I. &amp; Shinan-Altman, S. Assessing prognosis in depression: Comparing perspectives of AI models, mental health professionals and the general public. <italic toggle=\"yes\">Fam. Med. Community Health</italic><bold>12</bold>, e002583 (2024).<pub-id pub-id-type=\"pmid\">38199604</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1136/fmch-2023-002583</pub-id><pub-id pub-id-type=\"pmcid\">PMC10806564</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR21\"><label>21.</label><citation-alternatives><element-citation id=\"ec-CR21\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Barua</surname><given-names>PD</given-names></name><etal/></person-group><article-title>Artificial intelligence assisted tools for the detection of anxiety and depression leading to suicidal ideation in adolescents: a review</article-title><source>Cognit. Neurodyn.</source><year>2024</year><volume>18</volume><fpage>1</fpage><lpage>22</lpage><pub-id pub-id-type=\"doi\">10.1007/s11571-022-09904-0</pub-id><pub-id pub-id-type=\"pmcid\">PMC9684805</pub-id><pub-id pub-id-type=\"pmid\">36467993</pub-id></element-citation><mixed-citation id=\"mc-CR21\" publication-type=\"journal\">Barua, P. D. et al. Artificial intelligence assisted tools for the detection of anxiety and depression leading to suicidal ideation in adolescents: a review. <italic toggle=\"yes\">Cognit. Neurodyn.</italic><bold>18</bold>, 1&#8211;22 (2024).<pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1007/s11571-022-09904-0</pub-id><pub-id pub-id-type=\"pmcid\">PMC9684805</pub-id><pub-id pub-id-type=\"pmid\">36467993</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR22\"><label>22.</label><mixed-citation publication-type=\"other\">Ferguson, S., Aoyagui, P. A., Rizvi, R., Kim, Y.-H. &amp; Kuzminykh, A. The explanation that hits home: the characteristics of verbal explanations that affect human perception in subjective decision-making8, 517:1&#8211;517:37. 10.1145/3687056.</mixed-citation></ref><ref id=\"CR23\"><label>23.</label><citation-alternatives><element-citation id=\"ec-CR23\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Lawrence</surname><given-names>HR</given-names></name><etal/></person-group><article-title>The opportunities and risks of large language models in mental health</article-title><source>JMIR Ment. Health</source><year>2024</year><volume>11</volume><fpage>e59479</fpage><pub-id pub-id-type=\"doi\">10.2196/59479</pub-id><pub-id pub-id-type=\"pmid\">39105570</pub-id><pub-id pub-id-type=\"pmcid\">PMC11301767</pub-id></element-citation><mixed-citation id=\"mc-CR23\" publication-type=\"journal\">Lawrence, H. R. et al. The opportunities and risks of large language models in mental health. <italic toggle=\"yes\">JMIR Ment. Health</italic><bold>11</bold>, e59479 (2024).<pub-id pub-id-type=\"pmid\">39105570</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.2196/59479</pub-id><pub-id pub-id-type=\"pmcid\">PMC11301767</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR24\"><label>24.</label><mixed-citation publication-type=\"other\">ICD-10 Version:2016. <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://icd.who.int/browse10/2016/en\">https://icd.who.int/browse10/2016/en</ext-link>.</mixed-citation></ref><ref id=\"CR25\"><label>25.</label><mixed-citation publication-type=\"other\">Duckworth, K. <italic toggle=\"yes\">Understanding Mental Disorders: Your Guide to DSM-5.</italic> (American Psychiatric Association Publishing, Washington, D.C., 2015) 10.1176/appi.ajp.2015.15070879.</mixed-citation></ref><ref id=\"CR26\"><label>26.</label><mixed-citation publication-type=\"other\">Yang, A. et al. Qwen2 technical report. Preprint at arXiv preprint at <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://arxiv.org/abs/2407.10671\">https://arxiv.org/abs/2407.10671</ext-link> (2024).</mixed-citation></ref><ref id=\"CR27\"><label>27.</label><mixed-citation publication-type=\"other\">Hu, E. J. et al. LoRA: Low-rank adaptation of large language models. Preprint at arXiv preprint at <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://arxiv.org/abs/2106.09685\">https://arxiv.org/abs/2106.09685</ext-link> (2021).</mixed-citation></ref><ref id=\"CR28\"><label>28.</label><mixed-citation publication-type=\"other\">Derogatis, L. R. &amp; Unger, R. Symptom Checklist-90-Revised. In Corsini Encyclopedia of Psychology. 10.1002/9780470479216.CORPSY0970 (2010).</mixed-citation></ref><ref id=\"CR29\"><label>29.</label><citation-alternatives><element-citation id=\"ec-CR29\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>ZUNG</surname><given-names>WWK</given-names></name></person-group><article-title>A self-rating depression scale</article-title><source>Arch. Gen. Psychiatry</source><year>1965</year><volume>12</volume><fpage>63</fpage><lpage>70</lpage><pub-id pub-id-type=\"doi\">10.1001/archpsyc.1965.01720310065008</pub-id><pub-id pub-id-type=\"pmid\">14221692</pub-id></element-citation><mixed-citation id=\"mc-CR29\" publication-type=\"journal\">ZUNG, W. W. K. A self-rating depression scale. <italic toggle=\"yes\">Arch. Gen. Psychiatry</italic><bold>12</bold>, 63&#8211;70 (1965).<pub-id pub-id-type=\"pmid\">14221692</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1001/archpsyc.1965.01720310065008</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR30\"><label>30.</label><citation-alternatives><element-citation id=\"ec-CR30\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Zung</surname><given-names>WW</given-names></name></person-group><article-title>A rating instrument for anxiety disorders</article-title><source>Psychosomatics</source><year>1971</year><volume>12</volume><fpage>371</fpage><lpage>379</lpage><pub-id pub-id-type=\"doi\">10.1016/S0033-3182(71)71479-0</pub-id><pub-id pub-id-type=\"pmid\">5172928</pub-id></element-citation><mixed-citation id=\"mc-CR30\" publication-type=\"journal\">Zung, W. W. A rating instrument for anxiety disorders. <italic toggle=\"yes\">Psychosomatics</italic><bold>12</bold>, 371&#8211;379 (1971).<pub-id pub-id-type=\"pmid\">5172928</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1016/S0033-3182(71)71479-0</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR31\"><label>31.</label><mixed-citation publication-type=\"other\">Hamilton, M. The Hamilton Rating Scale for Depression. In Sartorius, N. &amp; Ban, T. A. (eds.) <italic toggle=\"yes\">Assessment of Depression</italic>, 143&#8722;152. 10.1007/978-3-642-70486-4_14 (Springer Berlin Heidelberg, 1986).</mixed-citation></ref><ref id=\"CR32\"><label>32.</label><citation-alternatives><element-citation id=\"ec-CR32\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Hamilton</surname><given-names>M</given-names></name></person-group><article-title>The assessment of anxiety states by rating</article-title><source>Br. J. Med. Psychol.</source><year>1959</year><volume>32</volume><fpage>50</fpage><lpage>55</lpage><pub-id pub-id-type=\"doi\">10.1111/j.2044-8341.1959.tb00467.x</pub-id><pub-id pub-id-type=\"pmid\">13638508</pub-id></element-citation><mixed-citation id=\"mc-CR32\" publication-type=\"journal\">Hamilton, M. The assessment of anxiety states by rating. <italic toggle=\"yes\">Br. J. Med. Psychol.</italic><bold>32</bold>, 50&#8211;55 (1959).<pub-id pub-id-type=\"pmid\">13638508</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1111/j.2044-8341.1959.tb00467.x</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR33\"><label>33.</label><citation-alternatives><element-citation id=\"ec-CR33\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Williams</surname><given-names>JBW</given-names></name><name name-style=\"western\"><surname>Kobak</surname><given-names>KA</given-names></name></person-group><article-title>Development and reliability of a structured interview guide for the Montgomery Asberg Depression Rating Scale (SIGMA)</article-title><source>Br. J. Psychiatry.</source><year>2008</year><volume>192</volume><fpage>52</fpage><lpage>58</lpage><pub-id pub-id-type=\"doi\">10.1192/bjp.bp.106.032532</pub-id><pub-id pub-id-type=\"pmid\">18174510</pub-id></element-citation><mixed-citation id=\"mc-CR33\" publication-type=\"journal\">Williams, J. B. W. &amp; Kobak, K. A. Development and reliability of a structured interview guide for the Montgomery Asberg Depression Rating Scale (SIGMA). <italic toggle=\"yes\">Br. J. Psychiatry.</italic><bold>192</bold>, 52&#8211;58 (2008).<pub-id pub-id-type=\"pmid\">18174510</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1192/bjp.bp.106.032532</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR34\"><label>34.</label><mixed-citation publication-type=\"other\">Pennebaker, J. W., Boyd, R. L., Jordan, K. &amp; Blackburn, K. The development and psychometric properties of LIWC2015 <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://repositories.lib.utexas.edu/items/705e81ca-940d-4c46-94ec-a52ffdc3b51f\">https://repositories.lib.utexas.edu/items/705e81ca-940d-4c46-94ec-a52ffdc3b51f</ext-link>.</mixed-citation></ref><ref id=\"CR35\"><label>35.</label><mixed-citation publication-type=\"other\">TF-IDF. In Sammut, C. &amp; Webb, G. I. (eds.) <italic toggle=\"yes\">Encyclopedia of Machine Learning</italic>, 986-987 (Springer US). 10.1007/978-0-387-30164-8_832.</mixed-citation></ref><ref id=\"CR36\"><label>36.</label><mixed-citation publication-type=\"other\">Zeng, X., Yang, C., Tu, C., Liu, Z. &amp; Sun, M. Chinese liwc lexicon expansion via hierarchical classification of word embeddings with sememe attention. In <italic toggle=\"yes\">Proc. AAAI conference on artificial intelligence (AAAI Press)</italic>, Vol. 32, 10.1609/aaai.v32i1.11982 (2018).</mixed-citation></ref><ref id=\"CR37\"><label>37.</label><mixed-citation publication-type=\"other\">Eyben, F., W&#246;llmer, M. &amp; Schuller, B. Opensmile: the munich versatile and fast open-source audio feature extractor. In <italic toggle=\"yes\">Proc. 18th ACM international conference on Multimedia</italic>, MM &#8217;10, 1459-1462 (Association for Computing Machinery). 10.1145/1873951.1874246.</mixed-citation></ref><ref id=\"CR38\"><label>38.</label><citation-alternatives><element-citation id=\"ec-CR38\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Chawla</surname><given-names>NV</given-names></name><name name-style=\"western\"><surname>Bowyer</surname><given-names>KW</given-names></name><name name-style=\"western\"><surname>Hall</surname><given-names>LO</given-names></name><name name-style=\"western\"><surname>Kegelmeyer</surname><given-names>WP</given-names></name></person-group><article-title>SMOTE: synthetic minority over-sampling technique</article-title><source>J. Artif. Intell. Res.</source><year>2002</year><volume>16</volume><fpage>321</fpage><lpage>357</lpage><pub-id pub-id-type=\"doi\">10.1613/jair.953</pub-id></element-citation><mixed-citation id=\"mc-CR38\" publication-type=\"journal\">Chawla, N. V., Bowyer, K. W., Hall, L. O. &amp; Kegelmeyer, W. P. SMOTE: synthetic minority over-sampling technique. <italic toggle=\"yes\">J. Artif. Intell. Res.</italic><bold>16</bold>, 321&#8211;357 (2002).</mixed-citation></citation-alternatives></ref><ref id=\"CR39\"><label>39.</label><mixed-citation publication-type=\"other\">Devlin, J., Chang, M., Lee, K. &amp; Toutanova, K. BERT: pre-training of deep bidirectional transformers for language understanding. CoRR abs/1810.04805, <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"http://arxiv.org/abs/1810.04805\">http://arxiv.org/abs/1810.04805</ext-link> (2018).</mixed-citation></ref><ref id=\"CR40\"><label>40.</label><mixed-citation publication-type=\"other\">Liu, Y. et al. Roberta: a robustly optimized bert pretraining approach. Preprint at arXiv preprint at 10.48550/arXiv.1907.11692 (2019).</mixed-citation></ref><ref id=\"CR41\"><label>41.</label><mixed-citation publication-type=\"other\">Cui, Y. et al. Revisiting pre-trained models for Chinese natural language processing. In <italic toggle=\"yes\">Proc. 2020 Conference on Empirical Methods in Natural Language Processing: Findings</italic>, 657-668, <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://www.aclweb.org/anthology/2020.findings-emnlp.58\">https://www.aclweb.org/anthology/2020.findings-emnlp.58</ext-link> (Association for Computational Linguistics, Online, 2020).</mixed-citation></ref><ref id=\"CR42\"><label>42.</label><citation-alternatives><element-citation id=\"ec-CR42\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Goh</surname><given-names>E</given-names></name><etal/></person-group><article-title>Large language model influence on diagnostic reasoning: a randomized clinical trial</article-title><source>JAMA Netw. Open</source><year>2024</year><volume>7</volume><fpage>e2440969</fpage><pub-id pub-id-type=\"doi\">10.1001/jamanetworkopen.2024.40969</pub-id><pub-id pub-id-type=\"pmid\">39466245</pub-id><pub-id pub-id-type=\"pmcid\">PMC11519755</pub-id></element-citation><mixed-citation id=\"mc-CR42\" publication-type=\"journal\">Goh, E. et al. Large language model influence on diagnostic reasoning: a randomized clinical trial. <italic toggle=\"yes\">JAMA Netw. Open</italic><bold>7</bold>, e2440969 (2024).<pub-id pub-id-type=\"pmid\">39466245</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1001/jamanetworkopen.2024.40969</pub-id><pub-id pub-id-type=\"pmcid\">PMC11519755</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR43\"><label>43.</label><mixed-citation publication-type=\"other\">Stade, E. C. et al. Large language models could change the future of behavioral healthcare: a proposal for responsible development and evaluation. In: <italic toggle=\"yes\">npj Mental Health Research 3.1</italic>, pp. 1-12. 10.1038/s44184-024-00056-z (2024).<pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1038/s44184-024-00056-z</pub-id><pub-id pub-id-type=\"pmcid\">PMC10987499</pub-id><pub-id pub-id-type=\"pmid\">38609507</pub-id></mixed-citation></ref><ref id=\"CR44\"><label>44.</label><mixed-citation publication-type=\"other\">Xu, S. et al. Automated Verbal and Non-verbal Speech Analysis of Interviews of Individuals with Schizophrenia and Depression. In <italic toggle=\"yes\">2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)</italic>, 225-228 (IEEE, 2019).<pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1109/EMBC.2019.8857071</pub-id><pub-id pub-id-type=\"pmid\">31945883</pub-id></mixed-citation></ref><ref id=\"CR45\"><label>45.</label><mixed-citation publication-type=\"other\">Li, L., Zhang, X., Zhou, X. &amp; Liu, Z. AutoMIR: Effective zero-shot medical information retrieval without relevance labels. <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"http://arxiv.org/abs/2410.20050\">http://arxiv.org/abs/2410.20050</ext-link>.</mixed-citation></ref><ref id=\"CR46\"><label>46.</label><mixed-citation publication-type=\"other\">Sadariya, T. &amp; Verma, S. Early prediction and detection of anxiety level using support vector machine. In Swaroop, A., Polkowski, Z., Correia, S. D. &amp; Virdee, B. (eds.). In <italic toggle=\"yes\">Proc. Data Analytics and Management</italic>, 279&#8211;291 (Springer Nature, 2023).</mixed-citation></ref><ref id=\"CR47\"><label>47.</label><mixed-citation publication-type=\"other\">Harati, A. et al. Speech-based depression prediction using encoder-weight-only transfer learning and a large corpus. In <italic toggle=\"yes\">ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</italic>, 7273-7277 (IEEE, 2021).</mixed-citation></ref><ref id=\"CR48\"><label>48.</label><citation-alternatives><element-citation id=\"ec-CR48\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Dibeklio&#287;lu</surname><given-names>H</given-names></name><name name-style=\"western\"><surname>Hammal</surname><given-names>Z</given-names></name><name name-style=\"western\"><surname>Yang</surname><given-names>Y</given-names></name><name name-style=\"western\"><surname>Cohn</surname><given-names>JF</given-names></name></person-group><article-title>Multimodal detection of depression in clinical interviews</article-title><source>Proc. ACM Int. Conf. Multimodal Interact. ICMI</source><year>2015</year><volume>2015</volume><fpage>307</fpage><lpage>310</lpage><pub-id pub-id-type=\"doi\">10.1145/2818346.2820776</pub-id><pub-id pub-id-type=\"pmid\">27213186</pub-id><pub-id pub-id-type=\"pmcid\">PMC4874497</pub-id></element-citation><mixed-citation id=\"mc-CR48\" publication-type=\"journal\">Dibeklio&#287;lu, H., Hammal, Z., Yang, Y. &amp; Cohn, J. F. Multimodal detection of depression in clinical interviews. <italic toggle=\"yes\">Proc. ACM Int. Conf. Multimodal Interact. ICMI</italic><bold>2015</bold>, 307&#8211;310 (2015).<pub-id pub-id-type=\"pmid\">27213186</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1145/2818346.2820776</pub-id><pub-id pub-id-type=\"pmcid\">PMC4874497</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR49\"><label>49.</label><citation-alternatives><element-citation id=\"ec-CR49\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Hettema</surname><given-names>JM</given-names></name><name name-style=\"western\"><surname>Aggen</surname><given-names>SH</given-names></name><name name-style=\"western\"><surname>Kubarych</surname><given-names>TS</given-names></name><name name-style=\"western\"><surname>Neale</surname><given-names>MC</given-names></name><name name-style=\"western\"><surname>Kendler</surname><given-names>KS</given-names></name></person-group><article-title>Identification and validation of mixed anxiety&#8211;depression</article-title><source>Psychol. Med.</source><year>2015</year><volume>45</volume><fpage>3075</fpage><lpage>3084</lpage><pub-id pub-id-type=\"doi\">10.1017/S0033291715001038</pub-id><pub-id pub-id-type=\"pmid\">26050714</pub-id></element-citation><mixed-citation id=\"mc-CR49\" publication-type=\"journal\">Hettema, J. M., Aggen, S. H., Kubarych, T. S., Neale, M. C. &amp; Kendler, K. S. Identification and validation of mixed anxiety&#8211;depression. <italic toggle=\"yes\">Psychol. Med.</italic><bold>45</bold>, 3075&#8211;3084 (2015).<pub-id pub-id-type=\"pmid\">26050714</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1017/S0033291715001038</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR50\"><label>50.</label><citation-alternatives><element-citation id=\"ec-CR50\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Richter</surname><given-names>T</given-names></name><name name-style=\"western\"><surname>Fishbain</surname><given-names>B</given-names></name><name name-style=\"western\"><surname>Markus</surname><given-names>A</given-names></name><name name-style=\"western\"><surname>Richter-Levin</surname><given-names>G</given-names></name><name name-style=\"western\"><surname>Okon-Singer</surname><given-names>H</given-names></name></person-group><article-title>Using machine learning-based analysis for behavioral differentiation between anxiety and depression</article-title><source>Sci. Rep.</source><year>2020</year><volume>10</volume><fpage>16381</fpage><pub-id pub-id-type=\"doi\">10.1038/s41598-020-72289-9</pub-id><pub-id pub-id-type=\"pmid\">33009424</pub-id><pub-id pub-id-type=\"pmcid\">PMC7532220</pub-id></element-citation><mixed-citation id=\"mc-CR50\" publication-type=\"journal\">Richter, T., Fishbain, B., Markus, A., Richter-Levin, G. &amp; Okon-Singer, H. Using machine learning-based analysis for behavioral differentiation between anxiety and depression. <italic toggle=\"yes\">Sci. Rep.</italic><bold>10</bold>, 16381 (2020).<pub-id pub-id-type=\"pmid\">33009424</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1038/s41598-020-72289-9</pub-id><pub-id pub-id-type=\"pmcid\">PMC7532220</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR51\"><label>51.</label><citation-alternatives><element-citation id=\"ec-CR51\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Liu</surname><given-names>K</given-names></name><name name-style=\"western\"><surname>Droncheff</surname><given-names>B</given-names></name><name name-style=\"western\"><surname>Warren</surname><given-names>SL</given-names></name></person-group><article-title>Predictive utility of symptom measures in classifying anxiety and depression: a machine-learning approach</article-title><source>Psychiatry Res.</source><year>2022</year><volume>312</volume><fpage>114534</fpage><pub-id pub-id-type=\"doi\">10.1016/j.psychres.2022.114534</pub-id><pub-id pub-id-type=\"pmid\">35381506</pub-id><pub-id pub-id-type=\"pmcid\">PMC9117511</pub-id></element-citation><mixed-citation id=\"mc-CR51\" publication-type=\"journal\">Liu, K., Droncheff, B. &amp; Warren, S. L. Predictive utility of symptom measures in classifying anxiety and depression: a machine-learning approach. <italic toggle=\"yes\">Psychiatry Res.</italic><bold>312</bold>, 114534 (2022).<pub-id pub-id-type=\"pmid\">35381506</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1016/j.psychres.2022.114534</pub-id><pub-id pub-id-type=\"pmcid\">PMC9117511</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR52\"><label>52.</label><citation-alternatives><element-citation id=\"ec-CR52\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Clark</surname><given-names>LA</given-names></name><name name-style=\"western\"><surname>Watson</surname><given-names>D</given-names></name></person-group><article-title>Tripartite model of anxiety and depression: psychometric evidence and taxonomic implications</article-title><source>J. Abnorm. Psychol.</source><year>1991</year><volume>100</volume><fpage>316</fpage><lpage>336</lpage><pub-id pub-id-type=\"doi\">10.1037/0021-843X.100.3.316</pub-id><pub-id pub-id-type=\"pmid\">1918611</pub-id></element-citation><mixed-citation id=\"mc-CR52\" publication-type=\"journal\">Clark, L. A. &amp; Watson, D. Tripartite model of anxiety and depression: psychometric evidence and taxonomic implications. <italic toggle=\"yes\">J. Abnorm. Psychol.</italic><bold>100</bold>, 316&#8211;336 (1991).<pub-id pub-id-type=\"pmid\">1918611</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1037//0021-843x.100.3.316</pub-id></mixed-citation></citation-alternatives></ref></ref-list></back></article></pmc-articleset>",
  "text": "pmc Npj Ment Health Res Npj Ment Health Res 4551 npjmhres NPJ Mental Health Research 2731-4251 Nature Publishing Group PMC12672715 PMC12672715.1 12672715 12672715 41331078 10.1038/s44184-025-00175-1 175 1 Article Identifying psychiatric manifestations in outpatients with depression and anxiety: a large language model-based approach Xu Shihao 1 2 3 Yan Yiming 1 4 Ding Yanli 1 4 Li Feng 2 Zhang Shu 2 Tang Haoyun 1 4 Luo Chao 1 4 Li Yan 1 4 Liu Hao 1 Mei Yu 1 Gu Wenjie 1 Qiu Hong 1 Wang Yong 1 4 Qiu Jianyin 1 4 Yang Tao 3 Wang Zike 2 Zhang Qing 1 4 5 Geng Haiyang 3 Han Yunyun 3 Shao Jun 2 Opel Nils 6 7 Bing Lidong 3 Zhao Min 1 4 5 Xu Yifeng 1 4 5 Jiang Xun xun.jiang@thetahealth.ai 2 3 Chen Jianhua jianhua.chen@smhc.org.cn 1 3 4 5 1 https://ror.org/0220qvk04 grid.16821.3c 0000 0004 0368 8293 Shanghai Mental Health Center, Shanghai Jiao Tong University School of Medicine, Shanghai, China 2 Theta Health Inc., Redwood City, CA USA 3 Tianqiao and Chrissy Chen Institute, Shanghai, China 4 https://ror.org/057tkkm33 grid.452344.0 Shanghai Clinical Research Center for Mental Health, Shanghai, China 5 https://ror.org/05bd2wa15 grid.415630.5 0000 0004 1782 6212 Shanghai Key Laboratory of Psychotic Disorder, Shanghai, China 6 https://ror.org/035rzkx15 grid.275559.9 0000 0000 8517 6224 University Hospital Jena Department of Psychiatry and Psychotherapy, Jena, Germany 7 German Centre for Mental Health (DZPG), Berlin, Germany 2 12 2025 2025 4 479056 63 24 1 2025 10 11 2025 02 12 2025 04 12 2025 04 12 2025 &#169; The Author(s) 2025 2025 https://creativecommons.org/licenses/by-nc-nd/4.0/ Open Access This article is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License, which permits any non-commercial use, sharing, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if you modified the licensed material. You do not have permission under this licence to share adapted material derived from this article or parts of it. The images or other third party material in this article are included in the article&#8217;s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article&#8217;s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by-nc-nd/4.0/ . Accurate psychiatric diagnosis and assessment are crucial for effective treatment. However, current diagnostic approaches heavily rely on subjective observations constrained by time and clinical resources. This study investigates the potential of using Large Language Models (LLMs) to identify the symptoms in psychiatrist-patient dialogues and use them as intermediate features to predict the diagnostic labels. We collected audio recordings of 1160 outpatients with depressive disorder and anxiety disorder. LLMs were trained and utilized to identify clinical symptoms, rate assessment scales, and an ensemble learning pipeline was designed to classify diagnostic results and symptoms with 10-fold cross-validation. The system achieved 86.9% accuracy for identifying the appearance of clinical annotations and 74.7% (77.2%) accuracy for identifying symptoms of anxiety (depression). In addition, analysis of LLM-generated features shows that depression cases exhibited prominent markers of anhedonia and decreased volition, whereas anxiety disorders were characterized by tension and an inability to relax. Subject terms Predictive markers Anxiety Depression Human behaviour Tianqiao and Chrissy Chen Institute 2023-TX-018 2023-TX-018 2023-TX-018 2023-TX-018 2023-TX-018 2023-TX-018 National Natural Science Foundation of China 82071500 82071500 82071500 82071500 82071500 82071500 Program of Shanghai Academic/Technology Research Leader 21XD1423300 21XD1423300 21XD1423300 21XD1423300 21XD1423300 21XD1423300 pmc-status-qastatus 0 pmc-status-live yes pmc-status-embargo no pmc-status-released yes pmc-prop-open-access yes pmc-prop-olf no pmc-prop-manuscript no pmc-prop-legally-suppressed no pmc-prop-has-pdf yes pmc-prop-has-supplement yes pmc-prop-pdf-only no pmc-prop-suppress-copyright no pmc-prop-is-real-version no pmc-prop-is-scanned-article no pmc-prop-preprint no pmc-prop-in-epmc yes issue-copyright-statement &#169; Springer Nature Limited 2025 Introduction Depression and anxiety disorders represent two of the most prevalent mental health conditions globally. Globally, it is estimated that over 300 million people suffer from major depressive disorders, which is equivalent to 4.4% of the world&#8217;s population. A similar number of people suffer from anxiety disorders, often with co-occurring depression 1 . The emerging field of digital phenotyping, which involves the nuanced quantification of human phenotypic expression at the individual level through digital device data, offers a quantitative approach to longitudinal observation 2 . The emerging field of digital phenotyping, characterized by continuous and nuanced quantification of human phenotypic expression at the individual level by leveraging digital device data, provides a quantitative approach for longitudinal observation 2 . Researchers have demonstrated that social signals (e.g., linguistics, speech, etc.) play a crucial role in the diagnosis and assessment of patients with depression and anxiety 3 , 4 . In particular, the content of a patient&#8217;s speech provides rich information about their mental state, cognitive patterns, and emotional experiences 5 , 6 . The linguistic features, topic choices, and narrative structures employed by individuals can offer valuable insights into their psychological well-being 6 . Recent advances in NLP, particularly in LLMs such as GPT 7 , Gemini 8 , and Qwen 9 , demonstrate diverse capabilities in clinical reasoning, social media analysis, and psychiatric education 10 , which could potentially provide objective, data-driven insights in psychiatry. Moreover, LLMs are able to process, generate, and respond to natural language inputs, which fit naturally into the NIMH&#8217;s Research Domain Criteria (RDoC) framework, which suggests new ways of classifying mental disorders based on dimensions of observable behaviors 11 . In recent psychiatric studies, these LLMs excel at understanding and generating complex linguistic patterns with human-like performance, making them widely explored for social media content analysis 12 , 13 , treatment performance enhancement 14 &#8211; 16 , chat counselor 17 , 18 , and supporting clinical decision-making 19 , 20 from an evidence-based practice perspective. Although LLMs demonstrate linguistic understanding and generation, they remain relatively scarce in producing objective digital biomarkers in psychiatry 21 . Studies have shown that the speech of patients with depression and anxiety contains distinctive quantitative verbal and nonverbal digital markers compared to healthy controls 4 , 6 , but these characteristics often remain too subtle for humans to perceive actionable insights, making their practical application and improvement challenging 22 . LLM is able to generate diagnostic results and provide reasoning steps, benefiting from a large amount of pre-training data. However, the interpretation and alignment of answers or decisions generated by LLM remain challenging 23 . Moreover, most studies on depression and anxiety rely primarily on two data sources: social media and structured clinical reports, and are often constrained by limited data availability 3 . Distinguishing between depression and anxiety in clinical settings remains challenging due to the overlap of symptoms and the high comorbidity rate, with limited research on the discovery of objective biomarkers for both conditions 21 . In addition, during clinical interviews, psychiatrists translate patients&#8217; informal symptom descriptions into professional diagnostic terminology; however, there remains a lack of approaches to automatically and effectively bridge this &#8220;semantic gap\" between patients and clinicians. To address these gaps in existing research, we collected a comprehensive dataset of psychiatric interviews at the Shanghai Mental Health Center (SMHC) in China, comprising over 15,000&#8201;min of speech recordings from 1160 individual outpatients with 25 different diagnoses. These recordings, primarily featuring patients diagnosed with depression and anxiety disorders, were collected in unstructured real-world environments to ensure ecological validity. To mimic the characteristics of clinical diagnosis, we designed a corpus of clinical indicators that incorporates diagnostic criteria, main complaints, mental status evaluations, and components from assessment scales using the Electronic Medical Records (EMRs) in the SMHC and widely-used assessment scales. Subsequently, we employed the pre-trained LLM to indicate the appearance of a corpus of clinical-related symptoms, rate the components of several assessment scales, and further fine-tuned the LLM with clinical annotations from professional psychiatrists to enhance its understanding of clinical-related concepts. In parallel, we extracted linguistic usage patterns and acoustic features to broaden the spectrum of biomarkers. Through the fusion of these modalities, we constructed an ensemble machine-learning pipeline capable of predicting both outpatient diagnostic groups and symptoms with moderately high accuracies. Moreover, we conducted an in-depth analysis of salient patterns between different diagnostic groups to enhance clinical interpretability. Our results demonstrate that objective cues extracted by the LLM, combined with other behavioral markers, can serve as valuable features for differentiating diagnostic groups and identifying symptom disclosure, potentially enhancing both the efficiency and effectiveness of psychiatric diagnosis and assessment in clinical practice. Methods This study collected the audio recording of 1160 participants between August 2023 and January 2024, in collaboration with the SMHC. The overall pipeline is shown in Fig. 1 . Data collection was conducted using the Scientific Speech Transcription Pen M1 (Iflytek Co., Ltd.) with a sampling rate of 44100&#8201;Hz. Firstly, the protocol involved three primary stages: preprocessing of audio samples, anonymization of personally identifiable information, and subsequent transcription via automated speech recognition systems followed by meticulous manual verification to ensure transcriptional accuracy. Secondly, we collaborated with professional psychiatrists to design a set of clinical entities and leveraged the LLM to identify these concepts using the transcripts as input, enhancing the LLM based on the psychiatrists&#8217; annotations through supervised fine-tuning (SFT). Linguistic and acoustic features were extracted from both the transcripts and the speech. Finally, we utilized different modalities to train an ensemble machine learning pipeline to differentiate diagnostic groups and the major symptoms. Fig. 1 Diagram of the analysis pipeline. The audio recordings were collected during the diagnosis interview for outpatients. We extracted four types of feature sets from the recordings, two of which utilized LLM. These feature sets were utilized to classify different groups of participants and predict the appearance of depression and anxiety symptoms. Participants The study sample comprised outpatients from the SMHC who attended clinical diagnostic interviews. Participants were aged 12 to 80 years and were fluent in Mandarin. Informed consent to participate in the study was obtained from all participants or their legal guardians, as appropriate. All diagnoses were established using the Chinese version of WHO International Classification of Diseases, Tenth Revision (ICD-10) 24 . The study protocol was approved by the Ethics Committee of the SMHC institutional review board (IRB) to ensure compliance with ethical research standards. Specifically, the recording setup consisted of a microphone placed between the psychiatrist and the participant, connected to a computer. At the beginning of each interview, participants were asked to read a standardized 30-second text passage, followed by the standard diagnostic procedure. All clinical information was documented in the EMR system by the psychiatrists. To protect the privacy of participants, all audio recordings and associated meta-information underwent a thorough manual de-identification process. Feature extraction We extracted a comprehensive clinical entity set to cover the intermediate features that assist psychiatrists in the diagnosis and assessment process: clinical observations and standardized assessment scales, which we designate as clinical-related and assessment-related feature sets. A clinical entity, in the context of our pipeline, is a structured representation of a psychiatric symptom or construct, developed from both clinical observations and standardized assessment scales. It encompasses key terms, expressions, and severity indicators related to specific diagnostic features, and serves as a unified unit for symptom detection and classification in our system. As compensation, we measured the linguistic usage and acoustic characteristics and form as individual feature sets. In the following paragraphs, we will introduce how we build and extract these feature sets in detail. The clinical-related feature set encompasses essential depression and anxiety indicators extracted from EMRs with comprehensive descriptions (shown in Supplementary Table 1 ). This feature set was developed through a collaborative approach involving both psychiatrists and LLM analysis. Firstly, the process began with extracting 218 clinical entities from three sections in the EMR system: chief complaint, personal medical history, and psychiatric examination. These entities represent predefined features within the documentation framework of the SMHC EMR system based on psychiatric diagnostic systems, textbooks, and experts&#8217; opinions. Then, we included a supplementary of 44 additional symptoms identified through clinical expertise and diagnostic criteria (e.g., DSM-5 and ICD-10) suggested by psychiatrists. We then utilized the Gemini 1.5 Pro 8 to generate descriptions for all clinical entities, using the Chinese version of the DSM-5 guidance 25 as a reference, leveraging the model&#8217;s strong extended context window capability. Through iterative psychiatric review, redundant and irrelevant items specific to depression and anxiety were eliminated, resulting in a refined set of 138 validated clinical-related features. After rigorously defining the clinical-related features, we leveraged large language models to extract symptom information from diagnostic conversations. We employed Qwen2-72B-Instruct 26 as our foundational model due to its advanced Chinese language processing capabilities and suitability for offline deployment within secure hospital environments. To enhance domain-specific performance, we implemented SFT using psychiatrists&#8217; annotations from electronic medical records EMRs. This approach adapted the base model to better recognize specialized medical terminology and clinical reasoning patterns specific to psychiatric assessment contexts. The fine-tuning methodology treated symptom identification as an autoregressive task, where the model learns to predict token probabilities based on previous context, ultimately generating binary judgments (&#8220;yes&#8221; or &#8220;no&#8221;) regarding specific symptom presence. The training data comprised individual samples where dialogue content, patient demographics (age, gender), and symptom categories were incorporated into prompt templates alongside corresponding symptom occurrence labels extracted from EMRs. For each clinical conversation, we systematically extracted all documented symptoms to create comprehensive training instances. The fine-tuning implementation utilized LLaMA-Factory ( https://github.com/hiyouga/LLaMA-Factory ), while inference processes were facilitated through vLLM ( https://github.com/vllm-project/vllm ). All computational procedures were executed on a high-performance computing infrastructure consisting of four A100 GPUs. Table 1 presents the prompt architecture used both for clinical feature generation and model fine-tuning (Supplementary Table 4 for the Chinese version), demonstrating our structured approach to symptom extraction within extended clinical dialogues. Table 1 Prompt template for clinical-related feature generation The content within the curly braces is the demographic, symptom descriptions, and dialogue information that form the prompt. We first began with structuring EMR data to create reliable training labels for the SFT. Since EMRs contain unstructured text fields where psychiatrists document patient information, we employed the LLM to analyze these 1160 EMRs. For each EMR, we leveraged LLM to evaluate the presence of above mentioned 138 predefined clinical features, including similar expressions and synonyms, generating a boolean value list (yes/no) for each record. The prompt for querying the LLM to generate labels from EMRs is shown in Supplementary Table 3 (Supplementary Table 6 for the Chinese version). Secondly, we implemented a rigorous filtering process for choosing high-quality data for SFT. We first leverage LLM to verify whether the information recorded in EMRs was adequately reflected in the interview dialogue transcripts, yielding 877 valid examples. Then, we collaborated with specialist psychiatrists to establish comprehensive evaluation criteria, encompassing five standards for psychiatric examination, one for chief complaints, and five for present illness history assessment. By using these criteria as the prompt (shown in Supplementary Table 3 ), we employed the LLM to evaluate each case and select the top 60% (527 examples) as high-quality cases based on the total score. From these high-quality cases, we allocated 477 cases for the SFT and 50 cases for the high-quality test set. The 50 high-quality test cases and 633 lower-quality cases are combined as a completed test set to evaluate the accuracy of clinical-related feature extraction. Subsequently, we fine-tuned the Qwen2-72B-Instruct model with Low-Rank Adaptation (LoRA) 27 . The LLM SFT involves training a pre-trained model on datasets with explicit input-output pairs to optimize the model&#8217;s performance on specific downstream tasks. LoRA is a parameter-efficient fine-tuning technique that adds small, trainable rank decomposition matrices to the LLM&#8217;s existing weights, allowing for efficient model adaptation while keeping most of the original model parameters frozen. The model was trained using the following hyperparameters: LoRA rank of 8, LoRA alpha of 16, batch size of 8, and an initial learning rate of 1e-4 for 7000 steps. During inference using the vLLM framework, we restricted the model&#8217;s output to a single token &#8220;Yes\" or &#8220;No\" as the binary output, while we also extracted the probability output for these two tokens from the whole vocabulary. After normalization of the probabilities, along with the binary outputs, we formed 276 features in the clinical-related feature set. The assessment-related feature set incorporates data from six validated psychiatric rating scales, combining self-rating and peer-rating instruments. Self-rating scales include SCL-90 28 , SDS 29 , and SAS 30 , while peer-rating scales comprise HAMD 31 , HAMA 32 , and MADRS 33 , totaling 177 items in all. These scales were selected for their proven reliability in clinical practice and research, offering comprehensive symptom coverage. We designed two meta-prompts to enable the LLM to mimic both psychiatrists and patients in rating assessment scales in a zero-shot manner, as illustrated in Supplementary Table 2 and (Supplementary Table 5 for the Chinese version). The scales&#8217; content and rating guidelines were integrated into the prompts for LLM to generate the features. For instance, when extracting features related to the first item of the HAMD, which measures depressed mood, we use the peer-rating meta-prompt to instruct the LLM to evaluate the severity of the patient&#8217;s depressed mood on a 0&#8211;4 scale based on age, gender, and conversation content, where 0 indicates the absence of depression and 4 represents severe depression. When the conversation lacks sufficient information about the depressed mood, the LLM is prompted to return &#8220;NULL\". Similar to the clinical-related feature extraction, we extracted and normalized the logits of related tokens from the last layer of LLM and served as the features for classification and prediction tasks, resulting in a total of 1199 features. We did not SFT the LLM for assessment-related feature extraction, since we do not have sufficient assessment scale labels. In addition to the features generated by LLM, we extracted verbal features through two bag-of-words approaches: LIWC 34 and TF-IDF 35 , both of which measure the frequency of word occurrence within a document. The LIWC tool is specifically designed to provide rich insights into psychological states, including emotions, thinking styles, and social concerns. Notably, since our transcripts are in Mandarin, we used the Simplified Chinese version of LIWC 36 . It comprises word counts for 63 categories, including 52 categories related to linguistic counts (e.g., function words, common verbs, numbers, etc.), psychological processes (e.g., affect, sociality, cognition, perception, drive, etc.), and personal concern (e.g., work, home, religion, etc.), as well as 7 emotional categories (e.g., happy, sad, fear, etc.) and 4 general text metrics (e.g., the number of unique words, words in LIWC dictionary, etc.). We normalized the LIWC category counts by the total number of words. The TF-IDF algorithm, which stands for Term Frequency-Inverse Document Frequency, is a popular technique used in text analysis to determine the importance of words within a document or collection of documents. Unlike simple word counting, TF-IDF considers both how often a word appears in a specific document and how common or rare that word is across all documents. This approach helps identify words that are particularly characteristic or important to specific documents. In this study, TF-IDF was applied alongside LIWC to provide a more comprehensive analysis of the verbal features in the documents, offering insights into both the frequency and relevance of words used by the subjects. We applied Jieba ( https://github.com/fxsjy/jieba ) for Chinese character segmentation, resulting in a total of 27,000 features. In addition to examining the verbal aspects of participants&#8217; speech, we preprocessed the audio and extracted low-level acoustic and prosodic features using the OpenSMILE toolkits 37 . The audio recordings were manually edited to obscure names, addresses, and personally identifiable information before analysis. To reduce the impact of environmental noise and the varying distance from the microphone to the participant on recording quality, we used the pyAudacity toolkit ( https://github.com/asweigart/pyaudacity ) and the FFmpeg-normalized toolkit ( https://github.com/slhck/ffmpeg-normalize ) to reduce the noise with a parameter of 12&#8201;dB and normalize the volume to &#8722;23&#8201;dB respectively. OpenSMILE is a versatile, customizable suite of acoustic features for signal processing and machine learning applications. We utilized OpenSMILE&#8217;s emobase_live4 configuration to extract the following LLDs (Low-Level Descriptors): intensity, loudness, 12 MFCCs, pitch (F0), voicing probability (VoiceProb), F0 envelope (F0env), 8 line spectral frequencies (LSF), and Zero-Crossing Rate (ZCR). Next, we applied various functions to these LLDs and their delta coefficients, including minimum and maximum values with their relative positions (minPos and maxPos), range, mean, linear regression coefficients (linregc1-2), linear and quadratic error, standard deviation (STD), skewness, kurtosis, quartile values (quartile1-3), and interquartile ranges (iqr1-2, iqr2-3, iqr1-3). This process yielded 988 features to represent each speech utterance. Before LLD computation, pauses and silences were eliminated from the speech to create a continuous signal. We then extracted 988 emotion-based prosodic features using a 100 ms sliding window over the entire speech sample. Lastly, we calculated these emotion-based features&#8217; maximum, minimum, mean, and standard deviation to compose the final set of OpenSMILE features, totaling 3952 features. Classification method As explained in previous sections, we extracted five feature sets using LLM and existing toolkits: clinical-related, assessment-related, LIWC, TF-IDF, and OpenSMILE features. Subsequently, we built a machine learning pipeline to fuse the outputs from multiple feature sets to predict the appearance of the symptom and classify diagnostic groups, which was implemented using Scikit-learn 1.2.0 in Python 3.10. Notably, as detailed in explaining the clinical feature extraction, we fine-tuned the LLM using 138 high-quality clinical annotations to improve its ability to identify clinical concepts. We excluded diagnostic labels from this process to prevent data leakage. To ensure robust validation, we employed 10-fold cross-validation (10-fold CV). This method involves dividing the data into 10 subsets, iteratively training the model on 9 subsets, and testing it on the remaining subset. The process is repeated 10 times, with each subset serving as the test set once, and the model&#8217;s performance is averaged across all iterations. We implemented the random forest classifier for all feature sets as it constantly achieved better performance than other types of classifiers. To address the challenge of class imbalance, we applied the Synthetic Minority Oversampling Technique (SMOTE) 38 , which generates synthetic data for minority classes. Furthermore, we performed z-score standardization on all features, resulting in standardized features with a mean of 0 and a standard deviation of 1. This step ensures that all features are on a comparable scale, preventing any single feature from dominating the analysis due to its magnitude. We also implemented probability calibration to standardize predictions from each feature set. This process involved an internal CV on the training set of the outer CV to obtain the probability distribution on training data, which were then used to calibrate test set predictions 6 . Moreover, based on the feature importance ranked by the classifier on training data, we filtered out features whose importance values fell below the mean to reduce unimportant features. For the final prediction, we employed a late fusion technique, a multi-modal machine learning approach that involved averaging the standardized prediction outputs from all feature sets to produce the final output. This method allows for the integration of diverse information sources while maintaining the integrity of each feature set&#8217;s contribution to the final prediction. Performance metrics To evaluate the performance of the LLM in extracting clinical features from interview dialogues, we employed standard information extraction metrics: precision and recall. Precision measures the proportion of correctly identified symptoms among all symptoms extracted by the LLM, while recall measures the proportion of symptoms correctly extracted from the EMR annotations. Given that psychiatrists may not document every symptom mentioned during interviews in the EMRs, recall serves as a particularly valuable metric in our evaluation framework. Precision and recall are calculated as follows: Precision&#8201;=&#8201;TP/(TP&#8201;+&#8201;FP); Recall&#8201;=&#8201;TP/(TP&#8201;+&#8201;FN), where TP (True Positives) represents symptoms correctly identified by both the LLM, FP (False Positives) represents symptoms incorrectly extracted by the LLM, and FN (False Negatives) represents symptoms present in the EMR but missed by the LLM. For classification and prediction tasks, we utilize a comprehensive set of standard metrics. Our analysis primarily focuses on balanced accuracy (BAC), which is particularly effective for imbalanced datasets by averaging sensitivity (SEN) and specificity (SPE). This metric provides a robust measure of overall performance, accounting for both true positive and true negative rates. In addition to BAC, we also employed AUPRC and weighted F1 score offering valuable insights into model performance across various classification thresholds, which are well-suited for machine learning tasks involving imbalanced data. Understanding the key distinguishing features among various mental health conditions is crucial for improving diagnostic accuracy, developing targeted interventions, and enhancing our overall comprehension of these disorders. To address this critical need, we employed a comprehensive approach to identify the most important features distinguishing between different mental health conditions. We utilized various feature sets, including LLM-generated clinical and assessment-related features, LIWC categories, and TF-IDF terms, and applied the Mann-Whitney U test with FDR correction across all feature sets to calculate p-values and measure feature importance. Features are ranked by their p-values, with those below 0.05 indicating a statistically significant difference between the two groups. Baseline experiment setup Excepted the LIWC and TF-IDF, we incorporated both traditional transformer-based language models and LLM-based methods as the baselines for mental health dialogue classification. We established a comprehensive methodological framework encompassing three distinct classification paradigms: pre-trained language models, zero-shot LLM classification, SFT LLM classification, and our proposed pipeline. We implemented two established pre-trained language models as baseline classifiers: BERT (Bidirectional Encoder Representations from Transformers) 39 and RoBERTa (Robustly Optimized BERT Pretraining) 40 . We utilized the &#8220;bert-base-chinese\" model 39 , which consists of 12 transformer layers with 768 hidden dimensions and 12 attention heads, totaling approximately 110 million parameters. BERT&#8217;s bidirectional contextual representations enable effective capture of semantic nuances within clinical dialogues. For RoBERTa, we employed the &#8220;chinese-roberta-wwm-ext-large\" variant 41 , featuring 24 transformer layers, 1024 hidden dimensions, and 16 attention heads (approximately 325 million parameters). This model incorporates the whole word masking technique specifically optimized for Chinese language understanding. RoBERTa&#8217;s enhanced training methodology and larger parameter space potentially offer improved representation capabilities for complex clinical narratives. Both BERT and RoBERTa were fine-tuned on the ANX vs. DP classification task using addition random initialed linear layer with softmax. For the LLM-based baseline method, we implemented both zero-shot and SFT manner. (1) Zero-shot Classification: We implemented direct classification using Qwen2.5-72B-Instruct through carefully designed prompts (as shown in Supplementary Table 7 ) that incorporated dialogue content and diagnostic ground truth. The model was constrained to output binary classifications (depression/anxiety), with token probabilities extracted to calculate performance metrics. (2) SFT: We augmented the zero-shot approach through parameter-efficient fine-tuning using LoRA. All methodologies underwent rigorous evaluation using consistent data partitioning and performance metrics. We implemented stratified sampling to allocate 60% of samples for training, 20% for validation, and 20% for testing across both depression and anxiety classes. Hyperparameter optimization was conducted using the validation set, while final performance evaluation utilized the held-out test set exclusively. Specifically, models exhibiting the lowest validation loss during the training process were preserved and subsequently employed for final performance evaluation on the held-out test set. This ensured methodological consistency and facilitated direct comparative analysis of classification paradigms. Results Sample The study included 1160 individuals, yielding about 15,000 minutes of speech data. All participants received diagnoses based on the ICD-10 24 . The sample comprised 553 participants diagnosed with &#8220;Depressive Episode\" or &#8220;Depressive Disorder\" (DP), 426 diagnosed with &#8220;Anxiety Disorder\" or &#8220;Anxiety State\" (ANX), and 181 classified as &#8220;Others\" (patients not diagnosed with DP or ANX). Table 2 presents the demographic characteristics of the participants. Moreover, based on the clinical annotations of symptom episodes in the EMRs, we categorized the participants into four groups: patients who experienced/presented anxiety symptoms (A), participants who experienced/presented depressive symptoms (D), participants who experienced/presented mixed depressive and anxiety symptoms (M), and participants without experienced/presented depressive and anxiety symptoms (N). Table 2 Demographics of all participants DP (N = 553) ANX (N = 426) Others (N = 181) Age 29.2&#8201;&#177;&#8201;10.0 34.0&#8201;&#177;&#8201;12.0 27.5&#8201;&#177;&#8201;11.1 Gender &#8195;Female 377 (68.2%) 288 (67.6%) 104 (57.5%) &#8195;Male 176 (31.8%) 138 (32.4%) 77 (42.5%) Occupation &#8195;Employed 266 (48.1%) 250 (58.7%) 74 (40.9%) &#8195;Student 201 (36.3%) 98 (23.0%) 81 (44.8%) &#8195;Unemployed 46 (8.3%) 44 (10.3%) 14 (7.7%) &#8195;Unknown 23 (4.2%) 15 (3.5%) 7 (3.9%) &#8195;Retired 9 (1.6%) 19 (4.5%) 4 (2.2%) &#8195;Dropped out 8 (1.4%) NaN 1 (0.6%) Personality &#8195;Introvert 274 (49.5%) 198 (46.5%) 106 (58.6%) &#8195;Extrovert 148 (26.8%) 114 (26.8%) 34 (18.8%) &#8195;Gentle 46 (8.3%) 38 (8.9%) 13 (7.2%) &#8195;Sensitive 29 (5.2%) 22 (5.2%) 4 (2.2%) &#8195;Strong welling 12 (2.2%) 14 (3.3%) 8 (4.4%) &#8195;Others 44 (8.0%) 40 (9.4%) 16 (8.8%) LLM-generated clinical-related features evaluation We evaluated the performance of LLM-generated clinical symptoms on the entire test samples and those with high-quality EMR, as shown in Table 3 . Our evaluation of LLM-based clinical symptom extraction demonstrated a significant performance improvement after the SFT, with the accuracy increased from 81.2 to 86.9% on the test set and 83.7 to 89.1% on the high-quality test set ( p &#8201;&lt;&#8201;0.01 in McNemar&#8217;s test). The recall metric showed substantial improvements, increasing from 66.1 to 81.1% on the whole test set and from 74.0 to 86.1% on the high-quality test set, indicating enhanced capability in identifying symptoms documented by psychiatrists in the EMR. Meanwhile, precision improved from 81.2 to 87.4% on the test set and from 84.2 to 89.5% on the high-quality test set. This precision increase, coupled with recall improvement, suggests that the fine-tuned model became more comprehensive in detecting symptoms from clinical dialogues. Table 3 Performance comparison of LLM-generated clinical-related features between Zero-shot and SFT approaches Test set High-quality test set Precision Recall Accuracy Precision Recall Accuracy Zero-shot 81.2% 66.1% 81.2% 84.2% 74.0% 83.7% the SFT 87.4% 81.1% 86.9% 89.5% 86.1% 89.1% We present a comparative analysis of classification performance using clinical-related features extracted by the LLM in Fig. 2 , comparing three feature sets: features extracted in a zero-shot manner, features extracted from the fine-tuned LLM, and psychiatrists&#8217; annotations derived from EMRs. Across all classification tasks, features from the fine-tuned LLM consistently demonstrate superior performance. For instance, in distinguishing between depression and anxiety diagnoses (A vs. D), the fine-tuned LLM achieves a BAC of 74.8%. In identifying depression (D vs. N) and anxiety symptoms (A vs. N), the BAC reaches 79.8% and 72.2% respectively. These results underscore the potential of fine-tuned LLMs for accurate and automated clinical manifestation extraction. Fig. 2 Comparative analysis of classification performance using the clinical-related features extracted by LLM in zero-shot, the SFT, and the annotations from EMRs across different classification tasks. &#8220;ANX\" represents Anxiety Disorder, &#8220;DP\" represents depression Disorder, &#8220;A\" represents participants with anxiety symptoms, &#8220;D\" represents participants with depressive symptoms, &#8220;M\" represents participants with mixed anxiety and depressive symptoms, and &#8220;N\" represents participants without anxiety and depressive symptoms. Classification of diagnostic groups The results of automated classification tasks for distinguishing between ANX, DP, and Others groups (not diagnosed with ANX or DP) using various linguistic and LLM-generated features are shown in Table 4 . For the binary classification task (ANX vs. DP), the model achieved a BAC of 75.5%, an F1 score of 0.762, and an AUPRC of 0.824, indicating good overall performance (permutation test p &#8201;&lt;&#8201;0.01, same for other tasks). In the three-way classification task (ANX vs. DP vs. Other), the model&#8217;s performance was achieved with a BAC of 65.6% and an F1 score of 0.656, presenting a significant gain compared to the majority baseline (47.7%). Table 4 Results for classification of ANX, DP, and Others groups Task Feature Set Confusion Matrix SEN SPE F1 AUPRC BAC MB Predicted Class A D ANX vs. DP AssRel + CliRel + LIWC + TF-IDF A 294 132 0.690 0.819 0.762 0.824 0.755 0.565 D 100 453 A D O SEN SPE F1 AUPRC BAC MB ANX vs. DP vs. Others AssRel + CliRel + LIWC + TF-IDF A 271 91 64 0.636 0.838 0.656 0.715 0.656 0.477 D 92 357 104 O 27 30 124 AssRel Assessment-related, CliRel Clinical-related, F1 F1-score, SEN Sensitivity, SPE Specificity, AUPRC Area under precision-recall curve, BAC Balanced Accuracy, MB Majority Baseline. Prediction of depression and anxiety symptoms In addition to identifying diagnostic results by ICD-10 code, we predicted whether participants exhibited symptoms of depression, anxiety, mixed depression/anxiety, or no symptoms at all, as shown in Table 5 . In the anxiety vs. no anxiety (A vs. N) classification task, the model achieved a sensitivity of 0.683 and specificity of 0.810 for detecting anxiety, with an overall F1 score of 0.754 and BAC of 74.7%. For the depression vs. no depression (D vs. N) task, the model performed slightly better, with a sensitivity of 0.806 and specificity of 0.737 for detecting depression, resulting in an F1 score of 0.783 and a BAC of 77.2%. When distinguishing between anxiety, depression, mixed symptoms, and no depression and anxiety symptoms (A vs. D vs. M vs. N), we achieved an AUPRC of 0.606 and a BAC of 60.7%, which achieved a significant improvement of about 30% compared to the majority baseline. Table 5 Results for classification of participants with depression (D), anxiety (A), mixed depression and anxiety (M), and no depression and anxiety symptoms (N) Task Features Confusion Matrix SEN SPE F1 AUPRC BAC MB Predicted Class A N A vs. N AssRel + CliRel + LIWC + TF-IDF A 285 135 0.683 0.810 0.754 0.813 0.747 0.565 N 176 564 D N SEN SPE F1 AUPRC BAC MB D vs. N AssRel + CliRel + LIWC + TF-IDF D 595 143 0.806 0.737 0.783 0.866 0.772 0.636 N 111 311 A D M N SEN SPE F1 AUPRC BAC MB A vs. D vs. M vs. N AssRel + CliRel + LIWC + TF-IDF A 114 2 17 12 0.786 0.865 0.586 0.606 0.607 0.399 D 22 272 98 71 M 55 58 123 39 N 60 30 19 168 AssRel Assessment-related; CliRel Clinical-related, F1 F1-score, SEN Sensitivity, SPE Specificity, AUPRC Area under precision-recall curve, BAC Balanced Accuracy, MB Majority Baseline. Interpretability The analysis revealed distinctive patterns across different mental health conditions and feature sets (Table 6 ). In differentiating ANX from DP, clinical-related features emphasized anxiety-specific symptoms such as &#8220;Unable to relax\", &#8220;Uncontrollable restlessness\", and &#8220;Anxiety\", contrasting with depressive symptoms like &#8220;Sadness\" and &#8220;Anhedonia\". Assessment measures showed a mixed profile, with both anxiety indicators (HAMD_Somatic anxiety) and depression markers (HAMD_Depressed mood). LIWC analysis revealed heightened use of anxiety and fear-related language, and TF-IDF identified anxiety-related terms. For depression detection, clinical-related features highlighted core depressive symptoms, with &#8220;Depressed mood\", &#8220;Loss of interest\", and &#8220;Anhedonia\" emerging as primary indicators of depression. The assessment-related features showed strong signals from SCL-90 scales, particularly in items related to feelings of sadness and loss of interest. LIWC analysis identified significant usage patterns in sadness-related words and negative emotions, while TF-IDF analysis captured depression-specific terms and notably, negation patterns (e.g., &#8220;Don&#8217;t want\", &#8220;No\", etc.). For anxiety identification, clinical-related features strongly centered on anxiety manifestations, such as &#8220;Unable to relax\", &#8220;Anxiety\", and &#8220;Worry.\" The assessment-related features prominently featured inner tension and somatic anxiety, along with various SCL-90 anxiety-related items. Both LIWC and TF-IDF analyses consistently identified anxiety-specific language patterns, with LIWC showing &#8220;Anxiety\" and &#8220;Fear\" as top features, and TF-IDF highlighting terms related to physical symptoms (e.g., &#8220;Palpitations\", &#8220;Heartbeat\", etc.) and worry. Table 6 Top ten salient features for each feature set in paired classification tasks Task Clinical-related Assessment-related LIWC TF-IDF ANX vs. DP Sadness Perturbed and uneasy Unable to relax Uncontrollable -restlessness Negativism Anxiety Anhedonia Anxiety and unease Negative ideation Anhedonia SCL-90_Feeling blue_2 SCL-90_Feeling no interest in things_2 HAMD_Depressed mood_4 HAMD_Somatic anxiety_3 MADRS_Inner tension_NULL SCL-90_Thoughts of ending your life_1 SCL-90_Feeling future hopeless_1 MADRS_Suicidal ideation_0 HAMD_A sense of hopelessness_0 SCL-90_Never feeling close to others_1 Anxiety Fear Biological Processes Death Sad Health Body Motion Perfect tense Anger Anxiety Ideas Emotion Palpitations Anxious Worried Terrified Heartbeat Excited Behavior A vs. N Unable to relax Anxiety Uncontrollable -restlessness Anxiety and unease Feeling of tension Somatic anxiety Excessive worrying with anxious Worry Delusion of Guilt Palpitations MADRS_Inner tension_4 HAMD_Somatic anxiety_3 SCL-90_Feeling tense or keyed up_NULL HAMD_Psychiatric anxiety_3 HAMA_Autonomic symptoms_2 SCL-90_Worrying too much about things_NULL SCL-90_Nervousness or shakiness inside_NULL SAS_Anxiety_NULL HAMA_Cardiovascular symptoms_2 SCL-90_Feeling restless_NULL Anxiety Fear Body Biological Processes Good Social Perfect tense Health Motion Death Anxiety Anxious Palpitations Worried Ideas Heartbeat Anxiety disorders Chest tightness Behavior Comfortable D vs. N Feeling Down Perturbed and Uneasy Sadness Loss of interests Anhedonia Negativism Hypobulia Low self-evaluation Helplessness Abulia SCL-90_Feeling blue_NULL SCL-90_Feeling no interest in things_NULL SCL-90_Feeling hopeless about the future_NULL SCL-90_Feeling everything is an effort_NULL HAMD_Depressed mood_3 HAMD_Work and interests_3 SCL-90_Feeling low in energy -or slowed down_NULL SCL-90_Feelings of worthlessness_NULL SDS_Depression_4 MADRS_Apparent sadness_0 Sad Affect Health Death Humans Biological processes Anger Achievement Negative emotion Anxiety No Depression Interests Emotion Yes Obstacle Don&#8217;t Contrary Ideas Anger All features in the table have p &#8201;&lt;&#8201;0.01. For Assessment-related features, the feature nomenclature follows the format: Scale_Symptom-Name_Rating, where a &#8216;NULL&#8217; rating indicates the absence of symptom in dialogue identified by LLM. The bold feature name represents that the underlined class has a higher mean value. Baseline experiment results We conducted a systematic investigation of diagnostic efficacy in clinical dialogue classification utilizing multiple model architectures. The conventional transformer models demonstrated variable performance: BERT achieved modest results with 88.1% sensitivity but only 39.5% specificity and 64.3% F1 score, while RoBERTa exhibited superior sensitivity (96.3%) but similarly limited specificity (37.2%). When examining LLM-based approaches, Qwen2.5-72B-Instruct demonstrated substantial improvements in balanced performance, achieving 75.0% balanced accuracy in zero-shot configuration and 76.7% after SFT. Our proposed methodology, leveraging LLM-generated feature sets with ensemble random forest classifiers, outperformed all other approaches across most metrics, most notably achieving 79.1% balanced accuracy and 88.1% AUPRC, demonstrating the efficacy of feature extraction over direct classification when utilizing large language models for clinical diagnostic tasks. Discussion Inspired by promising early research on digital phenotypes for diagnosing and classifying symptoms in psychiatric patients, we investigated using signal processing and state-of-the-art LLM to capture symptom-related expression cues in outpatient conversations. We developed an ensemble classification pipeline to automatically differentiate between clinical diagnostic outcomes and the presence of symptoms. Although recent studies have demonstrated promising capabilities of utilizing LLMs in medical diagnosis 42 , applications in mental health have predominantly centered on developing conversational agents 43 , while the potential of extracting precise symptoms from psychiatric conversations for evidence-based diagnosis has not been fully explored. In this study, we investigated the efficacy of LLM in detecting clinical and assessment-related symptoms. Our investigation revealed that without any additional training, the model achieved a recall rate of 77.3% on high-quality dialogue-case pairs, and increased to 86.1% by fine-tuning the LLM using clinical annotations. This aligns with recent observations regarding LLMs&#8217; strong zero-shot performance in healthcare domains and the fine-tuning could further boost LLM performance 23 . Furthermore, this enhanced base capability led to substantial improvements across all downstream classification and prediction tasks (e.g., the classification accuracy for ANX and DP increased from 72 to 75%). Current approaches to automated symptom detection predominantly rely on traditional natural language processing methods with predefined linguistic categories or rule-based systems 6 , 44 , which often struggle to capture the complex presentation of psychiatric symptoms in natural conversation. Some researchers have explored the use of LLMs to assist in medical information retrieval 45 . We further investigated the information extraction capabilities in clinical dialogues and enhanced them through SFT. Our study demonstrated moderate to high performance in anxiety symptom detection (BAC&#8201;=&#8201;74.7%, AUPRC&#8201;=&#8201;0.813), depression symptoms detection (BAC&#8201;=&#8201;77.2%, AUPRC&#8201;=&#8201;0.866), and a four-class classification of patients with anxiety/depression/mixed/none symptoms (BAC=60.7%, AUPRC&#8201;=&#8201;0.606). As shown in the summarization of existing literature (Supplementary Table 8 ), while anxiety detection in social media text has demonstrated promising results with high accuracy 46 , the performance of similar methods on spoken language data, such as interview transcripts and therapy dialogues, remains limited with accuracy rates below 65%. Recent advances combining LLM embedding with acoustic features have shown improved results, reaching 75% accuracy in a small cohort of 65 patients 4 ; however, in our experiments, incorporating acoustic features did not yield improvements in overall classification performance as shown in Supplementary Fig. 1 . This might be attributed to the noisy hospital environment and the limitations of our recording equipment, which resulted in suboptimal audio quality. While depression detection studies have reported wide-ranging accuracy rates (65&#8722;95%), some results should be interpreted with caution due to several methodological limitations: small sample sizes 44 , reliance on PHQ screening tools rather than clinical diagnoses 47 , data collection in structured experimental settings 48 , and not studied the first-episode outpatients in real-world, unstructured clinical environments. Our study leverages clinical diagnoses from psychiatrists of first-episode outpatients in real-world clinical environments, achieving moderate to high accuracy despite the inherent challenges and variability of unstructured, naturalistic settings representing a significant advancement over controlled laboratory conditions. This success particularly highlights the potential of LLMs in extracting and analyzing clinical symptoms for predicting anxiety and depression in outpatient populations, offering a more ecologically valid and scalable solution for mental health screening and monitoring. DP and ANX present significant assessment challenges due to their high prevalence, frequent comorbidity, and overlapping symptomatology 49 . By leveraging LLM-generated features, our approach achieved robust performance in distinguishing these disorders, with a BAC of 75.5% and AUPRC of 0.824 for binary classification between DP and ANX, and the performance outperformed the directly using LLMs as classifiers (see Table 7 ). In the more challenging multi-class scenario (ANX vs. DP vs. Others), the model maintained reasonable performance with a BAC of 65.6% and AUPRC of 0.715. Prior approaches to differentiating depression and anxiety disorders, such as cognitive tasks 50 and structured questionnaires 51 , have achieved accuracy rates of 70&#8211;80%. In addition, we tested the classification performance of each assessment scale as the feature set, where the results are presented in Supplementary Fig. 2 . We observed that assessment-related features, particularly from scales like SCL-90, HAMD, and MADRS, showed strong discriminatory power across all comparisons, and early fusion and late fusion present similar classification performance. A potential reason is that these scales contain sufficient depression-related symptoms, which are key components for differentiating different groups. To our knowledge, no study has explored the objective diagnosis of DP and ANX using speech data from clinical interviews, potentially due to a lack of data and inherent subjectivity. Our study addresses a critical gap by analyzing the linguistic and symptom-related markers in various participant groups, providing objective cues to assist psychiatrists. Table 7 Comparison of classification performance using Qwen2-72B-Instruct (Zero-shot and SFT) and Ours (LLM-generated feature sets with ensemble random forest classifiers) for DP/ANX classification SEN SPE F1 AUPRC BAC MB BERT 0.881 0.395 0.643 0.735 63.8% 0.566 RoBERTa 0.963 0.372 0.669 0.708 66.8% 0.566 Qwen2.5-72B-Instruct (Zero-shot) 0.748 0.753 0.751 0.842 75.0% 0.566 Qwen2.5-72B-Instruct (SFT) 0.757 0.776 0.766 0.828 76.7% 0.566 Ours 0.788 0.793 0.791 0.881 79.1% 0.566 The bold numbers indicate the highest performance within each metric column. The feature analysis provides several key insights into the differential characteristics of different groups of participants, as shown in Table 6 . We illustrate the distribution of clinical and assessment-related features for each group of participants in Supplementary Figs. 3 and 4 . The clinical-related features demonstrate clear condition-specific patterns: features that show more importance in patients with depression cluster around mood (sadness and disappointment) and motivational disturbances (anhedonia, reduced volition), while anxiety features predominantly reflect an inability to relax and worry. The observation for depression is in line with previous studies which also observed that patients with depression presented blunted facial affect and increased sadness in language 4 , 13 and anhedonia is specific to depression 52 . For anxiety recognition, the consistency of findings across different feature sets strengthens the reliability of these discriminators. For instance, the prominence of somatic symptoms in anxiety, captured in both assessment-related features and TF-IDF terms, suggests this could be a robust marker. Similarly, the persistent appearance of mood-related terms in depression across multiple feature sets reinforces their diagnostic utility. It is worth noting that acoustic features extracted using OpenSmile were not included in our feature importance analysis, as they did not demonstrate statistical significance in discriminating between the participant groups. Real-world implementation of this LLM pipeline demands careful consideration of practical and clinical factors. Our approach, leveraging LLMs on conversational data to derive symptom insights and classifications, underscores the need for stringent data privacy protocols and computationally capable infrastructure. Furthermore, the pipeline&#8217;s interpretability, stemming from its focus on clinically relevant features, must be clearly presented within EMR workflows to foster clinician trust. Beyond these pipeline-specific needs, seamless integration and clinician training are critical for usability. Building trust also requires ongoing validation, performance monitoring to detect model drift, and transparent ethical protocols, including patient consent and equity audits, ensuring the tool responsibly supports clinical decision-making. Our study has several limitations that should be addressed in future research. The absence of detailed symptom severity measures during the experiment limits our ability to correlate speech patterns with specific symptom intensities. Additionally, the study&#8217;s focus on specific disorders and potential biases in data collection may affect the generalizability of the results. Future work should prioritize the inclusion of comprehensive symptom severity assessments and explore the application of this approach to a broader range of mental health conditions. Besides, in the future, we will collect more data to perform longitudinal analysis, as it could provide insights into how linguistic patterns evolve with symptom progression or treatment response. Furthermore, expanding the use of more advanced LLMs in this context could potentially enhance the extraction of nuanced clinical concepts and provide even more detailed, interpretable insights for clinicians. Validating the model&#8217;s performance in diverse clinical settings and with larger, more diverse patient populations will be crucial to ensure its practical utility and generalizability. These advancements could significantly contribute to improving the efficiency and objectivity of consultations for depression, anxiety, and potentially other mental health disorders. In summary, this study demonstrates the potential of using LLM to analyze digital biomarkers in speech for automatic assistance in psychosis diagnosis and assessment. Our model achieved promising accuracy in identifying individuals with anxiety and depression symptoms, as well as differentiating between DP and ANX groups. Using LLMs to extract clinically relevant features and rate assessment scales improved the interpretability of the results, offering a novel approach to bridging the gap between automated analysis and clinical practice. While further research is needed, our findings suggest that well-developed LLMs could potentially serve as valuable tools in standardizing psychiatric evaluation and decision-making. Supplementary information Supplementary Information Publisher&#8217;s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. These authors contributed equally: Shihao Xu, Yiming Yan, Yanli Ding. Supplementary information The online version contains supplementary material available at 10.1038/s44184-025-00175-1. Acknowledgements This work was supported by Tianqiao and Chrissy Chen Institute (TCCI) with the Program of Chen Frontier Lab for AI and Mental Health - Shanghai Mental Health Center (2023-TX-018), the National Natural Science Foundation of China (82071500), the Natural Science Foundation of Shanghai, China (23ZR1454600), the Program of Shanghai Academic/Technology Research Leader (21XD1423300), Shanghai Shen-Kang Hospital Development Center (SHDC12025118, SHDC22025303) to J.C.; the National Social Science Foundation of China (25BKX030) to Q.Z. and the Integrated Innovation Team Project of Shanghai Mental Health Center. We deeply appreciate every participant involved in this study and all the efforts made by TCCI and SMHC colleagues who are not on the author list. Author contributions J.C. was the overall principal investigators for the study who conceived the study and obtained financial support, and was responsible for study design and supervised the entire study. S.X., Y.Y. and Y.D. participated in the study design. S.X. developed the large language model methodology, designed the machine learning pipeline, conducted the experiments, and wrote the original draft. Y.Y. and Y.D. performed clinical concept verification, analyzed the data and finalized the manuscript. F.L. and S.Z. developed the large language model methodology, performed data processing, and conducted the experiments. Z.W., T.Y. and H.G. provided technical support and data resources. J.S., X.J., Y.H., Q.Z., M.Z., Y.X. and J.C. supervised the project, acquired funding, and reviewed the final manuscript. N.O., L.B., reviewed the final manuscript. H.T., C.L., Y.L., H.L., Y.M., W.G., H.Q., Y.W. and J.Q. contributed to the participant recruitment and clinical data collection. All authors contributed to the manuscript revision and approved the submitted version. Data availability The research data cannot be publicly shared due to privacy concerns, but the code and instructions for requesting local access to the data are available at https://github.com/Shanda-Group-Ltd/SMHC_llm_psychiatry_study , with qualified researchers able to apply for on-site data access through this repository. Competing interests The authors declare no competing interests. References 1. Chodavadia P Teo I Poremski D Fung DSS Finkelstein EA Prevalence and economic burden of depression and anxiety symptoms among Singaporean adults: Results from a 2022 web panel BMC Psychiatry 2023 23 104 10.1186/s12888-023-04581-7 36782116 PMC9925363 Chodavadia, P., Teo, I., Poremski, D., Fung, D. S. S. &amp; Finkelstein, E. A. Prevalence and economic burden of depression and anxiety symptoms among Singaporean adults: Results from a 2022 web panel. BMC Psychiatry 23 , 104 (2023). 36782116 10.1186/s12888-023-04581-7 PMC9925363 2. Althubaiti A Information bias in health research: definition, pitfalls, and adjustment methods J. Multidiscip. Healthc. 2016 9 211 217 10.2147/JMDH.S104807 27217764 PMC4862344 Althubaiti, A. Information bias in health research: definition, pitfalls, and adjustment methods. J. Multidiscip. Healthc. 9 , 211&#8211;217 (2016). 27217764 10.2147/JMDH.S104807 PMC4862344 3. Sharma CM Damani D Chariar VM Review and content analysis of textual expressions as a marker for depressive and anxiety disorders (DAD) detection using machine learning Discov. Artif. Intell. 2023 3 38 10.1007/s44163-023-00090-4 Sharma, C. M., Damani, D. &amp; Chariar, V. M. Review and content analysis of textual expressions as a marker for depressive and anxiety disorders (DAD) detection using machine learning. Discov. Artif. Intell. 3 , 38 (2023). 4. Jiang Z Multimodal mental health digital biomarker analysis from remote interviews using facial, vocal, linguistic, and cardiovascular patterns IEEE J. Biomed. Health Inform. 2024 28 1680 1691 10.1109/JBHI.2024.3352075 38198249 PMC10986761 Jiang, Z. et al. Multimodal mental health digital biomarker analysis from remote interviews using facial, vocal, linguistic, and cardiovascular patterns. IEEE J. Biomed. Health Inform. 28 , 1680&#8211;1691 (2024). 38198249 10.1109/JBHI.2024.3352075 PMC10986761 5. Low DM Bentley KH Ghosh SS Automated assessment of psychiatric disorders using speech: a systematic review Laryngoscope Investig. Otolaryngol. 2020 5 96 116 10.1002/lio2.354 32128436 PMC7042657 Low, D. M., Bentley, K. H. &amp; Ghosh, S. S. Automated assessment of psychiatric disorders using speech: a systematic review. Laryngoscope Investig. Otolaryngol. 5 , 96&#8211;116 (2020). 32128436 10.1002/lio2.354 PMC7042657 6. Xu S Identifying psychiatric manifestations in schizophrenia and depression from audio-visual behavioural indicators through a machine-learning approach Schizophrenia 2022 8 1 13 10.1038/s41537-022-00287-z 36344515 PMC9640655 Xu, S. et al. Identifying psychiatric manifestations in schizophrenia and depression from audio-visual behavioural indicators through a machine-learning approach. Schizophrenia 8 , 1&#8211;13 (2022). 36344515 10.1038/s41537-022-00287-z PMC9640655 7. Openai. ChatGPT. https://chatgpt.com/chat (2024). 8. Team, G. et al. Gemini 1.5: unlocking multimodal understanding across millions of tokens of context. Preprint at 10.48550/arXiv.2403.05530 (2024). 9. Team, Q. Qwen2.5: a party of foundation models. https://qwenlm.github.io/blog/qwen2.5/ (2024). 10. Omar, M. et al. Applications of large language models in psychiatry: a systematic review. Front. Psychiatry 15 , 1422807 (2024). 10.3389/fpsyt.2024.1422807 PMC11228775 38979501 11. Marzano L The application of mHealth to mental health: opportunities and challenges Lancet Psychiatry 2015 2 942 948 10.1016/S2215-0366(15)00268-0 26462228 Marzano, L. et al. The application of mHealth to mental health: opportunities and challenges. Lancet Psychiatry 2 , 942&#8211;948 (2015). 26462228 10.1016/S2215-0366(15)00268-0 12. Lan, X., Cheng, Y., Sheng, L., Gao, C. &amp; Li, Y. Depression detection on social media with large language models. In Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing: Industry Track (2025). 13. Wang, Y., Inkpen, D. &amp; Kirinde Gamaarachchige, P. Explainable depression detection using large language models on social media data. In Proc. 9th Workshop on Computational Linguistics and Clinical Psychology (CLPsych 2024) , 108-126 (Association for Computational Linguistics, 2024). 14. Wang, X., Liu, K. &amp; Wang, C. Knowledge-enhanced Pre-training large language model for depression diagnosis and treatment. In 2023 IEEE 9th International Conference on Cloud Computing and Intelligent Systems (CCIS) , 532-536 (IEEE, 2023). 15. Agrawal, A. Illuminate: a novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering. Preprint at 10.48550/arXiv.2402.05127 (2024). 16. Chen, Z., Lu, Y. &amp; Wang, W. Y. Empowering psychotherapy with large language models: cognitive distortion detection through diagnosis of thought prompting. In Findings of the Association for Computational Linguistics: EMNLP 2023 , 4295&#8211;4304 (Association for Computational Linguistics, 2023). 17. Liu, J. M. et al. ChatCounselor: a large language models for mental health support. Preprint at10.48550/arXiv.2309.15461 (2023). 18. Li, J. et al. Agent hospital: a simulacrum of hospital with evolvable medical agents. Preprint at 10.48550/arXiv.2405.02957 (2024). 19. Xin, A. W. et al. Using large language models to detect outcomes in qualitative studies on adolescent depression. J. Am. Med. Inform. Assoc. ocae298, 10.1093/jamia/ocae298 (2024). 10.1093/jamia/ocae298 39661754 20. Elyoseph Z Levkovich I Shinan-Altman S Assessing prognosis in depression: Comparing perspectives of AI models, mental health professionals and the general public Fam. Med. Community Health 2024 12 e002583 10.1136/fmch-2023-002583 38199604 PMC10806564 Elyoseph, Z., Levkovich, I. &amp; Shinan-Altman, S. Assessing prognosis in depression: Comparing perspectives of AI models, mental health professionals and the general public. Fam. Med. Community Health 12 , e002583 (2024). 38199604 10.1136/fmch-2023-002583 PMC10806564 21. Barua PD Artificial intelligence assisted tools for the detection of anxiety and depression leading to suicidal ideation in adolescents: a review Cognit. Neurodyn. 2024 18 1 22 10.1007/s11571-022-09904-0 PMC9684805 36467993 Barua, P. D. et al. Artificial intelligence assisted tools for the detection of anxiety and depression leading to suicidal ideation in adolescents: a review. Cognit. Neurodyn. 18 , 1&#8211;22 (2024). 10.1007/s11571-022-09904-0 PMC9684805 36467993 22. Ferguson, S., Aoyagui, P. A., Rizvi, R., Kim, Y.-H. &amp; Kuzminykh, A. The explanation that hits home: the characteristics of verbal explanations that affect human perception in subjective decision-making8, 517:1&#8211;517:37. 10.1145/3687056. 23. Lawrence HR The opportunities and risks of large language models in mental health JMIR Ment. Health 2024 11 e59479 10.2196/59479 39105570 PMC11301767 Lawrence, H. R. et al. The opportunities and risks of large language models in mental health. JMIR Ment. Health 11 , e59479 (2024). 39105570 10.2196/59479 PMC11301767 24. ICD-10 Version:2016. https://icd.who.int/browse10/2016/en . 25. Duckworth, K. Understanding Mental Disorders: Your Guide to DSM-5. (American Psychiatric Association Publishing, Washington, D.C., 2015) 10.1176/appi.ajp.2015.15070879. 26. Yang, A. et al. Qwen2 technical report. Preprint at arXiv preprint at https://arxiv.org/abs/2407.10671 (2024). 27. Hu, E. J. et al. LoRA: Low-rank adaptation of large language models. Preprint at arXiv preprint at https://arxiv.org/abs/2106.09685 (2021). 28. Derogatis, L. R. &amp; Unger, R. Symptom Checklist-90-Revised. In Corsini Encyclopedia of Psychology. 10.1002/9780470479216.CORPSY0970 (2010). 29. ZUNG WWK A self-rating depression scale Arch. Gen. Psychiatry 1965 12 63 70 10.1001/archpsyc.1965.01720310065008 14221692 ZUNG, W. W. K. A self-rating depression scale. Arch. Gen. Psychiatry 12 , 63&#8211;70 (1965). 14221692 10.1001/archpsyc.1965.01720310065008 30. Zung WW A rating instrument for anxiety disorders Psychosomatics 1971 12 371 379 10.1016/S0033-3182(71)71479-0 5172928 Zung, W. W. A rating instrument for anxiety disorders. Psychosomatics 12 , 371&#8211;379 (1971). 5172928 10.1016/S0033-3182(71)71479-0 31. Hamilton, M. The Hamilton Rating Scale for Depression. In Sartorius, N. &amp; Ban, T. A. (eds.) Assessment of Depression , 143&#8722;152. 10.1007/978-3-642-70486-4_14 (Springer Berlin Heidelberg, 1986). 32. Hamilton M The assessment of anxiety states by rating Br. J. Med. Psychol. 1959 32 50 55 10.1111/j.2044-8341.1959.tb00467.x 13638508 Hamilton, M. The assessment of anxiety states by rating. Br. J. Med. Psychol. 32 , 50&#8211;55 (1959). 13638508 10.1111/j.2044-8341.1959.tb00467.x 33. Williams JBW Kobak KA Development and reliability of a structured interview guide for the Montgomery Asberg Depression Rating Scale (SIGMA) Br. J. Psychiatry. 2008 192 52 58 10.1192/bjp.bp.106.032532 18174510 Williams, J. B. W. &amp; Kobak, K. A. Development and reliability of a structured interview guide for the Montgomery Asberg Depression Rating Scale (SIGMA). Br. J. Psychiatry. 192 , 52&#8211;58 (2008). 18174510 10.1192/bjp.bp.106.032532 34. Pennebaker, J. W., Boyd, R. L., Jordan, K. &amp; Blackburn, K. The development and psychometric properties of LIWC2015 https://repositories.lib.utexas.edu/items/705e81ca-940d-4c46-94ec-a52ffdc3b51f . 35. TF-IDF. In Sammut, C. &amp; Webb, G. I. (eds.) Encyclopedia of Machine Learning , 986-987 (Springer US). 10.1007/978-0-387-30164-8_832. 36. Zeng, X., Yang, C., Tu, C., Liu, Z. &amp; Sun, M. Chinese liwc lexicon expansion via hierarchical classification of word embeddings with sememe attention. In Proc. AAAI conference on artificial intelligence (AAAI Press) , Vol. 32, 10.1609/aaai.v32i1.11982 (2018). 37. Eyben, F., W&#246;llmer, M. &amp; Schuller, B. Opensmile: the munich versatile and fast open-source audio feature extractor. In Proc. 18th ACM international conference on Multimedia , MM &#8217;10, 1459-1462 (Association for Computing Machinery). 10.1145/1873951.1874246. 38. Chawla NV Bowyer KW Hall LO Kegelmeyer WP SMOTE: synthetic minority over-sampling technique J. Artif. Intell. Res. 2002 16 321 357 10.1613/jair.953 Chawla, N. V., Bowyer, K. W., Hall, L. O. &amp; Kegelmeyer, W. P. SMOTE: synthetic minority over-sampling technique. J. Artif. Intell. Res. 16 , 321&#8211;357 (2002). 39. Devlin, J., Chang, M., Lee, K. &amp; Toutanova, K. BERT: pre-training of deep bidirectional transformers for language understanding. CoRR abs/1810.04805, http://arxiv.org/abs/1810.04805 (2018). 40. Liu, Y. et al. Roberta: a robustly optimized bert pretraining approach. Preprint at arXiv preprint at 10.48550/arXiv.1907.11692 (2019). 41. Cui, Y. et al. Revisiting pre-trained models for Chinese natural language processing. In Proc. 2020 Conference on Empirical Methods in Natural Language Processing: Findings , 657-668, https://www.aclweb.org/anthology/2020.findings-emnlp.58 (Association for Computational Linguistics, Online, 2020). 42. Goh E Large language model influence on diagnostic reasoning: a randomized clinical trial JAMA Netw. Open 2024 7 e2440969 10.1001/jamanetworkopen.2024.40969 39466245 PMC11519755 Goh, E. et al. Large language model influence on diagnostic reasoning: a randomized clinical trial. JAMA Netw. Open 7 , e2440969 (2024). 39466245 10.1001/jamanetworkopen.2024.40969 PMC11519755 43. Stade, E. C. et al. Large language models could change the future of behavioral healthcare: a proposal for responsible development and evaluation. In: npj Mental Health Research 3.1 , pp. 1-12. 10.1038/s44184-024-00056-z (2024). 10.1038/s44184-024-00056-z PMC10987499 38609507 44. Xu, S. et al. Automated Verbal and Non-verbal Speech Analysis of Interviews of Individuals with Schizophrenia and Depression. In 2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC) , 225-228 (IEEE, 2019). 10.1109/EMBC.2019.8857071 31945883 45. Li, L., Zhang, X., Zhou, X. &amp; Liu, Z. AutoMIR: Effective zero-shot medical information retrieval without relevance labels. http://arxiv.org/abs/2410.20050 . 46. Sadariya, T. &amp; Verma, S. Early prediction and detection of anxiety level using support vector machine. In Swaroop, A., Polkowski, Z., Correia, S. D. &amp; Virdee, B. (eds.). In Proc. Data Analytics and Management , 279&#8211;291 (Springer Nature, 2023). 47. Harati, A. et al. Speech-based depression prediction using encoder-weight-only transfer learning and a large corpus. In ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) , 7273-7277 (IEEE, 2021). 48. Dibeklio&#287;lu H Hammal Z Yang Y Cohn JF Multimodal detection of depression in clinical interviews Proc. ACM Int. Conf. Multimodal Interact. ICMI 2015 2015 307 310 10.1145/2818346.2820776 27213186 PMC4874497 Dibeklio&#287;lu, H., Hammal, Z., Yang, Y. &amp; Cohn, J. F. Multimodal detection of depression in clinical interviews. Proc. ACM Int. Conf. Multimodal Interact. ICMI 2015 , 307&#8211;310 (2015). 27213186 10.1145/2818346.2820776 PMC4874497 49. Hettema JM Aggen SH Kubarych TS Neale MC Kendler KS Identification and validation of mixed anxiety&#8211;depression Psychol. Med. 2015 45 3075 3084 10.1017/S0033291715001038 26050714 Hettema, J. M., Aggen, S. H., Kubarych, T. S., Neale, M. C. &amp; Kendler, K. S. Identification and validation of mixed anxiety&#8211;depression. Psychol. Med. 45 , 3075&#8211;3084 (2015). 26050714 10.1017/S0033291715001038 50. Richter T Fishbain B Markus A Richter-Levin G Okon-Singer H Using machine learning-based analysis for behavioral differentiation between anxiety and depression Sci. Rep. 2020 10 16381 10.1038/s41598-020-72289-9 33009424 PMC7532220 Richter, T., Fishbain, B., Markus, A., Richter-Levin, G. &amp; Okon-Singer, H. Using machine learning-based analysis for behavioral differentiation between anxiety and depression. Sci. Rep. 10 , 16381 (2020). 33009424 10.1038/s41598-020-72289-9 PMC7532220 51. Liu K Droncheff B Warren SL Predictive utility of symptom measures in classifying anxiety and depression: a machine-learning approach Psychiatry Res. 2022 312 114534 10.1016/j.psychres.2022.114534 35381506 PMC9117511 Liu, K., Droncheff, B. &amp; Warren, S. L. Predictive utility of symptom measures in classifying anxiety and depression: a machine-learning approach. Psychiatry Res. 312 , 114534 (2022). 35381506 10.1016/j.psychres.2022.114534 PMC9117511 52. Clark LA Watson D Tripartite model of anxiety and depression: psychometric evidence and taxonomic implications J. Abnorm. Psychol. 1991 100 316 336 10.1037/0021-843X.100.3.316 1918611 Clark, L. A. &amp; Watson, D. Tripartite model of anxiety and depression: psychometric evidence and taxonomic implications. J. Abnorm. Psychol. 100 , 316&#8211;336 (1991). 1918611 10.1037//0021-843x.100.3.316"
}