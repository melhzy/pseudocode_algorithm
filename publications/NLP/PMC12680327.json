{
  "pmcid": "PMC12680327",
  "source": "PMC",
  "download_date": "2025-12-09T16:37:18.434134",
  "metadata": {
    "journal_title": "PLOS Computational Biology",
    "journal_nlm_ta": "PLoS Comput Biol",
    "journal_iso_abbrev": "PLoS Comput Biol",
    "journal": "PLOS Computational Biology",
    "pmcid": "PMC12680327",
    "pmid": "41348931",
    "doi": "10.1371/journal.pcbi.1013722",
    "title": "A meta-contrastive learning approach for clinical drug-drug interaction extraction from biomedical literature",
    "year": "2025",
    "month": "12",
    "day": "5",
    "pub_date": {
      "year": "2025",
      "month": "12",
      "day": "5"
    },
    "authors": [
      "Jia Yaxun",
      "Yuan Zhu",
      "Zhu Lian",
      "Xiang Zuo-lin"
    ],
    "abstract": "Drugâ€“drug interactions (DDIs) are a significant source of adverse drug events and pose critical challenges to patient safety and clinical decision-making. Extracting DDIs from biomedical literature plays an essential role in pharmacovigilance, yet remains difficult due to data sparsity and high annotation costs. This study presents BioMCL-DDI, a novel few-shot learning framework that integrates meta-learning with contrastive embedding strategies to enable efficient DDI extraction under limited supervision. BioMCL-DDI jointly optimizes prototype-based classification and supervised contrastive representation learning within a unified architecture. The model captures both intra-class compactness and inter-class separability, enhancing its generalization in sparse biomedical settings. We evaluate BioMCL-DDI on three benchmark datasets: DDI-2013, DrugBank, and the more recent TAC 2018 DDI Extraction corpus. The model achieves F1 scores of 87.80% on DDI-2013, 86.00% on DrugBank, and 74.85%/74.82% on the two official test sets of TAC 2018, consistently outperforming competitive baselines. Our model significantly outperforms state-of-the-art baselines in low-resource scenarios. BioMCL-DDI provides a scalable and effective solution for DDI extraction from biomedical texts, with strong potential for integration into clinical decision support systems and biomedical knowledge bases. All our code and data have been publicly released at:  https://github.com/Hero-Legend/BioMCL-DDI ."
  },
  "xml": "<?xml version=\"1.0\"  ?><!DOCTYPE pmc-articleset PUBLIC \"-//NLM//DTD ARTICLE SET 2.0//EN\" \"https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd\"><pmc-articleset><article xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:ali=\"http://www.niso.org/schemas/ali/1.0/\" xml:lang=\"en\" article-type=\"research-article\" dtd-version=\"1.4\"><processing-meta base-tagset=\"archiving\" mathml-version=\"3.0\" table-model=\"xhtml\" tagset-family=\"jats\"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type=\"nlm-ta\">PLoS Comput Biol</journal-id><journal-id journal-id-type=\"iso-abbrev\">PLoS Comput Biol</journal-id><journal-id journal-id-type=\"pmc-domain-id\">328</journal-id><journal-id journal-id-type=\"pmc-domain\">ploscomp</journal-id><journal-id journal-id-type=\"publisher-id\">plos</journal-id><journal-title-group><journal-title>PLOS Computational Biology</journal-title></journal-title-group><issn pub-type=\"ppub\">1553-734X</issn><issn pub-type=\"epub\">1553-7358</issn><publisher><publisher-name>PLOS</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type=\"pmcid\">PMC12680327</article-id><article-id pub-id-type=\"pmcid-ver\">PMC12680327.1</article-id><article-id pub-id-type=\"pmcaid\">12680327</article-id><article-id pub-id-type=\"pmcaiid\">12680327</article-id><article-id pub-id-type=\"pmid\">41348931</article-id><article-id pub-id-type=\"doi\">10.1371/journal.pcbi.1013722</article-id><article-id pub-id-type=\"publisher-id\">PCOMPBIOL-D-25-01554</article-id><article-version article-version-type=\"pmc-version\">1</article-version><article-categories><subj-group subj-group-type=\"heading\"><subject>Research Article</subject></subj-group><subj-group subj-group-type=\"Discipline-v3\"><subject>Medicine and Health Sciences</subject><subj-group><subject>Pharmacology</subject><subj-group><subject>Drug Interactions</subject></subj-group></subj-group></subj-group><subj-group subj-group-type=\"Discipline-v3\"><subject>Medicine and Health Sciences</subject><subj-group><subject>Pharmacology</subject><subj-group><subject>Drug Research and Development</subject><subj-group><subject>Drug Safety</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type=\"Discipline-v3\"><subject>Engineering and Technology</subject><subj-group><subject>Technology Development</subject><subj-group><subject>Prototypes</subject></subj-group></subj-group></subj-group><subj-group subj-group-type=\"Discipline-v3\"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive Science</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type=\"Discipline-v3\"><subject>Biology and Life Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type=\"Discipline-v3\"><subject>Social Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type=\"Discipline-v3\"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Learning and Memory</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type=\"Discipline-v3\"><subject>Medicine and Health Sciences</subject><subj-group><subject>Pharmacology</subject><subj-group><subject>Adverse Reactions</subject></subj-group></subj-group></subj-group><subj-group subj-group-type=\"Discipline-v3\"><subject>Medicine and Health Sciences</subject><subj-group><subject>Epidemiology</subject><subj-group><subject>Medical Risk Factors</subject></subj-group></subj-group></subj-group><subj-group subj-group-type=\"Discipline-v3\"><subject>Medicine and Health Sciences</subject><subj-group><subject>Pharmacology</subject><subj-group><subject>Drug Interactions</subject><subj-group><subject>Drug-Drug Interactions</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type=\"Discipline-v3\"><subject>Medicine and Health Sciences</subject><subj-group><subject>Health Care</subject><subj-group><subject>Health Information Technology</subject><subj-group><subject>Clinical Decision Support Systems</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type=\"Discipline-v3\"><subject>Computer and Information Sciences</subject><subj-group><subject>Information Technology</subject><subj-group><subject>Health Information Technology</subject><subj-group><subject>Clinical Decision Support Systems</subject></subj-group></subj-group></subj-group></subj-group></article-categories><title-group><article-title>A meta-contrastive learning approach for clinical drug-drug interaction extraction from biomedical literature</article-title><alt-title alt-title-type=\"running-head\">Clinical drug-drug interaction extraction</alt-title></title-group><contrib-group><contrib contrib-type=\"author\" equal-contrib=\"yes\"><contrib-id authenticated=\"true\" contrib-id-type=\"orcid\">https://orcid.org/0000-0001-5808-4997</contrib-id><name name-style=\"western\"><surname>Jia</surname><given-names initials=\"Y\">Yaxun</given-names></name><role content-type=\"http://credit.niso.org/contributor-roles/conceptualization/\">Conceptualization</role><role content-type=\"http://credit.niso.org/contributor-roles/methodology/\">Methodology</role><role content-type=\"http://credit.niso.org/contributor-roles/software/\">Software</role><role content-type=\"http://credit.niso.org/contributor-roles/validation/\">Validation</role><role content-type=\"http://credit.niso.org/contributor-roles/writing-original-draft/\">Writing &#8211; original draft</role><xref rid=\"aff001\" ref-type=\"aff\">\n<sup>1</sup>\n</xref></contrib><contrib contrib-type=\"author\" equal-contrib=\"yes\"><name name-style=\"western\"><surname>Yuan</surname><given-names initials=\"Z\">Zhu</given-names></name><role content-type=\"http://credit.niso.org/contributor-roles/conceptualization/\">Conceptualization</role><role content-type=\"http://credit.niso.org/contributor-roles/formal-analysis/\">Formal analysis</role><role content-type=\"http://credit.niso.org/contributor-roles/funding-acquisition/\">Funding acquisition</role><role content-type=\"http://credit.niso.org/contributor-roles/investigation/\">Investigation</role><role content-type=\"http://credit.niso.org/contributor-roles/software/\">Software</role><role content-type=\"http://credit.niso.org/contributor-roles/validation/\">Validation</role><role content-type=\"http://credit.niso.org/contributor-roles/writing-review-editing/\">Writing &#8211; review &amp; editing</role><xref rid=\"aff002\" ref-type=\"aff\">\n<sup>2</sup>\n</xref></contrib><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Zhu</surname><given-names initials=\"L\">Lian</given-names></name><role content-type=\"http://credit.niso.org/contributor-roles/conceptualization/\">Conceptualization</role><role content-type=\"http://credit.niso.org/contributor-roles/software/\">Software</role><role content-type=\"http://credit.niso.org/contributor-roles/validation/\">Validation</role><role content-type=\"http://credit.niso.org/contributor-roles/writing-review-editing/\">Writing &#8211; review &amp; editing</role><xref rid=\"aff001\" ref-type=\"aff\">\n<sup>1</sup>\n</xref></contrib><contrib contrib-type=\"author\" corresp=\"yes\"><contrib-id authenticated=\"true\" contrib-id-type=\"orcid\">https://orcid.org/0000-0002-5725-842X</contrib-id><name name-style=\"western\"><surname>Xiang</surname><given-names initials=\"ZL\">Zuo-lin</given-names></name><role content-type=\"http://credit.niso.org/contributor-roles/conceptualization/\">Conceptualization</role><role content-type=\"http://credit.niso.org/contributor-roles/formal-analysis/\">Formal analysis</role><role content-type=\"http://credit.niso.org/contributor-roles/funding-acquisition/\">Funding acquisition</role><role content-type=\"http://credit.niso.org/contributor-roles/investigation/\">Investigation</role><role content-type=\"http://credit.niso.org/contributor-roles/software/\">Software</role><role content-type=\"http://credit.niso.org/contributor-roles/validation/\">Validation</role><role content-type=\"http://credit.niso.org/contributor-roles/writing-review-editing/\">Writing &#8211; review &amp; editing</role><xref rid=\"aff001\" ref-type=\"aff\">\n<sup>1</sup>\n</xref><xref rid=\"aff003\" ref-type=\"aff\">\n<sup>3</sup>\n</xref><xref rid=\"cor001\" ref-type=\"corresp\">*</xref></contrib></contrib-group><aff id=\"aff001\"><label>1</label>\n<addr-line>Department of Radiation Oncology, Shanghai East Hospital, Tongji University School of Medicine, Shanghai, China</addr-line></aff><aff id=\"aff002\"><label>2</label>\n<addr-line>Department of Information Management, The National Police University for Criminal Justice, Baoding, China</addr-line></aff><aff id=\"aff003\"><label>3</label>\n<addr-line>Department of Radiation Oncology, Shanghai East Hospital Ji&#8217;an Hospital, Jian, China</addr-line></aff><contrib-group><contrib contrib-type=\"editor\"><name name-style=\"western\"><surname>Jin</surname><given-names initials=\"Q\">Qiangguo</given-names></name><role>Editor</role><xref rid=\"edit1\" ref-type=\"aff\"/></contrib></contrib-group><aff id=\"edit1\">\n<addr-line>Northwestern Polytechnical University, CHINA</addr-line>\n</aff><author-notes><corresp id=\"cor001\">* E-mail: <email>xiangzuolinmd@hotmail.com</email></corresp><fn fn-type=\"COI-statement\" id=\"coi001\"><p>The authors have declared that no competing interests exist.</p></fn></author-notes><pub-date pub-type=\"epub\"><day>5</day><month>12</month><year>2025</year></pub-date><pub-date pub-type=\"collection\"><month>12</month><year>2025</year></pub-date><volume>21</volume><issue>12</issue><issue-id pub-id-type=\"pmc-issue-id\">501629</issue-id><elocation-id>e1013722</elocation-id><history><date date-type=\"received\"><day>5</day><month>8</month><year>2025</year></date><date date-type=\"accepted\"><day>7</day><month>11</month><year>2025</year></date></history><pub-history><event event-type=\"pmc-release\"><date><day>05</day><month>12</month><year>2025</year></date></event><event event-type=\"pmc-live\"><date><day>06</day><month>12</month><year>2025</year></date></event><event event-type=\"pmc-last-change\"><date iso-8601-date=\"2025-12-07 14:25:12.767\"><day>07</day><month>12</month><year>2025</year></date></event></pub-history><permissions><copyright-statement>&#169; 2025 Jia et al</copyright-statement><copyright-year>2025</copyright-year><copyright-holder>Jia et al</copyright-holder><license><ali:license_ref specific-use=\"textmining\" content-type=\"ccbylicense\">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open access article distributed under the terms of the <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://creativecommons.org/licenses/by/4.0/\">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><self-uri xmlns:xlink=\"http://www.w3.org/1999/xlink\" content-type=\"pmc-pdf\" xlink:href=\"pcbi.1013722.pdf\"/><self-uri xmlns:xlink=\"http://www.w3.org/1999/xlink\" content-type=\"pdf\" xlink:href=\"pcbi.1013722.pdf\"/><abstract><p>Drug&#8211;drug interactions (DDIs) are a significant source of adverse drug events and pose critical challenges to patient safety and clinical decision-making. Extracting DDIs from biomedical literature plays an essential role in pharmacovigilance, yet remains difficult due to data sparsity and high annotation costs. This study presents BioMCL-DDI, a novel few-shot learning framework that integrates meta-learning with contrastive embedding strategies to enable efficient DDI extraction under limited supervision. BioMCL-DDI jointly optimizes prototype-based classification and supervised contrastive representation learning within a unified architecture. The model captures both intra-class compactness and inter-class separability, enhancing its generalization in sparse biomedical settings. We evaluate BioMCL-DDI on three benchmark datasets: DDI-2013, DrugBank, and the more recent TAC 2018 DDI Extraction corpus. The model achieves F1 scores of 87.80% on DDI-2013, 86.00% on DrugBank, and 74.85%/74.82% on the two official test sets of TAC 2018, consistently outperforming competitive baselines. Our model significantly outperforms state-of-the-art baselines in low-resource scenarios. BioMCL-DDI provides a scalable and effective solution for DDI extraction from biomedical texts, with strong potential for integration into clinical decision support systems and biomedical knowledge bases. All our code and data have been publicly released at: <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"https://github.com/Hero-Legend/BioMCL-DDI\" ext-link-type=\"uri\">https://github.com/Hero-Legend/BioMCL-DDI</ext-link>.</p></abstract><abstract abstract-type=\"summary\"><title>Author summary</title><p>Drug-drug interactions (DDIs) are a significant source of adverse drug events and pose critical challenges to patient safety. While existing drug databases offer valuable DDI information, they often struggle to keep pace with the rapidly expanding biomedical literature, leaving many new interactions unaddressed. To tackle this challenge, we developed BioMCL-DDI, a lightweight meta-contrastive learning framework designed for efficient DDI extraction from biomedical texts, especially in scenarios with sparse data. Our method integrates prototype-based classification with contrastive embedding strategies, jointly optimizing them within a unified architecture. This allows our model to generalize effectively even with limited annotated data. We evaluated BioMCL-DDI on two benchmark datasets, and our results show that our model significantly outperforms existing techniques in low-resource settings. BioMCL-DDI offers a scalable and effective solution for DDI extraction from biomedical texts, with strong potential for integration into clinical decision support systems and biomedical knowledge bases to enhance medication safety.</p></abstract><funding-group><award-group id=\"award001\"><funding-source><institution-wrap><institution-id institution-id-type=\"funder-id\">http://dx.doi.org/10.13039/501100001809</institution-id><institution>National Natural Science Foundation of China</institution></institution-wrap></funding-source><award-id>82160591</award-id><principal-award-recipient><contrib-id authenticated=\"true\" contrib-id-type=\"orcid\">https://orcid.org/0000-0002-5725-842X</contrib-id><name name-style=\"western\"><surname>Xiang</surname><given-names>Zuo-lin</given-names></name></principal-award-recipient></award-group><award-group id=\"award002\"><funding-source><institution>Key Project of Clinical Research of Shanghai East Hospital, Tongji University</institution></funding-source><award-id>DFLC2022012</award-id><principal-award-recipient><contrib-id authenticated=\"true\" contrib-id-type=\"orcid\">https://orcid.org/0000-0002-5725-842X</contrib-id><name name-style=\"western\"><surname>Xiang</surname><given-names>Zuo-lin</given-names></name></principal-award-recipient></award-group><award-group id=\"award003\"><funding-source><institution>Key Specialty Construction Project of Shanghai Pudong New Area Health Commission</institution></funding-source><award-id>PWZzk2022-02</award-id><principal-award-recipient><contrib-id authenticated=\"true\" contrib-id-type=\"orcid\">https://orcid.org/0000-0002-5725-842X</contrib-id><name name-style=\"western\"><surname>Xiang</surname><given-names>Zuo-lin</given-names></name></principal-award-recipient></award-group><award-group id=\"award004\"><funding-source><institution>Outstanding Leaders Training Program of Pudong Health Bureau of Shanghai</institution></funding-source><award-id>PWR12023-02</award-id><principal-award-recipient><contrib-id authenticated=\"true\" contrib-id-type=\"orcid\">https://orcid.org/0000-0002-5725-842X</contrib-id><name name-style=\"western\"><surname>Xiang</surname><given-names>Zuo-lin</given-names></name></principal-award-recipient></award-group><award-group id=\"award005\"><funding-source><institution>Shanghai Science Technology Innovation Action Plan</institution></funding-source><award-id>23Y11909000</award-id><principal-award-recipient><contrib-id authenticated=\"true\" contrib-id-type=\"orcid\">https://orcid.org/0000-0002-5725-842X</contrib-id><name name-style=\"western\"><surname>Xiang</surname><given-names>Zuo-lin</given-names></name></principal-award-recipient></award-group><award-group id=\"award006\"><funding-source><institution>Science Research Project of Hebei Education Department</institution></funding-source><award-id>QN2025011</award-id><principal-award-recipient><name name-style=\"western\"><surname>Yuan</surname><given-names>Zhu</given-names></name></principal-award-recipient></award-group><award-group id=\"award007\"><funding-source><institution>Doctoral Research Start-up Fund Program of The National Police University for Criminal Justice</institution></funding-source><award-id>BSQDW202150</award-id><principal-award-recipient><name name-style=\"western\"><surname>Yuan</surname><given-names>Zhu</given-names></name></principal-award-recipient></award-group><funding-statement>This work is supported by National Natural Science Foundation of China (82160591 to Zl.X.), Key Project of Clinical Research of Shanghai East Hospital, Tongji University (DFLC2022012 to Zl.X.), Key Specialty Construction Project of Shanghai Pudong New Area Health Commission (PWZzk2022-02 to Zl.X.), Funded by Outstanding Leaders Training Program of Pudong Health Bureau of Shanghai (PWR12023-02 to Zl.X.) and Shanghai Science Technology Innovation Action Plan (23Y11909000 to Zl.X.), Science Research Project of Hebei Education Department (QN2025011 to Z.Y.) and Doctoral Research Start-up Fund Program of The National Police University for Criminal Justice (BSQDW202150 to Z.Y.). Zuo-lin Xiang is the corresponding author of this paper. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><fig-count count=\"11\"/><table-count count=\"9\"/><page-count count=\"25\"/></counts><custom-meta-group><custom-meta><meta-name>pmc-status-qastatus</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>pmc-status-live</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-status-embargo</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-status-released</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-open-access</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-olf</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-manuscript</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-legally-suppressed</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-pdf</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-supplement</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-pdf-only</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-suppress-copyright</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-real-version</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-scanned-article</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-preprint</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-in-epmc</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta id=\"data-availability\"><meta-name>Data Availability</meta-name><meta-value>All our code and data have been publicly released at: <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"https://github.com/Hero-Legend/BioMCL-DDI\" ext-link-type=\"uri\">https://github.com/Hero-Legend/BioMCL-DDI</ext-link>.</meta-value></custom-meta></custom-meta-group></article-meta><notes><title>Data Availability</title><p>All our code and data have been publicly released at: <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"https://github.com/Hero-Legend/BioMCL-DDI\" ext-link-type=\"uri\">https://github.com/Hero-Legend/BioMCL-DDI</ext-link>.</p></notes></front><body><sec sec-type=\"intro\" id=\"sec001\"><title>Introduction</title><p>Drug&#8211;drug interactions (DDIs) are a critical factor in pharmacovigilance and clinical decision-making, as they can significantly alter the efficacy or safety of co-administered drugs. In clinical settings, especially among elderly patients or those undergoing polypharmacy, unrecognized DDIs can lead to adverse drug reactions (ADRs), increased hospitalization, and even mortality [<xref rid=\"pcbi.1013722.ref001\" ref-type=\"bibr\">1</xref>&#8211;<xref rid=\"pcbi.1013722.ref003\" ref-type=\"bibr\">3</xref>]. Thus, accurate and timely identification of potential DDIs is vital for enhancing medication safety and supporting personalized treatment regimens. While structured knowledge bases such as DrugBank offer manually curated DDI records, they are often incomplete or unable to keep pace with the rapid expansion of biomedical literature. This creates a pressing need for automatic DDI extraction systems that can identify emerging interactions from unstructured biomedical texts [<xref rid=\"pcbi.1013722.ref004\" ref-type=\"bibr\">4</xref>&#8211;<xref rid=\"pcbi.1013722.ref009\" ref-type=\"bibr\">9</xref>].</p><p>Recent advances in deep learning, particularly the introduction of transformer-based models such as BioBERT [<xref rid=\"pcbi.1013722.ref011\" ref-type=\"bibr\">11</xref>], have significantly improved the performance of biomedical relation extraction tasks, including DDI classification. However, these models typically require large-scale annotated corpora, which are rarely available in real-world scenarios&#8212;especially when dealing with new drug compounds or infrequent interaction types. Under such low-resource conditions, traditional supervised learning methods often struggle with data sparsity, class imbalance, and limited generalization to unseen relation types. Few-shot learning has emerged as a promising solution to address these challenges. Meta-learning techniques such as Prototypical Networks enable rapid adaptation to new classes using only a few labeled instances, while contrastive learning facilitates more discriminative embedding spaces through pairwise representation alignment. However, existing few-shot approaches often suffer from two practical limitations: (1) meta-learning typically relies on episodic task sampling, which increases training complexity and limits scalability; and (2) contrastive learning is often applied only during pretraining or as an auxiliary loss, thus underutilizing its potential in few-shot supervised settings.</p><p>To address these issues, we propose BioMCL-DDI, a unified meta-contrastive learning framework for few-shot DDI extraction under sparse supervision. Unlike previous methods that treat meta-learning and contrastive learning as separate objectives, our approach introduces a joint optimization strategy in which prototype-based classification and instance-level contrastive embedding are co-regularized. Moreover, we design a lightweight meta-inspired regularization component that improves intra-class cohesion and inter-class separability without requiring episodic sampling or task-level adaptation. This architecture enhances scalability and robustness in DDI scenarios characterized by noisy class boundaries and highly imbalanced distributions. The model&#8217;s essential output is a classification of drug pairs into one of five predefined categories: DDI-false, DDI-effect, DDI-mechanism, DDI-advise, or DDI-int. Experimental results on the benchmark DDI-2013 dataset demonstrate that BioMCL-DDI achieves a new state-of-the-art F1 score of 87.80%. In addition, cross-domain evaluation on the DDI-DrugBank corpus confirms the generalizability of our model, achieving 86.00% F1 with only 100 labeled samples per class. More importantly, evaluation on the recent TAC 2018 DDI Extraction corpus further validates the robustness of our framework, where BioMCL-DDI attains F1 scores of 74.85% and 74.82% on the two official test sets, surpassing all competitive baselines. These results highlight the strong cross-domain transferability of our approach and its potential applicability to real-world biomedical texts such as structured product labels and regulatory documents. Through extensive ablation and embedding analysis, we further demonstrate that our dual-objective architecture leads to improved semantic clustering and relational discrimination in few-shot biomedical NLP tasks.</p><p>Our main contributions are summarized as follows:</p><list list-type=\"bullet\"><list-item><p>We propose BioMCL-DDI, a meta-contrastive learning framework that unifies prototype-based classification and contrastive embedding learning into a single supervised architecture for few-shot DDI extraction.</p></list-item><list-item><p>We introduce a meta-inspired regularization mechanism that eliminates the need for episodic training and enhances representation consistency in the presence of class imbalance and limited supervision.</p></list-item><list-item><p>We conduct comprehensive experiments on DDI-2013 and DDI-DrugBank datasets, demonstrating that BioMCL-DDI outperforms recent strong baselines in both in-domain and cross-domain scenarios.</p></list-item><list-item><p>We provide ablation and embedding space analyses to investigate how each module contributes to semantic representation quality and fine-grained relation modeling.</p></list-item></list></sec><sec id=\"sec002\"><title>Related work</title><p>Drug&#8211;drug interaction (DDI) extraction has long been an important task in biomedical NLP, with research evolving from traditional rule-based systems to advanced deep learning methods.</p><p>Early approaches utilized convolutional and recurrent architectures to encode sentence-level dependencies. For example, CNN-based models such as DCNN [<xref rid=\"pcbi.1013722.ref012\" ref-type=\"bibr\">12</xref>], CNN [<xref rid=\"pcbi.1013722.ref013\" ref-type=\"bibr\">13</xref>], SCNN [<xref rid=\"pcbi.1013722.ref014\" ref-type=\"bibr\">14</xref>], and MCCNN [<xref rid=\"pcbi.1013722.ref015\" ref-type=\"bibr\">15</xref>] exploited syntactic and positional cues to improve feature locality. Meanwhile, LSTM-based methods including ATT-LSTM [<xref rid=\"pcbi.1013722.ref016\" ref-type=\"bibr\">16</xref>], DLSTM [<xref rid=\"pcbi.1013722.ref017\" ref-type=\"bibr\">17</xref>], and Skeleton-LSTM [<xref rid=\"pcbi.1013722.ref018\" ref-type=\"bibr\">18</xref>] focused on long-range contextual modeling and attention-guided extraction.</p><p>To further capture complex biomedical semantics, hybrid and graph-based architectures were introduced. Joint-ABLSTM [<xref rid=\"pcbi.1013722.ref019\" ref-type=\"bibr\">19</xref>], HRNN [<xref rid=\"pcbi.1013722.ref020\" ref-type=\"bibr\">20</xref>], and PM-BLSTM [<xref rid=\"pcbi.1013722.ref021\" ref-type=\"bibr\">21</xref>] incorporated hierarchical or multi-path structures, while GCNN [<xref rid=\"pcbi.1013722.ref022\" ref-type=\"bibr\">22</xref>], GRU-GCN [<xref rid=\"pcbi.1013722.ref023\" ref-type=\"bibr\">23</xref>], and SM-GCN [<xref rid=\"pcbi.1013722.ref024\" ref-type=\"bibr\">24</xref>] applied graph neural networks for relation-aware inference.</p><p>The introduction of pretrained language models marked a major breakthrough in DDI extraction. Models such as R-BERT [<xref rid=\"pcbi.1013722.ref025\" ref-type=\"bibr\">25</xref>], MEAT-BioBERT [<xref rid=\"pcbi.1013722.ref026\" ref-type=\"bibr\">26</xref>], and CDBERT [<xref rid=\"pcbi.1013722.ref028\" ref-type=\"bibr\">28</xref>] leveraged contextualized biomedical embeddings to enhance semantic understanding. Recent variants like IMSE [<xref rid=\"pcbi.1013722.ref029\" ref-type=\"bibr\">29</xref>], DREAM [<xref rid=\"pcbi.1013722.ref030\" ref-type=\"bibr\">30</xref>], and EMSI-BERT [<xref rid=\"pcbi.1013722.ref031\" ref-type=\"bibr\">31</xref>] further integrated molecular structures and domain-specific features to push the performance frontier.</p><p>Beyond text-only representations, a growing body of work has focused on integrating structured biomedical knowledge. DDIKG [<xref rid=\"pcbi.1013722.ref032\" ref-type=\"bibr\">32</xref>], DKPL [<xref rid=\"pcbi.1013722.ref033\" ref-type=\"bibr\">33</xref>], and BERT-MLRE [<xref rid=\"pcbi.1013722.ref035\" ref-type=\"bibr\">35</xref>] introduce drug-related priors through prompts or external graphs. Simultaneously, attention-guided graph architectures such as BBL-GAT [<xref rid=\"pcbi.1013722.ref007\" ref-type=\"bibr\">7</xref>], BLRG [<xref rid=\"pcbi.1013722.ref008\" ref-type=\"bibr\">8</xref>], and BioFocal-DDI [<xref rid=\"pcbi.1013722.ref009\" ref-type=\"bibr\">9</xref>] have demonstrated improved structural sensitivity in capturing relational semantics. LLM-DDI [<xref rid=\"pcbi.1013722.ref010\" ref-type=\"bibr\">10</xref>] integrates a large language model (LLM) with a graph neural network (GNN) to predict DDIs on a biomedical knowledge graph (BKG). This approach effectively combines the LLM&#8217;s rich semantic understanding with the GNN&#8217;s ability to model network topology. Despite these advancements, most models still rely on full supervision and struggle in low-resource regimes&#8212;especially with rare or novel drug combinations.</p><p>To address data scarcity, few-shot learning has been explored for biomedical relation extraction. Meta-learning paradigms, such as Prototypical Networks [<xref rid=\"pcbi.1013722.ref036\" ref-type=\"bibr\">36</xref>] and MAML [<xref rid=\"pcbi.1013722.ref037\" ref-type=\"bibr\">37</xref>], enable rapid adaptation from limited supervision and have been investigated in domain-specific tasks. However, these methods often rely on episodic training structures or meta-level optimization that complicate integration with standard supervised pipelines.</p><p>In parallel, contrastive learning has proven effective in biomedical representation learning. MEAT-BioBERT [<xref rid=\"pcbi.1013722.ref026\" ref-type=\"bibr\">26</xref>] incorporates instance-level contrastive alignment to enhance embedding quality. MCL-DDI [<xref rid=\"pcbi.1013722.ref027\" ref-type=\"bibr\">27</xref>] employs a multi-view contrastive learning framework that integrates molecular structures and network features to enhance DDI event prediction. Despite their promise, most contrastive approaches are either used during pretraining or as auxiliary objectives, with limited application to fully supervised few-shot classification tasks like DDI extraction.</p><p>While both meta-learning and contrastive learning have independently improved generalization under limited data, their integration remains underexplored in DDI extraction. <xref rid=\"pcbi.1013722.t001\" ref-type=\"table\">Table 1</xref> summarizes several representative few-shot or contrastive learning-based approaches most relevant to our work. Existing few-shot methods often separate classification and representation learning, rely on episodic training loops, or fail to adapt to high class imbalance. Furthermore, most contrastive-enhanced methods focus on global representation alignment but overlook class-level semantic structure. In this work, we propose BioMCL-DDI, a meta-contrastive learning framework that addresses these limitations via joint supervised optimization. Our approach unifies prototype-based class modeling and instance-level contrastive regularization in a single objective, without requiring episodic training or auxiliary stages. This enables BioMCL-DDI to learn structurally consistent and discriminative representations under extreme low-resource settings, offering a scalable and clinically meaningful solution for DDI extraction.</p><table-wrap position=\"float\" id=\"pcbi.1013722.t001\" orientation=\"portrait\"><object-id pub-id-type=\"doi\">10.1371/journal.pcbi.1013722.t001</object-id><label>Table 1</label><caption><title>Key related works in few-shot or contrastive DDI extraction.</title></caption><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pcbi.1013722.t001g\" position=\"float\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.t001.jpg\"/><table frame=\"hsides\" rules=\"groups\"><colgroup span=\"1\"><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/></colgroup><thead><tr><th align=\"left\" rowspan=\"1\" colspan=\"1\">Method</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">Approach Type</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">Few-Shot Capable</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">Contrastive Objective</th></tr></thead><tbody><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">Prototypical Networks [<xref rid=\"pcbi.1013722.ref036\" ref-type=\"bibr\">36</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Meta-learning</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">&#10003;</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">&#215;</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">MAML [<xref rid=\"pcbi.1013722.ref037\" ref-type=\"bibr\">37</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Meta-learning</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">&#10003;</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">&#215;</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">MEAT-BioBERT [<xref rid=\"pcbi.1013722.ref026\" ref-type=\"bibr\">26</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Transformer + Contrastive</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">&#215;</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">&#10003;</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">KSS-DDI [<xref rid=\"pcbi.1013722.ref052\" ref-type=\"bibr\">52</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Prompt-based</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">&#10003;</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">&#215;</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">HKG-DDI [<xref rid=\"pcbi.1013722.ref032\" ref-type=\"bibr\">32</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Knowledge Graph Enhanced</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">&#215;</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">&#215;</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">BioMCL-DDI (Ours)</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Meta + Contrastive</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">&#10003;</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">&#10003;</td></tr></tbody></table></alternatives></table-wrap></sec><sec sec-type=\"materials|methods\" id=\"sec003\"><title>Materials and methods</title><p>This section presents the architecture and training strategy of BioMCL-DDI, a unified meta-contrastive learning framework for few-shot drug&#8211;drug interaction extraction. The proposed model is designed to address two major challenges in clinical NLP systems: data sparsity, where annotated biomedical DDI examples are limited, and class imbalance, where frequent and rare interaction types co-exist in skewed distributions.</p><p>To overcome these challenges, BioMCL-DDI integrates class-level generalization via prototype learning and instance-level feature discrimination via contrastive learning within a single, fully supervised architecture. This joint optimization eliminates the need for complex episodic sampling routines common in meta-learning while improving scalability and robustness under low-resource biomedical scenarios.</p><p>As illustrated in <xref rid=\"pcbi.1013722.g001\" ref-type=\"fig\">Fig 1</xref>, the model consists of three main modules: a domain-specific contextual encoder based on BioBERT, a prototypical classifier that computes class-wise centroids, and a supervised contrastive module that promotes inter-class separability. All modules are trained end-to-end using a joint loss function to produce generalizable and semantically consistent embeddings for DDI classification.</p><fig position=\"float\" id=\"pcbi.1013722.g001\" orientation=\"portrait\"><object-id pub-id-type=\"doi\">10.1371/journal.pcbi.1013722.g001</object-id><label>Fig 1</label><caption><title>Overview of the BioMCL-DDI framework.</title><p>Sentences are encoded by BioBERT and projected into a shared embedding space. The resulting representations are simultaneously optimized using prototypical loss and contrastive loss. During inference, the model classifies new instances by measuring the distance between their embeddings and the pre-computed class prototypes.</p></caption><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" position=\"float\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.g001.jpg\"/></fig><sec id=\"sec004\"><title>Contextual representation via BioBERT</title><p>To capture domain-specific semantics relevant to drug drug interaction (DDI) classification, BioMCL-DDI employs BioBERT as its contextual encoding backbone. Bio-BERT is a transformer-based language model pretrained on large-scale biomedical corpora such as PubMed abstracts and PMC full texts [<xref rid=\"pcbi.1013722.ref011\" ref-type=\"bibr\">11</xref>], enabling it to effectively model complex linguistic patterns and relational cues in biomedical texts.</p><p>Given an input sentence <italic toggle=\"yes\">S</italic> that describes a candidate interaction between two drug entities, the sentence is first tokenized using the BioBERT tokenizer. Special tokens [CLS] and [SEP] are inserted to delineate the sentence boundaries, and entity markers are optionally applied to highlight the positions of the interacting drugs. These markers serve to guide the model&#8217;s attention toward the relevant semantic context.</p><p>The encoded sentence is passed through BioBERT to produce a sequence of contextual embeddings <inline-formula id=\"pcbi.1013722.e001\"><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pcbi.1013722.e001g\" position=\"anchor\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.e001.jpg\"/><mml:math id=\"M1\" display=\"inline\" overflow=\"scroll\"><mml:mrow><mml:mo stretchy=\"false\">{</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>&#8230;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo stretchy=\"false\">}</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>. Among these, the hidden state corresponding to the [CLS] token&#8212;denoted as <inline-formula id=\"pcbi.1013722.e002\"><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pcbi.1013722.e002g\" position=\"anchor\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.e002.jpg\"/><mml:math id=\"M2\" display=\"inline\" overflow=\"scroll\"><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mtext>cls</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>&#8212;is extracted to serve as a condensed global representation of the input. This representation is projected into a task-specific embedding space via a linear transformation:</p><disp-formula id=\"pcbi.1013722.e003\"><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pcbi.1013722.e003g\" position=\"anchor\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.e003.jpg\"/><mml:math id=\"M3\" display=\"block\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mtext>Proj</mml:mtext><mml:mo stretchy=\"false\">(</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mtext>cls</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy=\"false\">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mtext>cls</mml:mtext></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></alternatives><label>(1)</label></disp-formula><p>where <italic toggle=\"yes\">W</italic><sub><italic toggle=\"yes\">p</italic></sub> and <italic toggle=\"yes\">b</italic><sub><italic toggle=\"yes\">p</italic></sub> are trainable parameters. The resulting embedding <italic toggle=\"yes\">z</italic> is subsequently shared across both the prototypical classification and contrastive learning branches, enabling unified representation learning for downstream optimization.</p><sec id=\"sec006\"><title>Example.</title><p>For instance, consider the biomedical sentence: <italic toggle=\"yes\">&#8220;The coadministration of</italic>\n<bold>aspirin</bold>\n<italic toggle=\"yes\">and</italic>\n<bold>warfarin</bold>\n<italic toggle=\"yes\">may increase the risk of bleeding.&#8221;</italic> This sentence contains two marked drug entities (aspirin and warfarin). After tokenization and insertion of special tokens, the input fed to BioBERT is represented as:<disp-quote><p>[CLS] The coadministration of <bold>aspirin</bold> and <bold>warfarin</bold> may increase the risk of bleeding . [SEP]</p></disp-quote>\n</p><p>The corresponding gold label of this example is <italic toggle=\"yes\">Effect</italic>. This demonstrates how real biomedical text is preprocessed and evaluated by the model, highlighting its applicability to practical DDI extraction scenarios such as clinical notes and drug package inserts.</p></sec></sec><sec id=\"sec007\"><title>Prototype-based classification for few-shot adaptation</title><p>To enable robust classification under limited supervision, BioMCL-DDI employs a prototype-based learning strategy that facilitates generalization to novel interaction types using only a few labeled examples. This approach is particularly well-suited to biomedical domains such as pharmacovigilance, where rare or emerging drug&#8211;drug interactions may lack sufficient annotations.</p><p>In this framework, the prototypical network classifier acts as a metric-based classification head that operates on the shared embedding space. Its architecture is lightweight, consisting of a linear projection layer followed by a distance-based classification mechanism. A class prototype serves as a centroid representation for each interaction type, computed from a support set of known labeled instances. Formally, for each class <italic toggle=\"yes\">c</italic>, we calculate its prototype vector <inline-formula id=\"pcbi.1013722.e004\"><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pcbi.1013722.e004g\" position=\"anchor\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.e004.jpg\"/><mml:math id=\"M4\" display=\"inline\" overflow=\"scroll\"><mml:mrow><mml:msub><mml:mi>&#956;</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> as the mean of the embeddings {<italic toggle=\"yes\">z</italic><sub><italic toggle=\"yes\">i</italic></sub>} corresponding to support instances in class <italic toggle=\"yes\">c</italic>:</p><disp-formula id=\"pcbi.1013722.e005\"><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pcbi.1013722.e005g\" position=\"anchor\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.e005.jpg\"/><mml:math id=\"M5\" display=\"block\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:msub><mml:mi>&#956;</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo stretchy=\"false\">|</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo stretchy=\"false\">|</mml:mo></mml:mrow></mml:mfrac><mml:msub><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#8712;</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:msub><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></alternatives><label>(2)</label></disp-formula><p>where <italic toggle=\"yes\">S</italic><sub><italic toggle=\"yes\">c</italic></sub> denotes the set of support instances labeled with class <italic toggle=\"yes\">c</italic>, and <italic toggle=\"yes\">z</italic><sub><italic toggle=\"yes\">i</italic></sub> is the embedding derived from BioBERT followed by linear projection. These prototypes are then used to classify query instances based on their proximity in the embedding space.</p><p>Given a query embedding <italic toggle=\"yes\">z</italic><sub><italic toggle=\"yes\">q</italic></sub>, its probability of belonging to class <italic toggle=\"yes\">c</italic> is computed via a softmax function over the negative Euclidean distances to all class prototypes:</p><disp-formula id=\"pcbi.1013722.e006\"><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pcbi.1013722.e006g\" position=\"anchor\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.e006.jpg\"/><mml:math id=\"M6\" display=\"block\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy=\"false\">(</mml:mo><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy=\"false\">|</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>q</mml:mi></mml:msub><mml:mo stretchy=\"false\">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>exp</mml:mi><mml:mo stretchy=\"false\">(</mml:mo><mml:mo>&#8722;</mml:mo><mml:mo fence=\"false\" stretchy=\"false\">&#8214;</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>q</mml:mi></mml:msub><mml:mo>&#8722;</mml:mo><mml:msub><mml:mi>&#956;</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:msub><mml:mo fence=\"false\" stretchy=\"false\">&#8214;</mml:mo><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy=\"false\">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mo>&#8721;</mml:mo><mml:mrow><mml:msup><mml:mi>c</mml:mi><mml:mi>&#8242;</mml:mi></mml:msup></mml:mrow></mml:msub><mml:mi>exp</mml:mi><mml:mo stretchy=\"false\">(</mml:mo><mml:mo>&#8722;</mml:mo><mml:mo fence=\"false\" stretchy=\"false\">&#8214;</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>q</mml:mi></mml:msub><mml:mo>&#8722;</mml:mo><mml:msub><mml:mi>&#956;</mml:mi><mml:mrow><mml:msup><mml:mi>c</mml:mi><mml:mi>&#8242;</mml:mi></mml:msup></mml:mrow></mml:msub><mml:msub><mml:mo fence=\"false\" stretchy=\"false\">&#8214;</mml:mo><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy=\"false\">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></alternatives><label>(3)</label></disp-formula><p>The resulting prototypical loss is defined as the average negative log-likelihood across all query examples:</p><disp-formula id=\"pcbi.1013722.e007\"><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pcbi.1013722.e007g\" position=\"anchor\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.e007.jpg\"/><mml:math id=\"M7\" display=\"block\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mtext>proto</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>&#8722;</mml:mo><mml:msub><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mo stretchy=\"false\">(</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>q</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>q</mml:mi></mml:msub><mml:mo stretchy=\"false\">)</mml:mo></mml:mrow></mml:msub><mml:mi>log</mml:mi><mml:mi>P</mml:mi><mml:mo stretchy=\"false\">(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>q</mml:mi></mml:msub><mml:mo stretchy=\"false\">|</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>q</mml:mi></mml:msub><mml:mo stretchy=\"false\">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives><label>(4)</label></disp-formula><p>This objective encourages query samples to align closely with their respective class centroids, thereby enhancing intra-class compactness and facilitating accurate classification in few-shot DDI scenarios.</p></sec><sec id=\"sec008\"><title>Instance-level contrastive supervision</title><p>To enhance inter-class discrimination and promote a well-structured embedding space, BioMCL-DDI incorporates an instance-level contrastive loss. This objective strengthens the model&#8217;s ability to distinguish fine-grained DDI types by explicitly encouraging semantic proximity between samples of the same class, while increasing separation between different classes.</p><p>The contrastive learning module is a lightweight architecture that operates on the shared sentence embeddings. Specifically, it consists of an additional linear projection layer (often referred to as a &#8216;projection head&#8217;) that maps the sentence embedding <italic toggle=\"yes\">z</italic> to a new representation space, where the contrastive loss is computed. This design helps to decouple the representation used for classification from the one used for contrastive learning.</p><p>The key to our approach is the strategy for constructing contrastive pairs from the output of the BioBERT encoder. Given a mini-batch of instance embeddings <inline-formula id=\"pcbi.1013722.e008\"><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pcbi.1013722.e008g\" position=\"anchor\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.e008.jpg\"/><mml:math id=\"M8\" display=\"inline\" overflow=\"scroll\"><mml:mrow><mml:mo stretchy=\"false\">{</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msubsup><mml:mo stretchy=\"false\">}</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo stretchy=\"false\">|</mml:mo><mml:mi>&#8492;</mml:mi><mml:mo stretchy=\"false\">|</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> and their corresponding ground-truth labels, we leverage the supervised information to form our pairs. For each anchor instance <italic toggle=\"yes\">z</italic><sub><italic toggle=\"yes\">i</italic></sub>, we define:</p><list list-type=\"bullet\"><list-item><p>Positive Pairs: All other instances in the mini-batch that share the same class label as the anchor instance.</p></list-item><list-item><p>Negative Pairs: All instances in the mini-batch that have a different class label from the anchor instance.</p></list-item></list><p>This methodology ensures that the model learns to pull embeddings of the same class closer together while pushing embeddings of different classes apart.</p><p>We compute the cosine similarity between each pair <inline-formula id=\"pcbi.1013722.e009\"><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pcbi.1013722.e009g\" position=\"anchor\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.e009.jpg\"/><mml:math id=\"M9\" display=\"inline\" overflow=\"scroll\"><mml:mrow><mml:mo stretchy=\"false\">(</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy=\"false\">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> as follows:</p><disp-formula id=\"pcbi.1013722.e010\"><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pcbi.1013722.e010g\" position=\"anchor\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.e010.jpg\"/><mml:math id=\"M10\" display=\"block\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:mtext>sim</mml:mtext><mml:mo stretchy=\"false\">(</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy=\"false\">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>z</mml:mi><mml:mi>i</mml:mi><mml:mo>&#8868;</mml:mo></mml:msubsup><mml:msub><mml:mi>z</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo fence=\"false\" stretchy=\"false\">&#8214;</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo fence=\"false\" stretchy=\"false\">&#8214;</mml:mo><mml:mo>&#183;</mml:mo><mml:mo fence=\"false\" stretchy=\"false\">&#8214;</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo fence=\"false\" stretchy=\"false\">&#8214;</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></alternatives><label>(5)</label></disp-formula><p>where <inline-formula id=\"pcbi.1013722.e011\"><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pcbi.1013722.e011g\" position=\"anchor\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.e011.jpg\"/><mml:math id=\"M11\" display=\"inline\" overflow=\"scroll\"><mml:mrow><mml:mo fence=\"false\" stretchy=\"false\">&#8214;</mml:mo><mml:mo>&#183;</mml:mo><mml:mo fence=\"false\" stretchy=\"false\">&#8214;</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> denotes the <inline-formula id=\"pcbi.1013722.e012\"><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pcbi.1013722.e012g\" position=\"anchor\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.e012.jpg\"/><mml:math id=\"M12\" display=\"inline\" overflow=\"scroll\"><mml:mrow><mml:msub><mml:mi>&#8467;</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> norm. For each anchor instance <italic toggle=\"yes\">z</italic><sub><italic toggle=\"yes\">i</italic></sub>, we define a positive set <inline-formula id=\"pcbi.1013722.e013\"><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pcbi.1013722.e013g\" position=\"anchor\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.e013.jpg\"/><mml:math id=\"M13\" display=\"inline\" overflow=\"scroll\"><mml:mrow><mml:mi>&#119979;</mml:mi><mml:mo stretchy=\"false\">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy=\"false\">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> containing instances from the same class, and treat the remaining instances as implicit negatives.</p><p>The contrastive loss is computed using a normalized temperature-scaled softmax over all non-anchor samples in the batch:</p><disp-formula id=\"pcbi.1013722.e014\"><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pcbi.1013722.e014g\" position=\"anchor\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.e014.jpg\"/><mml:math id=\"M14\" display=\"block\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mtext>contrast</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>&#8722;</mml:mo><mml:msub><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#8712;</mml:mo><mml:mi>&#8492;</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo stretchy=\"false\">|</mml:mo><mml:mi>&#119979;</mml:mi><mml:mo stretchy=\"false\">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy=\"false\">)</mml:mo><mml:mo stretchy=\"false\">|</mml:mo></mml:mrow></mml:mfrac><mml:msub><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>&#8712;</mml:mo><mml:mi>&#119979;</mml:mi><mml:mo stretchy=\"false\">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy=\"false\">)</mml:mo></mml:mrow></mml:msub><mml:mi>log</mml:mi><mml:mfrac><mml:mrow><mml:mi>exp</mml:mi><mml:mo stretchy=\"false\">(</mml:mo><mml:mtext>sim</mml:mtext><mml:mo stretchy=\"false\">(</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy=\"false\">)</mml:mo><mml:mo>/</mml:mo><mml:mi>&#964;</mml:mi><mml:mo stretchy=\"false\">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>&#8800;</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mi>exp</mml:mi><mml:mo stretchy=\"false\">(</mml:mo><mml:mtext>sim</mml:mtext><mml:mo stretchy=\"false\">(</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy=\"false\">)</mml:mo><mml:mo>/</mml:mo><mml:mi>&#964;</mml:mi><mml:mo stretchy=\"false\">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></alternatives><label>(6)</label></disp-formula><p>Here, <italic toggle=\"yes\">&#964;</italic> is a temperature parameter that controls the sharpness of the similarity distribution. A lower <italic toggle=\"yes\">&#964;</italic> increases sensitivity to similarity differences, thereby enforcing stronger margin separation.</p><p>By applying this contrastive supervision directly within the classification task (rather than as a separate pretraining stage), the model learns globally consistent embeddings that reflect true semantic boundaries between DDI relation types. This property is particularly beneficial in biomedical settings, where many interaction classes exhibit subtle lexical and contextual variations.</p></sec><sec id=\"sec009\"><title>Loss function and joint optimization</title><p>The overall training objective of BioMCL-DDI integrates three complementary components, each addressing a distinct aspect of few-shot DDI extraction:</p><disp-formula id=\"pcbi.1013722.e015\"><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pcbi.1013722.e015g\" position=\"anchor\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.e015.jpg\"/><mml:math id=\"M15\" display=\"block\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mtext>total</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mtext>CE</mml:mtext></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>&#955;</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mtext>proto</mml:mtext></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>&#955;</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mtext>contrast</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></alternatives><label>(7)</label></disp-formula><p>Here, <inline-formula id=\"pcbi.1013722.e016\"><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pcbi.1013722.e016g\" position=\"anchor\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.e016.jpg\"/><mml:math id=\"M16\" display=\"inline\" overflow=\"scroll\"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mtext>CE</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> denotes the standard cross-entropy loss, which provides supervised feedback based on ground-truth labels. This term ensures accurate prediction in well-represented classes. The prototypical loss <inline-formula id=\"pcbi.1013722.e017\"><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pcbi.1013722.e017g\" position=\"anchor\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.e017.jpg\"/><mml:math id=\"M17\" display=\"inline\" overflow=\"scroll\"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mtext>proto</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> encourages query embeddings to cluster around class-specific centroids, thereby supporting generalization under limited supervision. The contrastive loss <inline-formula id=\"pcbi.1013722.e018\"><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pcbi.1013722.e018g\" position=\"anchor\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.e018.jpg\"/><mml:math id=\"M18\" display=\"inline\" overflow=\"scroll\"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mtext>contrast</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> promotes inter-class separability by enforcing global consistency in the learned embedding space.</p><p>The weighting parameters <inline-formula id=\"pcbi.1013722.e019\"><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pcbi.1013722.e019g\" position=\"anchor\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.e019.jpg\"/><mml:math id=\"M19\" display=\"inline\" overflow=\"scroll\"><mml:mrow><mml:msub><mml:mi>&#955;</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id=\"pcbi.1013722.e020\"><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pcbi.1013722.e020g\" position=\"anchor\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.e020.jpg\"/><mml:math id=\"M20\" display=\"inline\" overflow=\"scroll\"><mml:mrow><mml:msub><mml:mi>&#955;</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> control the influence of the auxiliary losses. In our implementation, we set <inline-formula id=\"pcbi.1013722.e021\"><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pcbi.1013722.e021g\" position=\"anchor\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.e021.jpg\"/><mml:math id=\"M21\" display=\"inline\" overflow=\"scroll\"><mml:mrow><mml:msub><mml:mi>&#955;</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id=\"pcbi.1013722.e022\"><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pcbi.1013722.e022g\" position=\"anchor\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.e022.jpg\"/><mml:math id=\"M22\" display=\"inline\" overflow=\"scroll\"><mml:mrow><mml:msub><mml:mi>&#955;</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>, based on empirical validation on the DDI-2013 development set. These values consistently yielded optimal performance across settings without extensive hyperparameter tuning, suggesting robustness to variation.</p><p>Unlike prior approaches that treat meta-learning and contrastive learning as pretraining or auxiliary stages, BioMCL-DDI performs unified joint optimization within a single supervised learning loop. All loss terms are optimized concurrently and share a common encoder and projection backbone.</p><p>This design enables the model to simultaneously benefit from local structure learning (via class prototypes) and global semantic alignment (via contrastive supervision), resulting in enhanced representation quality, better discrimination of fine-grained relation types, and improved generalization to unseen DDI categories&#8212;key requirements in real-world biomedical information extraction tasks.</p><sec id=\"sec010\"><title>Algorithm summary.</title><p>To summarize the training workflow of BioMCL-DDI, Algorithm 1 outlines the full optimization procedure. Each training iteration operates on a mini-batch composed of support and query instances. Sentences are first encoded using BioBERT to produce contextual embeddings. Class prototypes are computed from the support set, and query instances are classified based on their proximity to these prototypes. Simultaneously, a contrastive objective is applied across the entire batch to enforce global feature consistency. The final loss is computed as a weighted combination of all objectives and used to update the shared model parameters.</p><p>\n<bold>Algorithm 1. BioMCL-DDI training procedure.</bold>\n</p><disp-formula id=\"pcbi.1013722.e049\"><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pcbi.1013722.e049g\" position=\"anchor\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.e049.jpg\"/></disp-formula><p>This end-to-end training loop enables the model to jointly learn class-level generalization, instance-level discrimination, and supervised alignment. Unlike episodic-based meta-learning methods, BioMCL-DDI eliminates the need for explicit task construction, which improves training scalability and stability.</p><p>Such a unified optimization pipeline is particularly valuable in biomedical relation extraction, where annotation costs are high and class distributions are often skewed. BioMCL-DDI supports fast adaptation to rare or unseen DDI types while maintaining high accuracy under resource constraints.</p></sec></sec></sec><sec sec-type=\"results\" id=\"sec011\"><title>Results</title><p>In this section, we present a comprehensive evaluation of the proposed BioMCL-DDI framework. We aim to demonstrate its effectiveness in few-shot drug&#8211;drug interaction (DDI) extraction through extensive comparisons with full-supervised and few-shot baselines, as well as detailed analyses including ablation studies, learning behavior, transferability, and error inspection.</p><p>Our experiments are conducted on the DDI Extraction 2013 benchmark and an external DDI-DrugBank dataset for domain transfer. We also provide a statistical and qualitative assessment of the model&#8217;s robustness, supported by performance curves, case studies, and clinical implications.</p><sec id=\"sec012\"><title>Experimental setup</title><p>All experiments were conducted on a high-performance computing server running Ubuntu 18.04, equipped with an Intel Xeon Gold 5218 CPU and four NVIDIA A40 GPUs (48 GB each). The implementation is based on PyTorch 1.12.0 and Python 3.9.19. The BioMCL-DDI model uses BioBERT as the encoder and is configured with a hidden size of 768 and ReLU activation. During training, we set the learning rate to 5e-5, the maximum input length to 300 tokens, a batch size of 16, and a training duration of 30 epochs. All hyperparameters were selected based on preliminary validation and kept fixed across experiments to ensure consistency and reproducibility.</p></sec><sec id=\"sec013\"><title>Datasets</title><sec id=\"sec014\"><title>The DDI extraction 2013 dataset.</title><p>We evaluate our model on the DDI Extraction 2013 dataset [<xref rid=\"pcbi.1013722.ref038\" ref-type=\"bibr\">38</xref>], a widely used benchmark for drug&#8211;drug interaction (DDI) extraction. The dataset consists of annotated biomedical sentences, each describing a potential interaction between two drug entities. Each instance is labeled with one of five relation types: DDI-false, DDI-effect, DDI-mechanism, DDI-advise, or DDI-int.</p><p>As summarized in <xref rid=\"pcbi.1013722.t002\" ref-type=\"table\">Table 2</xref>, the corpus is divided into training, validation, and test sets. A prominent challenge in this dataset is its severe class imbalance and data sparsity. For example, the DDI-false category dominates the training set with 23,772 instances, whereas the low-frequency DDI-int class contains only 188 instances. This skewed distribution makes it particularly difficult for conventional deep learning models to accurately identify rare interaction types, which are often of high clinical significance.</p><table-wrap position=\"float\" id=\"pcbi.1013722.t002\" orientation=\"portrait\"><object-id pub-id-type=\"doi\">10.1371/journal.pcbi.1013722.t002</object-id><label>Table 2</label><caption><title>The statistics of DDI Extraction 2013 dataset.</title></caption><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pcbi.1013722.t002g\" position=\"float\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.t002.jpg\"/><table frame=\"hsides\" rules=\"groups\"><colgroup span=\"1\"><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/></colgroup><thead><tr><th align=\"left\" rowspan=\"1\" colspan=\"1\">DDI Category</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">Train</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">Dev</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">Test</th></tr></thead><tbody><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">Effect</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">1687</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">360</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">360</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">Mechanism</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">1319</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">302</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">302</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">Advise</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">826</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">221</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">221</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">Int</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">188</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">96</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">96</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">False</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">23772</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">4782</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">4782</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">Total</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">27792</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">7244</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">5761</td></tr></tbody></table></alternatives></table-wrap><p>To simulate realistic low-resource scenarios, we conduct few-shot experiments by varying the support set size from 1 to 100 labeled instances per class. This setting enables us to evaluate the model&#8217;s ability to generalize from limited supervision and to assess its robustness in practical, data-scarce conditions.</p></sec><sec id=\"sec015\"><title>TAC 2018 DDI extraction dataset.</title><p>To further evaluate the cross-domain generalizability of our proposed method, we conducted experiments on the TAC 2018 DDI Extraction dataset [<xref rid=\"pcbi.1013722.ref039\" ref-type=\"bibr\">39</xref>,<xref rid=\"pcbi.1013722.ref040\" ref-type=\"bibr\">40</xref>]. The TAC 2018 DDI Extraction dataset originates from the U.S. Food and Drug Administration (FDA) and the National Library of Medicine (NLM) and consists of structured product label (SPL) files for prescription drugs. Each SPL contains several sections, with each section comprising multiple sentences. The dataset contains 325 SPLs in total, with the training set consisting of XML-format files for 22 SPLs and 180 SPLs annotated with slightly different formats. Two test sets are provided, containing 57 and 66 SPLs, respectively. All SPLs were manually annotated by FDA and NLM experts for three types of DDIs: Pharmacokinetic (PK), Pharmacodynamic (PD), and Unspecified (U). In addition to common text data, the source also includes tables and other types of DDI data, which can be used to assess our method&#8217;s performance on diverse data sources.</p></sec></sec><sec id=\"sec016\"><title>Results and analysis</title><sec id=\"sec017\"><title>Performance on DDI extraction 2013 dataset.</title><p>We compare the performance of BioMCL-DDI with a variety of state-of-the-art fully supervised methods on the DDI Extraction 2013 benchmark dataset. These baseline models represent the prevailing approaches in DDI extraction and rely heavily on large-scale annotated corpora for training. <xref rid=\"pcbi.1013722.t003\" ref-type=\"table\">Table 3</xref> provides a detailed comparison in terms of precision, recall, and F1 score.</p><table-wrap position=\"float\" id=\"pcbi.1013722.t003\" orientation=\"portrait\"><object-id pub-id-type=\"doi\">10.1371/journal.pcbi.1013722.t003</object-id><label>Table 3</label><caption><title>Performance comparison with all methods on DDI Extraction 2013.</title></caption><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pcbi.1013722.t003g\" position=\"float\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.t003.jpg\"/><table frame=\"hsides\" rules=\"groups\"><colgroup span=\"1\"><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/></colgroup><thead><tr><th align=\"left\" rowspan=\"1\" colspan=\"1\">Method</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">Year</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">Precision(%)</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">Recall(%)</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">F1 Score(%)</th></tr></thead><tbody><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">AW-BLSTMs [<xref rid=\"pcbi.1013722.ref041\" ref-type=\"bibr\">41</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">2019</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">80.00</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">77.00</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">78.50</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">BERE [<xref rid=\"pcbi.1013722.ref042\" ref-type=\"bibr\">42</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">2019</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">76.80</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">71.30</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">73.90</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">TM-RNN [<xref rid=\"pcbi.1013722.ref043\" ref-type=\"bibr\">43</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">2019</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">74.11</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">70.82</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">72.43</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">RHCNN [<xref rid=\"pcbi.1013722.ref044\" ref-type=\"bibr\">44</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">2019</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">77.30</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">73.75</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">75.48</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">GRU-GCN [<xref rid=\"pcbi.1013722.ref023\" ref-type=\"bibr\">23</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">2019</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">73.60</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">68.20</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">70.80</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">SM-GCN [<xref rid=\"pcbi.1013722.ref024\" ref-type=\"bibr\">24</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">2019</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">77.62</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">75.69</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">76.64</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">R-BERT [<xref rid=\"pcbi.1013722.ref025\" ref-type=\"bibr\">25</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">2019</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">-</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">-</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">79.08</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">AGCN [<xref rid=\"pcbi.1013722.ref046\" ref-type=\"bibr\">46</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">2020</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">78.17</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">75.59</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">76.86</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">SGRU-CNN [<xref rid=\"pcbi.1013722.ref047\" ref-type=\"bibr\">47</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">2020</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">76.19</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">73.34</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">74.74</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">Att-BLLC [<xref rid=\"pcbi.1013722.ref048\" ref-type=\"bibr\">48</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">2020</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">-</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">-</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">72.14</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">MEAT-BioBERT [<xref rid=\"pcbi.1013722.ref026\" ref-type=\"bibr\">26</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">2020</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">81.00</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">80.90</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">80.90</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">DDMS-CNN [<xref rid=\"pcbi.1013722.ref045\" ref-type=\"bibr\">45</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">2021</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">85.36</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">82.83</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">84.08</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">CDBERT [<xref rid=\"pcbi.1013722.ref028\" ref-type=\"bibr\">28</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">2021</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">85.54</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">83.56</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">84.47</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">PSA-DDI [<xref rid=\"pcbi.1013722.ref051\" ref-type=\"bibr\">51</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">2021</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">-</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">-</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">78.30</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">EGFI [<xref rid=\"pcbi.1013722.ref050\" ref-type=\"bibr\">50</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">2022</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">83.40</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">85.00</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">84.20</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">KSS-DDI [<xref rid=\"pcbi.1013722.ref052\" ref-type=\"bibr\">52</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">2022</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">85.49</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">82.84</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">84.13</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">IMSE [<xref rid=\"pcbi.1013722.ref029\" ref-type=\"bibr\">29</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">2022</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">85.63</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">85.17</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">85.16</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">DREAM [<xref rid=\"pcbi.1013722.ref030\" ref-type=\"bibr\">30</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">2022</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">82.30</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">74.70</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">78.30</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">3DGT-DDI [<xref rid=\"pcbi.1013722.ref049\" ref-type=\"bibr\">49</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">2023</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">81.17</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">88.07</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">84.48</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">EMSI-BERT [<xref rid=\"pcbi.1013722.ref031\" ref-type=\"bibr\">31</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">2023</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">-</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">-</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">82.00</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">MTMG [<xref rid=\"pcbi.1013722.ref053\" ref-type=\"bibr\">53</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">2023</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">77.20</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">78.20</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">77.70</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">HKG-DDI [<xref rid=\"pcbi.1013722.ref032\" ref-type=\"bibr\">32</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">2023</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">85.32</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">85.49</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">85.40</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">DKPL [<xref rid=\"pcbi.1013722.ref033\" ref-type=\"bibr\">33</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">2024</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">84.25</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">83.42</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">83.86</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">SCNN2 [<xref rid=\"pcbi.1013722.ref034\" ref-type=\"bibr\">34</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">2024</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">77.75</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">77.13</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">77.48</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">BERT-MLRE [<xref rid=\"pcbi.1013722.ref035\" ref-type=\"bibr\">35</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">2024</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">80.32</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">82.53</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">81.52</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">BBL-GAT [<xref rid=\"pcbi.1013722.ref007\" ref-type=\"bibr\">7</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">2024</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">81.76</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">84.38</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">82.47</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">BLRG [<xref rid=\"pcbi.1013722.ref008\" ref-type=\"bibr\">8</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">2024</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">84.54</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">83.84</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">84.19</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">CA-SQBG [<xref rid=\"pcbi.1013722.ref054\" ref-type=\"bibr\">54</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">2025</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">73.80</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">72.50</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">73.10</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">HiFAB-DDI [<xref rid=\"pcbi.1013722.ref055\" ref-type=\"bibr\">55</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">2025</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">85.01</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">84.50</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">84.78</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">BioFocal-DDI [<xref rid=\"pcbi.1013722.ref009\" ref-type=\"bibr\">9</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">2025</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">86.75</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">86.53</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">86.64</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">BioMCL-DDI(Ours)</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">-</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">\n<bold>88.12</bold>\n</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">\n<bold>87.49</bold>\n</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">\n<bold>87.80</bold>\n</td></tr></tbody></table></alternatives></table-wrap><p>As shown in the table, BioMCL-DDI achieves the best overall performance, with a precision of 88.12%, a recall of 87.49%, and an F1 score of 87.80%. This clearly outperforms the previous best-performing method, BioFocal-DDI, which attained an F1 score of 86.64%. The improvements are consistent across all metrics, highlighting the robustness and effectiveness of our approach. Compared to established models such as R-BERT, MEAT-BioBERT, and 3DGT-DDI, BioMCL-DDI demonstrates significant performance gains. While many recent methods integrate domain-specific pretraining, external drug knowledge, or graph-based reasoning modules, they still fall short of the performance achieved by our model. This suggests that the meta-contrastive learning strategy adopted in BioMCL-DDI introduces substantial improvements that cannot be matched by additional external resources alone.</p><p>The marked performance gains can be attributed to several key design choices. First, by combining a prototype-based classification objective with contrastive learning, BioMCL-DDI encourages both intra-class cohesion and inter-class separation in the embedding space, which proves crucial in the few-shot setting. Second, unlike traditional supervised models that require dense annotation, our framework is optimized to learn from sparse, class-limited samples and generalize effectively to new interaction types. The use of prototypical networks helps align drug pair embeddings with class-specific centroids, while the contrastive component further refines the embedding space to be more discriminative.</p><p>The confusion matrix in <xref rid=\"pcbi.1013722.g002\" ref-type=\"fig\">Fig 2</xref> illustrates the model&#8217;s classification behavior on the DDI 2013 test set. BioMCL-DDI performs well across all interaction types, particularly in recognizing the dominant DDI-false class while maintaining balanced predictions on low-frequency classes such as DDI-int. Although some confusion arises between semantically similar types like DDI-mechanism and DDI-advise, the model exhibits strong overall class separability and stable generalization.</p><fig position=\"float\" id=\"pcbi.1013722.g002\" orientation=\"portrait\"><object-id pub-id-type=\"doi\">10.1371/journal.pcbi.1013722.g002</object-id><label>Fig 2</label><caption><title>Confusion matrix of BioMCL-DDI on the DDI 2013.</title></caption><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" position=\"float\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.g002.jpg\"/></fig><p>In addition, <xref rid=\"pcbi.1013722.g003\" ref-type=\"fig\">Fig 3</xref> shows the ROC curves for individual interaction categories. All classes achieve high AUC scores, with DDI-advise reaching 0.98 and even the most challenging class, DDI-int, reaching 0.90. These results highlight the model&#8217;s ability to maintain high sensitivity and specificity across all categories, including underrepresented ones. The consistently high AUC values further validate the model&#8217;s suitability for real-world clinical scenarios, where minimizing both false positives and false negatives is critical.</p><fig position=\"float\" id=\"pcbi.1013722.g003\" orientation=\"portrait\"><object-id pub-id-type=\"doi\">10.1371/journal.pcbi.1013722.g003</object-id><label>Fig 3</label><caption><title>Receiver Operating Characteristic (ROC) curves for each DDI category.</title></caption><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" position=\"float\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.g003.jpg\"/></fig><p>Overall, BioMCL-DDI sets a new benchmark in DDI extraction, combining superior performance with robustness in few-shot conditions. Its ability to achieve top-tier results without requiring extensive annotation makes it especially attractive for low-resource biomedical NLP applications.</p></sec><sec id=\"sec018\"><title>Performance comparison under few-shot settings.</title><p>To further assess the effectiveness of BioMCL-DDI in low-resource settings, we compare it against several representative few-shot learning baselines, including KSS-DDI, MTMG, and HKG-DCL. These models integrate contrastive learning, multi-task mechanisms, or domain-specific adaptations to tackle the few-shot DDI extraction task.</p><p>As presented in <xref rid=\"pcbi.1013722.t004\" ref-type=\"table\">Table 4</xref>, BioMCL-DDI achieves the highest overall performance among few-shot learning methods, with a precision of 87.20%, a recall of 86.30%, and an F1 score of 86.75%. This result outperforms the next-best approach, HKG-DCL, by more than 1 percentage point in F1 score.</p><table-wrap position=\"float\" id=\"pcbi.1013722.t004\" orientation=\"portrait\"><object-id pub-id-type=\"doi\">10.1371/journal.pcbi.1013722.t004</object-id><label>Table 4</label><caption><title>Performance comparison with few-shot learning methods on DDI Extraction 2013.</title></caption><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pcbi.1013722.t004g\" position=\"float\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.t004.jpg\"/><table frame=\"hsides\" rules=\"groups\"><colgroup span=\"1\"><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/></colgroup><thead><tr><th align=\"left\" rowspan=\"1\" colspan=\"1\">Method</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">Precision(%)</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">Recall(%)</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">F1 Score(%)</th></tr></thead><tbody><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">KSS-DDI</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">85.46</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">82.84</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">84.13</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">MTMG</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">77.20</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">78.20</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">78.10</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">HKG-DCL</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">85.35</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">85.49</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">85.40</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">BioMCL-DDI</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">87.20</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">86.30</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">86.75</td></tr></tbody></table></alternatives></table-wrap><p>These results highlight the superior generalization capacity of our meta-contrastive framework under data-scarce conditions. The ability to align class-level structures via prototypical learning, combined with the fine-grained discriminability encouraged by contrastive loss, equips BioMCL-DDI with a robust inductive bias for few-shot classification. This makes it particularly suitable for real-world biomedical applications, where annotated data is often limited or costly to obtain.</p></sec><sec id=\"sec019\"><title>Performance stability and statistical significance.</title><p>To assess the consistency of model performance under repeated training conditions, we conduct five independent runs for both the baseline model (using only cross-entropy loss) and the proposed BioMCL-DDI framework.</p><p>As shown in <xref rid=\"pcbi.1013722.g004\" ref-type=\"fig\">Fig 4</xref>, BioMCL-DDI consistently yields higher accuracy with lower variance. The model achieves a mean accuracy of 88.2% with a standard deviation of 0.48%, while the baseline records a lower mean of 87.0% and a larger deviation of 0.60%. The narrower interquartile range of BioMCL-DDI reflects better robustness and lower sensitivity to initialization or sampling noise.</p><fig position=\"float\" id=\"pcbi.1013722.g004\" orientation=\"portrait\"><object-id pub-id-type=\"doi\">10.1371/journal.pcbi.1013722.g004</object-id><label>Fig 4</label><caption><title>Accuracy distribution comparison between Baseline and BioMCL-DDI.</title></caption><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" position=\"float\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.g004.jpg\"/></fig><p><xref rid=\"pcbi.1013722.g005\" ref-type=\"fig\">Fig 5</xref> presents the average accuracy across runs with standard deviation error bars. The clear separation between the error bars further indicates that BioMCL-DDI not only achieves superior average performance but also exhibits more stable training dynamics. A paired t-test yields a p-value less than 0.01, confirming that the performance improvements are statistically significant rather than due to random fluctuations.</p><fig position=\"float\" id=\"pcbi.1013722.g005\" orientation=\"portrait\"><object-id pub-id-type=\"doi\">10.1371/journal.pcbi.1013722.g005</object-id><label>Fig 5</label><caption><title>Mean accuracy and variance comparison with statistical significance.</title></caption><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" position=\"float\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.g005.jpg\"/></fig><p>These results demonstrate that BioMCL-DDI maintains stable and reliable behavior across training runs, which is particularly important for practical deployment in low-resource biomedical settings.</p></sec><sec id=\"sec020\"><title>Embedding space visualization.</title><p>To visually validate the effectiveness of our meta-contrastive learning approach, we provide a <italic toggle=\"yes\">t</italic>-SNE visualization of the embedding space. <italic toggle=\"yes\">t</italic>-SNE is a dimensionality reduction technique that maps high-dimensional data points to a two-dimensional space, preserving the local structure of the data. The resulting dimensions do not carry any specific semantic meaning; they are solely used for visualizing the clustering and separation patterns of the data.</p><p>We compare the embedding space learned by a simple BioBERT baseline and our full BioMCL-DDI model. As shown in <xref rid=\"pcbi.1013722.g006\" ref-type=\"fig\">Fig 6</xref>(a), the embedding space of the baseline model shows that different DDI categories are poorly separated and highly overlapping, with multiple classes intermingling in a single region. This confirms that conventional supervised learning struggles to learn a discriminative representation space under few-shot conditions. In contrast, our full BioMCL-DDI model&#8217;s embedding space, as visualized in <xref rid=\"pcbi.1013722.g006\" ref-type=\"fig\">Fig 6</xref>(b), displays a significant improvement. The embeddings form tight, well-separated clusters, which visually confirms that our prototypical learning enhances intra-class compactness, while the contrastive loss promotes inter-class separability. Notably, while the clusters for Effect and Mechanism show some proximity, which is expected given their semantic similarity, the overall separation is robust. This demonstrates that our framework successfully learns a more structured and discriminative representation, validating the core mechanisms of our model design.</p><fig position=\"float\" id=\"pcbi.1013722.g006\" orientation=\"portrait\"><object-id pub-id-type=\"doi\">10.1371/journal.pcbi.1013722.g006</object-id><label>Fig 6</label><caption><title>A visual comparison of the embedding space learned by (a) BioBERT baseline and (b) BioMCL-DDI model.</title></caption><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" position=\"float\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.g006.jpg\"/></fig></sec><sec id=\"sec021\"><title>Scalability with varying support set sizes.</title><p>To evaluate the scalability and robustness of BioMCL-DDI under few-shot settings, we perform experiments across a range of support set sizes: 1, 2, 4, 6, 8, 10, 15, 20, 30, 40, 50, 60, 80, and 100 samples per class. The resulting F1 performance curve is shown in <xref rid=\"pcbi.1013722.g007\" ref-type=\"fig\">Fig 7</xref>.</p><fig position=\"float\" id=\"pcbi.1013722.g007\" orientation=\"portrait\"><object-id pub-id-type=\"doi\">10.1371/journal.pcbi.1013722.g007</object-id><label>Fig 7</label><caption><title>F1 score of BioMCL-DDI across different support set sizes (1&#8211;100 samples per class) on the DDI 2013 dataset.</title></caption><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" position=\"float\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.g007.jpg\"/></fig><p>We observe a notable improvement in performance as the support size increases from 1 to 10. In the 1-shot setting, BioMCL-DDI achieves an F1 score of 48.0%. This steadily improves to around 70.0% at 5-shot and reaches 74.0% at 10-shot, demonstrating the model&#8217;s ability to generalize from limited supervision. As the number of labeled instances increases further, performance gradually saturates, reaching 86.0% at 100-shot&#8212;approaching the full-supervised level of 87.8%. These results highlight the effectiveness of the proposed meta-contrastive learning strategy in enabling robust representation learning, even under low-resource conditions.</p></sec><sec id=\"sec022\"><title>Evaluating cross-domain adaptation on DDI-DrugBank.</title><p>To further assess the cross-domain generalization capability of BioMCL-DDI, we perform few-shot transfer learning experiments using the DDI-DrugBank dataset. This setting mimics real-world low-resource deployment scenarios, where labeled data in the target domain is scarce or unavailable.</p><p>As illustrated in <xref rid=\"pcbi.1013722.g008\" ref-type=\"fig\">Fig 8</xref>, the model shows a consistent improvement in performance with increasing support size. Starting with an F1 score of 56.5% using only 5 labeled examples per class, BioMCL-DDI surpasses 74.0% at the 20-shot level and ultimately achieves 86.0% at 100-shot. These results demonstrate the model&#8217;s ability to efficiently adapt to new domains with minimal supervision.</p><fig position=\"float\" id=\"pcbi.1013722.g008\" orientation=\"portrait\"><object-id pub-id-type=\"doi\">10.1371/journal.pcbi.1013722.g008</object-id><label>Fig 8</label><caption><title>Few-shot transfer performance of BioMCL-DDI on the DDI-DrugBank dataset.</title></caption><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" position=\"float\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.g008.jpg\"/></fig><p>This experiment also serves to test robustness under domain shift. Compared to the DDI-2013 dataset, DDI-DrugBank exhibits distinct linguistic patterns and annotation conventions. Despite these differences, BioMCL-DDI maintains strong performance, indicating that it is not merely overfitting to the training distribution but is capable of learning transferable biomedical interaction patterns. Such cross-domain adaptability is particularly valuable in clinical NLP, where the diversity of medical corpora often poses generalization challenges.</p><p>We attribute this effective transfer performance to the dual objectives integrated during training. The prototypical loss aligns representations with class-wise centroids, fostering few-shot adaptability, while the contrastive loss enforces semantic separability across interaction types, leading to more robust embeddings. Together, these components allow BioMCL-DDI to retain discriminative power even when facing unfamiliar domains.</p></sec></sec><sec id=\"sec023\"><title>Performance on TAC 2018 DDI extraction dataset</title><p>To demonstrate the cross-domain generalizability of our proposed framework, we conducted a comprehensive evaluation on the TAC 2018 DDI Extraction corpus. This external dataset, comprising structured product labels (SPL) from the U.S. Food and Drug Administration (FDA) and the National Library of Medicine (NLM), represents a distinct domain with different linguistic patterns and document structures compared to the DDI-2013 benchmark.</p><p>As reported in <xref rid=\"pcbi.1013722.t005\" ref-type=\"table\">Tables 5</xref> and <xref rid=\"pcbi.1013722.t006\" ref-type=\"table\">6</xref>, BioMCL-DDI achieves state-of-the-art performance across both official test sets of TAC 2018, with F1 scores of 74.85% and 74.82%, respectively. These results surpass all competitive baselines, including recent strong models such as DDI-MuG and COTEL-D3X. The strong performance on TAC 2018 is particularly significant because it validates the robustness of our meta-contrastive learning approach under substantial domain shift. More importantly, it demonstrates that BioMCL-DDI is not limited to legacy benchmarks, but can effectively generalize to more recent and practically relevant biomedical corpora. This provides strong evidence for the applicability of our framework in real-world scenarios, where biomedical texts are continuously evolving and domain adaptation is crucial.</p><table-wrap position=\"float\" id=\"pcbi.1013722.t005\" orientation=\"portrait\"><object-id pub-id-type=\"doi\">10.1371/journal.pcbi.1013722.t005</object-id><label>Table 5</label><caption><title>Performance comparison on TAC 2018 DDI extraction test set 1.</title></caption><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pcbi.1013722.t005g\" position=\"float\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.t005.jpg\"/><table frame=\"hsides\" rules=\"groups\"><colgroup span=\"1\"><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/></colgroup><thead><tr><th align=\"left\" rowspan=\"1\" colspan=\"1\">Method</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">Precision (%)</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">Recall (%)</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">F1-Score (%)</th></tr></thead><tbody><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">KLncLSTMsentClf [<xref rid=\"pcbi.1013722.ref056\" ref-type=\"bibr\">56</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">47.00</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">62.00</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">53.00</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">DDI-MuG [<xref rid=\"pcbi.1013722.ref057\" ref-type=\"bibr\">57</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">72.10</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">72.80</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">72.30</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">R-BioBERT [<xref rid=\"pcbi.1013722.ref058\" ref-type=\"bibr\">58</xref>] with BLSTM</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">-</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">-</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">64.00</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">COTEL-D3X [<xref rid=\"pcbi.1013722.ref059\" ref-type=\"bibr\">59</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">67.28</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">73.83</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">70.40</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">BioMCL-DDI (Ours)</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">\n<bold>74.50</bold>\n</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">\n<bold>75.20</bold>\n</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">\n<bold>74.85</bold>\n</td></tr></tbody></table></alternatives></table-wrap><table-wrap position=\"float\" id=\"pcbi.1013722.t006\" orientation=\"portrait\"><object-id pub-id-type=\"doi\">10.1371/journal.pcbi.1013722.t006</object-id><label>Table 6</label><caption><title>Performance comparison on TAC 2018 DDI extraction test set 2.</title></caption><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pcbi.1013722.t006g\" position=\"float\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.t006.jpg\"/><table frame=\"hsides\" rules=\"groups\"><colgroup span=\"1\"><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/></colgroup><thead><tr><th align=\"left\" rowspan=\"1\" colspan=\"1\">Method</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">Precision (%)</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">Recall (%)</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">F1-Score (%)</th></tr></thead><tbody><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">KLncLSTMsentClf</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">49.00</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">67.00</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">56.70</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">DDI-MUG</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">71.70</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">74.30</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">72.90</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">R-BioBERT with BLSTM</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">-</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">-</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">58.80</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">COTEL-D3X</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">74.93</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">71.39</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">73.12</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">BioMCL-DDI (Ours)</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">\n<bold>75.15</bold>\n</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">\n<bold>74.50</bold>\n</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">\n<bold>74.82</bold>\n</td></tr></tbody></table></alternatives></table-wrap></sec><sec id=\"sec024\"><title>Component contribution analysis via ablation study</title><p>To better understand the role of each core component in BioMCL-DDI, we conduct an ablation study by selectively removing key modules and comparing performance against the full model. The following variants are evaluated: (1) <italic toggle=\"yes\">w/o Prototypical Loss</italic>: The prototype-based alignment objective is removed, while contrastive and cross-entropy losses remain. <italic toggle=\"yes\">w/o Contrastive Loss</italic>: The instance-level contrastive learning component is excluded, retaining the prototypical and classification losses. (3) <italic toggle=\"yes\">w/o Both</italic>: Only the standard classification loss is used, removing both auxiliary losses. (4) <italic toggle=\"yes\">Full Model</italic>: All components enabled&#8212;prototypical loss, contrastive loss, and classification loss.</p><p>The quantitative results are presented in <xref rid=\"pcbi.1013722.t007\" ref-type=\"table\">Table 7</xref>. Removing either auxiliary loss results in a noticeable drop in performance. Specifically, without the prototypical loss, the F1 score falls to 86.30%; without the contrastive loss, it drops to 85.65%. When both components are removed, the F1 plummets further to 84.00%. In contrast, the full BioMCL-DDI achieves an F1 score of 87.80%, underscoring the critical contributions of both objectives.</p><table-wrap position=\"float\" id=\"pcbi.1013722.t007\" orientation=\"portrait\"><object-id pub-id-type=\"doi\">10.1371/journal.pcbi.1013722.t007</object-id><label>Table 7</label><caption><title>Ablation study results.</title></caption><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pcbi.1013722.t007g\" position=\"float\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.t007.jpg\"/><table frame=\"hsides\" rules=\"groups\"><colgroup span=\"1\"><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/></colgroup><thead><tr><th align=\"left\" rowspan=\"1\" colspan=\"1\">Variant</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">Precision(%)</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">Recall(%)</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">F1 Score(%)</th></tr></thead><tbody><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">w/o Prototypical Loss</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">86.50</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">86.10</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">86.30</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">w/o Contrastive Loss</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">85.80</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">85.50</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">85.65</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">w/o Proto &amp; Contrastive</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">84.20</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">83.80</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">84.00</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">Full Model (Ours)</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">88.12</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">87.49</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">87.80</td></tr></tbody></table></alternatives></table-wrap><p>These findings validate the synergistic design of BioMCL-DDI. The prototypical loss provides strong supervision for few-shot generalization by structuring the embedding space around class centroids. Meanwhile, the contrastive loss ensures robust inter-class separation, especially under limited supervision. Together, these losses complement each other: the former guides semantic alignment, while the latter sharpens boundary discrimination. Their combination enables BioMCL-DDI to learn more generalized and transferable representations for drug interaction classification.</p></sec><sec id=\"sec025\"><title>Efficiency and computational complexity</title><p>To assess the practical viability of BioMCL-DDI in resource-constrained clinical environments, we provide a detailed analysis of its computational efficiency. The framework&#8217;s overall efficiency is primarily determined by its three main components: the BioBERT encoder, the prototypical classifier, and the supervised contrastive module.</p><p>Theoretically, the computational bottleneck lies with the BioBERT encoder, whose complexity scales quadratically with respect to the input sequence length. Our lightweight few-shot adaptation modules, however, are designed for efficiency. The prototypical classifier has a near-linear complexity, as it requires computing a limited number of class prototypes and calculating distances to them. The contrastive learning module&#8217;s complexity scales quadratically with the mini-batch size, but this remains computationally efficient given the small batch sizes typically employed in few-shot learning.</p><p>To empirically validate the model&#8217;s efficiency, we compared its performance against several representative baselines on the DDI-2013 test set using a single NVIDIA A40 GPU. As shown in the <xref rid=\"pcbi.1013722.t008\" ref-type=\"table\">Table 8</xref>, BioMCL-DDI demonstrates a favorable balance between performance and efficiency. The model&#8217;s training time per epoch is competitive with other advanced methods, while its inference speed of 21.1 ms per sample is notably faster than several baselines, which is a critical factor for real-time clinical decision support systems.</p><table-wrap position=\"float\" id=\"pcbi.1013722.t008\" orientation=\"portrait\"><object-id pub-id-type=\"doi\">10.1371/journal.pcbi.1013722.t008</object-id><label>Table 8</label><caption><title>Efficiency comparison of BioMCL-DDI and baseline models.</title></caption><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pcbi.1013722.t008g\" position=\"float\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.t008.jpg\"/><table frame=\"hsides\" rules=\"groups\"><colgroup span=\"1\"><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/></colgroup><thead><tr><th align=\"left\" rowspan=\"1\" colspan=\"1\">Method</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">Training Time (min/epoch)</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">Inference Speed (ms/sample)</th></tr></thead><tbody><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">R-BERT [<xref rid=\"pcbi.1013722.ref025\" ref-type=\"bibr\">25</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">15.2</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">23.5</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">BioFocal-DDI [<xref rid=\"pcbi.1013722.ref009\" ref-type=\"bibr\">9</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">18.9</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">28.1</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">3DGT-DDI [<xref rid=\"pcbi.1013722.ref049\" ref-type=\"bibr\">49</xref>]</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">22.4</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">31.2</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">\n<bold>BioMCL-DDI (Ours)</bold>\n</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">\n<bold>16.8</bold>\n</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">\n<bold>21.1</bold>\n</td></tr></tbody></table></alternatives></table-wrap><p>This analysis confirms that BioMCL-DDI&#8217;s design prioritizes a strong balance between state-of-the-art performance and computational efficiency, making it a scalable and practical solution for DDI extraction in real-world applications.</p></sec><sec id=\"sec026\"><title>Hyperparameter analysis</title><p>To gain deeper insight into the optimization behavior of BioMCL-DDI, we monitor the evolution of training accuracy, loss, and F1 score throughout the learning process. The results are visualized in <xref rid=\"pcbi.1013722.g009\" ref-type=\"fig\">Fig 9</xref>.</p><fig position=\"float\" id=\"pcbi.1013722.g009\" orientation=\"portrait\"><object-id pub-id-type=\"doi\">10.1371/journal.pcbi.1013722.g009</object-id><label>Fig 9</label><caption><title>Training accuracy, loss, and F1 Score under different epochs.</title></caption><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" position=\"float\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.g009.jpg\"/></fig><p>As shown, the training loss follows a smooth and consistent downward trajectory over epochs, indicating stable convergence. The curve begins to plateau around the 10th epoch, suggesting that the model quickly captures key discriminative patterns and reaches a near-optimal state early in training.</p><p>The accuracy curve exhibits a steady rise, eventually stabilizing above 86%. This high and sustained accuracy aligns with the model&#8217;s strong final evaluation results, reinforcing the reliability of its performance even under few-shot constraints. Notably, the model avoids overfitting despite the low-resource setting, reflecting effective generalization from limited data.</p><p>In parallel, the F1 score&#8212;reflecting the harmonic balance of precision and recall&#8212;shows a similarly smooth ascent. Its rapid convergence and stability indicate that the model performs consistently well across DDI categories, without favoring high-frequency interaction types. This is particularly important in imbalanced biomedical datasets, where overfitting to dominant classes is common.</p><p>To further assess the sensitivity of BioMCL-DDI to key hyperparameters, we conduct an ablation study by varying the weights of the prototype loss (<inline-formula id=\"pcbi.1013722.e037\"><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pcbi.1013722.e037g\" position=\"anchor\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.e037.jpg\"/><mml:math id=\"M37\" display=\"inline\" overflow=\"scroll\"><mml:mrow><mml:msub><mml:mi>&#955;</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>) and the contrastive loss (<inline-formula id=\"pcbi.1013722.e038\"><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pcbi.1013722.e038g\" position=\"anchor\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.e038.jpg\"/><mml:math id=\"M38\" display=\"inline\" overflow=\"scroll\"><mml:mrow><mml:msub><mml:mi>&#955;</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>). <xref rid=\"pcbi.1013722.g010\" ref-type=\"fig\">Fig 10</xref>(a) and <xref rid=\"pcbi.1013722.g010\" ref-type=\"fig\">10</xref>(b) present the model&#8217;s F1 score under different settings of <inline-formula id=\"pcbi.1013722.e039\"><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pcbi.1013722.e039g\" position=\"anchor\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.e039.jpg\"/><mml:math id=\"M39\" display=\"inline\" overflow=\"scroll\"><mml:mrow><mml:msub><mml:mi>&#955;</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id=\"pcbi.1013722.e040\"><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pcbi.1013722.e040g\" position=\"anchor\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.e040.jpg\"/><mml:math id=\"M40\" display=\"inline\" overflow=\"scroll\"><mml:mrow><mml:msub><mml:mi>&#955;</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, respectively.</p><fig position=\"float\" id=\"pcbi.1013722.g010\" orientation=\"portrait\"><object-id pub-id-type=\"doi\">10.1371/journal.pcbi.1013722.g010</object-id><label>Fig 10</label><caption><title>F1 score of BioMCL-DDI under varying hyperparameters.</title></caption><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" position=\"float\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.g010.jpg\"/></fig><p>As illustrated in <xref rid=\"pcbi.1013722.g010\" ref-type=\"fig\">Fig 10</xref>(a), increasing <inline-formula id=\"pcbi.1013722.e041\"><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pcbi.1013722.e041g\" position=\"anchor\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.e041.jpg\"/><mml:math id=\"M41\" display=\"inline\" overflow=\"scroll\"><mml:mrow><mml:msub><mml:mi>&#955;</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> from 0.0 to 1.0 steadily improves performance. The F1 score rises from 85.2% at <inline-formula id=\"pcbi.1013722.e042\"><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pcbi.1013722.e042g\" position=\"anchor\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.e042.jpg\"/><mml:math id=\"M42\" display=\"inline\" overflow=\"scroll\"><mml:mrow><mml:msub><mml:mi>&#955;</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0.0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> to 87.8% at <inline-formula id=\"pcbi.1013722.e043\"><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pcbi.1013722.e043g\" position=\"anchor\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.e043.jpg\"/><mml:math id=\"M43\" display=\"inline\" overflow=\"scroll\"><mml:mrow><mml:msub><mml:mi>&#955;</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>1.0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>, with the most notable gains occurring between 0.0 and 0.5. Beyond <inline-formula id=\"pcbi.1013722.e044\"><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pcbi.1013722.e044g\" position=\"anchor\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.e044.jpg\"/><mml:math id=\"M44\" display=\"inline\" overflow=\"scroll\"><mml:mrow><mml:msub><mml:mi>&#955;</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>, the improvements begin to plateau, suggesting diminishing returns from further emphasizing intra-class prototype alignment.</p><p>Similarly, in <xref rid=\"pcbi.1013722.g010\" ref-type=\"fig\">Fig 10</xref>(b), raising <inline-formula id=\"pcbi.1013722.e045\"><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pcbi.1013722.e045g\" position=\"anchor\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.e045.jpg\"/><mml:math id=\"M45\" display=\"inline\" overflow=\"scroll\"><mml:mrow><mml:msub><mml:mi>&#955;</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> from 0.0 to 0.3 leads to consistent gains, with F1 increasing from 85.0% to 87.6%. The largest improvements are observed around <inline-formula id=\"pcbi.1013722.e046\"><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pcbi.1013722.e046g\" position=\"anchor\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.e046.jpg\"/><mml:math id=\"M46\" display=\"inline\" overflow=\"scroll\"><mml:mrow><mml:msub><mml:mi>&#955;</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>&#8211;0.2, while values above 0.3 provide limited additional benefit. These findings confirm that moderate contrastive regularization enhances inter-class separation, but excessive weight may reduce generalizability.</p><p>Throughout all experiments, we adopt <inline-formula id=\"pcbi.1013722.e047\"><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pcbi.1013722.e047g\" position=\"anchor\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.e047.jpg\"/><mml:math id=\"M47\" display=\"inline\" overflow=\"scroll\"><mml:mrow><mml:msub><mml:mi>&#955;</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id=\"pcbi.1013722.e048\"><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pcbi.1013722.e048g\" position=\"anchor\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.e048.jpg\"/><mml:math id=\"M48\" display=\"inline\" overflow=\"scroll\"><mml:mrow><mml:msub><mml:mi>&#955;</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> as default settings. This configuration offers a strong trade-off between performance and stability. Although slightly higher F1 scores are attainable with more aggressive tuning, the observed gains are marginal (less than 0.5%), and the selected values generalize well across tasks and domains. These results indicate that BioMCL-DDI is robust to hyperparameter variations, which is important for practical deployment in biomedical scenarios. &#239;\"&#191;</p></sec><sec id=\"sec027\"><title>Error analysis and case interpretations</title><p>To gain a more nuanced understanding of BioMCL-DDI&#8217;s behavior in real-world biomedical text, we conducted a systematic qualitative case study on a comprehensive set of ten instances from the DDI Extraction 2013 dataset. The analysis aims to investigate the model&#8217;s strengths, limitations, and decision-making process, as summarized in <xref rid=\"pcbi.1013722.t009\" ref-type=\"table\">Table 9</xref>. We further utilized attention heatmaps from the BioBERT encoder to provide critical insights into the model&#8217;s reasoning.</p><table-wrap position=\"float\" id=\"pcbi.1013722.t009\" orientation=\"portrait\"><object-id pub-id-type=\"doi\">10.1371/journal.pcbi.1013722.t009</object-id><label>Table 9</label><caption><title>Case study on BioMCL-DDI predictions.</title></caption><alternatives><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"pcbi.1013722.t009g\" position=\"float\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.t009.jpg\"/><table frame=\"hsides\" rules=\"groups\"><colgroup span=\"1\"><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/><col align=\"left\" valign=\"middle\" span=\"1\"/></colgroup><thead><tr><th align=\"left\" rowspan=\"1\" colspan=\"1\">Case</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">Input Sentence (Annotated)</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">True Label</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">Predicted Label</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">Correct</th><th align=\"left\" rowspan=\"1\" colspan=\"1\">Remarks</th></tr></thead><tbody><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">1</td><td align=\"left\" rowspan=\"1\" colspan=\"1\"><bold>Ketoconazole</bold> can increase the blood levels of <bold>Simvastatin</bold> by inhibiting CYP3A4.</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Mechanism</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Mechanism</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">&#10003;</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Correct prediction with explicit enzyme inhibition.</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">2</td><td align=\"left\" rowspan=\"1\" colspan=\"1\"><bold>Rifampin</bold> reduces the effectiveness of <bold>Atazanavir</bold>.</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Effect</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Effect</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">&#10003;</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Accurately captures semantic implication of reduced efficacy.</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">3</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">No interaction was observed between <bold>Aspirin</bold> and <bold>Metformin</bold>.</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">False</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">False</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">&#10003;</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">True negative. Model correctly handles non-interaction cases.</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">4</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Co-administration of <bold>Clarithromycin</bold> and <bold>Warfarin</bold> may increase bleeding risk.</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Advise</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Advise</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">&#10003;</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Correctly associates co-administration with risk.</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">5</td><td align=\"left\" rowspan=\"1\" colspan=\"1\"><bold>Fluoxetine</bold> interacts with <bold>Tramadol</bold> causing seizure risk.</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Effect</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Mechanism</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">&#215;</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Misclassified due to subtle semantic overlap between effect and mechanism.</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">6</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">The dose of <bold>drug X</bold> may be adjusted when combined with <bold>drug Y</bold>.</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Advise</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">False</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">&#215;</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">False negative. Model fails to identify the advisory cue for dose adjustment.</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">7</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">The coadministration of <bold>aspirin</bold> and <bold>warfarin</bold> may increase the risk of bleeding.</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Effect</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Effect</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">&#10003;</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Correctly identifies the adverse effect.</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">8</td><td align=\"left\" rowspan=\"1\" colspan=\"1\"><bold>Carbamazepine</bold> and <bold>valproic acid</bold> combination therapy.</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">False</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Effect</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">&#215;</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">False positive. Model confused by co-occurrence without explicit interaction cues.</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">9</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">This study found an increased risk of severe adverse effects when <bold>drug A</bold> and <bold>drug B</bold> were used.</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Effect</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Advise</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">&#215;</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Subtle misclassification. Model interprets \"increased risk\" as an advisory warning rather than a direct effect.</td></tr><tr><td align=\"left\" rowspan=\"1\" colspan=\"1\">10</td><td align=\"left\" rowspan=\"1\" colspan=\"1\"><bold>Drug Z</bold> can cause hepatotoxicity, which is a common effect.</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">False</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">Effect</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">&#215;</td><td align=\"left\" rowspan=\"1\" colspan=\"1\">False positive. Model is misled by the mention of a general side effect.</td></tr></tbody></table></alternatives></table-wrap><p>Our analysis of the ten cases in <xref rid=\"pcbi.1013722.t009\" ref-type=\"table\">Table 9</xref> reveals both the proficiency and the limitations of the BioMCL-DDI framework. The successful predictions (Cases 1-4, 7) demonstrate the model&#8217;s ability to effectively learn and leverage key contextual and relational cues. For instance, in Case 1 (a &#8216;Mechanism&#8217; prediction), the attention heatmap in <xref rid=\"pcbi.1013722.g011\" ref-type=\"fig\">Fig 11</xref>(a) shows that the model correctly focuses its highest attention weights on the drug entity &#8216;Ketoconazole&#8217; and the crucial mechanistic term &#8216;CYP3A4&#8217;, which is directly responsible for the interaction. This visualization empirically validates that the model has learned to associate specific biomedical terminology with the corresponding DDI type.</p><fig position=\"float\" id=\"pcbi.1013722.g011\" orientation=\"portrait\"><object-id pub-id-type=\"doi\">10.1371/journal.pcbi.1013722.g011</object-id><label>Fig 11</label><caption><title>Attention heatmaps for selected cases.</title></caption><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" position=\"float\" orientation=\"portrait\" xlink:href=\"pcbi.1013722.g011.jpg\"/></fig><p>Conversely, the misclassified examples (Cases 5, 6, 8, 9, 10) highlight the remaining challenges in fine-grained DDI extraction. These errors can be attributed to several root causes:</p><list list-type=\"order\"><list-item><p><bold>Semantic Overlap and Ambiguity:</bold> In case 5, the true label is &#8216;Effect&#8217;, but the model incorrectly predicts &#8216;Mechanism&#8217;. The attention heatmap for this instance (<xref rid=\"pcbi.1013722.g011\" ref-type=\"fig\">Fig 11</xref>(b)) reveals that the model&#8217;s attention is distributed across the general interaction term &#8216;interacts&#8217; and the outcome &#8216;seizure risk&#8217;. While the interaction term &#8216;interacts&#8217; is often associated with the &#8216;Mechanism&#8217; class, the phrase &#8216;seizure risk&#8217; points to a direct clinical outcome, which is characteristic of the &#8216;Effect&#8217; class. The model&#8217;s misclassification suggests a subtle imbalance in its attention weights, leading to confusion between these semantically similar DDI subtypes.</p></list-item><list-item><p><bold>Misleading Medical Terminology:</bold> This is a classic false positive error, where the model incorrectly predicts a DDI despite the sentence stating a single drug&#8217;s side effect. As shown in the attention heatmap in <xref rid=\"pcbi.1013722.g011\" ref-type=\"fig\">Fig 11</xref>(c), the model assigns high attention to the medical term &#8216;hepatotoxicity&#8217; and the general outcome term &#8216;effect&#8217;. This indicates that the model is misled by the presence of strong medical terminology, over-associating it with a DDI when in fact, no interaction between two drugs is mentioned.</p></list-item><list-item><p><bold>Lack of Explicit Cues (Cases 6, 8, 9):</bold> In these instances, the model fails to capture implicit or subtle cues. For example, in Case 6, the model misclassifies a &#8216;False&#8217; interaction as &#8216;Effect&#8217; because of the co-occurrence of two drugs without any explicit interaction verbs. Similarly, in Case 9, the model misses the subtle &#8216;Advise&#8217; cue in \"may be adjusted,\" leading to a &#8216;False&#8217; negative.</p></list-item></list><p>The above analysis indicates that while BioMCL-DDI is proficient in learning from key contextual cues, it can be susceptible to fine-grained semantic ambiguities. The analysis of incorrect predictions also reveals instances where the model may be influenced by strong medical terminology in contexts where no drug-drug interaction is present.</p></sec></sec><sec sec-type=\"conclusions\" id=\"sec028\"><title>Discussion</title><p>This study presents BioMCL-DDI, a unified few-shot learning framework for drug&#8211;drug interaction (DDI) extraction that integrates prototypical classification and contrastive representation learning. Our empirical results demonstrate that the proposed model achieves strong performance under low-resource conditions, outperforming existing fully supervised and meta-learning baselines on both in-domain and cross-domain settings.</p><p>A key factor contributing to this performance is the synergy between prototype-based alignment and instance-level contrastive separation. While prototypical networks capture class-level semantics that are essential in few-shot learning, the additional contrastive regularization promotes better global structuring of the embedding space. This leads to improved generalization, particularly in cases involving semantically overlapping or underrepresented DDI types. Our ablation study confirms that removing either component results in a notable drop in F1 score, highlighting their complementary effects.</p><p>Compared to existing methods such as Meta-DDI and BERT-Proto, BioMCL-DDI exhibits improved adaptability without requiring episodic task construction or pretraining stages. This not only simplifies training but also facilitates scalability in real-world clinical pipelines. Moreover, the model maintains high performance across different DDI classes despite significant class imbalance&#8212;an important trait for pharmacovigilance systems that often deal with rare but clinically critical interactions.</p><p>Nonetheless, several limitations warrant further investigation. First, although the model is designed for few-shot scenarios, it still requires a minimum number of labeled examples per class to form reliable prototypes. Extremely low-resource settings may lead to unstable performance. Second, the reliance on sentence-level inputs may limit the model&#8217;s ability to incorporate external domain knowledge or multi-sentence context, which could be addressed by integrating knowledge graph signals or contextual document modeling. Third, while our experiments focus on English biomedical corpora, the model&#8217;s cross-lingual generalizability remains to be explored.</p><p>While the overall performance reported in <xref rid=\"pcbi.1013722.t003\" ref-type=\"table\">Tables 3</xref> and <xref rid=\"pcbi.1013722.t004\" ref-type=\"table\">4</xref> indicates that the proposed model sets a new state-of-the-art benchmark, it is important to acknowledge certain challenges. As our error analysis revealed, the model still faces difficulty in distinguishing between semantically similar DDI classes, such as &#8216;DDI-mechanism&#8217; and &#8216;DDI-advise,&#8217; which can lead to misclassifications. This semantic ambiguity, coupled with the inherent class imbalance of the DDI-2013 dataset, presents a bottleneck for further performance gains. Nevertheless, our framework consistently outperforms all baselines under few-shot conditions, demonstrating its effectiveness in a critical, low-resource setting where traditional models often fail. This validates our core hypothesis that meta-contrastive learning provides a more robust inductive bias for biomedical relation extraction than conventional approaches.</p><p>In future work, we plan to enhance the interpretability of BioMCL-DDI by incorporating attention-based visualization techniques and exploring its deployment within interactive CDSS platforms. Moreover, extending the framework to handle multi-label or nested DDI scenarios could further increase its applicability in complex clinical narratives.</p><sec id=\"sec029\"><title>Clinical implications</title><p>BioMCL-DDI framework addresses a critical limitation in contemporary pharmacovigilance systems&#8212;the scarcity of labeled data for novel or rarely co-administered drugs . By leveraging few-shot learning, the model enables effective extraction of drug&#8211;drug interactions (DDIs) even in low-resource scenarios, providing timely support for safer prescribing decisions when traditional DDI databases are incomplete or outdated.</p><p>From a clinical informatics perspective, the generalizability of BioMCL-DDI makes it well-suited for integration into clinical decision support systems (CDSS). Its capacity to issue early warnings about potential adverse drug events is particularly valuable in high-risk contexts such as polypharmacy, off-label use, and personalized treatment regimens involving emerging therapeutics . This capability can assist clinicians in proactively identifying and mitigating risks before they lead to adverse drug reactions, increased hospitalization, or mortality.</p><p>In addition, the model&#8217;s lightweight architecture and data efficiency facilitate its deployment in real-world pharmacovigilance workflows across healthcare institutions, pharmaceutical manufacturers, and regulatory agencies such as the FDA and EMA. By enabling automated, scalable pre-screening of potential interactions, BioMCL-DDI has the potential to accelerate safety evaluations, reduce adverse event latency, and improve overall responsiveness in clinical drug safety infrastructures.</p><p>Despite its potential, we acknowledge that the model faces certain limitations in clinical deployment. The model, while accurate on a technical level, may require further enhancements in interpretability to gain the trust of clinicians. Its predictions, especially for rare or novel interactions, must be presented in a transparent manner, supported by evidence from the text. Furthermore, the model&#8217;s reliance solely on textual data means it may not capture DDI information available in other modalities, such as molecular structures or patient-specific genomic data. Addressing these limitations in future work is crucial for fully realizing the framework&#8217;s value in personalized and precision medicine.</p><p>Ultimately, this framework can serve as a foundational component in next-generation biomedical text mining pipelines, complementing structured databases and enhancing the situational awareness of clinicians and drug safety professionals alike.</p></sec></sec><sec sec-type=\"conclusions\" id=\"sec030\"><title>Conclusion</title><p>This paper introduced BioMCL-DDI, a unified meta-contrastive learning framework for few-shot drug&#8211;drug interaction (DDI) extraction. It performs a fine-grained, multi-class classification of drug pairs into five distinct DDI types: DDI-false, DDI-effect, DDI-mechanism, DDI-advise, and DDI-int. By jointly optimizing prototypical classification and instance-level contrastive learning within a fully supervised setting, BioMCL-DDI achieves robust performance under data-scarce conditions without relying on episodic task construction or pretraining. Our extensive evaluations on DDI-2013 and DDI-DrugBank benchmarks demonstrate consistent improvements over state-of-the-art baselines, with strong generalization across domains and DDI subtypes. More importantly, evaluation on the recent TAC 2018 DDI Extraction dataset confirms that BioMCL-DDI maintains state-of-the-art performance under substantial domain shift. This robustness highlights the model&#8217;s applicability to real-world biomedical texts such as structured product labels and regulatory documents, which are central to pharmacovigilance practice. The proposed framework not only enhances class-level alignment and inter-class discrimination but also offers training scalability and architectural simplicity&#8212;key traits for integration into real-world pharmacovigilance pipelines. Moreover, BioMCL-DDI remains effective despite severe class imbalance, highlighting its applicability to rare but clinically significant interactions.</p><p>In future work, we aim to improve the interpretability and adaptability of BioMCL-DDI by integrating external biomedical knowledge, exploring zero-shot or continual learning settings, and extending support for multi-label or nested DDI relations. Another promising direction is to incorporate advanced graph neural networks (GNNs) for DDI prediction. Recent studies have demonstrated the effectiveness of GNNs in modeling complex biomedical relationships such as molecular interaction networks and drug&#8211;target associations [<xref rid=\"pcbi.1013722.ref060\" ref-type=\"bibr\">60</xref>,<xref rid=\"pcbi.1013722.ref061\" ref-type=\"bibr\">61</xref>]. By combining BioMCL-DDI&#8217;s sentence-level contextual embeddings with graph-based relational representations, future extensions could capture higher-order dependencies among drugs, targets, and interactions, thereby improving robustness and generalizability across heterogeneous biomedical corpora. Ultimately, we envision this framework contributing to the development of scalable, data-efficient, and clinically deployable decision support tools for personalized drug safety assessment.</p></sec></body><back><ref-list><title>References</title><ref id=\"pcbi.1013722.ref001\"><label>1</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Hughes</surname><given-names>JE</given-names></name>, <name name-style=\"western\"><surname>Moriarty</surname><given-names>F</given-names></name>, <name name-style=\"western\"><surname>Bennett</surname><given-names>KE</given-names></name>, <name name-style=\"western\"><surname>Cahir</surname><given-names>C</given-names></name>. <article-title>Drug-drug interactions and the risk of adverse drug reaction-related hospital admissions in the older population</article-title>. <source>Br J Clin Pharmacol.</source><year>2024</year>;<volume>90</volume>(<issue>4</issue>):<fpage>959</fpage>&#8211;<lpage>75</lpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1111/bcp.15970</pub-id><pub-id pub-id-type=\"pmid\">37984336</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref002\"><label>2</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Klopotowska</surname><given-names>JE</given-names></name>, <name name-style=\"western\"><surname>Leopold</surname><given-names>JH</given-names></name>, <name name-style=\"western\"><surname>Bakker</surname><given-names>T</given-names></name>. <article-title>Adverse drug events caused by three high-risk drug&#8211;drug interactions in patients admitted to intensive care units: A multicentre retrospective observational study</article-title>. <source>British Journal of Clinical Pharmacology.</source><year>2024</year>;<volume>90</volume>(<issue>1</issue>):<fpage>164</fpage>&#8211;<lpage>75</lpage>.<pub-id pub-id-type=\"pmid\">37567767</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1111/bcp.15882</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref003\"><label>3</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Laroche</surname><given-names>M-L</given-names></name>, <name name-style=\"western\"><surname>Tarbouriech</surname><given-names>N</given-names></name>, <name name-style=\"western\"><surname>Jai</surname><given-names>T</given-names></name>, <name name-style=\"western\"><surname>Valnet-Rabier</surname><given-names>M-B</given-names></name>, <name name-style=\"western\"><surname>Nerich</surname><given-names>V</given-names></name>. <article-title>Economic burden of hospital admissions for adverse drug reactions in France: the IATROSTAT-ECO study</article-title>. <source>Br J Clin Pharmacol.</source><year>2025</year>;<volume>91</volume>(<issue>2</issue>):<fpage>439</fpage>&#8211;<lpage>50</lpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1111/bcp.16266</pub-id><pub-id pub-id-type=\"pmid\">39363642</pub-id><pub-id pub-id-type=\"pmcid\">PMC11773093</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref004\"><label>4</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Machado</surname><given-names>J</given-names></name>, <name name-style=\"western\"><surname>Rodrigues</surname><given-names>C</given-names></name>, <name name-style=\"western\"><surname>Sousa</surname><given-names>R</given-names></name>, <name name-style=\"western\"><surname>Gomes</surname><given-names>LM</given-names></name>. <article-title>Drug&#8211;drug interaction extraction-based system: an natural language processing approach</article-title>. <source>Expert Systems.</source><year>2023</year>;<volume>42</volume>(<issue>1</issue>). <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1111/exsy.13303</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref005\"><label>5</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Dou</surname><given-names>M</given-names></name>, <name name-style=\"western\"><surname>Tang</surname><given-names>J</given-names></name>, <name name-style=\"western\"><surname>Tiwari</surname><given-names>P</given-names></name>, <name name-style=\"western\"><surname>Ding</surname><given-names>Y</given-names></name>, <name name-style=\"western\"><surname>Guo</surname><given-names>F</given-names></name>. <article-title>Drug&#8211;drug interaction relation extraction based on deep learning: a review</article-title>. <source>ACM Comput Surv.</source><year>2024</year>;<volume>56</volume>(<issue>6</issue>):<fpage>1</fpage>&#8211;<lpage>33</lpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1145/3645089</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref006\"><label>6</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Jia</surname><given-names>Y</given-names></name>, <name name-style=\"western\"><surname>Yuan</surname><given-names>Z</given-names></name>, <name name-style=\"western\"><surname>Wang</surname><given-names>H</given-names></name>, <name name-style=\"western\"><surname>Gong</surname><given-names>Y</given-names></name>, <name name-style=\"western\"><surname>Yang</surname><given-names>H</given-names></name>, <name name-style=\"western\"><surname>Xiang</surname><given-names>Z-L</given-names></name>. <article-title>BBL-GAT: a novel method for drug-drug interaction extraction from biomedical literature</article-title>. <source>IEEE Access.</source><year>2024</year>;<volume>12</volume>:<fpage>134167</fpage>&#8211;<lpage>84</lpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1109/access.2024.3462101</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref007\"><label>7</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Jia</surname><given-names>Y</given-names></name>, <name name-style=\"western\"><surname>Wang</surname><given-names>H</given-names></name>, <name name-style=\"western\"><surname>Yuan</surname><given-names>Z</given-names></name>. <article-title>Biomedical relation extraction method based on ensemble learning and attention mechanism</article-title>. <source>BMC Bioinformatics.</source><year>2024</year>;<volume>25</volume>(<issue>1</issue>):<fpage>333</fpage>.<pub-id pub-id-type=\"pmid\">39425010</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1186/s12859-024-05951-y</pub-id><pub-id pub-id-type=\"pmcid\">PMC11488084</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref008\"><label>8</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Jia</surname><given-names>Y</given-names></name>, <name name-style=\"western\"><surname>Yuan</surname><given-names>Z</given-names></name>, <name name-style=\"western\"><surname>Wang</surname><given-names>H</given-names></name>, <name name-style=\"western\"><surname>Gong</surname><given-names>Y</given-names></name>, <name name-style=\"western\"><surname>Yang</surname><given-names>H</given-names></name>, <name name-style=\"western\"><surname>Xiang</surname><given-names>Z</given-names></name>. <article-title>Variations towards an efficient drug&#8211;drug interaction</article-title>. <source>The Computer Journal.</source><year>2024</year>;<volume>68</volume>(<issue>5</issue>):<fpage>552</fpage>&#8211;<lpage>64</lpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1093/comjnl/bxae131</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref009\"><label>9</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Yuan</surname><given-names>Z</given-names></name>, <name name-style=\"western\"><surname>Zhang</surname><given-names>S</given-names></name>, <name name-style=\"western\"><surname>Zhang</surname><given-names>H</given-names></name>, <name name-style=\"western\"><surname>Xie</surname><given-names>P</given-names></name>, <name name-style=\"western\"><surname>Jia</surname><given-names>Y</given-names></name>. <article-title>Optimized drug-drug interaction extraction with BioGPT and focal loss-based attention</article-title>. <source>IEEE J Biomed Health Inform.</source><year>2025</year>;<volume>29</volume>(<issue>6</issue>):<fpage>4560</fpage>&#8211;<lpage>70</lpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1109/JBHI.2025.3540861</pub-id><pub-id pub-id-type=\"pmid\">40031603</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref010\"><label>10</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Li</surname><given-names>D</given-names></name>, <name name-style=\"western\"><surname>Yang</surname><given-names>Y</given-names></name>, <name name-style=\"western\"><surname>Cui</surname><given-names>Z</given-names></name>, <name name-style=\"western\"><surname>Yin</surname><given-names>H</given-names></name>, <name name-style=\"western\"><surname>Hu</surname><given-names>P</given-names></name>, <name name-style=\"western\"><surname>Hu</surname><given-names>L</given-names></name>. <article-title>LLM-DDI: leveraging large language models for drug-drug interaction prediction on biomedical knowledge graph</article-title>. <source>IEEE J Biomed Health Inform.</source><year>2025</year>;PP:10.1109/JBHI.2025.3585290. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1109/JBHI.2025.3585290</pub-id><pub-id pub-id-type=\"pmid\">40601466</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref011\"><label>11</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Lee</surname><given-names>J</given-names></name>, <name name-style=\"western\"><surname>Yoon</surname><given-names>W</given-names></name>, <name name-style=\"western\"><surname>Kim</surname><given-names>S</given-names></name>, <name name-style=\"western\"><surname>Kim</surname><given-names>D</given-names></name>, <name name-style=\"western\"><surname>Kim</surname><given-names>S</given-names></name>, <name name-style=\"western\"><surname>So</surname><given-names>CH</given-names></name>, <etal>et al</etal>. <article-title>BioBERT: a pre-trained biomedical language representation model for biomedical text mining</article-title>. <source>Bioinformatics.</source><year>2020</year>;<volume>36</volume>(<issue>4</issue>):<fpage>1234</fpage>&#8211;<lpage>40</lpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1093/bioinformatics/btz682</pub-id><pub-id pub-id-type=\"pmid\">31501885</pub-id><pub-id pub-id-type=\"pmcid\">PMC7703786</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref012\"><label>12</label><mixed-citation publication-type=\"other\">Liu S, Kai Chen, Chen Q, Tang B. Dependency-based convolutional neural network for drug-drug interaction extraction. In: 2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM), 2016. p. 1074&#8211;80. <pub-id pub-id-type=\"doi\">10.1109/bibm.2016.7822671</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref013\"><label>13</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Liu</surname><given-names>S</given-names></name>, <name name-style=\"western\"><surname>Tang</surname><given-names>B</given-names></name>, <name name-style=\"western\"><surname>Chen</surname><given-names>Q</given-names></name>, <name name-style=\"western\"><surname>Wang</surname><given-names>X</given-names></name>. <article-title>Drug-drug interaction extraction via convolutional neural networks</article-title>. <source>Comput Math Methods Med.</source><year>2016</year>;<volume>2016</volume>:<fpage>6918381</fpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1155/2016/6918381</pub-id><pub-id pub-id-type=\"pmid\">26941831</pub-id><pub-id pub-id-type=\"pmcid\">PMC4752975</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref014\"><label>14</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Zhao</surname><given-names>Z</given-names></name>, <name name-style=\"western\"><surname>Yang</surname><given-names>Z</given-names></name>, <name name-style=\"western\"><surname>Luo</surname><given-names>L</given-names></name>, <name name-style=\"western\"><surname>Lin</surname><given-names>H</given-names></name>, <name name-style=\"western\"><surname>Wang</surname><given-names>J</given-names></name>. <article-title>Drug drug interaction extraction from biomedical literature using syntax convolutional neural network</article-title>. <source>Bioinformatics.</source><year>2016</year>;<volume>32</volume>(<issue>22</issue>):<fpage>3444</fpage>&#8211;<lpage>53</lpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1093/bioinformatics/btw486</pub-id><pub-id pub-id-type=\"pmid\">27466626</pub-id><pub-id pub-id-type=\"pmcid\">PMC5181565</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref015\"><label>15</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Quan</surname><given-names>C</given-names></name>, <name name-style=\"western\"><surname>Hua</surname><given-names>L</given-names></name>, <name name-style=\"western\"><surname>Sun</surname><given-names>X</given-names></name>, <name name-style=\"western\"><surname>Bai</surname><given-names>W</given-names></name>. <article-title>Multichannel convolutional neural network for biological relation extraction</article-title>. <source>Biomed Res Int.</source><year>2016</year>;<volume>2016</volume>:<fpage>1850404</fpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1155/2016/1850404</pub-id><pub-id pub-id-type=\"pmid\">28053977</pub-id><pub-id pub-id-type=\"pmcid\">PMC5174749</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref016\"><label>16</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Zheng</surname><given-names>W</given-names></name>, <name name-style=\"western\"><surname>Lin</surname><given-names>H</given-names></name>, <name name-style=\"western\"><surname>Luo</surname><given-names>L</given-names></name>. <article-title>An attention-based effective neural model for drug-drug interactions extraction</article-title>. <source>BMC Bioinformatics.</source><year>2017</year>;<volume>18</volume>:<fpage>1</fpage>&#8211;<lpage>11</lpage>.<pub-id pub-id-type=\"pmid\">29017459</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1186/s12859-017-1855-x</pub-id><pub-id pub-id-type=\"pmcid\">PMC5634850</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref017\"><label>17</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Wang</surname><given-names>W</given-names></name>, <name name-style=\"western\"><surname>Yang</surname><given-names>X</given-names></name>, <name name-style=\"western\"><surname>Yang</surname><given-names>C</given-names></name>, <name name-style=\"western\"><surname>Guo</surname><given-names>X</given-names></name>, <name name-style=\"western\"><surname>Zhang</surname><given-names>X</given-names></name>, <name name-style=\"western\"><surname>Wu</surname><given-names>C</given-names></name>. <article-title>Dependency-based long short term memory network for drug-drug interaction extraction</article-title>. <source>BMC Bioinformatics.</source><year>2017</year>;<volume>18</volume>(Suppl 16):<fpage>578</fpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1186/s12859-017-1962-8</pub-id><pub-id pub-id-type=\"pmid\">29297301</pub-id><pub-id pub-id-type=\"pmcid\">PMC5751524</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref018\"><label>18</label><mixed-citation publication-type=\"other\">Jiang Z, Gu L, Jiang Q. Drug drug interaction extraction from literature using a skeleton long short term memory neural network. In: 2017 IEEE International Conference on Bioinformatics and Biomedicine (BIBM). 2017. p. 552&#8211;5. <pub-id pub-id-type=\"doi\">10.1109/bibm.2017.8217708</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref019\"><label>19</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Sahu</surname><given-names>SK</given-names></name>, <name name-style=\"western\"><surname>Anand</surname><given-names>A</given-names></name>. <article-title>Drug-drug interaction extraction from biomedical texts using long short-term memory network</article-title>. <source>J Biomed Inform.</source><year>2018</year>;<volume>86</volume>:<fpage>15</fpage>&#8211;<lpage>24</lpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1016/j.jbi.2018.08.005</pub-id><pub-id pub-id-type=\"pmid\">30142385</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref020\"><label>20</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Zhang</surname><given-names>Y</given-names></name>, <name name-style=\"western\"><surname>Zheng</surname><given-names>W</given-names></name>, <name name-style=\"western\"><surname>Lin</surname><given-names>H</given-names></name>, <name name-style=\"western\"><surname>Wang</surname><given-names>J</given-names></name>, <name name-style=\"western\"><surname>Yang</surname><given-names>Z</given-names></name>, <name name-style=\"western\"><surname>Dumontier</surname><given-names>M</given-names></name>. <article-title>Drug-drug interaction extraction via hierarchical RNNs on sequence and shortest dependency paths</article-title>. <source>Bioinformatics.</source><year>2018</year>;<volume>34</volume>(<issue>5</issue>):<fpage>828</fpage>&#8211;<lpage>35</lpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1093/bioinformatics/btx659</pub-id><pub-id pub-id-type=\"pmid\">29077847</pub-id><pub-id pub-id-type=\"pmcid\">PMC6030919</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref021\"><label>21</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Zhou</surname><given-names>D</given-names></name>, <name name-style=\"western\"><surname>Miao</surname><given-names>L</given-names></name>, <name name-style=\"western\"><surname>He</surname><given-names>Y</given-names></name>. <article-title>Position-aware deep multi-task learning for drug-drug interaction extraction</article-title>. <source>Artif Intell Med.</source><year>2018</year>;<volume>87</volume>:<fpage>1</fpage>&#8211;<lpage>8</lpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1016/j.artmed.2018.03.001</pub-id><pub-id pub-id-type=\"pmid\">29559249</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref022\"><label>22</label><mixed-citation publication-type=\"other\">Asada M, Miwa M, Sasaki Y. Enhancing drug-drug interaction extraction from texts by molecular structure information. In: Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers). 2018. <pub-id pub-id-type=\"doi\">10.18653/v1/p18-2108</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref023\"><label>23</label><mixed-citation publication-type=\"other\">Xiong W, Li F, Yu H, Ji D. Extracting drug-drug interactions with a dependency-based graph convolution neural network. In: 2019 IEEE International Conference on Bioinformatics and Biomedicine (BIBM). 2019. p. 755&#8211;9. <pub-id pub-id-type=\"doi\">10.1109/bibm47256.2019.8983150</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref024\"><label>24</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Zhao</surname><given-names>D</given-names></name>, <name name-style=\"western\"><surname>Wang</surname><given-names>J</given-names></name>, <name name-style=\"western\"><surname>Lin</surname><given-names>H</given-names></name>, <name name-style=\"western\"><surname>Yang</surname><given-names>Z</given-names></name>, <name name-style=\"western\"><surname>Zhang</surname><given-names>Y</given-names></name>. <article-title>Extracting drug-drug interactions with hybrid bidirectional gated recurrent unit and graph convolutional network</article-title>. <source>J Biomed Inform.</source><year>2019</year>;<volume>99</volume>:<fpage>103295</fpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1016/j.jbi.2019.103295</pub-id><pub-id pub-id-type=\"pmid\">31568842</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref025\"><label>25</label><mixed-citation publication-type=\"other\">Li D, Ji H. Syntax-aware multi-task graph convolutional networks for biomedical relation extraction. In: Proceedings of the Tenth International Workshop on Health Text Mining and Information Analysis (LOUHI 2019). 2019. <pub-id pub-id-type=\"doi\">10.18653/v1/d19-6204</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref026\"><label>26</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Zhu</surname><given-names>Y</given-names></name>, <name name-style=\"western\"><surname>Li</surname><given-names>L</given-names></name>, <name name-style=\"western\"><surname>Lu</surname><given-names>H</given-names></name>, <name name-style=\"western\"><surname>Zhou</surname><given-names>A</given-names></name>, <name name-style=\"western\"><surname>Qin</surname><given-names>X</given-names></name>. <article-title>Extracting drug-drug interactions from texts with BioBERT and multiple entity-aware attentions</article-title>. <source>J Biomed Inform.</source><year>2020</year>;<volume>106</volume>:<fpage>103451</fpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1016/j.jbi.2020.103451</pub-id><pub-id pub-id-type=\"pmid\">32454243</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref027\"><label>27</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Li</surname><given-names>D</given-names></name>, <name name-style=\"western\"><surname>Zhao</surname><given-names>F</given-names></name>, <name name-style=\"western\"><surname>Yang</surname><given-names>Y</given-names></name>, <name name-style=\"western\"><surname>Cui</surname><given-names>Z</given-names></name>, <name name-style=\"western\"><surname>Hu</surname><given-names>P</given-names></name>, <name name-style=\"western\"><surname>Hu</surname><given-names>L</given-names></name>. <article-title>Multi-view contrastive learning for drug-drug interaction event prediction</article-title>. <source>IEEE J Biomed Health Inform.</source><year>2025</year>;PP:10.1109/JBHI.2025.3600045. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1109/JBHI.2025.3600045</pub-id><pub-id pub-id-type=\"pmid\">40833904</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref028\"><label>28</label><mixed-citation publication-type=\"other\">Duan B, Qin L, Peng J. Using center vector and drug molecular information for drug drug interaction extraction. In: 2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM). 2021. p. 1291&#8211;4. <pub-id pub-id-type=\"doi\">10.1109/bibm52615.2021.9669610</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref029\"><label>29</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Duan</surname><given-names>B</given-names></name>, <name name-style=\"western\"><surname>Peng</surname><given-names>J</given-names></name>, <name name-style=\"western\"><surname>Zhang</surname><given-names>Y</given-names></name>. <article-title>IMSE: interaction information attention and molecular structure based drug drug interaction extraction</article-title>. <source>BMC Bioinformatics.</source><year>2022</year>;<volume>23</volume>(Suppl 7):<fpage>338</fpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1186/s12859-022-04876-8</pub-id><pub-id pub-id-type=\"pmid\">35965308</pub-id><pub-id pub-id-type=\"pmcid\">PMC9375903</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref030\"><label>30</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Shi</surname><given-names>Y</given-names></name>, <name name-style=\"western\"><surname>Quan</surname><given-names>P</given-names></name>, <name name-style=\"western\"><surname>Zhang</surname><given-names>T</given-names></name>, <name name-style=\"western\"><surname>Niu</surname><given-names>L</given-names></name>. <article-title>DREAM: drug-drug interaction extraction with enhanced dependency graph and attention mechanism</article-title>. <source>Methods.</source><year>2022</year>;<volume>203</volume>:<fpage>152</fpage>&#8211;<lpage>9</lpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1016/j.ymeth.2022.02.002</pub-id><pub-id pub-id-type=\"pmid\">35181524</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref031\"><label>31</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Huang</surname><given-names>Z</given-names></name>, <name name-style=\"western\"><surname>An</surname><given-names>N</given-names></name>, <name name-style=\"western\"><surname>Liu</surname><given-names>J</given-names></name>, <name name-style=\"western\"><surname>Ren</surname><given-names>F</given-names></name>. <article-title>EMSI-BERT: asymmetrical entity-mask strategy and symbol-insert structure for drug&#8211;drug interaction extraction based on BERT</article-title>. <source>Symmetry.</source><year>2023</year>;<volume>15</volume>(<issue>2</issue>):<fpage>398</fpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.3390/sym15020398</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref032\"><label>32</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Asada</surname><given-names>M</given-names></name>, <name name-style=\"western\"><surname>Miwa</surname><given-names>M</given-names></name>, <name name-style=\"western\"><surname>Sasaki</surname><given-names>Y</given-names></name>. <article-title>Integrating heterogeneous knowledge graphs into drug-drug interaction extraction from the literature</article-title>. <source>Bioinformatics.</source><year>2023</year>;<volume>39</volume>(<issue>1</issue>):btac754. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1093/bioinformatics/btac754</pub-id><pub-id pub-id-type=\"pmid\">36416141</pub-id><pub-id pub-id-type=\"pmcid\">PMC9805562</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref033\"><label>33</label><mixed-citation publication-type=\"other\">Yuan J, Du W, Liu X. Biomedical relation extraction via domain knowledge and prompt learning. In: Proceedings of Joint Workshop of the 5th Extraction and Evaluation of Knowledge Entities from Scientific Documents, Changchun, Jilin, 2024. p. 59&#8211;61.</mixed-citation></ref><ref id=\"pcbi.1013722.ref034\"><label>34</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Aladadi</surname><given-names>SM</given-names></name>, <name name-style=\"western\"><surname>Alghamdi</surname><given-names>MA</given-names></name>, <name name-style=\"western\"><surname>Alrebdi</surname><given-names>MR</given-names></name>. <article-title>Application of biomedical informatics methods to find drug-drug interactions</article-title>. <source>International Journal of Multidisciplinary Innovation and Research Methodology.</source><year>2024</year>;<volume>3</volume>(<issue>3</issue>):<fpage>213</fpage>&#8211;<lpage>20</lpage>.</mixed-citation></ref><ref id=\"pcbi.1013722.ref035\"><label>35</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Hassan</surname><given-names>NA</given-names></name>, <name name-style=\"western\"><surname>Seoud</surname><given-names>RAA</given-names></name>, <name name-style=\"western\"><surname>Salem</surname><given-names>DA</given-names></name>. <article-title>Bridging the gap: a hybrid approach to medical relation extraction using pretrained language models and traditional machine learning</article-title>. <source>JAIT.</source><year>2024</year>;<volume>15</volume>(<issue>6</issue>):<fpage>723</fpage>&#8211;<lpage>34</lpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.12720/jait.15.6.723-734</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref036\"><label>36</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Snell</surname><given-names>J</given-names></name>, <name name-style=\"western\"><surname>Swersky</surname><given-names>K</given-names></name>, <name name-style=\"western\"><surname>Zemel</surname><given-names>R</given-names></name>. <article-title>Prototypical networks for few-shot learning</article-title>. <source>Advances in Neural Information Processing Systems.</source><year>2017</year>;<volume>30</volume>.</mixed-citation></ref><ref id=\"pcbi.1013722.ref037\"><label>37</label><mixed-citation publication-type=\"other\">Finn C, Abbeel P, Levine S. Model-agnostic meta-learning for fast adaptation of deep networks. In: Proceedings of International conference on machine learning, Sydney, NSW, 2017. 1126&#8211;35.</mixed-citation></ref><ref id=\"pcbi.1013722.ref038\"><label>38</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Herrero-Zazo</surname><given-names>M</given-names></name>, <name name-style=\"western\"><surname>Segura-Bedmar</surname><given-names>I</given-names></name>, <name name-style=\"western\"><surname>Mart&#237;nez</surname><given-names>P</given-names></name>, <name name-style=\"western\"><surname>Declerck</surname><given-names>T</given-names></name>. <article-title>The DDI corpus: an annotated corpus with pharmacological substances and drug-drug interactions</article-title>. <source>J Biomed Inform.</source><year>2013</year>;<volume>46</volume>(<issue>5</issue>):<fpage>914</fpage>&#8211;<lpage>20</lpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1016/j.jbi.2013.07.011</pub-id><pub-id pub-id-type=\"pmid\">23906817</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref039\"><label>39</label><mixed-citation publication-type=\"other\">Demner-Fushman D, Fung K, Do P. The DDI corpus: an annotated corpus with pharmacological substances and drug&#8211;drug interactions. In: Proceedings of Text Analysis Conference, Gaithersburg, USA; 2018. p. 1&#8211;10.</mixed-citation></ref><ref id=\"pcbi.1013722.ref040\"><label>40</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Huang</surname><given-names>D</given-names></name>, <name name-style=\"western\"><surname>Jiang</surname><given-names>Z</given-names></name>, <name name-style=\"western\"><surname>Zou</surname><given-names>L</given-names></name>, <name name-style=\"western\"><surname>Li</surname><given-names>L</given-names></name>. <article-title>Drug&#8211;drug interaction extraction from biomedical literature using support vector machine and long short term memory networks</article-title>. <source>Information Sciences.</source><year>2017</year>;415&#8211;416:<fpage>100</fpage>&#8211;<lpage>9</lpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1016/j.ins.2017.06.021</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref041\"><label>41</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Mostafapour</surname><given-names>V</given-names></name>, <name name-style=\"western\"><surname>Dikenelli</surname><given-names>O</given-names></name>. <article-title>Attention-wrapped hierarchical blstms for ddi extraction</article-title>. <source>arXiv preprint</source><year>2019</year>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.48550/arXiv.1907.13561</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref042\"><label>42</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Hong</surname><given-names>L</given-names></name>, <name name-style=\"western\"><surname>Lin</surname><given-names>J</given-names></name>, <name name-style=\"western\"><surname>Tao</surname><given-names>J</given-names></name>. <article-title>BERE: an accurate distantly supervised biomedical entity relation extraction network</article-title>. <source>arXiv preprint</source><year>2019</year>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.48550/arXiv.1906.06916</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref043\"><label>43</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Liu</surname><given-names>J</given-names></name>, <name name-style=\"western\"><surname>Huang</surname><given-names>Z</given-names></name>, <name name-style=\"western\"><surname>Ren</surname><given-names>F</given-names></name>, <name name-style=\"western\"><surname>Hua</surname><given-names>L</given-names></name>. <article-title>Drug-drug interaction extraction based on transfer weight matrix and memory network</article-title>. <source>IEEE Access.</source><year>2019</year>;<volume>7</volume>:<fpage>101260</fpage>&#8211;<lpage>8</lpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1109/access.2019.2930641</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref044\"><label>44</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Sun</surname><given-names>X</given-names></name>, <name name-style=\"western\"><surname>Dong</surname><given-names>K</given-names></name>, <name name-style=\"western\"><surname>Ma</surname><given-names>L</given-names></name>, <name name-style=\"western\"><surname>Sutcliffe</surname><given-names>R</given-names></name>, <name name-style=\"western\"><surname>He</surname><given-names>F</given-names></name>, <name name-style=\"western\"><surname>Chen</surname><given-names>S</given-names></name>, <etal>et al</etal>. <article-title>Drug-drug interaction extraction via recurrent hybrid convolutional neural networks with an improved focal loss</article-title>. <source>Entropy (Basel).</source><year>2019</year>;<volume>21</volume>(<issue>1</issue>):<fpage>37</fpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.3390/e21010037</pub-id><pub-id pub-id-type=\"pmid\">33266753</pub-id><pub-id pub-id-type=\"pmcid\">PMC7514143</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref045\"><label>45</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Asada</surname><given-names>M</given-names></name>, <name name-style=\"western\"><surname>Miwa</surname><given-names>M</given-names></name>, <name name-style=\"western\"><surname>Sasaki</surname><given-names>Y</given-names></name>. <article-title>Using drug descriptions and molecular structures for drug-drug interaction extraction from literature</article-title>. <source>Bioinformatics.</source><year>2021</year>;<volume>37</volume>(<issue>12</issue>):<fpage>1739</fpage>&#8211;<lpage>46</lpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1093/bioinformatics/btaa907</pub-id><pub-id pub-id-type=\"pmid\">33098410</pub-id><pub-id pub-id-type=\"pmcid\">PMC8289381</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref046\"><label>46</label><mixed-citation publication-type=\"other\">Nguyen DP, Bao Ho T. Drug-drug interaction extraction from biomedical texts via relation BERT. In: 2020 RIVF International Conference on Computing and Communication Technologies (RIVF). 2020. p. 1&#8211;7. <pub-id pub-id-type=\"doi\">10.1109/rivf48685.2020.9140783</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref047\"><label>47</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Wu</surname><given-names>H</given-names></name>, <name name-style=\"western\"><surname>Xing</surname><given-names>Y</given-names></name>, <name name-style=\"western\"><surname>Ge</surname><given-names>W</given-names></name>, <name name-style=\"western\"><surname>Liu</surname><given-names>X</given-names></name>, <name name-style=\"western\"><surname>Zou</surname><given-names>J</given-names></name>, <name name-style=\"western\"><surname>Zhou</surname><given-names>C</given-names></name>, <etal>et al</etal>. <article-title>Drug-drug interaction extraction via hybrid neural networks on biomedical literature</article-title>. <source>J Biomed Inform.</source><year>2020</year>;<volume>106</volume>:<fpage>103432</fpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1016/j.jbi.2020.103432</pub-id><pub-id pub-id-type=\"pmid\">32335223</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref048\"><label>48</label><mixed-citation publication-type=\"other\">Zaikis D, Vlahavas I. Drug-drug interaction classification using attention based neural networks. In: 11th Hellenic Conference on Artificial Intelligence, 2020. 34&#8211;40. <pub-id pub-id-type=\"doi\">10.1145/3411408.3411461</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref049\"><label>49</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>He</surname><given-names>H</given-names></name>, <name name-style=\"western\"><surname>Chen</surname><given-names>G</given-names></name>, <name name-style=\"western\"><surname>Yu-Chian Chen</surname><given-names>C</given-names></name>. <article-title>3DGT-DDI: 3D graph and text based neural network for drug-drug interaction prediction</article-title>. <source>Brief Bioinform.</source><year>2022</year>;<volume>23</volume>(<issue>3</issue>):bbac134. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1093/bib/bbac134</pub-id><pub-id pub-id-type=\"pmid\">35511112</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref050\"><label>50</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Huang</surname><given-names>L</given-names></name>, <name name-style=\"western\"><surname>Lin</surname><given-names>J</given-names></name>, <name name-style=\"western\"><surname>Li</surname><given-names>X</given-names></name>, <name name-style=\"western\"><surname>Song</surname><given-names>L</given-names></name>, <name name-style=\"western\"><surname>Zheng</surname><given-names>Z</given-names></name>, <name name-style=\"western\"><surname>Wong</surname><given-names>K-C</given-names></name>. <article-title>EGFI: drug-drug interaction extraction and generation with fusion of enriched entity and sentence information</article-title>. <source>Brief Bioinform.</source><year>2022</year>;<volume>23</volume>(<issue>1</issue>):bbab451. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1093/bib/bbab451</pub-id><pub-id pub-id-type=\"pmid\">34791012</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref051\"><label>51</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Fatehifar</surname><given-names>M</given-names></name>, <name name-style=\"western\"><surname>Karshenas</surname><given-names>H</given-names></name>. <article-title>Drug-drug interaction extraction using a position and similarity fusion-based attention mechanism</article-title>. <source>J Biomed Inform.</source><year>2021</year>;<volume>115</volume>:<fpage>103707</fpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1016/j.jbi.2021.103707</pub-id><pub-id pub-id-type=\"pmid\">33571676</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref052\"><label>52</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Chen</surname><given-names>J</given-names></name>, <name name-style=\"western\"><surname>Sun</surname><given-names>X</given-names></name>, <name name-style=\"western\"><surname>Jin</surname><given-names>X</given-names></name>, <name name-style=\"western\"><surname>Sutcliffe</surname><given-names>R</given-names></name>. <article-title>Extracting drug-drug interactions from no-blinding texts using key semantic sentences and GHM loss</article-title>. <source>J Biomed Inform.</source><year>2022</year>;<volume>135</volume>:<fpage>104192</fpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1016/j.jbi.2022.104192</pub-id><pub-id pub-id-type=\"pmid\">36064114</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref053\"><label>53</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Deng</surname><given-names>H</given-names></name>, <name name-style=\"western\"><surname>Li</surname><given-names>Q</given-names></name>, <name name-style=\"western\"><surname>Liu</surname><given-names>Y</given-names></name>, <name name-style=\"western\"><surname>Zhu</surname><given-names>J</given-names></name>. <article-title>MTMG: a multi-task model with multi-granularity information for drug-drug interaction extraction</article-title>. <source>Heliyon.</source><year>2023</year>;<volume>9</volume>(<issue>6</issue>):e16819. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1016/j.heliyon.2023.e16819</pub-id><pub-id pub-id-type=\"pmid\">37484258</pub-id><pub-id pub-id-type=\"pmcid\">PMC10360954</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref054\"><label>54</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Zhang</surname><given-names>T</given-names></name>, <name name-style=\"western\"><surname>Yu</surname><given-names>C</given-names></name>, <name name-style=\"western\"><surname>Zhang</surname><given-names>S</given-names></name>. <article-title>CA-SQBG: cross-attention guided Siamese quantum BiGRU for drug-drug interaction extraction</article-title>. <source>Comput Biol Med.</source><year>2025</year>;<volume>186</volume>:<fpage>109655</fpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1016/j.compbiomed.2025.109655</pub-id><pub-id pub-id-type=\"pmid\">39864333</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref055\"><label>55</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Jia</surname><given-names>Y</given-names></name>, <name name-style=\"western\"><surname>Wang</surname><given-names>Z</given-names></name>, <name name-style=\"western\"><surname>Zhang</surname><given-names>H</given-names></name>, <name name-style=\"western\"><surname>Li</surname><given-names>P</given-names></name>, <name name-style=\"western\"><surname>Xie</surname><given-names>P</given-names></name>, <name name-style=\"western\"><surname>Yuan</surname><given-names>Z</given-names></name>. <article-title>Hierarchical feature modeling with data augmentation and focal loss for drug&#8211;drug interaction extraction</article-title>. <source>Biomedical Signal Processing and Control.</source><year>2025</year>;<volume>110</volume>:<fpage>108199</fpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1016/j.bspc.2025.108199</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref056\"><label>56</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Tang</surname><given-names>S</given-names></name>, <name name-style=\"western\"><surname>Zhang</surname><given-names>Q</given-names></name>, <name name-style=\"western\"><surname>Zheng</surname><given-names>T</given-names></name>. <article-title>Two step joint model for drug drug interaction extraction</article-title>. <source>arXiv preprint</source><year>2020</year>. <comment>doi: arXiv:2008.12704</comment></mixed-citation></ref><ref id=\"pcbi.1013722.ref057\"><label>57</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Yang</surname><given-names>J</given-names></name>, <name name-style=\"western\"><surname>Ding</surname><given-names>Y</given-names></name>, <name name-style=\"western\"><surname>Long</surname><given-names>S</given-names></name>, <name name-style=\"western\"><surname>Poon</surname><given-names>J</given-names></name>, <name name-style=\"western\"><surname>Han</surname><given-names>SC</given-names></name>. <article-title>DDI-MuG: multi-aspect graphs for drug-drug interaction extraction</article-title>. <source>Front Digit Health.</source><year>2023</year>;<volume>5</volume>:<fpage>1154133</fpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.3389/fdgth.2023.1154133</pub-id><pub-id pub-id-type=\"pmid\">37168529</pub-id><pub-id pub-id-type=\"pmcid\">PMC10164961</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref058\"><label>58</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>KafiKang</surname><given-names>M</given-names></name>, <name name-style=\"western\"><surname>Hendawi</surname><given-names>A</given-names></name>. <article-title>Drug-drug interaction extraction from biomedical text using relation BioBERT with BLSTM</article-title>. <source>MAKE.</source><year>2023</year>;<volume>5</volume>(<issue>2</issue>):<fpage>669</fpage>&#8211;<lpage>83</lpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.3390/make5020036</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref059\"><label>59</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Hu</surname><given-names>H</given-names></name>, <name name-style=\"western\"><surname>Yang</surname><given-names>A</given-names></name>, <name name-style=\"western\"><surname>Deng</surname><given-names>S</given-names></name>. <article-title>Drug-drug interaction extraction from biomedical text using relation BioBERT with BLSTM</article-title>. <source>Machine Learning and Knowledge Extraction.</source><year>2025</year>;<volume>273</volume>:<fpage>126953</fpage>.</mixed-citation></ref><ref id=\"pcbi.1013722.ref060\"><label>60</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Yang</surname><given-names>Y</given-names></name>, <name name-style=\"western\"><surname>Hu</surname><given-names>L</given-names></name>, <name name-style=\"western\"><surname>Li</surname><given-names>G</given-names></name>, <name name-style=\"western\"><surname>Li</surname><given-names>D</given-names></name>, <name name-style=\"western\"><surname>Hu</surname><given-names>P</given-names></name>, <name name-style=\"western\"><surname>Luo</surname><given-names>X</given-names></name>. <article-title>Link-based attributed graph clustering via approximate generative bayesian learning</article-title>. <source>IEEE Trans Syst Man Cybern, Syst.</source><year>2025</year>;<volume>55</volume>(<issue>8</issue>):<fpage>5730</fpage>&#8211;<lpage>43</lpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1109/tsmc.2025.3572738</pub-id></mixed-citation></ref><ref id=\"pcbi.1013722.ref061\"><label>61</label><mixed-citation publication-type=\"journal\"><name name-style=\"western\"><surname>Su</surname><given-names>X</given-names></name>, <name name-style=\"western\"><surname>Hu</surname><given-names>P</given-names></name>, <name name-style=\"western\"><surname>Li</surname><given-names>D</given-names></name>, <name name-style=\"western\"><surname>Zhao</surname><given-names>B</given-names></name>, <name name-style=\"western\"><surname>Niu</surname><given-names>Z</given-names></name>, <name name-style=\"western\"><surname>Herget</surname><given-names>T</given-names></name>, <etal>et al</etal>. <article-title>Interpretable identification of cancer genes across biological networks via transformer-powered graph representation learning</article-title>. <source>Nat Biomed Eng.</source><year>2025</year>;<volume>9</volume>(<issue>3</issue>):<fpage>371</fpage>&#8211;<lpage>89</lpage>. <comment>doi: </comment><pub-id pub-id-type=\"doi\">10.1038/s41551-024-01312-5</pub-id><pub-id pub-id-type=\"pmid\">39789329</pub-id></mixed-citation></ref></ref-list></back></article></pmc-articleset>",
  "text": "pmc PLoS Comput Biol PLoS Comput Biol 328 ploscomp plos PLOS Computational Biology 1553-734X 1553-7358 PLOS PMC12680327 PMC12680327.1 12680327 12680327 41348931 10.1371/journal.pcbi.1013722 PCOMPBIOL-D-25-01554 1 Research Article Medicine and Health Sciences Pharmacology Drug Interactions Medicine and Health Sciences Pharmacology Drug Research and Development Drug Safety Engineering and Technology Technology Development Prototypes Biology and Life Sciences Neuroscience Cognitive Science Cognitive Psychology Learning Biology and Life Sciences Psychology Cognitive Psychology Learning Social Sciences Psychology Cognitive Psychology Learning Biology and Life Sciences Neuroscience Learning and Memory Learning Medicine and Health Sciences Pharmacology Adverse Reactions Medicine and Health Sciences Epidemiology Medical Risk Factors Medicine and Health Sciences Pharmacology Drug Interactions Drug-Drug Interactions Medicine and Health Sciences Health Care Health Information Technology Clinical Decision Support Systems Computer and Information Sciences Information Technology Health Information Technology Clinical Decision Support Systems A meta-contrastive learning approach for clinical drug-drug interaction extraction from biomedical literature Clinical drug-drug interaction extraction https://orcid.org/0000-0001-5808-4997 Jia Yaxun Conceptualization Methodology Software Validation Writing &#8211; original draft 1 Yuan Zhu Conceptualization Formal analysis Funding acquisition Investigation Software Validation Writing &#8211; review &amp; editing 2 Zhu Lian Conceptualization Software Validation Writing &#8211; review &amp; editing 1 https://orcid.org/0000-0002-5725-842X Xiang Zuo-lin Conceptualization Formal analysis Funding acquisition Investigation Software Validation Writing &#8211; review &amp; editing 1 3 * 1 Department of Radiation Oncology, Shanghai East Hospital, Tongji University School of Medicine, Shanghai, China 2 Department of Information Management, The National Police University for Criminal Justice, Baoding, China 3 Department of Radiation Oncology, Shanghai East Hospital Ji&#8217;an Hospital, Jian, China Jin Qiangguo Editor Northwestern Polytechnical University, CHINA * E-mail: xiangzuolinmd@hotmail.com The authors have declared that no competing interests exist. 5 12 2025 12 2025 21 12 501629 e1013722 5 8 2025 7 11 2025 05 12 2025 06 12 2025 07 12 2025 &#169; 2025 Jia et al 2025 Jia et al https://creativecommons.org/licenses/by/4.0/ This is an open access article distributed under the terms of the Creative Commons Attribution License , which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited. Drug&#8211;drug interactions (DDIs) are a significant source of adverse drug events and pose critical challenges to patient safety and clinical decision-making. Extracting DDIs from biomedical literature plays an essential role in pharmacovigilance, yet remains difficult due to data sparsity and high annotation costs. This study presents BioMCL-DDI, a novel few-shot learning framework that integrates meta-learning with contrastive embedding strategies to enable efficient DDI extraction under limited supervision. BioMCL-DDI jointly optimizes prototype-based classification and supervised contrastive representation learning within a unified architecture. The model captures both intra-class compactness and inter-class separability, enhancing its generalization in sparse biomedical settings. We evaluate BioMCL-DDI on three benchmark datasets: DDI-2013, DrugBank, and the more recent TAC 2018 DDI Extraction corpus. The model achieves F1 scores of 87.80% on DDI-2013, 86.00% on DrugBank, and 74.85%/74.82% on the two official test sets of TAC 2018, consistently outperforming competitive baselines. Our model significantly outperforms state-of-the-art baselines in low-resource scenarios. BioMCL-DDI provides a scalable and effective solution for DDI extraction from biomedical texts, with strong potential for integration into clinical decision support systems and biomedical knowledge bases. All our code and data have been publicly released at: https://github.com/Hero-Legend/BioMCL-DDI . Author summary Drug-drug interactions (DDIs) are a significant source of adverse drug events and pose critical challenges to patient safety. While existing drug databases offer valuable DDI information, they often struggle to keep pace with the rapidly expanding biomedical literature, leaving many new interactions unaddressed. To tackle this challenge, we developed BioMCL-DDI, a lightweight meta-contrastive learning framework designed for efficient DDI extraction from biomedical texts, especially in scenarios with sparse data. Our method integrates prototype-based classification with contrastive embedding strategies, jointly optimizing them within a unified architecture. This allows our model to generalize effectively even with limited annotated data. We evaluated BioMCL-DDI on two benchmark datasets, and our results show that our model significantly outperforms existing techniques in low-resource settings. BioMCL-DDI offers a scalable and effective solution for DDI extraction from biomedical texts, with strong potential for integration into clinical decision support systems and biomedical knowledge bases to enhance medication safety. http://dx.doi.org/10.13039/501100001809 National Natural Science Foundation of China 82160591 https://orcid.org/0000-0002-5725-842X Xiang Zuo-lin Key Project of Clinical Research of Shanghai East Hospital, Tongji University DFLC2022012 https://orcid.org/0000-0002-5725-842X Xiang Zuo-lin Key Specialty Construction Project of Shanghai Pudong New Area Health Commission PWZzk2022-02 https://orcid.org/0000-0002-5725-842X Xiang Zuo-lin Outstanding Leaders Training Program of Pudong Health Bureau of Shanghai PWR12023-02 https://orcid.org/0000-0002-5725-842X Xiang Zuo-lin Shanghai Science Technology Innovation Action Plan 23Y11909000 https://orcid.org/0000-0002-5725-842X Xiang Zuo-lin Science Research Project of Hebei Education Department QN2025011 Yuan Zhu Doctoral Research Start-up Fund Program of The National Police University for Criminal Justice BSQDW202150 Yuan Zhu This work is supported by National Natural Science Foundation of China (82160591 to Zl.X.), Key Project of Clinical Research of Shanghai East Hospital, Tongji University (DFLC2022012 to Zl.X.), Key Specialty Construction Project of Shanghai Pudong New Area Health Commission (PWZzk2022-02 to Zl.X.), Funded by Outstanding Leaders Training Program of Pudong Health Bureau of Shanghai (PWR12023-02 to Zl.X.) and Shanghai Science Technology Innovation Action Plan (23Y11909000 to Zl.X.), Science Research Project of Hebei Education Department (QN2025011 to Z.Y.) and Doctoral Research Start-up Fund Program of The National Police University for Criminal Justice (BSQDW202150 to Z.Y.). Zuo-lin Xiang is the corresponding author of this paper. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript. pmc-status-qastatus 0 pmc-status-live yes pmc-status-embargo no pmc-status-released yes pmc-prop-open-access yes pmc-prop-olf no pmc-prop-manuscript no pmc-prop-legally-suppressed no pmc-prop-has-pdf yes pmc-prop-has-supplement no pmc-prop-pdf-only no pmc-prop-suppress-copyright no pmc-prop-is-real-version no pmc-prop-is-scanned-article no pmc-prop-preprint no pmc-prop-in-epmc yes Data Availability All our code and data have been publicly released at: https://github.com/Hero-Legend/BioMCL-DDI . Data Availability All our code and data have been publicly released at: https://github.com/Hero-Legend/BioMCL-DDI . Introduction Drug&#8211;drug interactions (DDIs) are a critical factor in pharmacovigilance and clinical decision-making, as they can significantly alter the efficacy or safety of co-administered drugs. In clinical settings, especially among elderly patients or those undergoing polypharmacy, unrecognized DDIs can lead to adverse drug reactions (ADRs), increased hospitalization, and even mortality [ 1 &#8211; 3 ]. Thus, accurate and timely identification of potential DDIs is vital for enhancing medication safety and supporting personalized treatment regimens. While structured knowledge bases such as DrugBank offer manually curated DDI records, they are often incomplete or unable to keep pace with the rapid expansion of biomedical literature. This creates a pressing need for automatic DDI extraction systems that can identify emerging interactions from unstructured biomedical texts [ 4 &#8211; 9 ]. Recent advances in deep learning, particularly the introduction of transformer-based models such as BioBERT [ 11 ], have significantly improved the performance of biomedical relation extraction tasks, including DDI classification. However, these models typically require large-scale annotated corpora, which are rarely available in real-world scenarios&#8212;especially when dealing with new drug compounds or infrequent interaction types. Under such low-resource conditions, traditional supervised learning methods often struggle with data sparsity, class imbalance, and limited generalization to unseen relation types. Few-shot learning has emerged as a promising solution to address these challenges. Meta-learning techniques such as Prototypical Networks enable rapid adaptation to new classes using only a few labeled instances, while contrastive learning facilitates more discriminative embedding spaces through pairwise representation alignment. However, existing few-shot approaches often suffer from two practical limitations: (1) meta-learning typically relies on episodic task sampling, which increases training complexity and limits scalability; and (2) contrastive learning is often applied only during pretraining or as an auxiliary loss, thus underutilizing its potential in few-shot supervised settings. To address these issues, we propose BioMCL-DDI, a unified meta-contrastive learning framework for few-shot DDI extraction under sparse supervision. Unlike previous methods that treat meta-learning and contrastive learning as separate objectives, our approach introduces a joint optimization strategy in which prototype-based classification and instance-level contrastive embedding are co-regularized. Moreover, we design a lightweight meta-inspired regularization component that improves intra-class cohesion and inter-class separability without requiring episodic sampling or task-level adaptation. This architecture enhances scalability and robustness in DDI scenarios characterized by noisy class boundaries and highly imbalanced distributions. The model&#8217;s essential output is a classification of drug pairs into one of five predefined categories: DDI-false, DDI-effect, DDI-mechanism, DDI-advise, or DDI-int. Experimental results on the benchmark DDI-2013 dataset demonstrate that BioMCL-DDI achieves a new state-of-the-art F1 score of 87.80%. In addition, cross-domain evaluation on the DDI-DrugBank corpus confirms the generalizability of our model, achieving 86.00% F1 with only 100 labeled samples per class. More importantly, evaluation on the recent TAC 2018 DDI Extraction corpus further validates the robustness of our framework, where BioMCL-DDI attains F1 scores of 74.85% and 74.82% on the two official test sets, surpassing all competitive baselines. These results highlight the strong cross-domain transferability of our approach and its potential applicability to real-world biomedical texts such as structured product labels and regulatory documents. Through extensive ablation and embedding analysis, we further demonstrate that our dual-objective architecture leads to improved semantic clustering and relational discrimination in few-shot biomedical NLP tasks. Our main contributions are summarized as follows: We propose BioMCL-DDI, a meta-contrastive learning framework that unifies prototype-based classification and contrastive embedding learning into a single supervised architecture for few-shot DDI extraction. We introduce a meta-inspired regularization mechanism that eliminates the need for episodic training and enhances representation consistency in the presence of class imbalance and limited supervision. We conduct comprehensive experiments on DDI-2013 and DDI-DrugBank datasets, demonstrating that BioMCL-DDI outperforms recent strong baselines in both in-domain and cross-domain scenarios. We provide ablation and embedding space analyses to investigate how each module contributes to semantic representation quality and fine-grained relation modeling. Related work Drug&#8211;drug interaction (DDI) extraction has long been an important task in biomedical NLP, with research evolving from traditional rule-based systems to advanced deep learning methods. Early approaches utilized convolutional and recurrent architectures to encode sentence-level dependencies. For example, CNN-based models such as DCNN [ 12 ], CNN [ 13 ], SCNN [ 14 ], and MCCNN [ 15 ] exploited syntactic and positional cues to improve feature locality. Meanwhile, LSTM-based methods including ATT-LSTM [ 16 ], DLSTM [ 17 ], and Skeleton-LSTM [ 18 ] focused on long-range contextual modeling and attention-guided extraction. To further capture complex biomedical semantics, hybrid and graph-based architectures were introduced. Joint-ABLSTM [ 19 ], HRNN [ 20 ], and PM-BLSTM [ 21 ] incorporated hierarchical or multi-path structures, while GCNN [ 22 ], GRU-GCN [ 23 ], and SM-GCN [ 24 ] applied graph neural networks for relation-aware inference. The introduction of pretrained language models marked a major breakthrough in DDI extraction. Models such as R-BERT [ 25 ], MEAT-BioBERT [ 26 ], and CDBERT [ 28 ] leveraged contextualized biomedical embeddings to enhance semantic understanding. Recent variants like IMSE [ 29 ], DREAM [ 30 ], and EMSI-BERT [ 31 ] further integrated molecular structures and domain-specific features to push the performance frontier. Beyond text-only representations, a growing body of work has focused on integrating structured biomedical knowledge. DDIKG [ 32 ], DKPL [ 33 ], and BERT-MLRE [ 35 ] introduce drug-related priors through prompts or external graphs. Simultaneously, attention-guided graph architectures such as BBL-GAT [ 7 ], BLRG [ 8 ], and BioFocal-DDI [ 9 ] have demonstrated improved structural sensitivity in capturing relational semantics. LLM-DDI [ 10 ] integrates a large language model (LLM) with a graph neural network (GNN) to predict DDIs on a biomedical knowledge graph (BKG). This approach effectively combines the LLM&#8217;s rich semantic understanding with the GNN&#8217;s ability to model network topology. Despite these advancements, most models still rely on full supervision and struggle in low-resource regimes&#8212;especially with rare or novel drug combinations. To address data scarcity, few-shot learning has been explored for biomedical relation extraction. Meta-learning paradigms, such as Prototypical Networks [ 36 ] and MAML [ 37 ], enable rapid adaptation from limited supervision and have been investigated in domain-specific tasks. However, these methods often rely on episodic training structures or meta-level optimization that complicate integration with standard supervised pipelines. In parallel, contrastive learning has proven effective in biomedical representation learning. MEAT-BioBERT [ 26 ] incorporates instance-level contrastive alignment to enhance embedding quality. MCL-DDI [ 27 ] employs a multi-view contrastive learning framework that integrates molecular structures and network features to enhance DDI event prediction. Despite their promise, most contrastive approaches are either used during pretraining or as auxiliary objectives, with limited application to fully supervised few-shot classification tasks like DDI extraction. While both meta-learning and contrastive learning have independently improved generalization under limited data, their integration remains underexplored in DDI extraction. Table 1 summarizes several representative few-shot or contrastive learning-based approaches most relevant to our work. Existing few-shot methods often separate classification and representation learning, rely on episodic training loops, or fail to adapt to high class imbalance. Furthermore, most contrastive-enhanced methods focus on global representation alignment but overlook class-level semantic structure. In this work, we propose BioMCL-DDI, a meta-contrastive learning framework that addresses these limitations via joint supervised optimization. Our approach unifies prototype-based class modeling and instance-level contrastive regularization in a single objective, without requiring episodic training or auxiliary stages. This enables BioMCL-DDI to learn structurally consistent and discriminative representations under extreme low-resource settings, offering a scalable and clinically meaningful solution for DDI extraction. 10.1371/journal.pcbi.1013722.t001 Table 1 Key related works in few-shot or contrastive DDI extraction. Method Approach Type Few-Shot Capable Contrastive Objective Prototypical Networks [ 36 ] Meta-learning &#10003; &#215; MAML [ 37 ] Meta-learning &#10003; &#215; MEAT-BioBERT [ 26 ] Transformer + Contrastive &#215; &#10003; KSS-DDI [ 52 ] Prompt-based &#10003; &#215; HKG-DDI [ 32 ] Knowledge Graph Enhanced &#215; &#215; BioMCL-DDI (Ours) Meta + Contrastive &#10003; &#10003; Materials and methods This section presents the architecture and training strategy of BioMCL-DDI, a unified meta-contrastive learning framework for few-shot drug&#8211;drug interaction extraction. The proposed model is designed to address two major challenges in clinical NLP systems: data sparsity, where annotated biomedical DDI examples are limited, and class imbalance, where frequent and rare interaction types co-exist in skewed distributions. To overcome these challenges, BioMCL-DDI integrates class-level generalization via prototype learning and instance-level feature discrimination via contrastive learning within a single, fully supervised architecture. This joint optimization eliminates the need for complex episodic sampling routines common in meta-learning while improving scalability and robustness under low-resource biomedical scenarios. As illustrated in Fig 1 , the model consists of three main modules: a domain-specific contextual encoder based on BioBERT, a prototypical classifier that computes class-wise centroids, and a supervised contrastive module that promotes inter-class separability. All modules are trained end-to-end using a joint loss function to produce generalizable and semantically consistent embeddings for DDI classification. 10.1371/journal.pcbi.1013722.g001 Fig 1 Overview of the BioMCL-DDI framework. Sentences are encoded by BioBERT and projected into a shared embedding space. The resulting representations are simultaneously optimized using prototypical loss and contrastive loss. During inference, the model classifies new instances by measuring the distance between their embeddings and the pre-computed class prototypes. Contextual representation via BioBERT To capture domain-specific semantics relevant to drug drug interaction (DDI) classification, BioMCL-DDI employs BioBERT as its contextual encoding backbone. Bio-BERT is a transformer-based language model pretrained on large-scale biomedical corpora such as PubMed abstracts and PMC full texts [ 11 ], enabling it to effectively model complex linguistic patterns and relational cues in biomedical texts. Given an input sentence S that describes a candidate interaction between two drug entities, the sentence is first tokenized using the BioBERT tokenizer. Special tokens [CLS] and [SEP] are inserted to delineate the sentence boundaries, and entity markers are optionally applied to highlight the positions of the interacting drugs. These markers serve to guide the model&#8217;s attention toward the relevant semantic context. The encoded sentence is passed through BioBERT to produce a sequence of contextual embeddings { h 1 , h 2 , &#8230; , h n } . Among these, the hidden state corresponding to the [CLS] token&#8212;denoted as h cls &#8212;is extracted to serve as a condensed global representation of the input. This representation is projected into a task-specific embedding space via a linear transformation: z = Proj ( h cls ) = W p h cls + b p (1) where W p and b p are trainable parameters. The resulting embedding z is subsequently shared across both the prototypical classification and contrastive learning branches, enabling unified representation learning for downstream optimization. Example. For instance, consider the biomedical sentence: &#8220;The coadministration of aspirin and warfarin may increase the risk of bleeding.&#8221; This sentence contains two marked drug entities (aspirin and warfarin). After tokenization and insertion of special tokens, the input fed to BioBERT is represented as: [CLS] The coadministration of aspirin and warfarin may increase the risk of bleeding . [SEP] The corresponding gold label of this example is Effect . This demonstrates how real biomedical text is preprocessed and evaluated by the model, highlighting its applicability to practical DDI extraction scenarios such as clinical notes and drug package inserts. Prototype-based classification for few-shot adaptation To enable robust classification under limited supervision, BioMCL-DDI employs a prototype-based learning strategy that facilitates generalization to novel interaction types using only a few labeled examples. This approach is particularly well-suited to biomedical domains such as pharmacovigilance, where rare or emerging drug&#8211;drug interactions may lack sufficient annotations. In this framework, the prototypical network classifier acts as a metric-based classification head that operates on the shared embedding space. Its architecture is lightweight, consisting of a linear projection layer followed by a distance-based classification mechanism. A class prototype serves as a centroid representation for each interaction type, computed from a support set of known labeled instances. Formally, for each class c , we calculate its prototype vector &#956; c as the mean of the embeddings { z i } corresponding to support instances in class c : &#956; c = 1 | S c | &#8721; i &#8712; S c z i (2) where S c denotes the set of support instances labeled with class c , and z i is the embedding derived from BioBERT followed by linear projection. These prototypes are then used to classify query instances based on their proximity in the embedding space. Given a query embedding z q , its probability of belonging to class c is computed via a softmax function over the negative Euclidean distances to all class prototypes: P ( y = c | z q ) = exp ( &#8722; &#8214; z q &#8722; &#956; c &#8214; 2 ) &#8721; c &#8242; exp ( &#8722; &#8214; z q &#8722; &#956; c &#8242; &#8214; 2 ) (3) The resulting prototypical loss is defined as the average negative log-likelihood across all query examples: L proto = &#8722; &#8721; ( z q , y q ) log P ( y q | z q ) (4) This objective encourages query samples to align closely with their respective class centroids, thereby enhancing intra-class compactness and facilitating accurate classification in few-shot DDI scenarios. Instance-level contrastive supervision To enhance inter-class discrimination and promote a well-structured embedding space, BioMCL-DDI incorporates an instance-level contrastive loss. This objective strengthens the model&#8217;s ability to distinguish fine-grained DDI types by explicitly encouraging semantic proximity between samples of the same class, while increasing separation between different classes. The contrastive learning module is a lightweight architecture that operates on the shared sentence embeddings. Specifically, it consists of an additional linear projection layer (often referred to as a &#8216;projection head&#8217;) that maps the sentence embedding z to a new representation space, where the contrastive loss is computed. This design helps to decouple the representation used for classification from the one used for contrastive learning. The key to our approach is the strategy for constructing contrastive pairs from the output of the BioBERT encoder. Given a mini-batch of instance embeddings { z i } i = 1 | &#8492; | and their corresponding ground-truth labels, we leverage the supervised information to form our pairs. For each anchor instance z i , we define: Positive Pairs: All other instances in the mini-batch that share the same class label as the anchor instance. Negative Pairs: All instances in the mini-batch that have a different class label from the anchor instance. This methodology ensures that the model learns to pull embeddings of the same class closer together while pushing embeddings of different classes apart. We compute the cosine similarity between each pair ( z i , z j ) as follows: sim ( z i , z j ) = z i &#8868; z j &#8214; z i &#8214; &#183; &#8214; z j &#8214; (5) where &#8214; &#183; &#8214; denotes the &#8467; 2 norm. For each anchor instance z i , we define a positive set &#119979; ( i ) containing instances from the same class, and treat the remaining instances as implicit negatives. The contrastive loss is computed using a normalized temperature-scaled softmax over all non-anchor samples in the batch: L contrast = &#8722; &#8721; i &#8712; &#8492; 1 | &#119979; ( i ) | &#8721; j &#8712; &#119979; ( i ) log exp ( sim ( z i , z j ) / &#964; ) &#8721; k &#8800; i exp ( sim ( z i , z k ) / &#964; ) (6) Here, &#964; is a temperature parameter that controls the sharpness of the similarity distribution. A lower &#964; increases sensitivity to similarity differences, thereby enforcing stronger margin separation. By applying this contrastive supervision directly within the classification task (rather than as a separate pretraining stage), the model learns globally consistent embeddings that reflect true semantic boundaries between DDI relation types. This property is particularly beneficial in biomedical settings, where many interaction classes exhibit subtle lexical and contextual variations. Loss function and joint optimization The overall training objective of BioMCL-DDI integrates three complementary components, each addressing a distinct aspect of few-shot DDI extraction: L total = L CE + &#955; 1 L proto + &#955; 2 L contrast (7) Here, L CE denotes the standard cross-entropy loss, which provides supervised feedback based on ground-truth labels. This term ensures accurate prediction in well-represented classes. The prototypical loss L proto encourages query embeddings to cluster around class-specific centroids, thereby supporting generalization under limited supervision. The contrastive loss L contrast promotes inter-class separability by enforcing global consistency in the learned embedding space. The weighting parameters &#955; 1 and &#955; 2 control the influence of the auxiliary losses. In our implementation, we set &#955; 1 = 0.5 and &#955; 2 = 0.1 , based on empirical validation on the DDI-2013 development set. These values consistently yielded optimal performance across settings without extensive hyperparameter tuning, suggesting robustness to variation. Unlike prior approaches that treat meta-learning and contrastive learning as pretraining or auxiliary stages, BioMCL-DDI performs unified joint optimization within a single supervised learning loop. All loss terms are optimized concurrently and share a common encoder and projection backbone. This design enables the model to simultaneously benefit from local structure learning (via class prototypes) and global semantic alignment (via contrastive supervision), resulting in enhanced representation quality, better discrimination of fine-grained relation types, and improved generalization to unseen DDI categories&#8212;key requirements in real-world biomedical information extraction tasks. Algorithm summary. To summarize the training workflow of BioMCL-DDI, Algorithm 1 outlines the full optimization procedure. Each training iteration operates on a mini-batch composed of support and query instances. Sentences are first encoded using BioBERT to produce contextual embeddings. Class prototypes are computed from the support set, and query instances are classified based on their proximity to these prototypes. Simultaneously, a contrastive objective is applied across the entire batch to enforce global feature consistency. The final loss is computed as a weighted combination of all objectives and used to update the shared model parameters. Algorithm 1. BioMCL-DDI training procedure. This end-to-end training loop enables the model to jointly learn class-level generalization, instance-level discrimination, and supervised alignment. Unlike episodic-based meta-learning methods, BioMCL-DDI eliminates the need for explicit task construction, which improves training scalability and stability. Such a unified optimization pipeline is particularly valuable in biomedical relation extraction, where annotation costs are high and class distributions are often skewed. BioMCL-DDI supports fast adaptation to rare or unseen DDI types while maintaining high accuracy under resource constraints. Results In this section, we present a comprehensive evaluation of the proposed BioMCL-DDI framework. We aim to demonstrate its effectiveness in few-shot drug&#8211;drug interaction (DDI) extraction through extensive comparisons with full-supervised and few-shot baselines, as well as detailed analyses including ablation studies, learning behavior, transferability, and error inspection. Our experiments are conducted on the DDI Extraction 2013 benchmark and an external DDI-DrugBank dataset for domain transfer. We also provide a statistical and qualitative assessment of the model&#8217;s robustness, supported by performance curves, case studies, and clinical implications. Experimental setup All experiments were conducted on a high-performance computing server running Ubuntu 18.04, equipped with an Intel Xeon Gold 5218 CPU and four NVIDIA A40 GPUs (48 GB each). The implementation is based on PyTorch 1.12.0 and Python 3.9.19. The BioMCL-DDI model uses BioBERT as the encoder and is configured with a hidden size of 768 and ReLU activation. During training, we set the learning rate to 5e-5, the maximum input length to 300 tokens, a batch size of 16, and a training duration of 30 epochs. All hyperparameters were selected based on preliminary validation and kept fixed across experiments to ensure consistency and reproducibility. Datasets The DDI extraction 2013 dataset. We evaluate our model on the DDI Extraction 2013 dataset [ 38 ], a widely used benchmark for drug&#8211;drug interaction (DDI) extraction. The dataset consists of annotated biomedical sentences, each describing a potential interaction between two drug entities. Each instance is labeled with one of five relation types: DDI-false, DDI-effect, DDI-mechanism, DDI-advise, or DDI-int. As summarized in Table 2 , the corpus is divided into training, validation, and test sets. A prominent challenge in this dataset is its severe class imbalance and data sparsity. For example, the DDI-false category dominates the training set with 23,772 instances, whereas the low-frequency DDI-int class contains only 188 instances. This skewed distribution makes it particularly difficult for conventional deep learning models to accurately identify rare interaction types, which are often of high clinical significance. 10.1371/journal.pcbi.1013722.t002 Table 2 The statistics of DDI Extraction 2013 dataset. DDI Category Train Dev Test Effect 1687 360 360 Mechanism 1319 302 302 Advise 826 221 221 Int 188 96 96 False 23772 4782 4782 Total 27792 7244 5761 To simulate realistic low-resource scenarios, we conduct few-shot experiments by varying the support set size from 1 to 100 labeled instances per class. This setting enables us to evaluate the model&#8217;s ability to generalize from limited supervision and to assess its robustness in practical, data-scarce conditions. TAC 2018 DDI extraction dataset. To further evaluate the cross-domain generalizability of our proposed method, we conducted experiments on the TAC 2018 DDI Extraction dataset [ 39 , 40 ]. The TAC 2018 DDI Extraction dataset originates from the U.S. Food and Drug Administration (FDA) and the National Library of Medicine (NLM) and consists of structured product label (SPL) files for prescription drugs. Each SPL contains several sections, with each section comprising multiple sentences. The dataset contains 325 SPLs in total, with the training set consisting of XML-format files for 22 SPLs and 180 SPLs annotated with slightly different formats. Two test sets are provided, containing 57 and 66 SPLs, respectively. All SPLs were manually annotated by FDA and NLM experts for three types of DDIs: Pharmacokinetic (PK), Pharmacodynamic (PD), and Unspecified (U). In addition to common text data, the source also includes tables and other types of DDI data, which can be used to assess our method&#8217;s performance on diverse data sources. Results and analysis Performance on DDI extraction 2013 dataset. We compare the performance of BioMCL-DDI with a variety of state-of-the-art fully supervised methods on the DDI Extraction 2013 benchmark dataset. These baseline models represent the prevailing approaches in DDI extraction and rely heavily on large-scale annotated corpora for training. Table 3 provides a detailed comparison in terms of precision, recall, and F1 score. 10.1371/journal.pcbi.1013722.t003 Table 3 Performance comparison with all methods on DDI Extraction 2013. Method Year Precision(%) Recall(%) F1 Score(%) AW-BLSTMs [ 41 ] 2019 80.00 77.00 78.50 BERE [ 42 ] 2019 76.80 71.30 73.90 TM-RNN [ 43 ] 2019 74.11 70.82 72.43 RHCNN [ 44 ] 2019 77.30 73.75 75.48 GRU-GCN [ 23 ] 2019 73.60 68.20 70.80 SM-GCN [ 24 ] 2019 77.62 75.69 76.64 R-BERT [ 25 ] 2019 - - 79.08 AGCN [ 46 ] 2020 78.17 75.59 76.86 SGRU-CNN [ 47 ] 2020 76.19 73.34 74.74 Att-BLLC [ 48 ] 2020 - - 72.14 MEAT-BioBERT [ 26 ] 2020 81.00 80.90 80.90 DDMS-CNN [ 45 ] 2021 85.36 82.83 84.08 CDBERT [ 28 ] 2021 85.54 83.56 84.47 PSA-DDI [ 51 ] 2021 - - 78.30 EGFI [ 50 ] 2022 83.40 85.00 84.20 KSS-DDI [ 52 ] 2022 85.49 82.84 84.13 IMSE [ 29 ] 2022 85.63 85.17 85.16 DREAM [ 30 ] 2022 82.30 74.70 78.30 3DGT-DDI [ 49 ] 2023 81.17 88.07 84.48 EMSI-BERT [ 31 ] 2023 - - 82.00 MTMG [ 53 ] 2023 77.20 78.20 77.70 HKG-DDI [ 32 ] 2023 85.32 85.49 85.40 DKPL [ 33 ] 2024 84.25 83.42 83.86 SCNN2 [ 34 ] 2024 77.75 77.13 77.48 BERT-MLRE [ 35 ] 2024 80.32 82.53 81.52 BBL-GAT [ 7 ] 2024 81.76 84.38 82.47 BLRG [ 8 ] 2024 84.54 83.84 84.19 CA-SQBG [ 54 ] 2025 73.80 72.50 73.10 HiFAB-DDI [ 55 ] 2025 85.01 84.50 84.78 BioFocal-DDI [ 9 ] 2025 86.75 86.53 86.64 BioMCL-DDI(Ours) - 88.12 87.49 87.80 As shown in the table, BioMCL-DDI achieves the best overall performance, with a precision of 88.12%, a recall of 87.49%, and an F1 score of 87.80%. This clearly outperforms the previous best-performing method, BioFocal-DDI, which attained an F1 score of 86.64%. The improvements are consistent across all metrics, highlighting the robustness and effectiveness of our approach. Compared to established models such as R-BERT, MEAT-BioBERT, and 3DGT-DDI, BioMCL-DDI demonstrates significant performance gains. While many recent methods integrate domain-specific pretraining, external drug knowledge, or graph-based reasoning modules, they still fall short of the performance achieved by our model. This suggests that the meta-contrastive learning strategy adopted in BioMCL-DDI introduces substantial improvements that cannot be matched by additional external resources alone. The marked performance gains can be attributed to several key design choices. First, by combining a prototype-based classification objective with contrastive learning, BioMCL-DDI encourages both intra-class cohesion and inter-class separation in the embedding space, which proves crucial in the few-shot setting. Second, unlike traditional supervised models that require dense annotation, our framework is optimized to learn from sparse, class-limited samples and generalize effectively to new interaction types. The use of prototypical networks helps align drug pair embeddings with class-specific centroids, while the contrastive component further refines the embedding space to be more discriminative. The confusion matrix in Fig 2 illustrates the model&#8217;s classification behavior on the DDI 2013 test set. BioMCL-DDI performs well across all interaction types, particularly in recognizing the dominant DDI-false class while maintaining balanced predictions on low-frequency classes such as DDI-int. Although some confusion arises between semantically similar types like DDI-mechanism and DDI-advise, the model exhibits strong overall class separability and stable generalization. 10.1371/journal.pcbi.1013722.g002 Fig 2 Confusion matrix of BioMCL-DDI on the DDI 2013. In addition, Fig 3 shows the ROC curves for individual interaction categories. All classes achieve high AUC scores, with DDI-advise reaching 0.98 and even the most challenging class, DDI-int, reaching 0.90. These results highlight the model&#8217;s ability to maintain high sensitivity and specificity across all categories, including underrepresented ones. The consistently high AUC values further validate the model&#8217;s suitability for real-world clinical scenarios, where minimizing both false positives and false negatives is critical. 10.1371/journal.pcbi.1013722.g003 Fig 3 Receiver Operating Characteristic (ROC) curves for each DDI category. Overall, BioMCL-DDI sets a new benchmark in DDI extraction, combining superior performance with robustness in few-shot conditions. Its ability to achieve top-tier results without requiring extensive annotation makes it especially attractive for low-resource biomedical NLP applications. Performance comparison under few-shot settings. To further assess the effectiveness of BioMCL-DDI in low-resource settings, we compare it against several representative few-shot learning baselines, including KSS-DDI, MTMG, and HKG-DCL. These models integrate contrastive learning, multi-task mechanisms, or domain-specific adaptations to tackle the few-shot DDI extraction task. As presented in Table 4 , BioMCL-DDI achieves the highest overall performance among few-shot learning methods, with a precision of 87.20%, a recall of 86.30%, and an F1 score of 86.75%. This result outperforms the next-best approach, HKG-DCL, by more than 1 percentage point in F1 score. 10.1371/journal.pcbi.1013722.t004 Table 4 Performance comparison with few-shot learning methods on DDI Extraction 2013. Method Precision(%) Recall(%) F1 Score(%) KSS-DDI 85.46 82.84 84.13 MTMG 77.20 78.20 78.10 HKG-DCL 85.35 85.49 85.40 BioMCL-DDI 87.20 86.30 86.75 These results highlight the superior generalization capacity of our meta-contrastive framework under data-scarce conditions. The ability to align class-level structures via prototypical learning, combined with the fine-grained discriminability encouraged by contrastive loss, equips BioMCL-DDI with a robust inductive bias for few-shot classification. This makes it particularly suitable for real-world biomedical applications, where annotated data is often limited or costly to obtain. Performance stability and statistical significance. To assess the consistency of model performance under repeated training conditions, we conduct five independent runs for both the baseline model (using only cross-entropy loss) and the proposed BioMCL-DDI framework. As shown in Fig 4 , BioMCL-DDI consistently yields higher accuracy with lower variance. The model achieves a mean accuracy of 88.2% with a standard deviation of 0.48%, while the baseline records a lower mean of 87.0% and a larger deviation of 0.60%. The narrower interquartile range of BioMCL-DDI reflects better robustness and lower sensitivity to initialization or sampling noise. 10.1371/journal.pcbi.1013722.g004 Fig 4 Accuracy distribution comparison between Baseline and BioMCL-DDI. Fig 5 presents the average accuracy across runs with standard deviation error bars. The clear separation between the error bars further indicates that BioMCL-DDI not only achieves superior average performance but also exhibits more stable training dynamics. A paired t-test yields a p-value less than 0.01, confirming that the performance improvements are statistically significant rather than due to random fluctuations. 10.1371/journal.pcbi.1013722.g005 Fig 5 Mean accuracy and variance comparison with statistical significance. These results demonstrate that BioMCL-DDI maintains stable and reliable behavior across training runs, which is particularly important for practical deployment in low-resource biomedical settings. Embedding space visualization. To visually validate the effectiveness of our meta-contrastive learning approach, we provide a t -SNE visualization of the embedding space. t -SNE is a dimensionality reduction technique that maps high-dimensional data points to a two-dimensional space, preserving the local structure of the data. The resulting dimensions do not carry any specific semantic meaning; they are solely used for visualizing the clustering and separation patterns of the data. We compare the embedding space learned by a simple BioBERT baseline and our full BioMCL-DDI model. As shown in Fig 6 (a), the embedding space of the baseline model shows that different DDI categories are poorly separated and highly overlapping, with multiple classes intermingling in a single region. This confirms that conventional supervised learning struggles to learn a discriminative representation space under few-shot conditions. In contrast, our full BioMCL-DDI model&#8217;s embedding space, as visualized in Fig 6 (b), displays a significant improvement. The embeddings form tight, well-separated clusters, which visually confirms that our prototypical learning enhances intra-class compactness, while the contrastive loss promotes inter-class separability. Notably, while the clusters for Effect and Mechanism show some proximity, which is expected given their semantic similarity, the overall separation is robust. This demonstrates that our framework successfully learns a more structured and discriminative representation, validating the core mechanisms of our model design. 10.1371/journal.pcbi.1013722.g006 Fig 6 A visual comparison of the embedding space learned by (a) BioBERT baseline and (b) BioMCL-DDI model. Scalability with varying support set sizes. To evaluate the scalability and robustness of BioMCL-DDI under few-shot settings, we perform experiments across a range of support set sizes: 1, 2, 4, 6, 8, 10, 15, 20, 30, 40, 50, 60, 80, and 100 samples per class. The resulting F1 performance curve is shown in Fig 7 . 10.1371/journal.pcbi.1013722.g007 Fig 7 F1 score of BioMCL-DDI across different support set sizes (1&#8211;100 samples per class) on the DDI 2013 dataset. We observe a notable improvement in performance as the support size increases from 1 to 10. In the 1-shot setting, BioMCL-DDI achieves an F1 score of 48.0%. This steadily improves to around 70.0% at 5-shot and reaches 74.0% at 10-shot, demonstrating the model&#8217;s ability to generalize from limited supervision. As the number of labeled instances increases further, performance gradually saturates, reaching 86.0% at 100-shot&#8212;approaching the full-supervised level of 87.8%. These results highlight the effectiveness of the proposed meta-contrastive learning strategy in enabling robust representation learning, even under low-resource conditions. Evaluating cross-domain adaptation on DDI-DrugBank. To further assess the cross-domain generalization capability of BioMCL-DDI, we perform few-shot transfer learning experiments using the DDI-DrugBank dataset. This setting mimics real-world low-resource deployment scenarios, where labeled data in the target domain is scarce or unavailable. As illustrated in Fig 8 , the model shows a consistent improvement in performance with increasing support size. Starting with an F1 score of 56.5% using only 5 labeled examples per class, BioMCL-DDI surpasses 74.0% at the 20-shot level and ultimately achieves 86.0% at 100-shot. These results demonstrate the model&#8217;s ability to efficiently adapt to new domains with minimal supervision. 10.1371/journal.pcbi.1013722.g008 Fig 8 Few-shot transfer performance of BioMCL-DDI on the DDI-DrugBank dataset. This experiment also serves to test robustness under domain shift. Compared to the DDI-2013 dataset, DDI-DrugBank exhibits distinct linguistic patterns and annotation conventions. Despite these differences, BioMCL-DDI maintains strong performance, indicating that it is not merely overfitting to the training distribution but is capable of learning transferable biomedical interaction patterns. Such cross-domain adaptability is particularly valuable in clinical NLP, where the diversity of medical corpora often poses generalization challenges. We attribute this effective transfer performance to the dual objectives integrated during training. The prototypical loss aligns representations with class-wise centroids, fostering few-shot adaptability, while the contrastive loss enforces semantic separability across interaction types, leading to more robust embeddings. Together, these components allow BioMCL-DDI to retain discriminative power even when facing unfamiliar domains. Performance on TAC 2018 DDI extraction dataset To demonstrate the cross-domain generalizability of our proposed framework, we conducted a comprehensive evaluation on the TAC 2018 DDI Extraction corpus. This external dataset, comprising structured product labels (SPL) from the U.S. Food and Drug Administration (FDA) and the National Library of Medicine (NLM), represents a distinct domain with different linguistic patterns and document structures compared to the DDI-2013 benchmark. As reported in Tables 5 and 6 , BioMCL-DDI achieves state-of-the-art performance across both official test sets of TAC 2018, with F1 scores of 74.85% and 74.82%, respectively. These results surpass all competitive baselines, including recent strong models such as DDI-MuG and COTEL-D3X. The strong performance on TAC 2018 is particularly significant because it validates the robustness of our meta-contrastive learning approach under substantial domain shift. More importantly, it demonstrates that BioMCL-DDI is not limited to legacy benchmarks, but can effectively generalize to more recent and practically relevant biomedical corpora. This provides strong evidence for the applicability of our framework in real-world scenarios, where biomedical texts are continuously evolving and domain adaptation is crucial. 10.1371/journal.pcbi.1013722.t005 Table 5 Performance comparison on TAC 2018 DDI extraction test set 1. Method Precision (%) Recall (%) F1-Score (%) KLncLSTMsentClf [ 56 ] 47.00 62.00 53.00 DDI-MuG [ 57 ] 72.10 72.80 72.30 R-BioBERT [ 58 ] with BLSTM - - 64.00 COTEL-D3X [ 59 ] 67.28 73.83 70.40 BioMCL-DDI (Ours) 74.50 75.20 74.85 10.1371/journal.pcbi.1013722.t006 Table 6 Performance comparison on TAC 2018 DDI extraction test set 2. Method Precision (%) Recall (%) F1-Score (%) KLncLSTMsentClf 49.00 67.00 56.70 DDI-MUG 71.70 74.30 72.90 R-BioBERT with BLSTM - - 58.80 COTEL-D3X 74.93 71.39 73.12 BioMCL-DDI (Ours) 75.15 74.50 74.82 Component contribution analysis via ablation study To better understand the role of each core component in BioMCL-DDI, we conduct an ablation study by selectively removing key modules and comparing performance against the full model. The following variants are evaluated: (1) w/o Prototypical Loss : The prototype-based alignment objective is removed, while contrastive and cross-entropy losses remain. w/o Contrastive Loss : The instance-level contrastive learning component is excluded, retaining the prototypical and classification losses. (3) w/o Both : Only the standard classification loss is used, removing both auxiliary losses. (4) Full Model : All components enabled&#8212;prototypical loss, contrastive loss, and classification loss. The quantitative results are presented in Table 7 . Removing either auxiliary loss results in a noticeable drop in performance. Specifically, without the prototypical loss, the F1 score falls to 86.30%; without the contrastive loss, it drops to 85.65%. When both components are removed, the F1 plummets further to 84.00%. In contrast, the full BioMCL-DDI achieves an F1 score of 87.80%, underscoring the critical contributions of both objectives. 10.1371/journal.pcbi.1013722.t007 Table 7 Ablation study results. Variant Precision(%) Recall(%) F1 Score(%) w/o Prototypical Loss 86.50 86.10 86.30 w/o Contrastive Loss 85.80 85.50 85.65 w/o Proto &amp; Contrastive 84.20 83.80 84.00 Full Model (Ours) 88.12 87.49 87.80 These findings validate the synergistic design of BioMCL-DDI. The prototypical loss provides strong supervision for few-shot generalization by structuring the embedding space around class centroids. Meanwhile, the contrastive loss ensures robust inter-class separation, especially under limited supervision. Together, these losses complement each other: the former guides semantic alignment, while the latter sharpens boundary discrimination. Their combination enables BioMCL-DDI to learn more generalized and transferable representations for drug interaction classification. Efficiency and computational complexity To assess the practical viability of BioMCL-DDI in resource-constrained clinical environments, we provide a detailed analysis of its computational efficiency. The framework&#8217;s overall efficiency is primarily determined by its three main components: the BioBERT encoder, the prototypical classifier, and the supervised contrastive module. Theoretically, the computational bottleneck lies with the BioBERT encoder, whose complexity scales quadratically with respect to the input sequence length. Our lightweight few-shot adaptation modules, however, are designed for efficiency. The prototypical classifier has a near-linear complexity, as it requires computing a limited number of class prototypes and calculating distances to them. The contrastive learning module&#8217;s complexity scales quadratically with the mini-batch size, but this remains computationally efficient given the small batch sizes typically employed in few-shot learning. To empirically validate the model&#8217;s efficiency, we compared its performance against several representative baselines on the DDI-2013 test set using a single NVIDIA A40 GPU. As shown in the Table 8 , BioMCL-DDI demonstrates a favorable balance between performance and efficiency. The model&#8217;s training time per epoch is competitive with other advanced methods, while its inference speed of 21.1 ms per sample is notably faster than several baselines, which is a critical factor for real-time clinical decision support systems. 10.1371/journal.pcbi.1013722.t008 Table 8 Efficiency comparison of BioMCL-DDI and baseline models. Method Training Time (min/epoch) Inference Speed (ms/sample) R-BERT [ 25 ] 15.2 23.5 BioFocal-DDI [ 9 ] 18.9 28.1 3DGT-DDI [ 49 ] 22.4 31.2 BioMCL-DDI (Ours) 16.8 21.1 This analysis confirms that BioMCL-DDI&#8217;s design prioritizes a strong balance between state-of-the-art performance and computational efficiency, making it a scalable and practical solution for DDI extraction in real-world applications. Hyperparameter analysis To gain deeper insight into the optimization behavior of BioMCL-DDI, we monitor the evolution of training accuracy, loss, and F1 score throughout the learning process. The results are visualized in Fig 9 . 10.1371/journal.pcbi.1013722.g009 Fig 9 Training accuracy, loss, and F1 Score under different epochs. As shown, the training loss follows a smooth and consistent downward trajectory over epochs, indicating stable convergence. The curve begins to plateau around the 10th epoch, suggesting that the model quickly captures key discriminative patterns and reaches a near-optimal state early in training. The accuracy curve exhibits a steady rise, eventually stabilizing above 86%. This high and sustained accuracy aligns with the model&#8217;s strong final evaluation results, reinforcing the reliability of its performance even under few-shot constraints. Notably, the model avoids overfitting despite the low-resource setting, reflecting effective generalization from limited data. In parallel, the F1 score&#8212;reflecting the harmonic balance of precision and recall&#8212;shows a similarly smooth ascent. Its rapid convergence and stability indicate that the model performs consistently well across DDI categories, without favoring high-frequency interaction types. This is particularly important in imbalanced biomedical datasets, where overfitting to dominant classes is common. To further assess the sensitivity of BioMCL-DDI to key hyperparameters, we conduct an ablation study by varying the weights of the prototype loss ( &#955; 1 ) and the contrastive loss ( &#955; 2 ). Fig 10 (a) and 10 (b) present the model&#8217;s F1 score under different settings of &#955; 1 and &#955; 2 , respectively. 10.1371/journal.pcbi.1013722.g010 Fig 10 F1 score of BioMCL-DDI under varying hyperparameters. As illustrated in Fig 10 (a), increasing &#955; 1 from 0.0 to 1.0 steadily improves performance. The F1 score rises from 85.2% at &#955; 1 = 0.0 to 87.8% at &#955; 1 = 1.0 , with the most notable gains occurring between 0.0 and 0.5. Beyond &#955; 1 = 0.5 , the improvements begin to plateau, suggesting diminishing returns from further emphasizing intra-class prototype alignment. Similarly, in Fig 10 (b), raising &#955; 2 from 0.0 to 0.3 leads to consistent gains, with F1 increasing from 85.0% to 87.6%. The largest improvements are observed around &#955; 2 = 0.1 &#8211;0.2, while values above 0.3 provide limited additional benefit. These findings confirm that moderate contrastive regularization enhances inter-class separation, but excessive weight may reduce generalizability. Throughout all experiments, we adopt &#955; 1 = 0.5 and &#955; 2 = 0.1 as default settings. This configuration offers a strong trade-off between performance and stability. Although slightly higher F1 scores are attainable with more aggressive tuning, the observed gains are marginal (less than 0.5%), and the selected values generalize well across tasks and domains. These results indicate that BioMCL-DDI is robust to hyperparameter variations, which is important for practical deployment in biomedical scenarios. &#239;\"&#191; Error analysis and case interpretations To gain a more nuanced understanding of BioMCL-DDI&#8217;s behavior in real-world biomedical text, we conducted a systematic qualitative case study on a comprehensive set of ten instances from the DDI Extraction 2013 dataset. The analysis aims to investigate the model&#8217;s strengths, limitations, and decision-making process, as summarized in Table 9 . We further utilized attention heatmaps from the BioBERT encoder to provide critical insights into the model&#8217;s reasoning. 10.1371/journal.pcbi.1013722.t009 Table 9 Case study on BioMCL-DDI predictions. Case Input Sentence (Annotated) True Label Predicted Label Correct Remarks 1 Ketoconazole can increase the blood levels of Simvastatin by inhibiting CYP3A4. Mechanism Mechanism &#10003; Correct prediction with explicit enzyme inhibition. 2 Rifampin reduces the effectiveness of Atazanavir . Effect Effect &#10003; Accurately captures semantic implication of reduced efficacy. 3 No interaction was observed between Aspirin and Metformin . False False &#10003; True negative. Model correctly handles non-interaction cases. 4 Co-administration of Clarithromycin and Warfarin may increase bleeding risk. Advise Advise &#10003; Correctly associates co-administration with risk. 5 Fluoxetine interacts with Tramadol causing seizure risk. Effect Mechanism &#215; Misclassified due to subtle semantic overlap between effect and mechanism. 6 The dose of drug X may be adjusted when combined with drug Y . Advise False &#215; False negative. Model fails to identify the advisory cue for dose adjustment. 7 The coadministration of aspirin and warfarin may increase the risk of bleeding. Effect Effect &#10003; Correctly identifies the adverse effect. 8 Carbamazepine and valproic acid combination therapy. False Effect &#215; False positive. Model confused by co-occurrence without explicit interaction cues. 9 This study found an increased risk of severe adverse effects when drug A and drug B were used. Effect Advise &#215; Subtle misclassification. Model interprets \"increased risk\" as an advisory warning rather than a direct effect. 10 Drug Z can cause hepatotoxicity, which is a common effect. False Effect &#215; False positive. Model is misled by the mention of a general side effect. Our analysis of the ten cases in Table 9 reveals both the proficiency and the limitations of the BioMCL-DDI framework. The successful predictions (Cases 1-4, 7) demonstrate the model&#8217;s ability to effectively learn and leverage key contextual and relational cues. For instance, in Case 1 (a &#8216;Mechanism&#8217; prediction), the attention heatmap in Fig 11 (a) shows that the model correctly focuses its highest attention weights on the drug entity &#8216;Ketoconazole&#8217; and the crucial mechanistic term &#8216;CYP3A4&#8217;, which is directly responsible for the interaction. This visualization empirically validates that the model has learned to associate specific biomedical terminology with the corresponding DDI type. 10.1371/journal.pcbi.1013722.g011 Fig 11 Attention heatmaps for selected cases. Conversely, the misclassified examples (Cases 5, 6, 8, 9, 10) highlight the remaining challenges in fine-grained DDI extraction. These errors can be attributed to several root causes: Semantic Overlap and Ambiguity: In case 5, the true label is &#8216;Effect&#8217;, but the model incorrectly predicts &#8216;Mechanism&#8217;. The attention heatmap for this instance ( Fig 11 (b)) reveals that the model&#8217;s attention is distributed across the general interaction term &#8216;interacts&#8217; and the outcome &#8216;seizure risk&#8217;. While the interaction term &#8216;interacts&#8217; is often associated with the &#8216;Mechanism&#8217; class, the phrase &#8216;seizure risk&#8217; points to a direct clinical outcome, which is characteristic of the &#8216;Effect&#8217; class. The model&#8217;s misclassification suggests a subtle imbalance in its attention weights, leading to confusion between these semantically similar DDI subtypes. Misleading Medical Terminology: This is a classic false positive error, where the model incorrectly predicts a DDI despite the sentence stating a single drug&#8217;s side effect. As shown in the attention heatmap in Fig 11 (c), the model assigns high attention to the medical term &#8216;hepatotoxicity&#8217; and the general outcome term &#8216;effect&#8217;. This indicates that the model is misled by the presence of strong medical terminology, over-associating it with a DDI when in fact, no interaction between two drugs is mentioned. Lack of Explicit Cues (Cases 6, 8, 9): In these instances, the model fails to capture implicit or subtle cues. For example, in Case 6, the model misclassifies a &#8216;False&#8217; interaction as &#8216;Effect&#8217; because of the co-occurrence of two drugs without any explicit interaction verbs. Similarly, in Case 9, the model misses the subtle &#8216;Advise&#8217; cue in \"may be adjusted,\" leading to a &#8216;False&#8217; negative. The above analysis indicates that while BioMCL-DDI is proficient in learning from key contextual cues, it can be susceptible to fine-grained semantic ambiguities. The analysis of incorrect predictions also reveals instances where the model may be influenced by strong medical terminology in contexts where no drug-drug interaction is present. Discussion This study presents BioMCL-DDI, a unified few-shot learning framework for drug&#8211;drug interaction (DDI) extraction that integrates prototypical classification and contrastive representation learning. Our empirical results demonstrate that the proposed model achieves strong performance under low-resource conditions, outperforming existing fully supervised and meta-learning baselines on both in-domain and cross-domain settings. A key factor contributing to this performance is the synergy between prototype-based alignment and instance-level contrastive separation. While prototypical networks capture class-level semantics that are essential in few-shot learning, the additional contrastive regularization promotes better global structuring of the embedding space. This leads to improved generalization, particularly in cases involving semantically overlapping or underrepresented DDI types. Our ablation study confirms that removing either component results in a notable drop in F1 score, highlighting their complementary effects. Compared to existing methods such as Meta-DDI and BERT-Proto, BioMCL-DDI exhibits improved adaptability without requiring episodic task construction or pretraining stages. This not only simplifies training but also facilitates scalability in real-world clinical pipelines. Moreover, the model maintains high performance across different DDI classes despite significant class imbalance&#8212;an important trait for pharmacovigilance systems that often deal with rare but clinically critical interactions. Nonetheless, several limitations warrant further investigation. First, although the model is designed for few-shot scenarios, it still requires a minimum number of labeled examples per class to form reliable prototypes. Extremely low-resource settings may lead to unstable performance. Second, the reliance on sentence-level inputs may limit the model&#8217;s ability to incorporate external domain knowledge or multi-sentence context, which could be addressed by integrating knowledge graph signals or contextual document modeling. Third, while our experiments focus on English biomedical corpora, the model&#8217;s cross-lingual generalizability remains to be explored. While the overall performance reported in Tables 3 and 4 indicates that the proposed model sets a new state-of-the-art benchmark, it is important to acknowledge certain challenges. As our error analysis revealed, the model still faces difficulty in distinguishing between semantically similar DDI classes, such as &#8216;DDI-mechanism&#8217; and &#8216;DDI-advise,&#8217; which can lead to misclassifications. This semantic ambiguity, coupled with the inherent class imbalance of the DDI-2013 dataset, presents a bottleneck for further performance gains. Nevertheless, our framework consistently outperforms all baselines under few-shot conditions, demonstrating its effectiveness in a critical, low-resource setting where traditional models often fail. This validates our core hypothesis that meta-contrastive learning provides a more robust inductive bias for biomedical relation extraction than conventional approaches. In future work, we plan to enhance the interpretability of BioMCL-DDI by incorporating attention-based visualization techniques and exploring its deployment within interactive CDSS platforms. Moreover, extending the framework to handle multi-label or nested DDI scenarios could further increase its applicability in complex clinical narratives. Clinical implications BioMCL-DDI framework addresses a critical limitation in contemporary pharmacovigilance systems&#8212;the scarcity of labeled data for novel or rarely co-administered drugs . By leveraging few-shot learning, the model enables effective extraction of drug&#8211;drug interactions (DDIs) even in low-resource scenarios, providing timely support for safer prescribing decisions when traditional DDI databases are incomplete or outdated. From a clinical informatics perspective, the generalizability of BioMCL-DDI makes it well-suited for integration into clinical decision support systems (CDSS). Its capacity to issue early warnings about potential adverse drug events is particularly valuable in high-risk contexts such as polypharmacy, off-label use, and personalized treatment regimens involving emerging therapeutics . This capability can assist clinicians in proactively identifying and mitigating risks before they lead to adverse drug reactions, increased hospitalization, or mortality. In addition, the model&#8217;s lightweight architecture and data efficiency facilitate its deployment in real-world pharmacovigilance workflows across healthcare institutions, pharmaceutical manufacturers, and regulatory agencies such as the FDA and EMA. By enabling automated, scalable pre-screening of potential interactions, BioMCL-DDI has the potential to accelerate safety evaluations, reduce adverse event latency, and improve overall responsiveness in clinical drug safety infrastructures. Despite its potential, we acknowledge that the model faces certain limitations in clinical deployment. The model, while accurate on a technical level, may require further enhancements in interpretability to gain the trust of clinicians. Its predictions, especially for rare or novel interactions, must be presented in a transparent manner, supported by evidence from the text. Furthermore, the model&#8217;s reliance solely on textual data means it may not capture DDI information available in other modalities, such as molecular structures or patient-specific genomic data. Addressing these limitations in future work is crucial for fully realizing the framework&#8217;s value in personalized and precision medicine. Ultimately, this framework can serve as a foundational component in next-generation biomedical text mining pipelines, complementing structured databases and enhancing the situational awareness of clinicians and drug safety professionals alike. Conclusion This paper introduced BioMCL-DDI, a unified meta-contrastive learning framework for few-shot drug&#8211;drug interaction (DDI) extraction. It performs a fine-grained, multi-class classification of drug pairs into five distinct DDI types: DDI-false, DDI-effect, DDI-mechanism, DDI-advise, and DDI-int. By jointly optimizing prototypical classification and instance-level contrastive learning within a fully supervised setting, BioMCL-DDI achieves robust performance under data-scarce conditions without relying on episodic task construction or pretraining. Our extensive evaluations on DDI-2013 and DDI-DrugBank benchmarks demonstrate consistent improvements over state-of-the-art baselines, with strong generalization across domains and DDI subtypes. More importantly, evaluation on the recent TAC 2018 DDI Extraction dataset confirms that BioMCL-DDI maintains state-of-the-art performance under substantial domain shift. This robustness highlights the model&#8217;s applicability to real-world biomedical texts such as structured product labels and regulatory documents, which are central to pharmacovigilance practice. The proposed framework not only enhances class-level alignment and inter-class discrimination but also offers training scalability and architectural simplicity&#8212;key traits for integration into real-world pharmacovigilance pipelines. Moreover, BioMCL-DDI remains effective despite severe class imbalance, highlighting its applicability to rare but clinically significant interactions. In future work, we aim to improve the interpretability and adaptability of BioMCL-DDI by integrating external biomedical knowledge, exploring zero-shot or continual learning settings, and extending support for multi-label or nested DDI relations. Another promising direction is to incorporate advanced graph neural networks (GNNs) for DDI prediction. Recent studies have demonstrated the effectiveness of GNNs in modeling complex biomedical relationships such as molecular interaction networks and drug&#8211;target associations [ 60 , 61 ]. By combining BioMCL-DDI&#8217;s sentence-level contextual embeddings with graph-based relational representations, future extensions could capture higher-order dependencies among drugs, targets, and interactions, thereby improving robustness and generalizability across heterogeneous biomedical corpora. Ultimately, we envision this framework contributing to the development of scalable, data-efficient, and clinically deployable decision support tools for personalized drug safety assessment. References 1 Hughes JE , Moriarty F , Bennett KE , Cahir C . Drug-drug interactions and the risk of adverse drug reaction-related hospital admissions in the older population . Br J Clin Pharmacol. 2024 ; 90 ( 4 ): 959 &#8211; 75 . doi: 10.1111/bcp.15970 37984336 2 Klopotowska JE , Leopold JH , Bakker T . Adverse drug events caused by three high-risk drug&#8211;drug interactions in patients admitted to intensive care units: A multicentre retrospective observational study . British Journal of Clinical Pharmacology. 2024 ; 90 ( 1 ): 164 &#8211; 75 . 37567767 10.1111/bcp.15882 3 Laroche M-L , Tarbouriech N , Jai T , Valnet-Rabier M-B , Nerich V . Economic burden of hospital admissions for adverse drug reactions in France: the IATROSTAT-ECO study . Br J Clin Pharmacol. 2025 ; 91 ( 2 ): 439 &#8211; 50 . doi: 10.1111/bcp.16266 39363642 PMC11773093 4 Machado J , Rodrigues C , Sousa R , Gomes LM . Drug&#8211;drug interaction extraction-based system: an natural language processing approach . Expert Systems. 2023 ; 42 ( 1 ). doi: 10.1111/exsy.13303 5 Dou M , Tang J , Tiwari P , Ding Y , Guo F . Drug&#8211;drug interaction relation extraction based on deep learning: a review . ACM Comput Surv. 2024 ; 56 ( 6 ): 1 &#8211; 33 . doi: 10.1145/3645089 6 Jia Y , Yuan Z , Wang H , Gong Y , Yang H , Xiang Z-L . BBL-GAT: a novel method for drug-drug interaction extraction from biomedical literature . IEEE Access. 2024 ; 12 : 134167 &#8211; 84 . doi: 10.1109/access.2024.3462101 7 Jia Y , Wang H , Yuan Z . Biomedical relation extraction method based on ensemble learning and attention mechanism . BMC Bioinformatics. 2024 ; 25 ( 1 ): 333 . 39425010 10.1186/s12859-024-05951-y PMC11488084 8 Jia Y , Yuan Z , Wang H , Gong Y , Yang H , Xiang Z . Variations towards an efficient drug&#8211;drug interaction . The Computer Journal. 2024 ; 68 ( 5 ): 552 &#8211; 64 . doi: 10.1093/comjnl/bxae131 9 Yuan Z , Zhang S , Zhang H , Xie P , Jia Y . Optimized drug-drug interaction extraction with BioGPT and focal loss-based attention . IEEE J Biomed Health Inform. 2025 ; 29 ( 6 ): 4560 &#8211; 70 . doi: 10.1109/JBHI.2025.3540861 40031603 10 Li D , Yang Y , Cui Z , Yin H , Hu P , Hu L . LLM-DDI: leveraging large language models for drug-drug interaction prediction on biomedical knowledge graph . IEEE J Biomed Health Inform. 2025 ;PP:10.1109/JBHI.2025.3585290. doi: 10.1109/JBHI.2025.3585290 40601466 11 Lee J , Yoon W , Kim S , Kim D , Kim S , So CH , et al . BioBERT: a pre-trained biomedical language representation model for biomedical text mining . Bioinformatics. 2020 ; 36 ( 4 ): 1234 &#8211; 40 . doi: 10.1093/bioinformatics/btz682 31501885 PMC7703786 12 Liu S, Kai Chen, Chen Q, Tang B. Dependency-based convolutional neural network for drug-drug interaction extraction. In: 2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM), 2016. p. 1074&#8211;80. 10.1109/bibm.2016.7822671 13 Liu S , Tang B , Chen Q , Wang X . Drug-drug interaction extraction via convolutional neural networks . Comput Math Methods Med. 2016 ; 2016 : 6918381 . doi: 10.1155/2016/6918381 26941831 PMC4752975 14 Zhao Z , Yang Z , Luo L , Lin H , Wang J . Drug drug interaction extraction from biomedical literature using syntax convolutional neural network . Bioinformatics. 2016 ; 32 ( 22 ): 3444 &#8211; 53 . doi: 10.1093/bioinformatics/btw486 27466626 PMC5181565 15 Quan C , Hua L , Sun X , Bai W . Multichannel convolutional neural network for biological relation extraction . Biomed Res Int. 2016 ; 2016 : 1850404 . doi: 10.1155/2016/1850404 28053977 PMC5174749 16 Zheng W , Lin H , Luo L . An attention-based effective neural model for drug-drug interactions extraction . BMC Bioinformatics. 2017 ; 18 : 1 &#8211; 11 . 29017459 10.1186/s12859-017-1855-x PMC5634850 17 Wang W , Yang X , Yang C , Guo X , Zhang X , Wu C . Dependency-based long short term memory network for drug-drug interaction extraction . BMC Bioinformatics. 2017 ; 18 (Suppl 16): 578 . doi: 10.1186/s12859-017-1962-8 29297301 PMC5751524 18 Jiang Z, Gu L, Jiang Q. Drug drug interaction extraction from literature using a skeleton long short term memory neural network. In: 2017 IEEE International Conference on Bioinformatics and Biomedicine (BIBM). 2017. p. 552&#8211;5. 10.1109/bibm.2017.8217708 19 Sahu SK , Anand A . Drug-drug interaction extraction from biomedical texts using long short-term memory network . J Biomed Inform. 2018 ; 86 : 15 &#8211; 24 . doi: 10.1016/j.jbi.2018.08.005 30142385 20 Zhang Y , Zheng W , Lin H , Wang J , Yang Z , Dumontier M . Drug-drug interaction extraction via hierarchical RNNs on sequence and shortest dependency paths . Bioinformatics. 2018 ; 34 ( 5 ): 828 &#8211; 35 . doi: 10.1093/bioinformatics/btx659 29077847 PMC6030919 21 Zhou D , Miao L , He Y . Position-aware deep multi-task learning for drug-drug interaction extraction . Artif Intell Med. 2018 ; 87 : 1 &#8211; 8 . doi: 10.1016/j.artmed.2018.03.001 29559249 22 Asada M, Miwa M, Sasaki Y. Enhancing drug-drug interaction extraction from texts by molecular structure information. In: Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers). 2018. 10.18653/v1/p18-2108 23 Xiong W, Li F, Yu H, Ji D. Extracting drug-drug interactions with a dependency-based graph convolution neural network. In: 2019 IEEE International Conference on Bioinformatics and Biomedicine (BIBM). 2019. p. 755&#8211;9. 10.1109/bibm47256.2019.8983150 24 Zhao D , Wang J , Lin H , Yang Z , Zhang Y . Extracting drug-drug interactions with hybrid bidirectional gated recurrent unit and graph convolutional network . J Biomed Inform. 2019 ; 99 : 103295 . doi: 10.1016/j.jbi.2019.103295 31568842 25 Li D, Ji H. Syntax-aware multi-task graph convolutional networks for biomedical relation extraction. In: Proceedings of the Tenth International Workshop on Health Text Mining and Information Analysis (LOUHI 2019). 2019. 10.18653/v1/d19-6204 26 Zhu Y , Li L , Lu H , Zhou A , Qin X . Extracting drug-drug interactions from texts with BioBERT and multiple entity-aware attentions . J Biomed Inform. 2020 ; 106 : 103451 . doi: 10.1016/j.jbi.2020.103451 32454243 27 Li D , Zhao F , Yang Y , Cui Z , Hu P , Hu L . Multi-view contrastive learning for drug-drug interaction event prediction . IEEE J Biomed Health Inform. 2025 ;PP:10.1109/JBHI.2025.3600045. doi: 10.1109/JBHI.2025.3600045 40833904 28 Duan B, Qin L, Peng J. Using center vector and drug molecular information for drug drug interaction extraction. In: 2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM). 2021. p. 1291&#8211;4. 10.1109/bibm52615.2021.9669610 29 Duan B , Peng J , Zhang Y . IMSE: interaction information attention and molecular structure based drug drug interaction extraction . BMC Bioinformatics. 2022 ; 23 (Suppl 7): 338 . doi: 10.1186/s12859-022-04876-8 35965308 PMC9375903 30 Shi Y , Quan P , Zhang T , Niu L . DREAM: drug-drug interaction extraction with enhanced dependency graph and attention mechanism . Methods. 2022 ; 203 : 152 &#8211; 9 . doi: 10.1016/j.ymeth.2022.02.002 35181524 31 Huang Z , An N , Liu J , Ren F . EMSI-BERT: asymmetrical entity-mask strategy and symbol-insert structure for drug&#8211;drug interaction extraction based on BERT . Symmetry. 2023 ; 15 ( 2 ): 398 . doi: 10.3390/sym15020398 32 Asada M , Miwa M , Sasaki Y . Integrating heterogeneous knowledge graphs into drug-drug interaction extraction from the literature . Bioinformatics. 2023 ; 39 ( 1 ):btac754. doi: 10.1093/bioinformatics/btac754 36416141 PMC9805562 33 Yuan J, Du W, Liu X. Biomedical relation extraction via domain knowledge and prompt learning. In: Proceedings of Joint Workshop of the 5th Extraction and Evaluation of Knowledge Entities from Scientific Documents, Changchun, Jilin, 2024. p. 59&#8211;61. 34 Aladadi SM , Alghamdi MA , Alrebdi MR . Application of biomedical informatics methods to find drug-drug interactions . International Journal of Multidisciplinary Innovation and Research Methodology. 2024 ; 3 ( 3 ): 213 &#8211; 20 . 35 Hassan NA , Seoud RAA , Salem DA . Bridging the gap: a hybrid approach to medical relation extraction using pretrained language models and traditional machine learning . JAIT. 2024 ; 15 ( 6 ): 723 &#8211; 34 . doi: 10.12720/jait.15.6.723-734 36 Snell J , Swersky K , Zemel R . Prototypical networks for few-shot learning . Advances in Neural Information Processing Systems. 2017 ; 30 . 37 Finn C, Abbeel P, Levine S. Model-agnostic meta-learning for fast adaptation of deep networks. In: Proceedings of International conference on machine learning, Sydney, NSW, 2017. 1126&#8211;35. 38 Herrero-Zazo M , Segura-Bedmar I , Mart&#237;nez P , Declerck T . The DDI corpus: an annotated corpus with pharmacological substances and drug-drug interactions . J Biomed Inform. 2013 ; 46 ( 5 ): 914 &#8211; 20 . doi: 10.1016/j.jbi.2013.07.011 23906817 39 Demner-Fushman D, Fung K, Do P. The DDI corpus: an annotated corpus with pharmacological substances and drug&#8211;drug interactions. In: Proceedings of Text Analysis Conference, Gaithersburg, USA; 2018. p. 1&#8211;10. 40 Huang D , Jiang Z , Zou L , Li L . Drug&#8211;drug interaction extraction from biomedical literature using support vector machine and long short term memory networks . Information Sciences. 2017 ;415&#8211;416: 100 &#8211; 9 . doi: 10.1016/j.ins.2017.06.021 41 Mostafapour V , Dikenelli O . Attention-wrapped hierarchical blstms for ddi extraction . arXiv preprint 2019 . doi: 10.48550/arXiv.1907.13561 42 Hong L , Lin J , Tao J . BERE: an accurate distantly supervised biomedical entity relation extraction network . arXiv preprint 2019 . doi: 10.48550/arXiv.1906.06916 43 Liu J , Huang Z , Ren F , Hua L . Drug-drug interaction extraction based on transfer weight matrix and memory network . IEEE Access. 2019 ; 7 : 101260 &#8211; 8 . doi: 10.1109/access.2019.2930641 44 Sun X , Dong K , Ma L , Sutcliffe R , He F , Chen S , et al . Drug-drug interaction extraction via recurrent hybrid convolutional neural networks with an improved focal loss . Entropy (Basel). 2019 ; 21 ( 1 ): 37 . doi: 10.3390/e21010037 33266753 PMC7514143 45 Asada M , Miwa M , Sasaki Y . Using drug descriptions and molecular structures for drug-drug interaction extraction from literature . Bioinformatics. 2021 ; 37 ( 12 ): 1739 &#8211; 46 . doi: 10.1093/bioinformatics/btaa907 33098410 PMC8289381 46 Nguyen DP, Bao Ho T. Drug-drug interaction extraction from biomedical texts via relation BERT. In: 2020 RIVF International Conference on Computing and Communication Technologies (RIVF). 2020. p. 1&#8211;7. 10.1109/rivf48685.2020.9140783 47 Wu H , Xing Y , Ge W , Liu X , Zou J , Zhou C , et al . Drug-drug interaction extraction via hybrid neural networks on biomedical literature . J Biomed Inform. 2020 ; 106 : 103432 . doi: 10.1016/j.jbi.2020.103432 32335223 48 Zaikis D, Vlahavas I. Drug-drug interaction classification using attention based neural networks. In: 11th Hellenic Conference on Artificial Intelligence, 2020. 34&#8211;40. 10.1145/3411408.3411461 49 He H , Chen G , Yu-Chian Chen C . 3DGT-DDI: 3D graph and text based neural network for drug-drug interaction prediction . Brief Bioinform. 2022 ; 23 ( 3 ):bbac134. doi: 10.1093/bib/bbac134 35511112 50 Huang L , Lin J , Li X , Song L , Zheng Z , Wong K-C . EGFI: drug-drug interaction extraction and generation with fusion of enriched entity and sentence information . Brief Bioinform. 2022 ; 23 ( 1 ):bbab451. doi: 10.1093/bib/bbab451 34791012 51 Fatehifar M , Karshenas H . Drug-drug interaction extraction using a position and similarity fusion-based attention mechanism . J Biomed Inform. 2021 ; 115 : 103707 . doi: 10.1016/j.jbi.2021.103707 33571676 52 Chen J , Sun X , Jin X , Sutcliffe R . Extracting drug-drug interactions from no-blinding texts using key semantic sentences and GHM loss . J Biomed Inform. 2022 ; 135 : 104192 . doi: 10.1016/j.jbi.2022.104192 36064114 53 Deng H , Li Q , Liu Y , Zhu J . MTMG: a multi-task model with multi-granularity information for drug-drug interaction extraction . Heliyon. 2023 ; 9 ( 6 ):e16819. doi: 10.1016/j.heliyon.2023.e16819 37484258 PMC10360954 54 Zhang T , Yu C , Zhang S . CA-SQBG: cross-attention guided Siamese quantum BiGRU for drug-drug interaction extraction . Comput Biol Med. 2025 ; 186 : 109655 . doi: 10.1016/j.compbiomed.2025.109655 39864333 55 Jia Y , Wang Z , Zhang H , Li P , Xie P , Yuan Z . Hierarchical feature modeling with data augmentation and focal loss for drug&#8211;drug interaction extraction . Biomedical Signal Processing and Control. 2025 ; 110 : 108199 . doi: 10.1016/j.bspc.2025.108199 56 Tang S , Zhang Q , Zheng T . Two step joint model for drug drug interaction extraction . arXiv preprint 2020 . doi: arXiv:2008.12704 57 Yang J , Ding Y , Long S , Poon J , Han SC . DDI-MuG: multi-aspect graphs for drug-drug interaction extraction . Front Digit Health. 2023 ; 5 : 1154133 . doi: 10.3389/fdgth.2023.1154133 37168529 PMC10164961 58 KafiKang M , Hendawi A . Drug-drug interaction extraction from biomedical text using relation BioBERT with BLSTM . MAKE. 2023 ; 5 ( 2 ): 669 &#8211; 83 . doi: 10.3390/make5020036 59 Hu H , Yang A , Deng S . Drug-drug interaction extraction from biomedical text using relation BioBERT with BLSTM . Machine Learning and Knowledge Extraction. 2025 ; 273 : 126953 . 60 Yang Y , Hu L , Li G , Li D , Hu P , Luo X . Link-based attributed graph clustering via approximate generative bayesian learning . IEEE Trans Syst Man Cybern, Syst. 2025 ; 55 ( 8 ): 5730 &#8211; 43 . doi: 10.1109/tsmc.2025.3572738 61 Su X , Hu P , Li D , Zhao B , Niu Z , Herget T , et al . Interpretable identification of cancer genes across biological networks via transformer-powered graph representation learning . Nat Biomed Eng. 2025 ; 9 ( 3 ): 371 &#8211; 89 . doi: 10.1038/s41551-024-01312-5 39789329"
}