{
  "pmcid": "PMC12680801",
  "source": "PMC",
  "download_date": "2025-12-09T16:37:19.168876",
  "metadata": {
    "journal_title": "Current Environmental Health Reports",
    "journal_nlm_ta": "Curr Environ Health Rep",
    "journal_iso_abbrev": "Curr Environ Health Rep",
    "journal": "Current Environmental Health Reports",
    "pmcid": "PMC12680801",
    "pmid": "41348304",
    "doi": "10.1007/s40572-025-00514-6",
    "title": "Navigating the AI Frontier in Toxicology: Trends, Trust, and Transformation",
    "year": "2025",
    "month": "12",
    "day": "5",
    "pub_date": {
      "year": "2025",
      "month": "12",
      "day": "5"
    },
    "authors": [
      "Luechtefeld Thomas",
      "Hartung Thomas"
    ],
    "abstract": "Purpose of Review The integration of artificial intelligence (AI) into toxicology marks a profound paradigm shift in chemical safety science. No longer limited to automating traditional workflows, AI is redefining how we assess risk, interpret complex biological data, and inform regulatory decision-making. This article explores the convergence of AI and other new approach methodologies (NAMs), emphasizing key trends such as multimodal learning, causal inference, explainable AI (xAI), generative modeling, and federated learning. Recent Findings These technologies enable more human-relevant, mechanistically grounded, and ethically aligned toxicological predictions—surpassing the reproducibility and scalability of animal-based methods. However, the dynamic nature of AI models challenges traditional validation paradigms. To address this, we introduced the e-validation framework, which operationalizes the TREAT principles (Trustworthiness, Reproducibility, Explainability, Applicability, Transparency) and incorporates AI-powered modules for reference chemical selection, virtual study simulation, mechanistic cross-validation, and post-validation surveillance through companion agents. Ethical considerations—including bias audits, equity audits, and participatory governance—are also foregrounded as critical elements for responsible AI adoption. The emergence of a co-pilot model, where AI augments but does not replace human judgment, offers a pragmatic path forward. Supported by evidence from the 2025 Stanford AI Index and recent regulatory advances, we argue that the infrastructure, economics, and policy momentum are now aligned for global-scale deployment of AI-based toxicology. Summary The future of the field lies not in replicating legacy practices, but in reinventing toxicology as an adaptive, transparent, and ethically grounded science that delivers more accurate, inclusive, and human-centric safety assessments. Lay Summary Artificial intelligence (AI) is changing how we test chemicals for safety. Instead of using animals, new computer-based tools can predict how substances affect human health more quickly, accurately, and ethically. This article looks at how these technologies—like smart data systems, models that explain their reasoning, and even AI \"agents\" that run simulations—can improve toxicology. We also introduce a new idea called \"e-validation\", which uses AI to help validate these methods in real-time, not just once. This ensures the models stay up to date and reliable. But using AI safely means tackling big questions: Can we trust results we don't fully understand? How do we prevent unfairness or bias in the data? We suggest a \"co-pilot\" model, where AI supports, but doesn't replace, human experts. With better data sharing, strong ethics, and smarter oversight, AI can help make chemical safety testing more human-focused, fair, and effective.",
    "keywords": [
      "Artificial Intelligence (AI)",
      "Toxicology",
      "New Approach Methodologies (NAM)",
      "e-Validation",
      "Explainable AI (xAI)",
      "Chemical risk assessment",
      "Regulatory science",
      "Bias audit",
      "Digital twins",
      "Causal modeling",
      "Responsible AI",
      "Human relevance",
      "TREAT principles",
      "Ethical toxicology",
      "Federated learning"
    ]
  },
  "xml": "<?xml version=\"1.0\"  ?><!DOCTYPE pmc-articleset PUBLIC \"-//NLM//DTD ARTICLE SET 2.0//EN\" \"https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd\"><pmc-articleset><article xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:ali=\"http://www.niso.org/schemas/ali/1.0/\" article-type=\"review-article\" xml:lang=\"en\" dtd-version=\"1.4\"><processing-meta base-tagset=\"archiving\" mathml-version=\"3.0\" table-model=\"xhtml\" tagset-family=\"jats\"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type=\"nlm-ta\">Curr Environ Health Rep</journal-id><journal-id journal-id-type=\"iso-abbrev\">Curr Environ Health Rep</journal-id><journal-id journal-id-type=\"pmc-domain-id\">365</journal-id><journal-id journal-id-type=\"pmc-domain\">springeropen</journal-id><journal-title-group><journal-title>Current Environmental Health Reports</journal-title></journal-title-group><issn pub-type=\"epub\">2196-5412</issn><custom-meta-group><custom-meta><meta-name>pmc-is-collection-domain</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-collection-title</meta-name><meta-value>Springer</meta-value></custom-meta></custom-meta-group></journal-meta><article-meta><article-id pub-id-type=\"pmcid\">PMC12680801</article-id><article-id pub-id-type=\"pmcid-ver\">PMC12680801.1</article-id><article-id pub-id-type=\"pmcaid\">12680801</article-id><article-id pub-id-type=\"pmcaiid\">12680801</article-id><article-id pub-id-type=\"pmid\">41348304</article-id><article-id pub-id-type=\"doi\">10.1007/s40572-025-00514-6</article-id><article-id pub-id-type=\"publisher-id\">514</article-id><article-version article-version-type=\"pmc-version\">1</article-version><article-categories><subj-group subj-group-type=\"heading\"><subject>Review</subject></subj-group></article-categories><title-group><article-title>Navigating the AI Frontier in Toxicology: Trends, Trust, and Transformation</article-title></title-group><contrib-group><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Luechtefeld</surname><given-names initials=\"T\">Thomas</given-names></name><xref ref-type=\"aff\" rid=\"Aff1\">1</xref><xref ref-type=\"aff\" rid=\"Aff2\">2</xref><xref ref-type=\"aff\" rid=\"Aff3\">3</xref></contrib><contrib contrib-type=\"author\" corresp=\"yes\"><name name-style=\"western\"><surname>Hartung</surname><given-names initials=\"T\">Thomas</given-names></name><address><email>Thomas.Hartung@uni-konstanz.de</email></address><xref ref-type=\"aff\" rid=\"Aff3\">3</xref><xref ref-type=\"aff\" rid=\"Aff4\">4</xref><xref ref-type=\"aff\" rid=\"Aff5\">5</xref><xref ref-type=\"aff\" rid=\"Aff6\">6</xref></contrib><aff id=\"Aff1\"><label>1</label>ToxTrack LLC, Bethesda, MD 20894 USA </aff><aff id=\"Aff2\"><label>2</label><institution-wrap><institution-id institution-id-type=\"GRID\">grid.524916.d</institution-id><institution>Insilica Inc., </institution></institution-wrap>Rockville, MD 20848 USA </aff><aff id=\"Aff3\"><label>3</label>Center for Alternatives to Animal Testing (CAAT), Baltimore, MD 21205 USA </aff><aff id=\"Aff4\"><label>4</label><institution-wrap><institution-id institution-id-type=\"ROR\">https://ror.org/00za53h95</institution-id><institution-id institution-id-type=\"GRID\">grid.21107.35</institution-id><institution-id institution-id-type=\"ISNI\">0000 0001 2171 9311</institution-id><institution>Doerenkamp-Zbinden-Chair for Evidence-Based Toxicology, </institution><institution>Johns Hopkins Bloomberg School of Public Health, </institution></institution-wrap>615 N Wolfe St, Baltimore, MD W703221201 USA </aff><aff id=\"Aff5\"><label>5</label><institution-wrap><institution-id institution-id-type=\"ROR\">https://ror.org/0546hnb39</institution-id><institution-id institution-id-type=\"GRID\">grid.9811.1</institution-id><institution-id institution-id-type=\"ISNI\">0000 0001 0658 7699</institution-id><institution>CAAT-Europe, </institution><institution>University of Konstanz, </institution></institution-wrap>Konstanz, 78464 Germany </aff><aff id=\"Aff6\"><label>6</label>CAATevents, Solingen, 42651 Germany </aff></contrib-group><pub-date pub-type=\"epub\"><day>5</day><month>12</month><year>2025</year></pub-date><pub-date pub-type=\"ppub\"><year>2025</year></pub-date><volume>12</volume><issue>1</issue><issue-id pub-id-type=\"pmc-issue-id\">501979</issue-id><elocation-id>51</elocation-id><history><date date-type=\"received\"><day>17</day><month>6</month><year>2025</year></date><date date-type=\"accepted\"><day>5</day><month>11</month><year>2025</year></date></history><pub-history><event event-type=\"pmc-release\"><date><day>05</day><month>12</month><year>2025</year></date></event><event event-type=\"pmc-live\"><date><day>07</day><month>12</month><year>2025</year></date></event><event event-type=\"pmc-last-change\"><date iso-8601-date=\"2025-12-07 00:25:13.690\"><day>07</day><month>12</month><year>2025</year></date></event></pub-history><permissions><copyright-statement>&#169; The Author(s) 2025</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref specific-use=\"textmining\" content-type=\"ccbylicense\">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article&#8217;s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article&#8217;s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://creativecommons.org/licenses/by/4.0/\">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><self-uri xmlns:xlink=\"http://www.w3.org/1999/xlink\" content-type=\"pmc-pdf\" xlink:href=\"40572_2025_Article_514.pdf\"/><abstract id=\"Abs1\"><sec><title>Purpose of Review</title><p id=\"Par1\">The integration of artificial intelligence (AI) into toxicology marks a profound paradigm shift in chemical safety science. No longer limited to automating traditional workflows, AI is redefining how we assess risk, interpret complex biological data, and inform regulatory decision-making. This article explores the convergence of AI and other new approach methodologies (NAMs), emphasizing key trends such as multimodal learning, causal inference, explainable AI (xAI), generative modeling, and federated learning.</p></sec><sec><title>Recent Findings</title><p id=\"Par2\">These technologies enable more human-relevant, mechanistically grounded, and ethically aligned toxicological predictions&#8212;surpassing the reproducibility and scalability of animal-based methods. However, the dynamic nature of AI models challenges traditional validation paradigms. To address this, we introduced the e-validation framework, which operationalizes the TREAT principles (Trustworthiness, Reproducibility, Explainability, Applicability, Transparency) and incorporates AI-powered modules for reference chemical selection, virtual study simulation, mechanistic cross-validation, and post-validation surveillance through companion agents. Ethical considerations&#8212;including bias audits, equity audits, and participatory governance&#8212;are also foregrounded as critical elements for responsible AI adoption. The emergence of a co-pilot model, where AI augments but does not replace human judgment, offers a pragmatic path forward. Supported by evidence from the 2025 Stanford AI Index and recent regulatory advances, we argue that the infrastructure, economics, and policy momentum are now aligned for global-scale deployment of AI-based toxicology.</p></sec><sec><title>Summary</title><p id=\"Par3\">The future of the field lies not in replicating legacy practices, but in reinventing toxicology as an adaptive, transparent, and ethically grounded science that delivers more accurate, inclusive, and human-centric safety assessments.</p></sec><sec><title>Lay Summary</title><p id=\"Par4\">Artificial intelligence (AI) is changing how we test chemicals for safety. Instead of using animals, new computer-based tools can predict how substances affect human health more quickly, accurately, and ethically. This article looks at how these technologies&#8212;like smart data systems, models that explain their reasoning, and even AI \"agents\" that run simulations&#8212;can improve toxicology. We also introduce a new idea called \"e-validation\", which uses AI to help validate these methods in real-time, not just once. This ensures the models stay up to date and reliable. But using AI safely means tackling big questions: Can we trust results we don't fully understand? How do we prevent unfairness or bias in the data? We suggest a \"co-pilot\" model, where AI supports, but doesn't replace, human experts. With better data sharing, strong ethics, and smarter oversight, AI can help make chemical safety testing more human-focused, fair, and effective.</p></sec></abstract><kwd-group xml:lang=\"en\"><title>Keywords</title><kwd>Artificial Intelligence (AI)</kwd><kwd>Toxicology</kwd><kwd>New Approach Methodologies (NAM)</kwd><kwd>e-Validation</kwd><kwd>Explainable AI (xAI)</kwd><kwd>Chemical risk assessment</kwd><kwd>Regulatory science</kwd><kwd>Bias audit</kwd><kwd>Digital twins</kwd><kwd>Causal modeling</kwd><kwd>Responsible AI</kwd><kwd>Human relevance</kwd><kwd>TREAT principles</kwd><kwd>Ethical toxicology</kwd><kwd>Federated learning</kwd></kwd-group><funding-group><award-group><funding-source><institution>Universit&#228;t Konstanz (3156)</institution></funding-source></award-group><open-access><p>Open Access funding enabled and organized by Projekt DEAL.</p></open-access></funding-group><custom-meta-group><custom-meta><meta-name>pmc-status-qastatus</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>pmc-status-live</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-status-embargo</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-status-released</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-open-access</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-olf</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-manuscript</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-legally-suppressed</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-pdf</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-supplement</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-pdf-only</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-suppress-copyright</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-real-version</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-scanned-article</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-preprint</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-in-epmc</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#169; Springer Nature Switzerland AG 2025</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id=\"Sec1\"><title>Introduction: A Paradigm Shift</title><p id=\"Par5\">The integration of artificial intelligence (AI) into toxicology is no longer a speculative vision [<xref ref-type=\"bibr\" rid=\"CR1\">1</xref>]; it is a scientific necessity. Over the past two decades, toxicology has evolved from a primarily observational discipline of black-box animal models and some human data to a data-rich science poised for algorithmic innovation. Fueled by the proliferation of big data from high-throughput screening,&#8201;~&#8201;omics, digital pathology, and curated chemical databases as well as machine-readable scientific literature, the field has entered a new era where AI is not merely a tool&#8212;it is a transformative force. This shift is underpinned by the convergence of three accelerating forces: the exponential growth of toxicological data, unprecedented gains in computational power, and rapid advances in machine learning algorithms [<xref ref-type=\"bibr\" rid=\"CR2\">2</xref>]. Together, they are reshaping how we interrogate toxicity, predict risk, extract mechanistic insight, and ultimately make regulatory decisions. In this context, AI offers more than automation&#8212;it represents a redefinition of toxicological practice.</p><p id=\"Par6\">Modern toxicology must now contend with the \"Five Vs\" of big data&#8212;volume, velocity, variety, veracity, and value [<xref ref-type=\"bibr\" rid=\"CR3\">3</xref>]. These dimensions collectively exceed the capacity of traditional methods and demand scalable, adaptive computational approaches. AI excels at distilling signal from complexity, enabling predictive modeling across structurally diverse chemicals, integration of heterogeneous evidence streams, and synthesis of multi-omics and legacy data.</p><p id=\"Par7\">At the forefront of this revolution are AI-based New Approach Methodologies (NAMs), which promise not only greater speed and cost efficiency, but also enhanced human relevance and ethical acceptability. Tools such as deep neural networks, graph-based learning, natural language processing, and generative models are enabling new paradigms&#8212;from automated read-across and mechanistic hypothesis generation to probabilistic risk assessment and evidence synthesis [<xref ref-type=\"bibr\" rid=\"CR4\">4</xref>]. These emerging paradigms are being benchmarked through comparative validation studies. For instance, RASAR models achieved 87% balanced accuracy across nine OECD guideline endpoints&#8212;surpassing the&#8201;~&#8201;81% reproducibility of the respective animal studies [<xref ref-type=\"bibr\" rid=\"CR5\">5</xref>]. Probabilistic read-across and causal-inference models similarly demonstrate enhanced mechanistic resolution and reproducibility over traditional toxicity tests. Such metrics provide quantitative evidence that AI-based NAMs outperform legacy paradigms while improving interpretability and consistency.</p><p id=\"Par8\">However, this transformation is not without challenges. AI systems, particularly deep learning models, often suffer from interpretability issues, raising concerns about trust and transparency&#8212;core requirements in regulatory toxicology. Furthermore, biases in training data, lack of standardization, and gaps in cross-disciplinary expertise impede broader adoption. As emphasized in the TREAT framework [<xref ref-type=\"bibr\" rid=\"CR6\">6</xref>] and e-validation paradigm [<xref ref-type=\"bibr\" rid=\"CR7\">7</xref>], rigorous validation, explainability, and human oversight must be embedded throughout the model lifecycle.</p><p id=\"Par9\">The maturation of AI-readiness in toxicology is evident: inference costs have dropped by over 280-fold in just two years, performance saturation is driving the shift from generic to domain-specific models, and regulatory precedents are being set, as seen in the FDA's approval of over 200 AI-enabled devices in 2023 [<xref ref-type=\"bibr\" rid=\"CR7\">7</xref>]. Toxicology must now seize this momentum to define how AI can be responsibly, ethically, and scientifically integrated into every stage of chemical safety assessment. In short, toxicology stands at an inflection point. The discipline must evolve from merely adopting AI to actively co-developing it&#8212;ensuring that the next generation of safety science is not only data-driven, but also mechanistically grounded, socially responsible, and globally harmonized.</p><p id=\"Par10\">Equally central to responsible innovation is the social dimension. Transitioning toward AI-enabled toxicology will not displace the scientific workforce but rather redirect expertise. Routine in-vivo assay technicians can transition toward data-curation, validation, and quality-assurance roles; regulatory scientists can specialize in AI oversight, bias auditing, and ethical governance. Investment in up-skilling and continuing education must therefore accompany technical deployment to ensure workforce sustainability and social responsibility.</p></sec><sec id=\"Sec2\"><title>The Emerging AI Landscape: What's New in 2025?</title><p id=\"Par11\">In Hartung &amp; Kleinstreuer (2025, Table 1 therein) [<xref ref-type=\"bibr\" rid=\"CR6\">6</xref>] discussing AI-validation, we highlighted key AI trends poised to reshape toxicology. These include (Fig.&#160;<xref rid=\"Fig1\" ref-type=\"fig\">1</xref>):<fig id=\"Fig1\" position=\"float\" orientation=\"portrait\"><label>Fig.&#160;1</label><caption><p><bold>The Emerging AI Landscape and its Implications for Toxicology</bold>. A number of trends in AI technological developments were identified and their impact on toxicology is summarized. Boxes in blue indicate current trends, those in purple the longer-term impactors. The white box summarizes the expected impacts on the field</p></caption><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"MO1\" position=\"float\" orientation=\"portrait\" xlink:href=\"40572_2025_514_Fig1_HTML.jpg\"/></fig></p><sec id=\"Sec3\"><title>Foundations: Data, Modeling, and Infrastructure</title><p id=\"Par12\"><italic toggle=\"yes\">Data-Centric AI and FAIRification</italic>&#8212;In contrast to model-centric AI approaches that focus on algorithmic sophistication, data-centric AI prioritizes dataset quality, curation, and infrastructure. This paradigm is particularly relevant to toxicology, where data heterogeneity, legacy formats, and annotation gaps often undermine model performance. Initiatives such as the EPA's CompTox Chemistry Dashboard,<xref ref-type=\"fn\" rid=\"Fn1\">1</xref> OECD's QSAR Toolbox,<xref ref-type=\"fn\" rid=\"Fn2\">2</xref> and NIEHS's Integrated Chemical Environment (ICE)<xref ref-type=\"fn\" rid=\"Fn3\">3</xref> exemplify data FAIRification&#8212;making data findable, accessible, interoperable, and reusable.<xref ref-type=\"fn\" rid=\"Fn4\">4</xref> Reusable FAIR Implementation Profiles [<xref ref-type=\"bibr\" rid=\"CR8\">8</xref>] appear to be a way forward here [<xref ref-type=\"bibr\" rid=\"CR9\">9</xref>]. AI systems built on curated, standardized, and semantically annotated data are not only more accurate but also more trustworthy and transparent. Moreover, data-centric workflows increasingly incorporate AI tools themselves to assist in cleaning, labeling, harmonizing, and flagging inconsistencies in toxicological datasets. These \"AI-curates-AI\" cycles are essential for scaling up robust, reproducible, and generalizable toxicology models across institutions, jurisdictions, and species.<xref ref-type=\"fn\" rid=\"Fn5\">5</xref> The old mantra of <italic toggle=\"yes\">trash in, trash out</italic> still holds, but it is no longer the humans sorting the trash but the machines.</p><p id=\"Par13\">Equity-aware data governance is critical. Scenarios in which low-quality or biased &#8216;trash data&#8217; disproportionately represent specific ethnic or geographic sub-populations can perpetuate inequities. FAIRification efforts should therefore include demographic representativeness audits, targeted high-quality data collection where gaps exist, and alignment with CARE (Collective Benefit, Authority to Control, Responsibility, and Ethics) principles to ensure inclusive datasets.</p><p id=\"Par14\"><italic toggle=\"yes\">Self-supervised learning (SSL)</italic> offers a transformative advantage for toxicology, where data scarcity, label noise, and high annotation costs often limit the applicability of supervised machine learning. SSL leverages unlabeled data&#8212;abundant in toxicological literature, chemical registries, omics repositories, and legacy datasets&#8212;to learn useful data representations without requiring predefined labels. This pretraining process allows downstream tasks, such as toxicity prediction or chemical classification, to be fine-tuned on smaller, high-quality labeled datasets, dramatically enhancing model performance and generalizability. For instance, SSL techniques can extract embeddings from chemical graphs or transcriptomic time-series, which can then be used to cluster compounds, identify outliers, or predict missing annotations. Given the abundance of historical toxicology data that are incomplete or inconsistently labeled, SSL could unlock substantial latent value by turning raw, unlabeled information into a source of predictive insight [<xref ref-type=\"bibr\" rid=\"CR10\">10</xref>&#8211;<xref ref-type=\"bibr\" rid=\"CR12\">12</xref>].</p><p id=\"Par15\"><italic toggle=\"yes\">Synthetic data</italic> generation&#8212;via methods such as generative adversarial networks (GANs), variational autoencoders, or large language models&#8212;is increasingly viewed as a practical solution to toxicology's chronic data scarcity and privacy constraints. Synthetic datasets can be used to augment training sets, simulate underrepresented scenarios, or generate in silico populations for probabilistic risk assessment. This approach has been particularly useful in drug discovery and genomics, where data sharing restrictions or rare events limit model training. However, the toxicological utility of synthetic data remains debated, particularly in terms of biological plausibility and statistical fidelity. Overfitting to synthetic artifacts, loss of real-world variance, and \"data nutritional deficiency\" are valid concerns. As such, rigorous quality assessment of synthetic datasets is required before they can be trusted for regulatory decision-making. Nonetheless, when carefully designed and benchmarked, synthetic data may become a valuable complement to traditional datasets&#8212;particularly in precompetitive or federated toxicology initiatives [<xref ref-type=\"bibr\" rid=\"CR13\">13</xref>, <xref ref-type=\"bibr\" rid=\"CR14\">14</xref>].</p><p id=\"Par16\"><italic toggle=\"yes\">Foundation models</italic>&#8212;large-scale, pre-trained models developed on broad datasets&#8212; have become the backbone of modern AI. By pre-training on massive text, image, or biological sequence corpora, models such as GPT-4 (OpenAI, 2023)&#160;[<xref ref-type=\"bibr\" rid=\"CR15\">15</xref>], Med-PaLM [<xref ref-type=\"bibr\" rid=\"CR16\">16</xref>], and AlphaFold [<xref ref-type=\"bibr\" rid=\"CR17\">17</xref>] capture rich general-purpose representations that can be fine-tuned or prompt-tuned for toxicology tasks&#8212;literature mining for adverse outcome pathways, graph-based chemical classification, or proteomic interaction prediction&#8212;without the resource intensity of training from scratch. However, their scale and opacity raise valid concerns about transparency, reproducibility, and regulatory suitability. To address this, the Foundation Model Transparency Index<xref ref-type=\"fn\" rid=\"Fn6\">6</xref> provides a 100-indicator framework assessing model providers&#8217; disclosure practices,<xref ref-type=\"fn\" rid=\"Fn7\">7</xref> while the Explainable AI Toolkit (XAITK)<xref ref-type=\"fn\" rid=\"Fn8\">8</xref> offers modular xAI components (e.g., saliency maps [<xref ref-type=\"bibr\" rid=\"CR18\">18</xref>], SHAP values, counterfactual explanations) that can be integrated into toxicology-focused pipelines to illuminate decision logic and satisfy interpretability requirements [<xref ref-type=\"bibr\" rid=\"CR19\">19</xref>].</p><p id=\"Par17\"><italic toggle=\"yes\">Zero-shot and few-shot learning</italic> methods represent a frontier for applying AI in underexplored areas of toxicology. Unlike traditional machine learning models, which require large, annotated datasets, zero-shot learning allows models to generalize to new toxicity endpoints or chemical classes without prior exposure to annotated examples (Fig. <xref rid=\"Fig2\" ref-type=\"fig\">2</xref>). This is achieved by leveraging semantic relationships, often via embeddings or prompt-based learning in large pre-trained models, such as foundation models like GPT-4 or Med-PaLM.<xref ref-type=\"fn\" rid=\"Fn9\">9</xref> Few-shot learning, in contrast, allows for rapid model adaptation using only a small number of labeled instances, making it ideal for toxicological domains with limited training sets, such as developmental immunotoxicity or endocrine disruption [<xref ref-type=\"bibr\" rid=\"CR20\">20</xref>]. These methods are particularly advantageous when assessing rare endpoints or substances, where high-quality labeled data is limited or difficult to generate. When coupled with domain-specific prompts or ontologies, large language or multimodal models can infer hazard potential, enabling applications like automated chemical grouping, virtual screening, and read-across with minimal empirical input [<xref ref-type=\"bibr\" rid=\"CR2\">2</xref>]. Such techniques significantly enhance the scalability and agility of AI systems in (non-)regulatory toxicology (Fig.&#160;<xref rid=\"Fig2\" ref-type=\"fig\">2</xref>), offering a path forward for predictive toxicology that is both efficient and aligned with human-relevant outcomes. Prominent examples are regulatory read-across and grouping [<xref ref-type=\"bibr\" rid=\"CR21\">21</xref>, <xref ref-type=\"bibr\" rid=\"CR22\">22</xref>] and &#8220;benign-by-design&#8221;, in the EU called &#8220;safe and sustainable by design&#8221; (SSbD), framework of Green Toxicology [<xref ref-type=\"bibr\" rid=\"CR23\">23</xref>, <xref ref-type=\"bibr\" rid=\"CR24\">24</xref>], i.e., the toxicological aspects of Green Chemistry avoiding toxic liabilities early in the product development process.<fig id=\"Fig2\" position=\"float\" orientation=\"portrait\"><label>Fig.&#160;2</label><caption><p>\n<bold>Zero- and few-shot learning for toxicology workflows</bold>. The graphic is visualizing how zero- and few-shot learning plug into toxicology workflows (e.g., data-sparse endpoints to regulatory read-across); Developmental Immunotoxicity and per- and polyfluoroalkyl substances (PFAS) are used as examples of being sparse for (good) data</p></caption><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"MO2\" position=\"float\" orientation=\"portrait\" xlink:href=\"40572_2025_514_Fig2_HTML.jpg\"/></fig></p><p id=\"Par18\"><italic toggle=\"yes\">Parallel and Cloud-Based Compute Infrastructure</italic>&#8212;The integration of scalable compute resources&#8212;enabled by cloud services and parallel processing architectures&#8212;has lowered the entry barrier for toxicological AI. Cloud platforms like AWS, Azure, and Google Cloud allow rapid scaling of storage and compute power, enabling large-scale training on toxicological datasets or batch evaluations of QSAR models. Parallelization frameworks (e.g., Spark,<xref ref-type=\"fn\" rid=\"Fn10\">10</xref> Ray,<xref ref-type=\"fn\" rid=\"Fn11\">11</xref> or Dask<xref ref-type=\"fn\" rid=\"Fn12\">12</xref>) can accelerate high-throughput workflows, such as large-scale screening of virtual compound libraries or Monte Carlo simulations in probabilistic risk assessment. Importantly, this infrastructure supports collaborative toxicology through centralized data lakes, version control, and reproducible pipelines. By enabling real-time analysis, cross-institutional modeling, and continuous integration of new data, these tools facilitate a dynamic, open innovation ecosystem that advances both predictive capacity and transparency in toxicological research [<xref ref-type=\"bibr\" rid=\"CR25\">25</xref>].</p></sec><sec id=\"Sec4\"><title>Modeling the Complexity of Toxicological Phenomena</title><p id=\"Par19\"><italic toggle=\"yes\">Multimodal AI</italic> represents one of the most powerful evolutions in toxicological modeling by enabling the integration of diverse data types&#8212;including text,&#8201;~&#8201;omics (genomics, transcriptomics, metabolomics), chemical structures, and imaging data&#8212;into a single analytical framework. In toxicology, this approach is particularly advantageous given the multifactorial nature of toxicity mechanisms, which often require correlating molecular-level perturbations with phenotypic or pathological endpoints. Applications of multimodal AI include digital pathology for objective tissue assessment, multi-omics integration to elucidate toxicity pathways, and real-time exposure monitoring through the fusion of environmental sensor data with biological responses. These capabilities significantly enhance the translational potential of AI-driven predictions, bridging the gap between high-content mechanistic data and regulatory endpoints. As toxicology transitions from apical observations to pathway-based assessments, multimodal architectures are poised to become the analytic backbone of next-generation safety science [<xref ref-type=\"bibr\" rid=\"CR26\">26</xref>].</p><p id=\"Par20\"><italic toggle=\"yes\">Causal AI</italic> marks a fundamental shift in the epistemological foundation of computational toxicology by moving beyond association-based models toward causation-based inference. Traditional AI models excel at identifying statistical correlations but often fall short when tasked with uncovering mechanistic pathways or predicting the consequences of perturbing biological systems. Causal inference frameworks&#8212;especially those grounded in directed acyclic graphs, structural equation models, or counterfactual analysis&#8212;enable the identification of key drivers within adverse outcome pathways (AOPs) [<xref ref-type=\"bibr\" rid=\"CR27\">27</xref>], facilitating mechanistic validation and regulatory acceptance. LLM are increasingly capable of supporting mechanistic reasoning or for example the fulfillment of Bradford-Hill criteria for causality [<xref ref-type=\"bibr\" rid=\"CR28\">28</xref>]. These tools allow toxicologists to simulate \"what-if\" scenarios, predict the effects of interventions, and prioritize molecular initiating events based on causal relevance rather than statistical association alone. Such capabilities are essential for risk assessment, hazard identification, and the development of human-relevant NAMs. As data-rich toxicology continues to mature, causal AI may redefine how safety science understands and quantifies chemical effects on biological systems [<xref ref-type=\"bibr\" rid=\"CR29\">29</xref>].</p><p id=\"Par21\"><italic toggle=\"yes\">Physics-informed AI</italic> (PI-AI), and actually more science-informed AI, combines data-driven learning with established mechanistic models&#8212;such as toxicokinetics, cell signaling, or biotransformation dynamics&#8212;to improve generalizability and credibility of predictions. These hybrid models incorporate differential equations or physical constraints into the AI learning process, ensuring that outputs remain scientifically plausible and interpretable. In toxicology, PI-AI could improve IVIVE (in-vitro-to-in-vivo-extrapolations) predictions [<xref ref-type=\"bibr\" rid=\"CR30\">30</xref>], PBPK model accuracy, or dose&#8211;response extrapolations by embedding known pharmacodynamic principles. For regulators, the integration of first-principles modeling offers reassurance that AI systems are not just statistical correlations, but grounded in biological realism. This synthesis of mechanistic and statistical modeling represents a critical step toward harmonizing AI outputs with regulatory frameworks and translational toxicology needs [<xref ref-type=\"bibr\" rid=\"CR31\">31</xref>].</p><p id=\"Par22\"><italic toggle=\"yes\">Probabilistic Modeling and Uncertainty Quantification</italic> enables toxicological risk assessments to move beyond binary hazard classification toward nuanced, uncertainty-aware decision-making. AI models&#8212;especially Bayesian neural networks and ensemble learning systems&#8212;can provide confidence intervals and probabilistic risk estimates that account for biological variability, data gaps, and extrapolation uncertainty. These models support more robust safety margins and better-informed regulatory decisions, particularly for chemicals with sparse in vivo data. Advanced techniques in uncertainty quantification, such as Monte Carlo dropout,<xref ref-type=\"fn\" rid=\"Fn13\">13</xref> deep ensembles,<xref ref-type=\"fn\" rid=\"Fn14\">14</xref> or variational inference,<xref ref-type=\"fn\" rid=\"Fn15\">15</xref> are waiting to be implemented in toxicology to identify influential parameters and prioritize data acquisition. Furthermore, probabilistic read-across and risk assessment (ProbRA) [<xref ref-type=\"bibr\" rid=\"CR20\">20</xref>, <xref ref-type=\"bibr\" rid=\"CR32\">32</xref>, <xref ref-type=\"bibr\" rid=\"CR33\">33</xref>] models are being developed as a refinement of conventional structural analog approaches, incorporating prior knowledge and real-world exposure variance. These frameworks support a more human-centric and evidence-based toxicology [<xref ref-type=\"bibr\" rid=\"CR34\">34</xref>]&#8212;critical for translating AI insights into risk governance.</p></sec><sec id=\"Sec5\"><title>Democratizing Access and Building Adaptability</title><p id=\"Par23\"><italic toggle=\"yes\">Explainable AI (xAI)</italic>&#8212;Explainability is not merely a desirable feature for AI in toxicology&#8212;it is a prerequisite for regulatory trust, scientific rigor, and ethical accountability. While deep learning models may offer superior predictive performance, their \"black-box\" nature limits adoption in high-stakes domains like chemical safety assessment. Explainable AI (xAI) addresses this limitation by providing interpretive insights into model behavior, enabling users to understand why a prediction was made and what features contributed most to it. Techniques such as SHAP values,<xref ref-type=\"fn\" rid=\"Fn16\">16</xref> i.e., a game-theoretic approach used to explain the output of any machine learning model, local interpretable model-agnostic explanations (LIME) [<xref ref-type=\"bibr\" rid=\"CR35\">35</xref>], i.e., a method that explains the predictions of any machine learning model by approximating it locally with a simpler, interpretable model, as well as integrated gradients, and rule extraction methods can be used to illuminate complex model outputs.<xref ref-type=\"fn\" rid=\"Fn17\">17</xref> xAI also facilitates alignment with mechanistic toxicology frameworks, such as adverse outcome pathways (AOPs), by linking predictions to plausible biological mechanisms. As emphasized by both DARPA and the OECD, explainability is increasingly viewed not just as a technical feature but as a governance requirement for the use of AI in toxicological risk assessment [<xref ref-type=\"bibr\" rid=\"CR36\">36</xref>].</p><p id=\"Par24\"><italic toggle=\"yes\">AutoML and No-Code AI</italic>&#8212;The rise of automated machine learning (AutoML) and no-code AI platforms democratizes (toxicological) modeling by lowering the barrier to entry. AutoML frameworks such as Google's Vertex AI,<xref ref-type=\"fn\" rid=\"Fn18\">18</xref> H2O.ai,<xref ref-type=\"fn\" rid=\"Fn19\">19</xref> or AutoSklearn<xref ref-type=\"fn\" rid=\"Fn20\">20</xref> allow users to build, optimize, and validate machine learning pipelines with minimal manual intervention. For toxicology, this means domain experts without formal training in data science can rapidly develop predictive models for specific endpoints, such as hepatotoxicity or endocrine disruption. These tools automate tasks like feature selection, hyperparameter tuning, and performance benchmarking, freeing up resources and accelerating hypothesis generation. No-code platforms further can extend accessibility by offering drag-and-drop interfaces that support toxicological workflows from dataset ingestion to result visualization. While these tools promise to promote inclusivity and speed, they must be coupled with best practices in validation [<xref ref-type=\"bibr\" rid=\"CR7\">7</xref>, <xref ref-type=\"bibr\" rid=\"CR37\">37</xref>], reproducibility, and model documentation to ensure scientific integrity and regulatory alignment.</p><p id=\"Par25\"><italic toggle=\"yes\">Adaptive and continual learning</italic> systems enable AI models to evolve with new data&#8212;critical in a field like toxicology, where understanding of chemical mechanisms and regulations is constantly expanding: PubMed alone gives about 13,000 articles per year with the term&#8221;toxicology&#8221; over the last decade. These systems allow AI models to incrementally update their knowledge base, retrain with emerging evidence, and adapt to shifts in data distribution, such as new formulations or exposure routes. Companion AI agents for post-validation monitoring, as proposed in your e-validation framework [<xref ref-type=\"bibr\" rid=\"CR7\">7</xref>], exemplify this trend by tracking model performance over time and signaling when retraining or recalibration is needed. Adaptive AI systems are also crucial for maintaining consistency in toxicological assessments as new AOPs are developed or reference standards change. These dynamic capabilities make continual learning indispensable for trustworthy, up-to-date safety decision support systems.</p></sec><sec id=\"Sec6\"><title>Scaling Collaboration and Privacy-Preserving Analysis</title><p id=\"Par26\"><italic toggle=\"yes\">Edge AI</italic>, also known as on-device AI, and federated learning provide enabling architectures for decentralized toxicological modeling and privacy-preserving analysis. In scenarios where data cannot be centrally pooled&#8212;such as multi-center studies, proprietary industrial datasets, or human subject data&#8212;federated learning allows model training across distributed nodes without data transfer. Edge AI further extends this capability by enabling real-time toxicological inference at the site of data generation, such as sensors in environmental monitoring stations or wearable biosensors. These approaches reduce latency, enhance privacy, and facilitate context-aware modeling in situ. For instance, federated toxicology could harmonize predictive models across pharmaceutical partners without exposing proprietary compounds, while edge AI could power on-device exposure assessments in occupational health settings. These technologies align well with ethical data stewardship, especially under General Data Protection Regulation (GDPR) law of the European Union<xref ref-type=\"fn\" rid=\"Fn21\">21</xref> and related frameworks, and offer scalable pathways toward global, collaborative toxicology without compromising privacy or security.</p><p id=\"Par27\">However, decentralized computation introduces new disparities. To maintain result consistency across low- and high-resource nodes, federated frameworks should incorporate standardized validation toolkits, model cards, and inter-node proficiency testing. ISO 42001<xref ref-type=\"fn\" rid=\"Fn22\">22</xref> and OECD AI<xref ref-type=\"fn\" rid=\"Fn23\">23</xref> Principles provide templates for harmonizing quality control and ethical oversight in such distributed environments.</p><p id=\"Par28\"><italic toggle=\"yes\">Privacy-preserving AI</italic> technologies&#8212;such as homomorphic encryption, i.e., a type of encryption that allows computations to be performed on encrypted data without decrypting it first, secure multi-party computation (SMPC),<xref ref-type=\"fn\" rid=\"Fn24\">24</xref> i.e., a cryptographic technique that allows multiple parties to collaboratively compute a function on their private inputs while keeping those inputs secret, and differential privacy, i.e., a technique that allows for data analysis and sharing while protecting the privacy of individual data points protects user data from being traced back to individual users&#8212;are increasingly critical in toxicology, particularly when handling sensitive human exposure or biomonitoring data. These techniques enable the training and deployment of AI models without direct access to raw data, thereby safeguarding propriety and confidentiality while still extracting value. Beyond de-identification, ethical deployment requires explicit consent for algorithmic data use. Dynamic consent models&#8212;allowing participants to grant, withdraw, or refine permission for AI-based analysis&#8212;should be embedded in toxicology data-collection workflows. Consent forms should transparently specify potential secondary uses of anonymized data by AI systems. In collaborative toxicological research or regulatory decision-making, where industry hesitancy over intellectual property and patient privacy concerns can limit data sharing, these approaches facilitate secure collaboration. Privacy-preserving AI also supports compliance with frameworks like the GDPR law of the European Union <xref ref-type=\"fn\" rid=\"Fn25\">25</xref> or the US Health Insurance Portability and Accountability Act (HIPAA),<xref ref-type=\"fn\" rid=\"Fn26\">26</xref> making it an essential component of trustworthy AI ecosystems. When combined with federated learning, these technologies could create secure, distributed toxicology infrastructures that transcend institutional and jurisdictional barriers.</p></sec><sec id=\"Sec7\"><title>Advanced Horizons: Automation and New Hardware</title><p id=\"Par29\"><italic toggle=\"yes\">Agentic AI</italic>, or AI agents capable of autonomous reasoning and task execution, introduces the potential for self-directed workflows in toxicology&#8212;from literature review and study design to experimental optimization and data interpretation. These agents, built upon large language models and reinforcement learning frameworks, can plan, execute, and revise multistep procedures, offering a vision of fully automated toxicological pipelines. This is probably the most transformative part of current developments, as it changes the role of AI from a knowledge acquiring and digesting algorithm on command to an orchestrator of active inquiry and self-optimization. For instance, an AI agent might design a virtual screening experiment, adjust dose ranges based on early feedback, and generate preliminary risk assessments. However, the practical deployment of such systems remains constrained by current limitations in multistep reasoning accuracy. Error compounding across long agentic chains, coupled with challenges in uncertainty quantification and task-specific calibration, hinders their application in high-stakes regulatory contexts. First proof-of-concept demonstrations, however, without peer-review, exist [<xref ref-type=\"bibr\" rid=\"CR38\">38</xref>], which introduces TxAgent, an AI agent designed for therapeutic reasoning that leverages multi-step reasoning and real-time biomedical knowledge retrieval across a toolbox of 211 tools. However, robust governance, validation frameworks, and error-mitigation strategies must be developed before agentic AI can become a mainstay in regulatory toxicology [<xref ref-type=\"bibr\" rid=\"CR7\">7</xref>]. A critical caveat concerns hallucination&#8212;the generation of plausible but false outputs. Mitigation strategies include retrieval-augmented generation (RAG), ensemble verification, and mandatory human-in-the-loop review before high-impact conclusions are adopted. Continuous benchmark testing for factual accuracy should accompany every agentic deployment. Very soon, we will see agents capable of integrating and manipulating a wide range of tools&#8212;constantly running, dynamically scaling, and even cloning themselves in response to new signals. For toxicology, this could manifest as a continuous monitoring agent across the human exposome, capable of both interpreting exposure signals and initiating mitigation or hazard assessment actions. These agentic models will not just analyze data, but self-improve by interacting with real-world testing environments. Their value will hinge on access to experiments, not just pretraining. The ability to design, execute, and learn from minimally harmful yet maximally informative experiments will become a defining competitive advantage, especially compared to static models trained on legacy datasets. This ties directly to our points around bias, causality, and the epistemic limits of black-box AI. Experimental feedback loops can shift AI from correlation to true scientific inquiry. Latest development include Recursive Self-improving AI (RSI),<xref ref-type=\"fn\" rid=\"Fn27\">27</xref> i.e., systems capable of autonomously enhancing their own intelligence, algorithms, and architecture through iterative self-modification cycles. Unlike traditional AI that requires human intervention for improvements, RSI systems improve their ability to self-improve, creating a feedback loop that can lead to exponential growth in intelligence and capabilities; their use is currently mostly limited to coding and solving mathematical problems, but they show a direction where AI independently finds problem solving strategies.</p><p id=\"Par30\"><italic toggle=\"yes\">Digital twins</italic>&#8212;computational replicas of biological systems informed by individual data&#8212;are emerging as powerful platforms for personalized and predictive toxicology. In combination with AI, digital twins can simulate chemical exposure scenarios, dynamically model organ-specific responses, and support patient-centric safety decisions. In toxicology, virtual twin systems are being developed using integrated PBPK (physiologically based pharmacokinetic) models, exposure datasets, and&#8201;~&#8201;omics signatures to predict real-time responses under different conditions. These models allow for scenario testing, dose extrapolation, and early identification of susceptible subpopulations. When implemented with cloud-based infrastructures, digital twins can also be embedded in decision-support systems for regulators or industry risk managers. The ONTOX project<xref ref-type=\"fn\" rid=\"Fn28\">28</xref> [<xref ref-type=\"bibr\" rid=\"CR39\">39</xref>, <xref ref-type=\"bibr\" rid=\"CR40\">40</xref>] and NICEATM's Integrated Chemical Environment (ICE)<xref ref-type=\"fn\" rid=\"Fn29\">29</xref> already use components of this paradigm, positioning it as a next-generation NAM for regulatory toxicology [<xref ref-type=\"bibr\" rid=\"CR32\">32</xref>]. A broader EU Virtual Human Twins (VHT) Initiative<xref ref-type=\"fn\" rid=\"Fn30\">30</xref> launched in 2023 to integrate multi-scale computational models of human physiology. It combines the EDITH<xref ref-type=\"fn\" rid=\"Fn31\">31</xref> (Ecosystem for Digital Twins in Healthcare) roadmap for ecosystem development led by the Virtual Physiological Human Institute (VPHi)<xref ref-type=\"fn\" rid=\"Fn32\">32</xref> and Horizon Europe funding (&#8364;80 million) for research on patient-specific disease models and a &#8364;24 million digital platform (Digital Europe Programme) for model integration and validation. The Initiative completed its first demonstration phase in mid-2025, validating cardiac and hepatic digital-twin modules within the EDITH WP2 framework. These milestones confirm that AI-driven virtual humans are moving from concept to early implementation in regulatory research.</p><p id=\"Par31\"><italic toggle=\"yes\">Generative AI</italic>, particularly transformer-based architectures such as generative adversarial networks (GANs) and large language models (LLMs), is reshaping toxicological workflows [<xref ref-type=\"bibr\" rid=\"CR14\">14</xref>, <xref ref-type=\"bibr\" rid=\"CR41\">41</xref>]. These models are capable of generating synthetic chemical structures, filling in missing exposure data, simulating literature summaries, and even producing mechanistic hypotheses. For example, GANs have been used to create synthetic toxicogenomic profiles that mirror real data distributions, providing additional training material for rare endpoints. LLMs can automate literature triage, protocol drafting, and annotation of legacy studies, thereby accelerating evidence synthesis. However, generative models must be carefully validated to prevent the propagation of artifacts or hallucinated outputs, especially when informing regulatory decisions. Nevertheless, their creative and data-augmentation capabilities make them powerful allies in addressing the data scarcity, heterogeneity, and synthesis [<xref ref-type=\"bibr\" rid=\"CR42\">42</xref>] challenges endemic to toxicology [<xref ref-type=\"bibr\" rid=\"CR43\">43</xref>]. Not all data types should be synthetically reproduced. Generation of identifiable human exposure records, proprietary in-vivo datasets, or clinical information without governance approval poses ethical and legal risks. Generative pipelines must therefore include safeguards and provenance tagging to prevent inadvertent re-creation of protected data.</p><p id=\"Par32\"><italic toggle=\"yes\">Neuromorphic and Quantum Computing</italic>&#8212;Emerging hardware paradigms such as neuromorphic computing and quantum computing offer long-term prospects for expanding the scope of AI in toxicology by increasing computational power. Neuromorphic chips mimic the architecture of biological neural systems, allowing energy-efficient processing of complex, temporal data such as electrophysiology or toxicokinetics. These systems could enable real-time learning from biosensors or in vitro time-course data, supporting dynamic toxicity assessment. Quantum computing, although still nascent, holds the potential to revolutionize molecular simulations, multi-objective optimization, and network-based causal inference&#8212;tasks that are computationally prohibitive for classical systems. For example, simulating toxicant interactions with protein networks or predicting emergent properties in chemical mixtures could benefit from the exponential speedup quantum algorithms promise. While practical deployment is years away, early investment in quantum-aware toxicology models and neuromorphic architecture optimization will prepare the field for next-generation breakthroughs.</p></sec><sec id=\"Sec8\"><title>Ranking Ethical Priorities for AI in Toxicology</title><p id=\"Par33\">We have recently described two visions for the future of AI-facilitated science, i.e., first a more and more AI-driven scAInce [<xref ref-type=\"bibr\" rid=\"CR44\">44</xref>] and the development of toxicology toward a Human Exposome Project [<xref ref-type=\"bibr\" rid=\"CR45\">45</xref>] through AI [<xref ref-type=\"bibr\" rid=\"CR46\">46</xref>] with considerable ethical challenges [<xref ref-type=\"bibr\" rid=\"CR47\">47</xref>]. To translate ethical discourse into action, we introduce a ranked priority matrix (Table&#160;<xref rid=\"Tab1\" ref-type=\"table\">1</xref>) classifying immediacy of ethical concerns: short-term&#8212;bias and transparency; mid-term&#8212;consent, data sovereignty, and workforce impact; long-term&#8212;algorithmic autonomy and sustainability. This ranked matrix translates abstract ethical discourse into staged action priorities, providing regulators and researchers with a pragmatic roadmap for responsible AI integration in toxicology. This framing provides a practical roadmap for regulators and researchers.<table-wrap id=\"Tab1\" position=\"float\" orientation=\"portrait\"><label>Table&#160;1</label><caption><p>Ranked ethical priorities for AI in toxicology</p></caption><table frame=\"hsides\" rules=\"groups\"><thead><tr><th align=\"left\" colspan=\"1\" rowspan=\"1\">Time Horizon</th><th align=\"left\" colspan=\"1\" rowspan=\"1\">Ethical Focus Area</th><th align=\"left\" colspan=\"1\" rowspan=\"1\">Core Challenge</th><th align=\"left\" colspan=\"1\" rowspan=\"1\">Operational Imperative / Example Implementation</th></tr></thead><tbody><tr><td align=\"left\" colspan=\"1\" rowspan=\"1\">Short-term (0&#8211;3 years)</td><td align=\"left\" colspan=\"1\" rowspan=\"1\">Bias and Fairness</td><td align=\"left\" colspan=\"1\" rowspan=\"1\">Historical toxicology data reflect systemic, methodological, or demographic biases that can propagate through AI models</td><td align=\"left\" colspan=\"1\" rowspan=\"1\">Conduct <italic toggle=\"yes\">bias audits</italic> across datasets and algorithms; employ fairness metrics (e.g., demographic parity); establish independent oversight panels</td></tr><tr><td align=\"left\" colspan=\"1\" rowspan=\"1\"/><td align=\"left\" colspan=\"1\" rowspan=\"1\">Transparency and Explainability</td><td align=\"left\" colspan=\"1\" rowspan=\"1\">Deep models act as &#8220;black boxes,&#8221; eroding trust and regulatory acceptance</td><td align=\"left\" colspan=\"1\" rowspan=\"1\">Mandate model documentation (model cards); adopt explainable-AI toolkits (e.g., SHAP, LIME); publish interpretability benchmarks per OECD AI Principles</td></tr><tr><td align=\"left\" colspan=\"1\" rowspan=\"1\">Mid-term (3&#8211;10 years)</td><td align=\"left\" colspan=\"1\" rowspan=\"1\">Consent and Data Sovereignty</td><td align=\"left\" colspan=\"1\" rowspan=\"1\">AI training often repurposes human or proprietary toxicology data without ongoing consent or governance</td><td align=\"left\" colspan=\"1\" rowspan=\"1\">Embed <italic toggle=\"yes\">dynamic consent</italic> frameworks; align with GDPR/HIPAA; implement data-provenance tracking and CARE/FAIR compliance</td></tr><tr><td align=\"left\" colspan=\"1\" rowspan=\"1\"/><td align=\"left\" colspan=\"1\" rowspan=\"1\">Workforce Impact and Accountability</td><td align=\"left\" colspan=\"1\" rowspan=\"1\">Automation shifts skill demands, risking displacement or deskilling of laboratory and regulatory personnel</td><td align=\"left\" colspan=\"1\" rowspan=\"1\">Invest in <italic toggle=\"yes\">up-skilling</italic> programs for AI literacy; define shared human&#8211;machine accountability (&#8220;co-pilot&#8221; model)</td></tr><tr><td align=\"left\" colspan=\"1\" rowspan=\"1\">Long-term (10&#8201;+&#8201;years)</td><td align=\"left\" colspan=\"1\" rowspan=\"1\">Algorithmic Autonomy</td><td align=\"left\" colspan=\"1\" rowspan=\"1\">Agentic or self-improving AI may operate beyond human interpretability or oversight</td><td align=\"left\" colspan=\"1\" rowspan=\"1\">Require <italic toggle=\"yes\">human-in-the-loop</italic> governance; implement continuous audit trails, sandboxed deployment, and ethical &#8220;kill switches.&#8221;</td></tr><tr><td align=\"left\" colspan=\"1\" rowspan=\"1\"/><td align=\"left\" colspan=\"1\" rowspan=\"1\">Sustainability and Societal Equity</td><td align=\"left\" colspan=\"1\" rowspan=\"1\">Compute intensity and unequal access threaten environmental and global fairness goals</td><td align=\"left\" colspan=\"1\" rowspan=\"1\">Promote <italic toggle=\"yes\">green AI</italic> metrics (energy transparency, carbon reporting); ensure equitable access for low-resource regulators through federated infrastructures</td></tr></tbody></table></table-wrap></p></sec><sec id=\"Sec9\"><title>Timelines</title><p id=\"Par34\">To contextualize development timelines, near-term (2025&#8211;2030) adoption is expected for federated and xAI workflows; medium-term (2030&#8211;2035) for agentic and digital-twin integration; and long-term (&gt;&#8201;2035) for neuromorphic and quantum computing applications. These projections provide a temporal roadmap for research and regulatory preparation.</p></sec></sec><sec id=\"Sec10\"><title>From Validation Bottlenecks to E-Validation and Companion Agents</title><p id=\"Par35\">The transformative potential of AI-based NAMs in toxicology is increasingly recognized, but it remains bottlenecked by legacy validation frameworks that were originally designed for static, animal-centric assays. Traditional validation&#8212;rooted in ring trials, protocol freezing, and one-to-one concordance with animal models&#8212;cannot accommodate the dynamism, complexity, and continuous learning capabilities of modern AI systems [<xref ref-type=\"bibr\" rid=\"CR7\">7</xref>]. Similar validation bottlenecks are recognized in other domains such as radiology, genomics, and medical device software. The FDA&#8217;s continuous-learning framework and EMA&#8217;s adaptive evidence models offer instructive precedents for how performance-centric validation can coexist with regulatory rigor [<xref ref-type=\"bibr\" rid=\"CR38\">38</xref>, <xref ref-type=\"bibr\" rid=\"CR48\">48</xref>]. The urgent need for faster, more adaptive, and scientifically robust validation pathways has led to the emergence of the e-validation framework, which reimagines the validation process through the lens of AI, translational science, and mechanistic relevance. At the heart of e-validation are five interlocking AI-powered components [<xref ref-type=\"bibr\" rid=\"CR5\">5</xref>]:<list list-type=\"order\"><list-item><p id=\"Par36\"><italic toggle=\"yes\">Smart Reference Chemical Selection</italic> Instead of relying on historical reference compounds chosen by expert consensus&#8212;which often results in overused, biased, or mechanistically narrow test sets&#8212;e-validation deploys clustering algorithms (e.g., k-means, Density-Based Spatial Clustering of Applications with Noise (DBSCAN)) [<xref ref-type=\"bibr\" rid=\"CR49\">49</xref>] to ensure structurally and mechanistically diverse chemical spaces are covered. Reference chemicals are selected not only for their availability and historical data but also for their relevance to human biology and the mechanistic diversity they represent. Chemical clustering leverages molecular fingerprints, bioactivity profiles, and AOP ontology embeddings to ensure mechanistic and structural diversity. This increases coverage of chemical space and improves transferability of validation results across compound classes. These selections can be iteratively refined as new data emerges, and integrated with public databases to ensure regulatory applicability.</p></list-item><list-item><p id=\"Par37\"><italic toggle=\"yes\">Simulation of Validation Study Outcomes</italic> Validation no longer needs to be confined to wet-lab trials with fixed endpoints. The e-validation framework [<xref ref-type=\"bibr\" rid=\"CR50\">50</xref>] uses virtual validation studies that combine physiologically based pharmacokinetic (PBPK) and in vitro biokinetic modeling with QSAR predictions, systems biology networks, and statistical optimization to pre-test study designs [<xref ref-type=\"bibr\" rid=\"CR51\">51</xref>&#8211;<xref ref-type=\"bibr\" rid=\"CR53\">53</xref>]. By simulating experimental conditions&#8212;such as dosing ranges, time points, and replication schemes&#8212;AI-driven modeling enables scenario testing, power calculations, and sensitivity analyses before laboratory execution. This allows identification of designs with the highest informational yield and reproducibility, while minimizing resource demands and ethical costs.</p><p id=\"Par38\">Simulated validation thus becomes an evidence-preparation stage that anticipates real-world outcomes, identifies key sources of uncertainty, and guides optimal experimental design [<xref ref-type=\"bibr\" rid=\"CR32\">32</xref>, <xref ref-type=\"bibr\" rid=\"CR50\">50</xref>, <xref ref-type=\"bibr\" rid=\"CR54\">54</xref>]. Iterative simulations can compare study architectures across virtual populations, generating quantitative predictions of expected variance and robustness. The result is not a replacement for empirical testing but a refinement step that makes subsequent physical validation faster, more reproducible, and better aligned with human-relevant biology.</p></list-item><list-item><p id=\"Par39\"><italic toggle=\"yes\">Mechanistic Cross-Validation </italic>via<italic toggle=\"yes\"> Literature Mining</italic> Mechanistic validation [<xref ref-type=\"bibr\" rid=\"CR55\">55</xref>, <xref ref-type=\"bibr\" rid=\"CR56\">56</xref>], often under-emphasized in traditional frameworks, becomes a cornerstone of e-validation. AI&#8212;particularly large language models (LLMs) and graph neural networks&#8212;can mine the literature for evidence of pathway activation, AOP concordance, and causal inference [<xref ref-type=\"bibr\" rid=\"CR28\">28</xref>]. Using tools like NLP-enhanced Bradford Hill assessments [<xref ref-type=\"bibr\" rid=\"CR28\">28</xref>], mechanistic cross-validation aligns NAMs with human-relevant biological processes rather than simply mimicking animal results.</p></list-item><list-item><p id=\"Par40\"><italic toggle=\"yes\">AI-Enhanced Training Dashboards</italic> A core component of the validation process is ensuring consistent implementation across participating labs. AI-enhanced dashboards offer protocol customization, troubleshooting, video support, and live guidance for end users. This fosters consistency and transparency across validation studies while democratizing access to best practices. Post-validation, these dashboards serve as knowledge transfer tools for regulatory and industry uptake.&#160;Current exemplars include the OECD AI Platform<xref ref-type=\"fn\" rid=\"Fn33\">33</xref> and NIH NAM-Navigator<xref ref-type=\"fn\" rid=\"Fn34\">34</xref> platforms, which provide standardized dashboard hosting under neutral, multi-stakeholder governance. Such public&#8211;private stewardship minimizes conflicts of interest while ensuring transparent, auditable dissemination of training materials.</p></list-item><list-item><p id=\"Par41\"><italic toggle=\"yes\">Continuous Performance Monitoring and Companion Agents</italic> The concept of companion post-validation agents represents an evolution in how validated methods are maintained over time. These autonomous AI systems monitor performance metrics in real-world use, perform back-testing as new data accumulates, and flag when retraining or re-validation may be necessary. This marks a departure from the current static view of validation and introduces a lifecycle model where AI-based NAMs evolve alongside evidence and regulatory requirements [<xref ref-type=\"bibr\" rid=\"CR20\">20</xref>].</p></list-item></list></p><p id=\"Par42\">This entire e-validation framework resonates with and operationalizes the TREAT criteria&#8212;Trustworthiness, Reproducibility, Explainability, Applicability, and Transparency&#8212;proposed for AI applications in regulatory contexts [<xref ref-type=\"bibr\" rid=\"CR6\">6</xref>]. Importantly, e-validation complements the modular and fit-for-purpose concepts already gaining traction in validation science. It also aligns with the translational medicine paradigm, particularly through the use of qualified biomarkers to benchmark predictive and mechanistic validity, not merely historical concordance with animal models [<xref ref-type=\"bibr\" rid=\"CR32\">32</xref>].</p><p id=\"Par43\">On a philosophical level, e-validation addresses key ethical and epistemological critiques of the existing validation paradigm. Validation, as discussed [<xref ref-type=\"bibr\" rid=\"CR38\">38</xref>], must shift from being a static gatekeeper to a dynamic enabler&#8212;one that ensures scientific credibility without stifling innovation [<xref ref-type=\"bibr\" rid=\"CR33\">33</xref>]. It must accommodate uncertainty, embrace adaptive designs, and prioritize human health relevance over legacy comparators.</p><p id=\"Par44\">In sum, e-validation and companion agents together propose a paradigm shift from \"validate and forget\" to \"validate, monitor, and evolve.\" This approach offers not only a scientific upgrade but also an ethical one&#8212;aligning toxicology with the values of animal replacement, human relevance, and continuous improvement [<xref ref-type=\"bibr\" rid=\"CR34\">34</xref>]. Importantly, AI need not imply immediate full replacement of animal studies. Progressive refinement and reduction through AI-enabled prioritization can drastically decrease animal use while maintaining data continuity. The e-validation framework thus supports all 3Rs&#8212;replacement, reduction, and refinement&#8212;within a unified strategy (Fig.&#160;<xref rid=\"Fig3\" ref-type=\"fig\">3</xref>).<fig id=\"Fig3\" position=\"float\" orientation=\"portrait\"><label>Fig.&#160;3</label><caption><p><bold>The concept of e-validation</bold>. The figure depicts the key components of an AI-facilitated validation process for in vitro, computational and AI-based methods [<xref ref-type=\"bibr\" rid=\"CR7\">7</xref>, <xref ref-type=\"bibr\" rid=\"CR51\">51</xref>]</p></caption><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"MO3\" position=\"float\" orientation=\"portrait\" xlink:href=\"40572_2025_514_Fig3_HTML.jpg\"/></fig></p><sec id=\"Sec11\"><title>Bridging Innovation and Oversight</title><p id=\"Par45\">The surge in AI capabilities for toxicology&#8212;spanning predictive modeling, data harmonization, mechanistic insight generation, and in silico experimentation&#8212;has transformed what is technically possible. However, this innovation outpaces existing validation, governance, and oversight structures, prompting a critical reckoning within regulatory science. Bridging this innovation-oversight divide is essential to harness AI's potential responsibly, credibly, and equitably. This section explores three central dimensions: trust and epistemology, governance frameworks, and the ethical&#8211;political context of regulatory AI [<xref ref-type=\"bibr\" rid=\"CR35\">35</xref>].</p></sec><sec id=\"Sec12\"><title>Rethinking Trust in the Age of Algorithmic Prediction</title><p id=\"Par46\"><italic toggle=\"yes\">AI's epistemological disruption</italic> to toxicology centers on the tension between accuracy and understanding. Classical validation frameworks emphasize reproducibility, transparency, and mechanistic clarity. Yet many AI systems, particularly deep neural networks, offer robust performance without interpretable logic or consistent reproducibility, particularly when outputs depend on random initializations or iterative retraining [<xref ref-type=\"bibr\" rid=\"CR36\">36</xref>].</p><p id=\"Par47\">This raises profound questions:<list list-type=\"bullet\"><list-item><p id=\"Par48\">Can we trust AI systems we do not fully understand?</p></list-item><list-item><p id=\"Par49\">Should we prioritize empirical performance over mechanistic transparency?</p></list-item><list-item><p id=\"Par50\">What constitutes sufficient evidence for regulatory confidence?</p></list-item></list></p><p id=\"Par51\">While some argue that non-reproducible models cannot meet the standards of toxicology&#8212;a field long reliant on Good Laboratory Practice (GLP) and standard operating procedures&#8212;others propose a performance-centric validation, where a model is trusted if it consistently delivers accurate predictions under predefined conditions [<xref ref-type=\"bibr\" rid=\"CR37\">37</xref>]. This tension recalls debates in medicine over \"black-box\" diagnostics that outperform clinicians but resist human explanation.</p><p id=\"Par52\">One potential resolution is layered trust architecture, where models are conditionally accepted for tightly scoped use-cases (e.g., screening or prioritization) but require additional validation layers&#8212;such as explainable AI (xAI), post-deployment monitoring, and uncertainty quantification&#8212;for broader applications [<xref ref-type=\"bibr\" rid=\"CR38\">38</xref>]. This reminds of the &#8220;<italic toggle=\"yes\">incremental validation</italic>&#8221; we suggested earlier expanding applicability domains continuously [<xref ref-type=\"bibr\" rid=\"CR57\">57</xref>].</p><sec id=\"Sec13\"><title>Building Adaptive, Collaborative Oversight Frameworks</title><p id=\"Par53\">To integrate AI safely into toxicology, oversight must evolve from static validation to adaptive lifecycle governance. This shift is already underway in adjacent sectors. The FDA's action plan for AI/ML-based software<xref ref-type=\"fn\" rid=\"Fn35\">35</xref> emphasizes the continuous learning nature of these models and proposes pre-determined change control protocols, real-time monitoring, and transparency measures [<xref ref-type=\"bibr\" rid=\"CR39\">39</xref>]. Similarly, OECD and EU initiatives now support modular, fit-for-purpose validation and the use of evidence-weighted frameworks that include biomarker performance, mechanistic validity, and confidence intervals, rather than binary concordance with animal models [<xref ref-type=\"bibr\" rid=\"CR40\">40</xref>]. These initiatives are advancing steadily: the OECD modular validation pilot completed two inter-laboratory case studies in 2025, and the EU ONTOX project, pioneering a lot of AI use in toxicology, reached mid-term milestones including AOP alignment and a publicly released model catalogue.</p><p id=\"Par54\">A centerpiece of this new oversight landscape is the e-validation framework (see above). This approach aligns with the TREAT principles&#8212;Trustworthiness, Reproducibility, Explainability, Applicability, and Transparency&#8212;which form an emerging gold standard for AI in safety&#8211;critical contexts. Rather than validating a model once and freezing it, the emphasis shifts to dynamic credibility, where validation is an ongoing, evidence-responsive process [<xref ref-type=\"bibr\" rid=\"CR6\">6</xref>].</p><p id=\"Par55\">Global harmonization is also critical. Collaborative initiatives such as the Global Coalition for Regulatory Science Research (GCRSR)<xref ref-type=\"fn\" rid=\"Fn36\">36</xref> and International Cooperation on Alternative Test Methods (ICATM)<xref ref-type=\"fn\" rid=\"Fn37\">37</xref> aim to standardize AI validation expectations across borders, avoiding the emergence of divergent regulatory ecosystems that could fragment trust or stall progress.</p></sec></sec><sec id=\"Sec14\"><title>Ethics, Equity, and the Politics of Risk</title><p id=\"Par56\">While the technical capabilities of AI-enabled NAMs continue to expand&#8212;delivering increasingly accurate, scalable, and human-relevant predictions&#8212;regulatory science must grapple with deep, foundational questions that challenge long-held assumptions about evidence, trust, and oversight [<xref ref-type=\"bibr\" rid=\"CR58\">58</xref>]. One such question concerns the reliability of non-reproducible but consistently accurate AI models. Traditionally, reproducibility has been a cornerstone of toxicological validation, but AI models&#8212;especially those employing deep learning or probabilistic outputs&#8212;often operate with degrees of stochasticity that defy exact duplication. This calls for a paradigm shift in how reproducibility is defined and evaluated, especially if models demonstrate performance stability over time and across datasets [<xref ref-type=\"bibr\" rid=\"CR7\">7</xref>].</p><p id=\"Par57\">Another core issue is the requirement for explainability. Should the ability to interpret an AI model's decision pathway be a precondition for regulatory acceptance, or is empirical accuracy alone sufficient in specific contexts? While many support explainability as a matter of transparency and trust, Bhuller et al. remind us that ethical principles such as autonomy and open decision-making also demand interpretability, especially in decisions that affect public health or environmental protection [<xref ref-type=\"bibr\" rid=\"CR50\">50</xref>]. Ensuring that stakeholders can make informed choices about risk assessments aligns with both scientific integrity and moral norms around fairness and accountability.</p><p id=\"Par58\">Equally pressing is the question of how to manage and correct for the biases embedded in legacy toxicological datasets, many of which were generated using outdated or ethically questionable practices. These datasets&#8212;often used to train AI models&#8212;carry forward implicit assumptions and structural disparities. Without active measures to audit and mitigate these biases, AI may amplify, rather than eliminate, existing inequities in risk assessment. Ethical principles such as \"reduce disparities\" and \"maintain respect and trust,\" as articulated in Bhuller et al.'s projector model, provide important guidance for navigating these challenges [<xref ref-type=\"bibr\" rid=\"CR50\">50</xref>].</p><p id=\"Par59\">In response to these dilemmas, consensus is emerging around a \"co-pilot\" model for AI integration into regulatory workflows. Rather than replacing human expertise, AI is envisioned as an analytical assistant: augmenting human reasoning with speed, scope, and statistical rigor, while keeping the final decision authority with human risk assessors. This reflects an ethic of adaptability and shared decision-making, balancing innovation with oversight in a way that aligns with both public trust and institutional responsibility.</p><p id=\"Par60\">Moreover, bridging innovation and oversight requires active participation in global harmonization initiatives. Regulatory bodies such as the U.S. FDA are setting new precedents with their lifecycle-based principles for AI/ML models, emphasizing continual model monitoring, retraining protocols, and transparency obligations [<xref ref-type=\"bibr\" rid=\"CR59\">59</xref>]. Meanwhile, the OECD and its members have adopted flexible, tiered validation strategies that accommodate emerging technologies and uphold principles like \"fit-for-purpose\" and \"evidence-based decision-making.\" Global platforms such as the GCRSR promote capacity-building through training and joint guidance efforts, ensuring that both high- and low-resource countries can participate in and benefit from the AI transformation of toxicology.</p><p id=\"Par61\">These developments represent not only a modernization of regulatory science, but also a reassertion of its ethical mandate. As emphasized in the projector model proposed by Bhuller et al., ethical principles such as openness, stakeholder engagement, fairness, and the One Health perspective must be integral to every phase of risk decision-making&#8212;from problem formulation and data generation to model deployment and post-validation monitoring [<xref ref-type=\"bibr\" rid=\"CR50\">50</xref>]. In this light, oversight is not an obstacle to innovation, but its ethical scaffold&#8212;ensuring that new technologies serve not only efficiency and accuracy but also justice, transparency, and the collective well-being of humans, animals, and the environment.</p><p id=\"Par62\">To navigate these tensions, ethical AI for toxicology must embed:<list list-type=\"bullet\"><list-item><p id=\"Par63\"><italic toggle=\"yes\">Bias audits and data provenance tracking</italic>, to ensure inclusivity and accuracy across subpopulations,</p></list-item><list-item><p id=\"Par64\"><italic toggle=\"yes\">xAI methods</italic> to explain predictions in human-understandable terms,</p></list-item><list-item><p id=\"Par65\"><italic toggle=\"yes\">Participatory governance</italic>, involving civil society, regulators, scientists, and industry in model design, deployment, and oversight, and</p></list-item><list-item><p id=\"Par66\"><italic toggle=\"yes\">Tiered access mechanisms</italic>, ensuring that low-resource regulatory agencies can benefit from AI without ceding sovereignty to commercial or technical gatekeepers.</p></list-item></list></p><p id=\"Par67\">Bias audits are rapidly becoming an essential component of both traditional and AI-driven toxicological workflows, offering a structured way to identify and mitigate systematic errors that can distort study findings and mislead regulatory decisions. As discussed by Hartung et al. (2025), these audits focus on detecting various forms of bias&#8212;such as selection, performance, detection, attrition, and reporting biases&#8212;in experimental and computational studies [<xref ref-type=\"bibr\" rid=\"CR60\">60</xref>]. In the context of AI-enabled toxicology, bias audits must expand beyond classical risk of bias tools to also interrogate data provenance, model assumptions, algorithmic fairness, and outcome reproducibility. This is critical given the susceptibility of AI systems to <italic toggle=\"yes\">data bias</italic> (e.g., non-representative training sets), <italic toggle=\"yes\">algorithmic bias</italic> (e.g., overfitting, feature selection bias), and <italic toggle=\"yes\">institutional bias</italic> (e.g., confirmation bias embedded during model development). As such, effective bias audits should integrate human-led domain expertise with automated tools for bias detection&#8212;such as SHAP or LIME for model explainability, or AI-enabled protocol checkers for methodological consistency. The goal is not only to flag risks, but to estimate the <italic toggle=\"yes\">probabilistic impact and direction</italic> of those biases on predicted outcomes, ultimately guiding safer, more equitable chemical assessments.</p><p id=\"Par68\">Moreover, as discussed already, a co-pilot paradigm is gaining favor, where AI may offer expansive data integration, mechanistic modeling, and scenario simulation, but final decisions remain with expert risk assessors who can weigh context, uncertainty, and ethical nuance. This co-pilot model provides a pragmatic equilibrium between innovation and oversight, autonomy and control, speed and trust.<xref ref-type=\"fn\" rid=\"Fn38\">38</xref></p><p id=\"Par69\">In conclusion, bridging innovation and oversight requires nothing less than a rethinking of what validation means in the age of AI. Static frameworks must give way to dynamic ecosystems. Reproducibility must be complemented by robustness. Trust must be earned through transparency, feedback, and performance. Only then can toxicology fully benefit from the predictive power of AI while remaining true to its ethical commitments and societal mandate [<xref ref-type=\"bibr\" rid=\"CR6\">6</xref>, <xref ref-type=\"bibr\" rid=\"CR61\">61</xref>].</p></sec></sec><sec id=\"Sec15\"><title>AI Readiness Landscape: From Capacity to Consequence</title><p id=\"Par70\">The evolving landscape of AI readiness&#8212;spanning technological capacity, cost, trust, and institutional adoption&#8212;signals a pivotal moment for its integration into toxicology. The <italic toggle=\"yes\">2025 Stanford AI Index Report</italic> [<xref ref-type=\"bibr\" rid=\"CR62\">62</xref>] provides a comprehensive, global benchmark of this transformation, with findings that directly reinforce the feasibility and urgency of embedding AI into toxicological science and regulatory decision-making.</p><sec id=\"Sec16\"><title>Scaling with Affordability and Accessibility</title><p id=\"Par71\">One of the most striking developments is the dramatic drop in inference cost for large language models. A system performing at the level of GPT-3.5 now costs less than $0.07 per million tokens, down from $20 in late 2022&#8212;a&#8201;&gt;&#8201;280-fold reduction in 18&#160;months [<xref ref-type=\"bibr\" rid=\"CR54\">54</xref>]. This cost democratization, coupled with the rise of small, efficient models (e.g., Microsoft's Phi-3-mini with 3.8B parameters), expands access for academic labs, startups, and public health agencies alike.</p><p id=\"Par72\">Meanwhile, model performance is saturating at the frontier: the Elo score gap between the top and 10th-ranked models has narrowed from 11.9% to just 5.4% in one year, and the top two models are now separated by only 0.7%. This convergence marks a transition from raw power to domain specialization, interpretability, and real-world integration&#8212;a shift that favors toxicology applications where explainability and regulatory trust are paramount [<xref ref-type=\"bibr\" rid=\"CR54\">54</xref>].</p></sec><sec id=\"Sec17\"><title>Institutionalization of AI in Biomedicine</title><p id=\"Par73\">AI is increasingly embedded in real-world health technologies. In 2023 alone, the FDA approved 223 AI-enabled medical devices, up from just 6 in 2015 [<xref ref-type=\"bibr\" rid=\"CR54\">54</xref>]. Simultaneously, domain-specific foundation models like Med-Gemini,<xref ref-type=\"fn\" rid=\"Fn39\">39</xref> ChexAgent,<xref ref-type=\"fn\" rid=\"Fn40\">40</xref> and EchoCLIP [<xref ref-type=\"bibr\" rid=\"CR63\">63</xref>] are redefining how AI processes clinical, radiological, and&#8201;~&#8201;omics data.</p><p id=\"Par74\">These developments parallel trends in toxicology, where in silico predictions, high-content screening, and organoid data require robust interpretive frameworks. The normalization of AI across regulatory medicine validates the prospect of similar uptake in chemical risk assessment&#8212;particularly for evidence-weighted read-across, developmental neurotoxicity, and adverse outcome pathway (AOP) modeling [<xref ref-type=\"bibr\" rid=\"CR7\">7</xref>].</p></sec><sec id=\"Sec18\"><title>Trust Gaps and the Rise of Responsible AI Benchmarks</title><p id=\"Par75\">Despite technical advances, responsible AI (RAI) practice lags behind deployment. The number of reported AI incidents increased by over 56% in 2024 [<xref ref-type=\"bibr\" rid=\"CR54\">54</xref>], while only a fraction of models are evaluated on emerging safety and transparency benchmarks like HELM Safety<xref ref-type=\"fn\" rid=\"Fn41\">41</xref> [<xref ref-type=\"bibr\" rid=\"CR64\">64</xref>] or Fact-Checking Transparency Benchmarks (FACTS).<xref ref-type=\"fn\" rid=\"Fn42\">42</xref> Noteworthy, AIR-Bench 2024<xref ref-type=\"fn\" rid=\"Fn43\">43</xref> is a benchmark based on risk categories from regulations and policies evaluates models on a comprehensive taxonomy of AI risks (currently 8 government regulations and 16 company policies into a four-tiered safety taxonomy with 314 granular risk categories) enabling standardized evaluation of AI model safety across jurisdictions and regulatory frameworks. They provide standardized benchmarks, open-source code, and public leaderboards to ensure transparency in evaluating AI models, especially Large Language Models, including aspects like safety, bias, and toxicity (N.B., &#8220;toxicity&#8221; in the context of AI models refers to the generation or amplification of harmful, offensive, or malicious content by an artificial intelligence system).</p><p id=\"Par76\">We will have to explore how this translates to possible benchmarks for AI in the safety sciences and it underscores the relevance of the proposed TREAT framework (Trustworthiness, Reproducibility, Explainability, Applicability, Transparency) [<xref ref-type=\"bibr\" rid=\"CR6\">6</xref>]. The AI Index data supports the notion that post-validation companion agents and continuous uncertainty monitoring are not aspirational concepts&#8212;but necessary guardrails for high-stakes applications [<xref ref-type=\"bibr\" rid=\"CR7\">7</xref>].</p></sec><sec id=\"Sec19\"><title>Strategic Implications for Toxicology</title><p id=\"Par77\">The convergence of accelerated compute capabilities, diminishing inference costs, plateauing performance across frontier models, and the mainstreaming of regulatory frameworks for AI has created fertile ground for the transformation of toxicology. What once appeared speculative&#8212;AI-enabled predictive toxicology replacing traditional animal-based paradigms&#8212;is now increasingly feasible. These developments reflect not just a shift in technology, but a profound maturation in the infrastructure and collective mindset surrounding AI in the life sciences. As such, the field stands at a pivotal moment: the readiness for large-scale adoption of AI-based toxicology is no longer a question of possibility, but of strategy. It is now more about trust building and change management than about technological development.</p><p id=\"Par78\">To seize this momentum, coordinated action is essential across several key fronts. First, the development and deployment of benchmarking frameworks tailored to toxicological applications is crucial. Tools like HELM and AIR-Bench, originally developed for broader AI model safety evaluations, must be adapted to encompass toxicology-specific endpoints, such as genotoxicity, developmental neurotoxicity, or organ-specific adverse effects. Such benchmarks will provide standardized, comparative performance metrics and foster trust in AI-based predictions across regulatory and research domains.</p><p id=\"Par79\">Second, model auditability must become a cornerstone of AI deployment in toxicology. Integrating explainable AI (xAI) techniques&#8212;such as SHAP values, saliency maps, i.e., visual or numerical representations that highlight the most important regions of an input that significantly influence a machine learning model&#8217;s prediction, or feature attribution tools, i.e., methods and software that help interpret and explain the predictions of complex machine learning models by quantifying the contribution of each input feature to a given prediction,&#8212;will help regulators, scientists, and other stakeholders interpret predictions and trace them back to specific data inputs or mechanistic reasoning. This integration is not merely a technical enhancement; it is an accountability mechanism that ensures AI models remain interpretable, responsive to feedback, and transparent in their assumptions and outputs.</p><p id=\"Par80\">Third, achieving the full promise of AI-based toxicology requires robust global data-sharing frameworks. Given the distributed nature of toxicological data&#8212;ranging from industry submissions to academic omics studies and regulatory exposure registries&#8212;traditional centralized databases are no longer sufficient. Federated learning and encrypted collaboration platforms offer a way forward, enabling decentralized toxicology consortia to jointly train models without compromising proprietary or sensitive information. This is particularly promising for applications like chemical similarity learning, read-across modeling, and transfer learning for rare or novel endpoints. Increasingly, experience is gained from large pharma consortia on toxicology data sharing and analysis such as eTox,<xref ref-type=\"fn\" rid=\"Fn44\">44</xref> eTRANSAFE<xref ref-type=\"fn\" rid=\"Fn45\">45</xref> [<xref ref-type=\"bibr\" rid=\"CR65\">65</xref>] and VICT3R<xref ref-type=\"fn\" rid=\"Fn46\">46</xref> [<xref ref-type=\"bibr\" rid=\"CR66\">66</xref>] by the Innovative Medicines Initiative (IMI), now Innovative Health Initiative (IHI). eTox created a large, shared toxicology database (eTOXsys) containing information from over 8,000 studies on nearly 2,000 compounds. eTRANSAFE integrated over 10,000 pharmacological studies from pharmaceutical companies into a unified system, called ToxHub. VICT3R is a public&#8211;private partnership launched in 2024 dedicated to reducing animal use in toxicology research by developing Virtual Control Groups (VCGs) based on data sharing by 23 pharmaceutical companies and an increasing number of Contract Research Organizations (CRO). It was developed out of a workshop organized by our center [<xref ref-type=\"bibr\" rid=\"CR67\">67</xref>]. These projects set a new standard for data sharing in pharmaceutical safety by building a secure, standardized, and collaborative data ecosystem that will continue to benefit drug development and regulatory science. Nonetheless, federated learning complicates standardization and auditability. Harmonized metadata ontologies, cryptographically signed model updates, and inter-node proficiency testing are needed to ensure quality control and consistent ethical compliance across decentralized infrastructures.</p><p id=\"Par81\">Finally, no discussion of strategy is complete without addressing ethical oversight. As AI systems become embedded in regulatory and public health decisions, the inclusion of equity audits in the design and deployment of new approach methodologies (NAMs) is essential. These audits should examine not only the technical performance of AI models across demographic subgroups, but also the representativeness of training datasets, the inclusiveness of development processes, and the potential for disproportionate impacts on vulnerable populations. Ethical governance must be integrated from the outset&#8212;not as an afterthought, but as a core design principle.</p><p id=\"Par82\">Together, these actions form a blueprint for scaling AI in toxicology both responsibly and effectively. They recognize that readiness is not only about technological capability, but about cultural, regulatory, and ethical alignment. As the field advances, these pillars will shape the transition from fragmented innovation to a harmonized, global infrastructure for human-relevant safety science.</p></sec></sec><sec id=\"Sec20\"><title>Outlook: From Disruption to Reinvention</title><p id=\"Par83\">Artificial intelligence is poised not merely to streamline existing toxicological methods but to fundamentally transform how we approach chemical safety assessment. In the regulatory context, AI-based NAMs are expected to integrate directly into the pre-clinical&#8211;to&#8211;clinical continuum. Digital-twin and probabilistic simulation models can inform micro-dosing, adaptive trial design, and post-market pharmacovigilance, bridging current gaps between toxicology and clinical risk evaluation. Rather than replicating the outcomes of traditional animal studies, the true potential of AI lies in generating human-relevant, mechanistically informed predictions that are more accurate, ethical, and actionable. This shift represents a reinvention of toxicology itself, aligning the field with the imperatives of precision public health, sustainable innovation, and evidence-based policy.</p><p id=\"Par84\">Realizing this vision requires a comprehensive reevaluation of the data that drive toxicological inference. It begins with a decisive commitment to improving data quality&#8212;not only in terms of statistical robustness or completeness, but also in how representative datasets are of human biology, diverse populations, and realistic exposure scenarios. Poorly curated or biased training data can entrench historical errors, particularly when drawn from outdated or poorly standardized animal studies. Therefore, the toxicology community must invest in systematic data FAIRification, curated repositories, and the inclusion of underrepresented endpoints and vulnerable subpopulations.</p><p id=\"Par85\">Parallel to this, the field must advance xAI and causal modeling frameworks that move beyond correlational outputs toward biological intelligibility. Unlike traditional black-box models, xAI tools can identify the mechanistic underpinnings of predicted effects, providing transparency that fosters both regulatory trust and scientific insight. Causal inference frameworks&#8212;such as counterfactual reasoning, graphical models, and pathway reconstruction&#8212;enable researchers to trace predicted outcomes back to molecular initiating events or key events in adverse outcome pathways. This mechanistic clarity is not only scientifically rigorous, but also essential for replacing animal models with human-relevant, ethically grounded alternatives.</p><p id=\"Par86\">Equally transformative is the need to embrace validation paradigms that are dynamic, iterative, and performance-centered. The e-validation framework exemplifies this shift by integrating AI tools for reference compound selection, simulation-based protocol design, and post-validation surveillance. Rather than freezing test methods at a single point in time, adaptive validation enables continuous learning, uncertainty monitoring, and context-specific calibration. This is particularly vital for AI models, which evolve with incoming data and may respond to environmental, demographic, or regulatory changes in real-time.</p><p id=\"Par87\">Ultimately, the reinvention of toxicology through AI demands a reimagining of regulatory science itself&#8212;not as a rigid gatekeeper of past standards, but as a co-evolving, evidence-driven system capable of learning and adapting alongside the tools it evaluates. Regulatory frameworks must shift from static validation checklists to lifecycle governance models, incorporating probabilistic risk estimates, digital trust audits, and stakeholder-centered transparency protocols. As AI systems increasingly power both prediction and decision-support, the role of regulators will expand to include oversight of algorithmic integrity, post-market surveillance, and equitable deployment.</p><p id=\"Par88\">This reinvention is not merely a technological upgrade&#8212;it is a paradigm shift. It offers an opportunity to align toxicology with 21st-century values: replacing harm with prevention, opacity with transparency, and extrapolation with human specificity. In doing so, AI can fulfill its promise not only to accelerate toxicological science, but to transform it into a more just, responsive, and human-centered discipline.</p></sec><sec id=\"Sec21\"><title>Conclusions</title><p id=\"Par89\">Artificial intelligence is no longer a distant promise for toxicology&#8212;it is the transformative force now shaping the discipline's future. Over the course of this review, we have mapped the landscape of AI-driven change in toxicology across technical, regulatory, ethical, and strategic dimensions. These developments mark a critical inflection point: toxicology is transitioning from adapting AI to co-evolving with it, entering a new era of mechanistically grounded, human-relevant, and dynamically validated safety science.</p><p id=\"Par90\">Central to this transformation is the recognition that AI does not merely automate legacy workflows&#8212;it reinvents them. Multimodal AI, causal inference, generative modeling, and physics-informed learning have expanded the predictive and interpretive capabilities of toxicology beyond what animal models can achieve. Combined with real-time data access, edge computing, and federated learning, these tools have made toxicology more responsive, personalized, and ethically aligned. The emergence of digital twins and agentic AI systems further signals the rise of intelligent, autonomous toxicology pipelines, capable of simulation, prediction, and adaptation at unprecedented scale.</p><p id=\"Par91\">However, the realization of AI's full potential demands more than technical readiness&#8212;it requires a transformation in how toxicology conceptualizes validation, governance, and trus<bold>t</bold>. The e-validation framework, grounded in the TREAT principles, exemplifies this shift [<xref ref-type=\"bibr\" rid=\"CR6\">6</xref>]. It introduces adaptive, AI-powered modules for selecting reference chemicals, simulating outcomes, cross-validating mechanisms, and ensuring lifecycle monitoring through post-validation companion agents [<xref ref-type=\"bibr\" rid=\"CR7\">7</xref>].</p><p id=\"Par92\">At the same time, the ethical landscape must evolve alongside the technical. Bias audits, participatory governance, and equity-aware development practices are no longer optional&#8212;they are foundational. As AI systems increasingly shape regulatory decisions, these systems must be interrogated for their fairness, representativeness, and inclusivity. The co-pilot model&#8212;where AI augments rather than replaces human judgment&#8212;offers a pragmatic path forward, one that combines the scale and speed of algorithms with the contextual, moral, and experiential insights of human decision-makers.</p><p id=\"Par93\">The global readiness for AI in toxicology is accelerating. With inference costs plummeting, model performance stabilizing, and regulatory precedent expanding&#8212;most notably through the FDA's endorsement of AI-enabled diagnostics&#8212;the infrastructure is now in place. The challenge ahead lies in coordination: establishing shared benchmarks, harmonized validation frameworks, secure data-sharing ecosystems, and inclusive ethical oversight. These are not merely supporting structures; they are the scaffolds upon which the future of responsible AI-driven toxicology will be built.</p><p id=\"Par94\">In sum, this moment offers more than an opportunity for innovation&#8212;it demands reinvention. AI offers the means not just to do toxicology faster or cheaper, but to do it better: with more precision, with greater relevance to human biology, and with deeper ethical integrity. It challenges the field to move beyond inherited paradigms of animal testing and binary endpoints, toward a future where chemical safety science is data-rich, mechanistically informed, and globally inclusive.</p><p id=\"Par95\">If this vision is realized&#8212;through science, governance, and trust&#8212;AI will not merely assist toxicology. It will elevate it. And in doing so, it will help build a future where the assessment of chemical risk is not only smarter, but safer, more equitable, and fundamentally more humane.</p></sec><sec id=\"Sec22\"><title>Key References</title><p id=\"Par96\">\n<list list-type=\"bullet\"><list-item><p id=\"Par97\">Hartung T, Kleinstreuer NC. Challenges and opportunities for validation of AI-based new approach methods. ALTEX 2025;42(1):3-21.<list list-type=\"bullet\"><list-item><p id=\"Par98\">&#9675; Conceptual paper on validation of AI-facilitated methods coauthored with the then head of the US validation body.</p></list-item></list></p></list-item><list-item><p id=\"Par99\">Hartung T, Whelan, Tong W, Califf RM. Is Regulatory Science Ready for Artificial Intelligence? NPJ Digital Medicine 2025;8:200<list list-type=\"bullet\"><list-item><p id=\"Par100\">&#9675; Opinion piece on the prospects of building trust into the regulatory use of AI coauthored with at the time FDA leadership and head of the EU validation body.</p></list-item></list></p></list-item><list-item><p id=\"Par101\">Kleinstreuer N, Hartung T. Artificial Intelligence (AI) &#8211; it&#8217;s the end of the tox as we know it (and I feel fine)&#8212;AI for Predictive Toxicology. Arch Toxicol. 2024;98:735&#8211;754<list list-type=\"bullet\"><list-item><p id=\"Par102\">&#9675; Extensive review of the history, current examples and future prospects of AI in toxicology coauthored with the then head of the US validation body.</p></list-item></list></p></list-item></list>\n</p></sec></body><back><fn-group><fn id=\"Fn1\"><label>1</label><p id=\"Par107\"><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://comptox.epa.gov/dashboard/\">https://comptox.epa.gov/dashboard/</ext-link></p></fn><fn id=\"Fn2\"><label>2</label><p id=\"Par108\"><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://qsartoolbox.org\">https://qsartoolbox.org</ext-link></p></fn><fn id=\"Fn3\"><label>3</label><p id=\"Par109\"><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://ntp.niehs.nih.gov/whatwestudy/niceatm/comptox/ct-ice/ice\">https://ntp.niehs.nih.gov/whatwestudy/niceatm/comptox/ct-ice/ice</ext-link></p></fn><fn id=\"Fn4\"><label>4</label><p id=\"Par110\"><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://worldfair-project.eu/fair-implementation-profiles/\">https://worldfair-project.eu/fair-implementation-profiles/</ext-link></p></fn><fn id=\"Fn5\"><label>5</label><p id=\"Par111\">FDA. Artificial Intelligence and Machine Learning (AI/ML) Medical Devices. U.S. Food and Drug Administration Annual Report. 2024. Available at: <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://www.fda.gov/medical-devices/software-medical-device-samd/artificial-intelligence-and-machine-learning-aiml-enabled-medical-devices\">https://www.fda.gov/medical-devices/software-medical-device-samd/artificial-intelligence-and-machine-learning-aiml-enabled-medical-devices</ext-link> (last accessed 25 Apr 2025).</p></fn><fn id=\"Fn6\"><label>6</label><p id=\"Par112\"><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://crfm.stanford.edu/fmti/May-2024/index.html\">https://crfm.stanford.edu/fmti/May-2024/index.html</ext-link></p></fn><fn id=\"Fn7\"><label>7</label><p id=\"Par113\">Bommasani et al., 2024, <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://crfm.stanford.edu/fmti/paper.pdf\">https://crfm.stanford.edu/fmti/paper.pdf</ext-link></p></fn><fn id=\"Fn8\"><label>8</label><p id=\"Par114\"><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://xaitk.org\">https://xaitk.org</ext-link></p></fn><fn id=\"Fn9\"><label>9</label><p id=\"Par115\"><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://sites.research.google/med-palm/\">https://sites.research.google/med-palm/</ext-link></p></fn><fn id=\"Fn10\"><label>10</label><p id=\"Par116\"><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://spark.apache.org/docs/latest/index.html\">https://spark.apache.org/docs/latest/index.html</ext-link></p></fn><fn id=\"Fn11\"><label>11</label><p id=\"Par117\"><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://www.ray.io\">https://www.ray.io</ext-link></p></fn><fn id=\"Fn12\"><label>12</label><p id=\"Par118\"><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://www.dask.org\">https://www.dask.org</ext-link></p></fn><fn id=\"Fn13\"><label>13</label><p id=\"Par119\"><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://www.geeksforgeeks.org/deep-learning/what-is-monte-carlo-mc-dropout/\">https://www.geeksforgeeks.org/deep-learning/what-is-monte-carlo-mc-dropout/</ext-link></p></fn><fn id=\"Fn14\"><label>14</label><p id=\"Par120\"><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://docs.aws.amazon.com/prescriptive-guidance/latest/ml-quantifying-uncertainty/deep-ensembles.html\">https://docs.aws.amazon.com/prescriptive-guidance/latest/ml-quantifying-uncertainty/deep-ensembles.html</ext-link></p></fn><fn id=\"Fn15\"><label>15</label><p id=\"Par121\"><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://ermongroup.github.io/cs228-notes/inference/variational/\">https://ermongroup.github.io/cs228-notes/inference/variational/</ext-link></p></fn><fn id=\"Fn16\"><label>16</label><p id=\"Par122\"><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://shap.readthedocs.io/en/latest/index.html\">https://shap.readthedocs.io/en/latest/index.html</ext-link></p></fn><fn id=\"Fn17\"><label>17</label><p id=\"Par123\"><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://christophm.github.io/interpretable-ml-book/overview.html\">https://christophm.github.io/interpretable-ml-book/overview.html</ext-link></p></fn><fn id=\"Fn18\"><label>18</label><p id=\"Par124\"><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://cloud.google.com/vertex-ai\">https://cloud.google.com/vertex-ai</ext-link></p></fn><fn id=\"Fn19\"><label>19</label><p id=\"Par125\"><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://h2o.ai\">https://h2o.ai</ext-link></p></fn><fn id=\"Fn20\"><label>20</label><p id=\"Par126\"><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://www.automl.org/automl-for-x/tabular-data/auto-sklearn/\">https://www.automl.org/automl-for-x/tabular-data/auto-sklearn/</ext-link></p></fn><fn id=\"Fn21\"><label>21</label><p id=\"Par127\"><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://eur-lex.europa.eu/eli/reg/2016/679/oj\">https://eur-lex.europa.eu/eli/reg/2016/679/oj</ext-link></p></fn><fn id=\"Fn22\"><label>22</label><p id=\"Par128\"><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://www.iso.org/standard/42001\">https://www.iso.org/standard/42001</ext-link></p></fn><fn id=\"Fn23\"><label>23</label><p id=\"Par129\"><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://www.oecd.org/en/topics/sub-issues/ai-principles.html\">https://www.oecd.org/en/topics/sub-issues/ai-principles.html</ext-link></p></fn><fn id=\"Fn24\"><label>24</label><p id=\"Par130\"><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://chain.link/education-hub/secure-multiparty-computation-mcp\">https://chain.link/education-hub/secure-multiparty-computation-mcp</ext-link></p></fn><fn id=\"Fn25\"><label>25</label><p id=\"Par131\"><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://eur-lex.europa.eu/eli/reg/2016/679/oj\">https://eur-lex.europa.eu/eli/reg/2016/679/oj</ext-link>.</p></fn><fn id=\"Fn26\"><label>26</label><p id=\"Par132\"><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://www.govinfo.gov/content/pkg/PLAW-104publ191/pdf/PLAW-104publ191.pdf\">https://www.govinfo.gov/content/pkg/PLAW-104publ191/pdf/PLAW-104publ191.pdf</ext-link></p></fn><fn id=\"Fn27\"><label>27</label><p id=\"Par133\"><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/AlphaEvolve.pdf\">https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/AlphaEvolve.pdf</ext-link></p></fn><fn id=\"Fn28\"><label>28</label><p id=\"Par134\"><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://ontox-project.eu\">https://ontox-project.eu</ext-link></p></fn><fn id=\"Fn29\"><label>29</label><p id=\"Par135\"><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://ice.ntp.niehs.nih.gov\">https://ice.ntp.niehs.nih.gov</ext-link></p></fn><fn id=\"Fn30\"><label>30</label><p id=\"Par136\"><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://digital-strategy.ec.europa.eu/en/policies/virtual-human-twins\">https://digital-strategy.ec.europa.eu/en/policies/virtual-human-twins</ext-link></p></fn><fn id=\"Fn31\"><label>31</label><p id=\"Par137\"><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://vito.be/en/projects/edith\">https://vito.be/en/projects/edith</ext-link></p></fn><fn id=\"Fn32\"><label>32</label><p id=\"Par138\"><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://www.vph-institute.org\">https://www.vph-institute.org</ext-link></p></fn><fn id=\"Fn33\"><label>33</label><p id=\"Par139\"><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://oecd.ai/en/\">https://oecd.ai/en/</ext-link></p></fn><fn id=\"Fn34\"><label>34</label><p id=\"Par140\"><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://oacu.oir.nih.gov/new-approach-methodologies\">https://oacu.oir.nih.gov/new-approach-methodologies</ext-link></p></fn><fn id=\"Fn35\"><label>35</label><p id=\"Par141\"><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://www.fda.gov/medical-devices/software-medical-device-samd/artificial-intelligence-and-machine-learning-software-medical-device\">https://www.fda.gov/medical-devices/software-medical-device-samd/artificial-intelligence-and-machine-learning-software-medical-device</ext-link></p></fn><fn id=\"Fn36\"><label>36</label><p id=\"Par142\"><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://gcrsr.net\">https://gcrsr.net</ext-link></p></fn><fn id=\"Fn37\"><label>37</label><p id=\"Par143\"><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://ntp.niehs.nih.gov/whatwestudy/niceatm/iccvam/international-partnerships/icatm\">https://ntp.niehs.nih.gov/whatwestudy/niceatm/iccvam/international-partnerships/icatm</ext-link></p></fn><fn id=\"Fn38\"><label>38</label><p id=\"Par144\"><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://medium.com/data-science/top-10-data-ai-trends-for-2025-4ed785cafe16\">https://medium.com/data-science/top-10-data-ai-trends-for-2025-4ed785cafe16</ext-link></p></fn><fn id=\"Fn39\"><label>39</label><p id=\"Par145\"><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://research.google/blog/advancing-medical-ai-with-med-gemini/\">https://research.google/blog/advancing-medical-ai-with-med-gemini/</ext-link></p></fn><fn id=\"Fn40\"><label>40</label><p id=\"Par146\"><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://stanford-aimi.github.io/chexagent.html\">https://stanford-aimi.github.io/chexagent.html</ext-link></p></fn><fn id=\"Fn41\"><label>41</label><p id=\"Par147\"><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://github.com/stanford-crfm/helm/blob/main/README.md\">https://github.com/stanford-crfm/helm/blob/main/README.md</ext-link></p></fn><fn id=\"Fn42\"><label>42</label><p id=\"Par148\"><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://arxiv.org/html/2410.15135v2\">https://arxiv.org/html/2410.15135v2</ext-link></p></fn><fn id=\"Fn43\"><label>43</label><p id=\"Par149\"><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://arxiv.org/html/2407.17436v2\">https://arxiv.org/html/2407.17436v2</ext-link></p></fn><fn id=\"Fn44\"><label>44</label><p id=\"Par150\"><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://www.ihi.europa.eu/projects-results/project-factsheets/etox\">https://www.ihi.europa.eu/projects-results/project-factsheets/etox</ext-link></p></fn><fn id=\"Fn45\"><label>45</label><p id=\"Par151\"><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://etransafe.eu\">https://etransafe.eu</ext-link></p></fn><fn id=\"Fn46\"><label>46</label><p id=\"Par152\"><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://www.vict3r.eu\">https://www.vict3r.eu</ext-link></p></fn><fn><p><bold>Publisher's Note</bold></p><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn></fn-group><ack><title>Acknowledgements</title><p>The editors would like to thank Monica Espinoza for assisting with the review of this manuscript.</p></ack><notes notes-type=\"author-contribution\"><title>Author Contribution</title><p>T.H. drafted the manuscript and all authors reviewed the manuscript.</p></notes><notes notes-type=\"funding-information\"><title>Funding</title><p>Open Access funding enabled and organized by Projekt DEAL. Funding was received from the European Union&#8217;s Horizon 2020 research and innovation program under grant agreement No.963845 (ONTOX) to both authors. Support by VICT3R to THA is gratefully acknowledged; VICT3R is supported by the Innovative Health Initiative Joint Undertaking (IHI JU) under grant agreement No 101172693. The JU receives support from the European Union&#8217;s Horizon Europe research and innovation programme and COCIR, EFPIA, EuropaBio, MedTech Europe, Vaccines Europe, and Instem Scientific Limited. Funded by the European Union, the private members, and those contributing partners of the IHI JU. Views and opinions expressed are, however, those of the author(s) only and do not necessarily reflect those of the aforementioned parties. Neither of the aforementioned parties can be held responsible for them. TL acknowledges funding for BioBricks from NIEHS (1R43ES036069-01) and NSF (# 2333728).</p></notes><notes notes-type=\"data-availability\"><title>Data Availability</title><p>Data sharing is not applicable to this article as no datasets were generated or analyzed during the current study.</p></notes><notes><title>Declarations</title><notes id=\"FPar1\"><title>Ethics Approval</title><p id=\"Par103\">Not applicable.</p></notes><notes id=\"FPar2\"><title>Consent to Participate</title><p id=\"Par104\">Not applicable.</p></notes><notes id=\"FPar3\"><title>Consent for Publication</title><p id=\"Par105\">Not applicable.</p></notes><notes id=\"FPar4\" notes-type=\"COI-statement\"><title>Competing interests</title><p id=\"Par106\">Thomas Luechtefeld is founder and owner of Tox-Track Inc. and Insilica LLC. Thomas Hartung holds stock options in and consults ToxTrack Inc. and Insilica LLC. Both are consultant for computational toxicology for Underwriters Laboratories (UL) and receive shares of their respective sales. Thomas Hartung is a member of Apple&#8217;s Green Chemistry Advisory Board. Thomas Hartung is the founder and owner of the non-profit CAATevents gGmbH, Solingen, Germany.</p></notes></notes><ref-list id=\"Bib1\"><title>References</title><ref id=\"CR1\"><label>1.</label><citation-alternatives><element-citation id=\"ec-CR1\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Luechtefeld</surname><given-names>T</given-names></name><name name-style=\"western\"><surname>Hartung</surname><given-names>T</given-names></name></person-group><article-title>Computational approaches to chemical hazard assessment</article-title><source>Altex</source><year>2017</year><volume>34</volume><fpage>459</fpage><lpage>478</lpage><pub-id pub-id-type=\"doi\">10.14573/altex.1710141</pub-id><pub-id pub-id-type=\"pmid\">29101769</pub-id><pub-id pub-id-type=\"pmcid\">PMC5848496</pub-id></element-citation><mixed-citation id=\"mc-CR1\" publication-type=\"journal\">Luechtefeld T, Hartung T. Computational approaches to chemical hazard assessment. Altex. 2017;34:459&#8211;78.<pub-id pub-id-type=\"pmid\">29101769</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.14573/altex.1710141</pub-id><pub-id pub-id-type=\"pmcid\">PMC5848496</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR2\"><label>2.</label><citation-alternatives><element-citation id=\"ec-CR2\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Kleinstreuer</surname><given-names>N</given-names></name><name name-style=\"western\"><surname>Hartung</surname><given-names>T</given-names></name></person-group><article-title>Artificial intelligence (AI) &#8211; it&#8217;s the end of the tox as we know it (and I feel fine) - AI for predictive toxicology</article-title><source>Arch Toxicol</source><year>2024</year><volume>98</volume><fpage>735</fpage><lpage>754</lpage><pub-id pub-id-type=\"doi\">10.1007/s00204-023-03666-2</pub-id><pub-id pub-id-type=\"pmid\">38244040</pub-id><pub-id pub-id-type=\"pmcid\">PMC10861653</pub-id></element-citation><mixed-citation id=\"mc-CR2\" publication-type=\"journal\">Kleinstreuer N, Hartung T. Artificial intelligence (AI) &#8211; it&#8217;s the end of the tox as we know it (and I feel fine) - AI for predictive toxicology. Arch Toxicol. 2024;98:735&#8211;54.<pub-id pub-id-type=\"pmid\">38244040</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1007/s00204-023-03666-2</pub-id><pub-id pub-id-type=\"pmcid\">PMC10861653</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR3\"><label>3.</label><citation-alternatives><element-citation id=\"ec-CR3\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Hartung</surname><given-names>T</given-names></name></person-group><article-title>ToxAIcology - the evolving role of artificial intelligence in advancing toxicology and modernizing regulatory science</article-title><source>Altex</source><year>2023</year><volume>40</volume><fpage>559</fpage><lpage>570</lpage><pub-id pub-id-type=\"doi\">10.14573/altex.2309191</pub-id><pub-id pub-id-type=\"pmid\">37889187</pub-id></element-citation><mixed-citation id=\"mc-CR3\" publication-type=\"journal\">Hartung T. ToxAIcology - the evolving role of artificial intelligence in advancing toxicology and modernizing regulatory science. Altex. 2023;40:559&#8211;70.<pub-id pub-id-type=\"pmid\">37889187</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.14573/altex.2309191</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR4\"><label>4.</label><citation-alternatives><element-citation id=\"ec-CR4\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Bender</surname><given-names>A</given-names></name><name name-style=\"western\"><surname>Cortes-Ciriano</surname><given-names>I</given-names></name></person-group><article-title>Artificial intelligence in drug discovery: what is realistic, what are illusions? Part 1: Ways to make an impact, and why we are not there yet</article-title><source>Drug Discov Today</source><year>2021</year><volume>26</volume><fpage>511</fpage><lpage>524</lpage><pub-id pub-id-type=\"doi\">10.1016/j.drudis.2020.12.009</pub-id><pub-id pub-id-type=\"pmid\">33346134</pub-id></element-citation><mixed-citation id=\"mc-CR4\" publication-type=\"journal\">Bender A, Cortes-Ciriano I. Artificial intelligence in drug discovery: what is realistic, what are illusions? Part 1: Ways to make an impact, and why we are not there yet. Drug Discov Today. 2021;26:511&#8211;24.<pub-id pub-id-type=\"pmid\">33346134</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1016/j.drudis.2020.12.009</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR5\"><label>5.</label><citation-alternatives><element-citation id=\"ec-CR5\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Luechtefeld</surname><given-names>T</given-names></name><name name-style=\"western\"><surname>Marsh</surname><given-names>D</given-names></name><name name-style=\"western\"><surname>Rowlands</surname><given-names>C</given-names></name><name name-style=\"western\"><surname>Hartung</surname><given-names>T</given-names></name></person-group><article-title>Machine learning of toxicological big data enables read-across structure activity relationships (RASAR) outperforming animal test reproducibility</article-title><source>Toxicol Sci</source><year>2018</year><volume>165</volume><fpage>198</fpage><lpage>212</lpage><pub-id pub-id-type=\"doi\">10.1093/toxsci/kfy152</pub-id><pub-id pub-id-type=\"pmid\">30007363</pub-id><pub-id pub-id-type=\"pmcid\">PMC6135638</pub-id></element-citation><mixed-citation id=\"mc-CR5\" publication-type=\"journal\">Luechtefeld T, Marsh D, Rowlands C, Hartung T. Machine learning of toxicological big data enables read-across structure activity relationships (RASAR) outperforming animal test reproducibility. Toxicol Sci. 2018;165:198&#8211;212.<pub-id pub-id-type=\"pmid\">30007363</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1093/toxsci/kfy152</pub-id><pub-id pub-id-type=\"pmcid\">PMC6135638</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR6\"><label>6.</label><mixed-citation publication-type=\"other\">Hartung T, Whelan, Tong W, Califf RM. Is Regulatory Science Ready for Artificial Intelligence?. NPJ Dig Med 2025;8:200.<pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1038/s41746-025-01596-0</pub-id><pub-id pub-id-type=\"pmcid\">PMC11985935</pub-id><pub-id pub-id-type=\"pmid\">40210953</pub-id></mixed-citation></ref><ref id=\"CR7\"><label>7.</label><citation-alternatives><element-citation id=\"ec-CR7\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Hartung</surname><given-names>T</given-names></name><name name-style=\"western\"><surname>Kleinstreuer</surname><given-names>NC</given-names></name></person-group><article-title>Challenges and opportunities for validation of AI-based new approach methods</article-title><source>Altex</source><year>2025</year><volume>42</volume><issue>1</issue><fpage>3</fpage><lpage>21</lpage><pub-id pub-id-type=\"pmid\">39815689</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.14573/altex.2412291</pub-id></element-citation><mixed-citation id=\"mc-CR7\" publication-type=\"journal\">Hartung T, Kleinstreuer NC. Challenges and opportunities for validation of AI-based new approach methods. Altex. 2025;42(1):3&#8211;21.<pub-id pub-id-type=\"pmid\">39815689</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.14573/altex.2412291</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR8\"><label>8.</label><mixed-citation publication-type=\"other\">Schultes E, Magagna B, Hettne K, Pergl R, Such&#225;nek M, Kuhn T. Reusable FAIR implementation profiles as accelerators of FAIR convergence. 2020. 10.1007/978-3-030-65847-2_13.</mixed-citation></ref><ref id=\"CR9\"><label>9.</label><mixed-citation publication-type=\"other\">Schultes E, Magagna B, Hettne KM, Pergl R, Such&#225;nek M, Kuhn T. Reusable FAIR implementation profiles as accelerators of FAIR convergence. In: Grossmann G, Ram S (eds) Advances in Conceptual Modeling. ER 2020. Lecture Notes in Computer Science. Springer, Cham. 2020; p. 12584.</mixed-citation></ref><ref id=\"CR10\"><label>10.</label><citation-alternatives><element-citation id=\"ec-CR10\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Chen</surname><given-names>J</given-names></name><name name-style=\"western\"><surname>Si</surname><given-names>YW</given-names></name><name name-style=\"western\"><surname>Un</surname><given-names>CW</given-names></name><name name-style=\"western\"><surname>Siu</surname><given-names>SWI</given-names></name></person-group><article-title>Chemical toxicity prediction based on semi-supervised learning and graph convolutional neural network</article-title><source>J Cheminform</source><year>2021</year><volume>13</volume><fpage>93</fpage><pub-id pub-id-type=\"doi\">10.1186/s13321-021-00570-8</pub-id><pub-id pub-id-type=\"pmid\">34838140</pub-id><pub-id pub-id-type=\"pmcid\">PMC8627024</pub-id></element-citation><mixed-citation id=\"mc-CR10\" publication-type=\"journal\">Chen J, Si YW, Un CW, Siu SWI. Chemical toxicity prediction based on semi-supervised learning and graph convolutional neural network. J Cheminform. 2021;13:93.<pub-id pub-id-type=\"pmid\">34838140</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1186/s13321-021-00570-8</pub-id><pub-id pub-id-type=\"pmcid\">PMC8627024</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR11\"><label>11.</label><citation-alternatives><element-citation id=\"ec-CR11\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Zhang</surname><given-names>J</given-names></name><name name-style=\"western\"><surname>Zhao</surname><given-names>L</given-names></name><name name-style=\"western\"><surname>Wang</surname><given-names>W</given-names></name><name name-style=\"western\"><surname>Xing</surname><given-names>DF</given-names></name><name name-style=\"western\"><surname>Wang</surname><given-names>ZX</given-names></name><name name-style=\"western\"><surname>Ma</surname><given-names>J</given-names></name><etal/></person-group><article-title>New trend on chemical structure representation learning in toxicology: in reviews of machine learning model methodology</article-title><source>Crit Rev Environ Sci Technol</source><year>2025</year><volume>55</volume><fpage>951</fpage><lpage>976</lpage><pub-id pub-id-type=\"doi\">10.1080/10643389.2025.2469868</pub-id></element-citation><mixed-citation id=\"mc-CR11\" publication-type=\"journal\">Zhang J, Zhao L, Wang W, Xing DF, Wang ZX, Ma J, et al. New trend on chemical structure representation learning in toxicology: in reviews of machine learning model methodology. Crit Rev Environ Sci Technol. 2025;55:951&#8211;76.</mixed-citation></citation-alternatives></ref><ref id=\"CR12\"><label>12.</label><citation-alternatives><element-citation id=\"ec-CR12\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Li</surname><given-names>X</given-names></name><name name-style=\"western\"><surname>Makarov</surname><given-names>I</given-names></name><name name-style=\"western\"><surname>Kiselev</surname><given-names>D</given-names></name></person-group><article-title>Predicting molecule toxicity via descriptor-based graph self-supervised learning</article-title><source>IEEE Access.</source><year>2023</year><volume>11</volume><fpage>91842</fpage><lpage>91849</lpage><pub-id pub-id-type=\"doi\">10.1109/ACCESS.2023.3308203</pub-id></element-citation><mixed-citation id=\"mc-CR12\" publication-type=\"journal\">Li X, Makarov I, Kiselev D. Predicting molecule toxicity via descriptor-based graph self-supervised learning. IEEE Access. 2023;11:91842&#8211;9.</mixed-citation></citation-alternatives></ref><ref id=\"CR13\"><label>13.</label><citation-alternatives><element-citation id=\"ec-CR13\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Chen</surname><given-names>X</given-names></name><name name-style=\"western\"><surname>Roberts</surname><given-names>R</given-names></name><name name-style=\"western\"><surname>Liu</surname><given-names>Z</given-names></name><name name-style=\"western\"><surname>Toing</surname><given-names>W</given-names></name></person-group><article-title>A generative adversarial network model alternative to animal studies for clinical pathology assessment</article-title><source>Nat Commun</source><year>2023</year><volume>14</volume><fpage>7141</fpage><pub-id pub-id-type=\"doi\">10.1038/s41467-023-42933-9</pub-id><pub-id pub-id-type=\"pmid\">37932302</pub-id><pub-id pub-id-type=\"pmcid\">PMC10628291</pub-id></element-citation><mixed-citation id=\"mc-CR13\" publication-type=\"journal\">Chen X, Roberts R, Liu Z, Toing W. A generative adversarial network model alternative to animal studies for clinical pathology assessment. Nat Commun. 2023;14:7141.<pub-id pub-id-type=\"pmid\">37932302</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1038/s41467-023-42933-9</pub-id><pub-id pub-id-type=\"pmcid\">PMC10628291</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR14\"><label>14.</label><citation-alternatives><element-citation id=\"ec-CR14\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Chen</surname><given-names>X</given-names></name><name name-style=\"western\"><surname>Roberts</surname><given-names>R</given-names></name><name name-style=\"western\"><surname>Tong</surname><given-names>W</given-names></name><name name-style=\"western\"><surname>Liu</surname><given-names>Z</given-names></name></person-group><article-title>Tox-GAN: an artificial intelligence approach alternative to animal studies-a case study with toxicogenomics</article-title><source>Toxicol Sci</source><year>2022</year><volume>186</volume><fpage>242</fpage><lpage>259</lpage><pub-id pub-id-type=\"doi\">10.1093/toxsci/kfab157</pub-id><pub-id pub-id-type=\"pmid\">34971401</pub-id></element-citation><mixed-citation id=\"mc-CR14\" publication-type=\"journal\">Chen X, Roberts R, Tong W, Liu Z. Tox-GAN: an artificial intelligence approach alternative to animal studies-a case study with toxicogenomics. Toxicol Sci. 2022;186:242&#8211;59.<pub-id pub-id-type=\"pmid\">34971401</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1093/toxsci/kfab157</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR15\"><label>15.</label><mixed-citation publication-type=\"other\">OpenAI. GPT-4 Technical Report. 2023. Available at: <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://cdn.openai.com/papers/gpt-4.pdf\">https://cdn.openai.com/papers/gpt-4.pdf</ext-link>. Accessed 25 Nov 2025.</mixed-citation></ref><ref id=\"CR16\"><label>16.</label><citation-alternatives><element-citation id=\"ec-CR16\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Singhal</surname><given-names>K</given-names></name><name name-style=\"western\"><surname>Azizi</surname><given-names>S</given-names></name><name name-style=\"western\"><surname>Tu</surname><given-names>T</given-names></name><name name-style=\"western\"><surname>Mahdavi</surname><given-names>SS</given-names></name><name name-style=\"western\"><surname>Wie</surname><given-names>J</given-names></name><name name-style=\"western\"><surname>Chung</surname><given-names>HW</given-names></name><etal/></person-group><article-title>Large language models encode clinical knowledge</article-title><source>Nature</source><year>2023</year><volume>620</volume><fpage>172</fpage><lpage>180</lpage><pub-id pub-id-type=\"doi\">10.1038/s41586-023-06291-2</pub-id><pub-id pub-id-type=\"pmid\">37438534</pub-id><pub-id pub-id-type=\"pmcid\">PMC10396962</pub-id></element-citation><mixed-citation id=\"mc-CR16\" publication-type=\"journal\">Singhal K, Azizi S, Tu T, Mahdavi SS, Wie J, Chung HW, et al. Large language models encode clinical knowledge. Nature. 2023;620:172&#8211;80.<pub-id pub-id-type=\"pmid\">37438534</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1038/s41586-023-06291-2</pub-id><pub-id pub-id-type=\"pmcid\">PMC10396962</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR17\"><label>17.</label><citation-alternatives><element-citation id=\"ec-CR17\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Jumper</surname><given-names>J</given-names></name><name name-style=\"western\"><surname>Evans</surname><given-names>R</given-names></name><name name-style=\"western\"><surname>Pritzel</surname><given-names>A</given-names></name><name name-style=\"western\"><surname>Green</surname><given-names>T</given-names></name><name name-style=\"western\"><surname>Figurnov</surname><given-names>M</given-names></name><name name-style=\"western\"><surname>Ronneberger</surname><given-names>O</given-names></name><etal/></person-group><article-title>Highly accurate protein structure prediction with AlphaFold</article-title><source>Nature</source><year>2021</year><volume>596</volume><fpage>583</fpage><lpage>589</lpage><pub-id pub-id-type=\"doi\">10.1038/s41586-021-03819-2</pub-id><pub-id pub-id-type=\"pmid\">34265844</pub-id><pub-id pub-id-type=\"pmcid\">PMC8371605</pub-id></element-citation><mixed-citation id=\"mc-CR17\" publication-type=\"journal\">Jumper J, Evans R, Pritzel A, Green T, Figurnov M, Ronneberger O, et al. Highly accurate protein structure prediction with AlphaFold. Nature. 2021;596:583&#8211;9.<pub-id pub-id-type=\"pmid\">34265844</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1038/s41586-021-03819-2</pub-id><pub-id pub-id-type=\"pmcid\">PMC8371605</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR18\"><label>18.</label><mixed-citation publication-type=\"other\">Szczepankiewicz K, Popowicz A, CharkiewiczK, Na&#322;&#281;cz-Charkiewicz K, Szczepankiewicz M, Lasota S, et al. Ground truth based comparison of saliency maps algorithms. Sci Rep. 2023;13:16887<pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1038/s41598-023-42946-w</pub-id><pub-id pub-id-type=\"pmcid\">PMC10558518</pub-id><pub-id pub-id-type=\"pmid\">37803108</pub-id></mixed-citation></ref><ref id=\"CR19\"><label>19.</label><citation-alternatives><element-citation id=\"ec-CR19\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Hu</surname><given-names>B</given-names></name><name name-style=\"western\"><surname>Tunison</surname><given-names>P</given-names></name><name name-style=\"western\"><surname>Vasu</surname><given-names>B</given-names></name><name name-style=\"western\"><surname>Menon</surname><given-names>N</given-names></name><name name-style=\"western\"><surname>Collins</surname><given-names>R</given-names></name><name name-style=\"western\"><surname>Hoogs</surname><given-names>A</given-names></name></person-group><article-title>XAITK: The explainable AI toolkit</article-title><source>Appl AI Lett</source><year>2021</year><volume>2</volume><fpage>e40</fpage><pub-id pub-id-type=\"doi\">10.1002/ail2.40</pub-id></element-citation><mixed-citation id=\"mc-CR19\" publication-type=\"journal\">Hu B, Tunison P, Vasu B, Menon N, Collins R, Hoogs A. XAITK: The explainable AI toolkit. Appl AI Lett. 2021;2:e40.</mixed-citation></citation-alternatives></ref><ref id=\"CR20\"><label>20.</label><citation-alternatives><element-citation id=\"ec-CR20\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Maertens</surname><given-names>A</given-names></name><name name-style=\"western\"><surname>Golden</surname><given-names>E</given-names></name><name name-style=\"western\"><surname>Luechtefeld</surname><given-names>TH</given-names></name><name name-style=\"western\"><surname>Hoffmann</surname><given-names>S</given-names></name><name name-style=\"western\"><surname>Tsaioun</surname><given-names>K</given-names></name><name name-style=\"western\"><surname>Hartung</surname><given-names>T</given-names></name></person-group><article-title>Probabilistic risk assessment &#8211; the keystone for the future of toxicology</article-title><source>Altex</source><year>2022</year><volume>39</volume><fpage>3</fpage><lpage>29</lpage><pub-id pub-id-type=\"doi\">10.14573/altex.2201081</pub-id><pub-id pub-id-type=\"pmid\">35034131</pub-id><pub-id pub-id-type=\"pmcid\">PMC8906258</pub-id></element-citation><mixed-citation id=\"mc-CR20\" publication-type=\"journal\">Maertens A, Golden E, Luechtefeld TH, Hoffmann S, Tsaioun K, Hartung T. Probabilistic risk assessment &#8211; the keystone for the future of toxicology. Altex. 2022;39:3&#8211;29.<pub-id pub-id-type=\"pmid\">35034131</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.14573/altex.2201081</pub-id><pub-id pub-id-type=\"pmcid\">PMC8906258</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR21\"><label>21.</label><citation-alternatives><element-citation id=\"ec-CR21\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Ball</surname><given-names>N</given-names></name><name name-style=\"western\"><surname>Cronin</surname><given-names>MTD</given-names></name><name name-style=\"western\"><surname>Shen</surname><given-names>J</given-names></name><name name-style=\"western\"><surname>Adenuga</surname><given-names>MD</given-names></name><name name-style=\"western\"><surname>Blackburn</surname><given-names>K</given-names></name><name name-style=\"western\"><surname>Booth</surname><given-names>ED</given-names></name><etal/></person-group><article-title>Toward good read-across practice (GRAP) guidance</article-title><source>Altex</source><year>2016</year><volume>33</volume><fpage>149</fpage><lpage>166</lpage><pub-id pub-id-type=\"doi\">10.14573/altex.1601251</pub-id><pub-id pub-id-type=\"pmid\">26863606</pub-id><pub-id pub-id-type=\"pmcid\">PMC5581000</pub-id></element-citation><mixed-citation id=\"mc-CR21\" publication-type=\"journal\">Ball N, Cronin MTD, Shen J, Adenuga MD, Blackburn K, Booth ED, et al. Toward good read-across practice (GRAP) guidance. Altex. 2016;33:149&#8211;66.<pub-id pub-id-type=\"pmid\">26863606</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.14573/altex.1601251</pub-id><pub-id pub-id-type=\"pmcid\">PMC5581000</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR22\"><label>22.</label><citation-alternatives><element-citation id=\"ec-CR22\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Zhu</surname><given-names>H</given-names></name><name name-style=\"western\"><surname>Bouhifd</surname><given-names>M</given-names></name><name name-style=\"western\"><surname>Kleinstreuer</surname><given-names>N</given-names></name><name name-style=\"western\"><surname>Kroese</surname><given-names>ED</given-names></name><name name-style=\"western\"><surname>Liu</surname><given-names>Z</given-names></name><name name-style=\"western\"><surname>Luechtefeld</surname><given-names>T</given-names></name><etal/></person-group><article-title>Supporting read-across using biological data</article-title><source>Altex</source><year>2016</year><volume>33</volume><fpage>167</fpage><lpage>182</lpage><pub-id pub-id-type=\"doi\">10.14573/altex.1601252</pub-id><pub-id pub-id-type=\"pmid\">26863516</pub-id><pub-id pub-id-type=\"pmcid\">PMC4834201</pub-id></element-citation><mixed-citation id=\"mc-CR22\" publication-type=\"journal\">Zhu H, Bouhifd M, Kleinstreuer N, Kroese ED, Liu Z, Luechtefeld T, et al. Supporting read-across using biological data. Altex. 2016;33:167&#8211;82.<pub-id pub-id-type=\"pmid\">26863516</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.14573/altex.1601252</pub-id><pub-id pub-id-type=\"pmcid\">PMC4834201</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR23\"><label>23.</label><citation-alternatives><element-citation id=\"ec-CR23\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Maertens</surname><given-names>A</given-names></name><name name-style=\"western\"><surname>Hartung</surname><given-names>T</given-names></name></person-group><article-title>Green toxicology &#8211; know early about and avoid toxic product liabilities</article-title><source>Toxicol Sci</source><year>2018</year><volume>161</volume><fpage>285</fpage><lpage>289</lpage><pub-id pub-id-type=\"doi\">10.1093/toxsci/kfx243</pub-id><pub-id pub-id-type=\"pmid\">29267930</pub-id></element-citation><mixed-citation id=\"mc-CR23\" publication-type=\"journal\">Maertens A, Hartung T. Green toxicology &#8211; know early about and avoid toxic product liabilities. Toxicol Sci. 2018;161:285&#8211;9.<pub-id pub-id-type=\"pmid\">29267930</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1093/toxsci/kfx243</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR24\"><label>24.</label><citation-alternatives><element-citation id=\"ec-CR24\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Maertens</surname><given-names>A</given-names></name><name name-style=\"western\"><surname>Luechtefeld</surname><given-names>T</given-names></name><name name-style=\"western\"><surname>Hartung</surname><given-names>T</given-names></name></person-group><article-title>Alternative methods go green! Green toxicology as a sustainable approach for assessing chemical safety and designing safer chemicals</article-title><source>Altex</source><year>2024</year><volume>41</volume><fpage>3</fpage><lpage>19</lpage><pub-id pub-id-type=\"pmid\">38194639</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.14573/altex.2312291</pub-id></element-citation><mixed-citation id=\"mc-CR24\" publication-type=\"journal\">Maertens A, Luechtefeld T, Hartung T. Alternative methods go green! Green toxicology as a sustainable approach for assessing chemical safety and designing safer chemicals. Altex. 2024;41:3&#8211;19.<pub-id pub-id-type=\"pmid\">38194639</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.14573/altex.2312291</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR25\"><label>25.</label><citation-alternatives><element-citation id=\"ec-CR25\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Kone&#269;n&#253;</surname><given-names>J</given-names></name><name name-style=\"western\"><surname>McMahan</surname><given-names>HB</given-names></name><name name-style=\"western\"><surname>Yu</surname><given-names>FX</given-names></name><name name-style=\"western\"><surname>Suresh</surname><given-names>AT</given-names></name><name name-style=\"western\"><surname>Bacon</surname><given-names>D</given-names></name></person-group><article-title>Federated learning: strategies for improving communication efficiency</article-title><source>Commun ACM</source><year>2022</year><volume>65</volume><fpage>86</fpage><lpage>94</lpage></element-citation><mixed-citation id=\"mc-CR25\" publication-type=\"journal\">Kone&#269;n&#253; J, McMahan HB, Yu FX, Suresh AT, Bacon D. Federated learning: strategies for improving communication efficiency. Commun ACM. 2022;65:86&#8211;94.</mixed-citation></citation-alternatives></ref><ref id=\"CR26\"><label>26.</label><citation-alternatives><element-citation id=\"ec-CR26\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Kaissis</surname><given-names>GA</given-names></name><name name-style=\"western\"><surname>Makowski</surname><given-names>MR</given-names></name><name name-style=\"western\"><surname>R&#252;ckert</surname><given-names>D</given-names></name><name name-style=\"western\"><surname>Braren</surname><given-names>RF</given-names></name></person-group><article-title>Secure, privacy-preserving and federated machine learning in medical imaging</article-title><source>Nat Mach Intell</source><year>2020</year><volume>2</volume><fpage>305</fpage><lpage>311</lpage><pub-id pub-id-type=\"doi\">10.1038/s42256-020-0186-1</pub-id></element-citation><mixed-citation id=\"mc-CR26\" publication-type=\"journal\">Kaissis GA, Makowski MR, R&#252;ckert D, Braren RF. Secure, privacy-preserving and federated machine learning in medical imaging. Nat Mach Intell. 2020;2:305&#8211;11.</mixed-citation></citation-alternatives></ref><ref id=\"CR27\"><label>27.</label><citation-alternatives><element-citation id=\"ec-CR27\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Leist</surname><given-names>M</given-names></name><name name-style=\"western\"><surname>Ghallab</surname><given-names>A</given-names></name><name name-style=\"western\"><surname>Graepel</surname><given-names>R</given-names></name><name name-style=\"western\"><surname>Marchan</surname><given-names>R</given-names></name><name name-style=\"western\"><surname>Hassan</surname><given-names>R</given-names></name><name name-style=\"western\"><surname>Hougaard Bennekou</surname><given-names>S</given-names></name><etal/></person-group><article-title>Adverse outcome pathways: opportunities, limitations and open questions</article-title><source>Archives Toxicology</source><year>2017</year><volume>31</volume><fpage>221</fpage><lpage>229</lpage><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1007/s00204-017-2045-3</pub-id><pub-id pub-id-type=\"pmid\">29051992</pub-id></element-citation><mixed-citation id=\"mc-CR27\" publication-type=\"journal\">Leist M, Ghallab A, Graepel R, Marchan R, Hassan R, Hougaard Bennekou S, et al. Adverse outcome pathways: opportunities, limitations and open questions. Archives Toxicology. 2017;31:221&#8211;9.<pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1007/s00204-017-2045-3</pub-id><pub-id pub-id-type=\"pmid\">29051992</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR28\"><label>28.</label><citation-alternatives><element-citation id=\"ec-CR28\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Corradi</surname><given-names>M</given-names></name><name name-style=\"western\"><surname>Luechtefeld</surname><given-names>T</given-names></name><name name-style=\"western\"><surname>de Haan</surname><given-names>AM</given-names></name><name name-style=\"western\"><surname>Pieters</surname><given-names>R</given-names></name><name name-style=\"western\"><surname>Freedman</surname><given-names>JH</given-names></name><name name-style=\"western\"><surname>Vanhaecke</surname><given-names>T</given-names></name><etal/></person-group><article-title>The application of natural language processing for the extraction of mechanistic information in toxicology</article-title><source>Front Toxicol</source><year>2024</year><volume>6</volume><fpage>1393662</fpage><pub-id pub-id-type=\"doi\">10.3389/ftox.2024.1393662</pub-id><pub-id pub-id-type=\"pmid\">38800806</pub-id><pub-id pub-id-type=\"pmcid\">PMC11116573</pub-id></element-citation><mixed-citation id=\"mc-CR28\" publication-type=\"journal\">Corradi M, Luechtefeld T, de Haan AM, Pieters R, Freedman JH, Vanhaecke T, et al. The application of natural language processing for the extraction of mechanistic information in toxicology. Front Toxicol. 2024;6:1393662.<pub-id pub-id-type=\"pmid\">38800806</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.3389/ftox.2024.1393662</pub-id><pub-id pub-id-type=\"pmcid\">PMC11116573</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR29\"><label>29.</label><mixed-citation publication-type=\"other\">Park D, Ramesh A, Goldstein T, Ringel Morris M, Liang P, Bernstein MS. Generative agents: Interactive simulacra of human behavior. Proc 36th Ann ACM Symp Interface Softw Technol. 2023;2:1&#8211;22.</mixed-citation></ref><ref id=\"CR30\"><label>30.</label><citation-alternatives><element-citation id=\"ec-CR30\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Hartung</surname><given-names>T</given-names></name></person-group><article-title>Perspectives on <italic toggle=\"yes\">in vitro</italic> to <italic toggle=\"yes\">in vivo</italic> extrapolations</article-title><source>Appl In Vitro Toxicol</source><year>2018</year><volume>4</volume><fpage>305</fpage><lpage>316</lpage><pub-id pub-id-type=\"doi\">10.1089/aivt.2016.0026</pub-id><pub-id pub-id-type=\"pmid\">31890748</pub-id><pub-id pub-id-type=\"pmcid\">PMC6309130</pub-id></element-citation><mixed-citation id=\"mc-CR30\" publication-type=\"journal\">Hartung T. Perspectives on <italic toggle=\"yes\">in vitro</italic> to <italic toggle=\"yes\">in vivo</italic> extrapolations. Appl In Vitro Toxicol. 2018;4:305&#8211;16.<pub-id pub-id-type=\"pmid\">31890748</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1089/aivt.2016.0026</pub-id><pub-id pub-id-type=\"pmcid\">PMC6309130</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR31\"><label>31.</label><citation-alternatives><element-citation id=\"ec-CR31\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Chou</surname><given-names>WC</given-names></name><name name-style=\"western\"><surname>Lin</surname><given-names>Z</given-names></name></person-group><article-title>Machine learning and artificial intelligence in physiologically based pharmacokinetic modeling</article-title><source>Toxicol Sci</source><year>2023</year><volume>191</volume><fpage>1</fpage><lpage>14</lpage><pub-id pub-id-type=\"doi\">10.1093/toxsci/kfac101</pub-id><pub-id pub-id-type=\"pmid\">36156156</pub-id><pub-id pub-id-type=\"pmcid\">PMC9887681</pub-id></element-citation><mixed-citation id=\"mc-CR31\" publication-type=\"journal\">Chou WC, Lin Z. Machine learning and artificial intelligence in physiologically based pharmacokinetic modeling. Toxicol Sci. 2023;191:1&#8211;14.<pub-id pub-id-type=\"pmid\">36156156</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1093/toxsci/kfac101</pub-id><pub-id pub-id-type=\"pmcid\">PMC9887681</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR32\"><label>32.</label><citation-alternatives><element-citation id=\"ec-CR32\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Maertens</surname><given-names>A</given-names></name><name name-style=\"western\"><surname>Antignac</surname><given-names>E</given-names></name><name name-style=\"western\"><surname>Benfenati</surname><given-names>E</given-names></name><name name-style=\"western\"><surname>Bloch</surname><given-names>D</given-names></name><name name-style=\"western\"><surname>Fritsche</surname><given-names>E</given-names></name><name name-style=\"western\"><surname>Hoffmann</surname><given-names>S</given-names></name><etal/></person-group><article-title>The probable future of toxicology - probabilistic risk assessment</article-title><source>Altex</source><year>2024</year><volume>41</volume><fpage>273</fpage><lpage>281</lpage><pub-id pub-id-type=\"pmid\">38215352</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.14573/altex.2310301</pub-id></element-citation><mixed-citation id=\"mc-CR32\" publication-type=\"journal\">Maertens A, Antignac E, Benfenati E, Bloch D, Fritsche E, Hoffmann S, et al. The probable future of toxicology - probabilistic risk assessment. Altex. 2024;41:273&#8211;81.<pub-id pub-id-type=\"pmid\">38215352</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.14573/altex.2310301</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR33\"><label>33.</label><mixed-citation publication-type=\"other\">Maertens A, Kincaid B, Bridgeford E, Brochot C, de Carvalho e Silva A, Dorne J-LCM, et al. From cellular perturbation to probabilistic risk assessments. ALTEX. 2025;42:413&#8211;434.<pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.14573/altex.2501291</pub-id><pub-id pub-id-type=\"pmid\">40418784</pub-id></mixed-citation></ref><ref id=\"CR34\"><label>34.</label><citation-alternatives><element-citation id=\"ec-CR34\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Hartung</surname><given-names>T</given-names></name><name name-style=\"western\"><surname>Tsaioun</surname><given-names>K</given-names></name></person-group><article-title>Evidence-based approaches in toxicology: their origins, challenges, and future directions</article-title><source>Evid-Based Toxicol</source><year>2024</year><volume>2</volume><issue>1</issue><fpage>2421187</fpage><pub-id pub-id-type=\"doi\">10.1080/2833373X.2024.2421187</pub-id></element-citation><mixed-citation id=\"mc-CR34\" publication-type=\"journal\">Hartung T, Tsaioun K. Evidence-based approaches in toxicology: their origins, challenges, and future directions. Evid-Based Toxicol. 2024;2(1):2421187.</mixed-citation></citation-alternatives></ref><ref id=\"CR35\"><label>35.</label><mixed-citation publication-type=\"other\">Ribeiro MT, Singh S, Guestrin C. Model-agnostic interpretability of machine learning. arXiv Preprint. 2016. <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"http://arxiv.org/abs/1606.05386\">arXiv:1606.05386</ext-link>.</mixed-citation></ref><ref id=\"CR36\"><label>36.</label><citation-alternatives><element-citation id=\"ec-CR36\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Bueso-Bordils</surname><given-names>JI</given-names></name><name name-style=\"western\"><surname>Ant&#243;n-Fos</surname><given-names>GM</given-names></name><name name-style=\"western\"><surname>Mart&#237;n-Algarra</surname><given-names>R</given-names></name><name name-style=\"western\"><surname>Alem&#225;n-L&#243;pez</surname><given-names>PA</given-names></name></person-group><article-title>Overview of computational toxicology methods applied in drug and green chemical discovery</article-title><source>J Xenobiotics</source><year>2024</year><volume>14</volume><fpage>1901</fpage><lpage>1918</lpage><pub-id pub-id-type=\"doi\">10.3390/jox14040101</pub-id><pub-id pub-id-type=\"pmcid\">PMC11677645</pub-id><pub-id pub-id-type=\"pmid\">39728409</pub-id></element-citation><mixed-citation id=\"mc-CR36\" publication-type=\"journal\">Bueso-Bordils JI, Ant&#243;n-Fos GM, Mart&#237;n-Algarra R, Alem&#225;n-L&#243;pez PA. Overview of computational toxicology methods applied in drug and green chemical discovery. J Xenobiotics. 2024;14:1901&#8211;18.<pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.3390/jox14040101</pub-id><pub-id pub-id-type=\"pmcid\">PMC11677645</pub-id><pub-id pub-id-type=\"pmid\">39728409</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR37\"><label>37.</label><citation-alternatives><element-citation id=\"ec-CR37\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Hartung</surname><given-names>T</given-names></name></person-group><article-title>The validation of regulatory test methods &#8211; conceptual, ethical, and philosophical foundations</article-title><source>Altex</source><year>2024</year><volume>41</volume><fpage>525</fpage><lpage>544</lpage><pub-id pub-id-type=\"pmid\">39440637</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.14573/altex.2409271</pub-id></element-citation><mixed-citation id=\"mc-CR37\" publication-type=\"journal\">Hartung T. The validation of regulatory test methods &#8211; conceptual, ethical, and philosophical foundations. Altex. 2024;41:525&#8211;44.<pub-id pub-id-type=\"pmid\">39440637</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.14573/altex.2409271</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR38\"><label>38.</label><mixed-citation publication-type=\"other\">Gao S, Zhu R, Kong Z, Noori A, Su X, Ginder C, et al. TxAgent: an AI agent for therapeutic reasoning across a universe of tools. <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"http://arxiv.org/abs/2503.10970\">arXiv:2503.10970</ext-link></mixed-citation></ref><ref id=\"CR39\"><label>39.</label><citation-alternatives><element-citation id=\"ec-CR39\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Vinken</surname><given-names>M</given-names></name><name name-style=\"western\"><surname>Benfenati</surname><given-names>E</given-names></name><name name-style=\"western\"><surname>Busquet</surname><given-names>F</given-names></name><name name-style=\"western\"><surname>Castell</surname><given-names>J</given-names></name><name name-style=\"western\"><surname>Clevert</surname><given-names>D-A</given-names></name><name name-style=\"western\"><surname>de Kok</surname><given-names>T</given-names></name><etal/></person-group><article-title>Safer chemicals using less animals: kick-off of the European ONTOX project</article-title><source>Toxicology</source><year>2021</year><volume>458</volume><fpage>152846</fpage><pub-id pub-id-type=\"doi\">10.1016/j.tox.2021.152846</pub-id><pub-id pub-id-type=\"pmid\">34216698</pub-id></element-citation><mixed-citation id=\"mc-CR39\" publication-type=\"journal\">Vinken M, Benfenati E, Busquet F, Castell J, Clevert D-A, de Kok T, et al. Safer chemicals using less animals: kick-off of the European ONTOX project. Toxicology. 2021;458:152846.<pub-id pub-id-type=\"pmid\">34216698</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1016/j.tox.2021.152846</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR40\"><label>40.</label><citation-alternatives><element-citation id=\"ec-CR40\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Diemar</surname><given-names>M</given-names></name><name name-style=\"western\"><surname>Vinken</surname><given-names>M</given-names></name><name name-style=\"western\"><surname>Teunis</surname><given-names>M</given-names></name><name name-style=\"western\"><surname>Krul</surname><given-names>C</given-names></name><name name-style=\"western\"><surname>Busquet</surname><given-names>F</given-names></name><name name-style=\"western\"><surname>Zajac</surname><given-names>J</given-names></name><etal/></person-group><article-title>Report of the first ONTOX stakeholder network meeting: digging under the surface of ONTOX together with the stakeholders</article-title><source>Altern Lab Anim</source><year>2024</year><volume>52</volume><fpage>117</fpage><lpage>131</lpage><pub-id pub-id-type=\"doi\">10.1177/02611929231225730</pub-id><pub-id pub-id-type=\"pmid\">38235727</pub-id></element-citation><mixed-citation id=\"mc-CR40\" publication-type=\"journal\">Diemar M, Vinken M, Teunis M, Krul C, Busquet F, Zajac J, et al. Report of the first ONTOX stakeholder network meeting: digging under the surface of ONTOX together with the stakeholders. Altern Lab Anim. 2024;52:117&#8211;31.<pub-id pub-id-type=\"pmid\">38235727</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1177/02611929231225730</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR41\"><label>41.</label><citation-alternatives><element-citation id=\"ec-CR41\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Chen</surname><given-names>X</given-names></name><name name-style=\"western\"><surname>Roberts</surname><given-names>R</given-names></name><name name-style=\"western\"><surname>Liu</surname><given-names>Z</given-names></name><name name-style=\"western\"><surname>Tong</surname><given-names>W</given-names></name></person-group><article-title>A generative adversarial network model alternative to animal studies for clinical pathology assessment</article-title><source>Nat Commun</source><year>2023</year><volume>14</volume><fpage>7141</fpage><pub-id pub-id-type=\"doi\">10.1038/s41467-023-42933-9</pub-id><pub-id pub-id-type=\"pmid\">37932302</pub-id><pub-id pub-id-type=\"pmcid\">PMC10628291</pub-id></element-citation><mixed-citation id=\"mc-CR41\" publication-type=\"journal\">Chen X, Roberts R, Liu Z, Tong W. A generative adversarial network model alternative to animal studies for clinical pathology assessment. Nat Commun. 2023;14:7141.<pub-id pub-id-type=\"pmid\">37932302</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1038/s41467-023-42933-9</pub-id><pub-id pub-id-type=\"pmcid\">PMC10628291</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR42\"><label>42.</label><citation-alternatives><element-citation id=\"ec-CR42\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Meyers</surname><given-names>J</given-names></name><name name-style=\"western\"><surname>Fabian</surname><given-names>B</given-names></name><name name-style=\"western\"><surname>Brown</surname><given-names>N</given-names></name></person-group><article-title>De novo molecular design and generative models</article-title><source>Drug Discov Today</source><year>2021</year><volume>26</volume><fpage>2707</fpage><lpage>2715</lpage><pub-id pub-id-type=\"doi\">10.1016/j.drudis.2021.05.019</pub-id><pub-id pub-id-type=\"pmid\">34082136</pub-id></element-citation><mixed-citation id=\"mc-CR42\" publication-type=\"journal\">Meyers J, Fabian B, Brown N. De novo molecular design and generative models. Drug Discov Today. 2021;26:2707&#8211;15.<pub-id pub-id-type=\"pmid\">34082136</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1016/j.drudis.2021.05.019</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR43\"><label>43.</label><mixed-citation publication-type=\"other\">Hartung T. AI as the new frontier in chemical risk assessment. Front AI, Sec. Med Pub Health. 2023;6:1269932.<pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.3389/frai.2023.1269932</pub-id><pub-id pub-id-type=\"pmcid\">PMC10616238</pub-id><pub-id pub-id-type=\"pmid\">37915539</pub-id></mixed-citation></ref><ref id=\"CR44\"><label>44.</label><citation-alternatives><element-citation id=\"ec-CR44\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Hartung</surname><given-names>T</given-names></name></person-group><article-title>AI, agentic models and lab automation for scientific discovery &#8211; the beginning of scAInce</article-title><source>Frontiers in AI</source><year>2025</year><volume>8</volume><fpage>1649155</fpage><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.3389/frai.2025.1649155</pub-id><pub-id pub-id-type=\"pmcid\">PMC12426084</pub-id><pub-id pub-id-type=\"pmid\">40951330</pub-id></element-citation><mixed-citation id=\"mc-CR44\" publication-type=\"journal\">Hartung T. AI, agentic models and lab automation for scientific discovery &#8211; the beginning of scAInce. Frontiers in AI. 2025;8:1649155.<pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.3389/frai.2025.1649155</pub-id><pub-id pub-id-type=\"pmcid\">PMC12426084</pub-id><pub-id pub-id-type=\"pmid\">40951330</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR45\"><label>45.</label><citation-alternatives><element-citation id=\"ec-CR45\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Hartung</surname><given-names>T</given-names></name></person-group><article-title>A call for a human exposome project</article-title><source>Altex</source><year>2023</year><volume>40</volume><fpage>4</fpage><lpage>33</lpage><pub-id pub-id-type=\"doi\">10.14573/altex.2301061</pub-id><pub-id pub-id-type=\"pmid\">36648285</pub-id></element-citation><mixed-citation id=\"mc-CR45\" publication-type=\"journal\">Hartung T. A call for a human exposome project. Altex. 2023;40:4&#8211;33.<pub-id pub-id-type=\"pmid\">36648285</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.14573/altex.2301061</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR46\"><label>46.</label><citation-alternatives><element-citation id=\"ec-CR46\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Hartung</surname><given-names>T</given-names></name></person-group><article-title>How AI can deliver the human exposome project</article-title><source>Nat Med</source><year>2025</year><volume>31</volume><fpage>1738</fpage><pub-id pub-id-type=\"doi\">10.1038/s41591-025-03749-w</pub-id><pub-id pub-id-type=\"pmid\">40514463</pub-id></element-citation><mixed-citation id=\"mc-CR46\" publication-type=\"journal\">Hartung T. How AI can deliver the human exposome project. Nat Med. 2025;31:1738.<pub-id pub-id-type=\"pmid\">40514463</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1038/s41591-025-03749-w</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR47\"><label>47.</label><mixed-citation publication-type=\"other\">Sill&#233; FCM, Belkadi M, Koehler K, Ali J, Vasiliou V, Sagigiannis D, Hartung T. Charting exposomoethics: A roadmap for the ethical foundations of the human exposome project, human genomics, revised.</mixed-citation></ref><ref id=\"CR48\"><label>48.</label><citation-alternatives><element-citation id=\"ec-CR48\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Hartung</surname><given-names>T</given-names></name><name name-style=\"western\"><surname>King</surname><given-names>N</given-names></name><name name-style=\"western\"><surname>Kleinstreuer</surname><given-names>N</given-names></name><name name-style=\"western\"><surname>Leist</surname><given-names>M</given-names></name><name name-style=\"western\"><surname>Tagle</surname><given-names>D</given-names></name></person-group><article-title>Leveraging biomarkers and translational medicine for preclinical safety - lessons for advancing the validation of alternatives to animal testing</article-title><source>Altex</source><year>2024</year><volume>41</volume><fpage>545</fpage><lpage>566</lpage><pub-id pub-id-type=\"pmid\">39440996</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.14573/altex.2410011</pub-id></element-citation><mixed-citation id=\"mc-CR48\" publication-type=\"journal\">Hartung T, King N, Kleinstreuer N, Leist M, Tagle D. Leveraging biomarkers and translational medicine for preclinical safety - lessons for advancing the validation of alternatives to animal testing. Altex. 2024;41:545&#8211;66.<pub-id pub-id-type=\"pmid\">39440996</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.14573/altex.2410011</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR49\"><label>49.</label><citation-alternatives><element-citation id=\"ec-CR49\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Ezugwu</surname><given-names>AE</given-names></name><name name-style=\"western\"><surname>Ikotun</surname><given-names>AM</given-names></name><name name-style=\"western\"><surname>Oyelade</surname><given-names>OO</given-names></name><name name-style=\"western\"><surname>Abualigah</surname><given-names>L</given-names></name><name name-style=\"western\"><surname>Agushaka</surname><given-names>JO</given-names></name><name name-style=\"western\"><surname>Eke</surname><given-names>CI</given-names></name><name name-style=\"western\"><surname>Akinyelu</surname><given-names>AA</given-names></name></person-group><article-title>A comprehensive survey of clustering algorithms: state-of-the-art machine learning applications, taxonomy, challenges, and future research prospects</article-title><source>Eng Appl Artif Intell</source><year>2022</year><volume>110</volume><fpage>104743</fpage><pub-id pub-id-type=\"doi\">10.1016/j.engappai.2022.104743</pub-id></element-citation><mixed-citation id=\"mc-CR49\" publication-type=\"journal\">Ezugwu AE, Ikotun AM, Oyelade OO, Abualigah L, Agushaka JO, Eke CI, et al. A comprehensive survey of clustering algorithms: state-of-the-art machine learning applications, taxonomy, challenges, and future research prospects. Eng Appl Artif Intell. 2022;110:104743.</mixed-citation></citation-alternatives></ref><ref id=\"CR50\"><label>50.</label><citation-alternatives><element-citation id=\"ec-CR50\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Hartung</surname><given-names>T</given-names></name><name name-style=\"western\"><surname>Maertens</surname><given-names>A</given-names></name><name name-style=\"western\"><surname>Luechtefeld</surname><given-names>T</given-names></name></person-group><article-title>E-validation &#8211; unleashing AI for validation</article-title><source>Altex</source><year>2024</year><volume>41</volume><fpage>567</fpage><lpage>587</lpage><pub-id pub-id-type=\"pmid\">39444208</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.14573/altex.2409211</pub-id></element-citation><mixed-citation id=\"mc-CR50\" publication-type=\"journal\">Hartung T, Maertens A, Luechtefeld T. E-validation &#8211; unleashing AI for validation. Altex. 2024;41:567&#8211;87.<pub-id pub-id-type=\"pmid\">39444208</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.14573/altex.2409211</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR51\"><label>51.</label><citation-alternatives><element-citation id=\"ec-CR51\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Bouvier d&#8217;Yvoire</surname><given-names>M</given-names></name><name name-style=\"western\"><surname>Prieto</surname><given-names>P</given-names></name><name name-style=\"western\"><surname>Blaauboer</surname><given-names>BJ</given-names></name><name name-style=\"western\"><surname>Bois</surname><given-names>FY</given-names></name><name name-style=\"western\"><surname>Boobis</surname><given-names>A</given-names></name><name name-style=\"western\"><surname>Brochot</surname><given-names>C</given-names></name><etal/></person-group><article-title>Physiologically-based kinetic modelling (PBK modelling): Meeting the 3Rs agenda. The report and recommendations of ECVAM workshop 63</article-title><source>Altern Lab Anim</source><year>2007</year><volume>35</volume><fpage>661</fpage><lpage>671</lpage><pub-id pub-id-type=\"doi\">10.1177/026119290703500606</pub-id><pub-id pub-id-type=\"pmid\">18186671</pub-id></element-citation><mixed-citation id=\"mc-CR51\" publication-type=\"journal\">Bouvier d&#8217;Yvoire M, Prieto P, Blaauboer BJ, Bois FY, Boobis A, Brochot C, et al. Physiologically-based kinetic modelling (PBK modelling): Meeting the 3Rs agenda. The report and recommendations of ECVAM workshop 63. Altern Lab Anim. 2007;35:661&#8211;71.<pub-id pub-id-type=\"pmid\">18186671</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1177/026119290703500606</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR52\"><label>52.</label><citation-alternatives><element-citation id=\"ec-CR52\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Blaauboer</surname><given-names>BJ</given-names></name></person-group><article-title>Biokinetic modeling and in vitro-in vivo extrapolations</article-title><source>J Toxicol Environ Health B</source><year>2010</year><volume>13</volume><fpage>242</fpage><lpage>252</lpage><pub-id pub-id-type=\"doi\">10.1080/10937404.2010.483940</pub-id><pub-id pub-id-type=\"pmid\">20574900</pub-id></element-citation><mixed-citation id=\"mc-CR52\" publication-type=\"journal\">Blaauboer BJ. Biokinetic modeling and in vitro-in vivo extrapolations. J Toxicol Environ Health B. 2010;13:242&#8211;52.<pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1080/10937404.2010.483940</pub-id><pub-id pub-id-type=\"pmid\">20574900</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR53\"><label>53.</label><citation-alternatives><element-citation id=\"ec-CR53\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Proen&#231;a</surname><given-names>S</given-names></name><name name-style=\"western\"><surname>Paini</surname><given-names>A</given-names></name><name name-style=\"western\"><surname>Joossens</surname><given-names>E</given-names></name><name name-style=\"western\"><surname>Sala Benito</surname><given-names>JV</given-names></name><name name-style=\"western\"><surname>Berggren</surname><given-names>E</given-names></name><name name-style=\"western\"><surname>Worth</surname><given-names>A</given-names></name><etal/></person-group><article-title>Insights into in vitro biokinetics using virtual cell based assay simulations</article-title><source>Altex</source><year>2019</year><volume>36</volume><fpage>447</fpage><lpage>461</lpage><pub-id pub-id-type=\"pmid\">30924507</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.14573/altex.1812101</pub-id></element-citation><mixed-citation id=\"mc-CR53\" publication-type=\"journal\">Proen&#231;a S, Paini A, Joossens E, Sala Benito JV, Berggren E, Worth A, et al. Insights into in vitro biokinetics using virtual cell based assay simulations. Altex. 2019;36:447&#8211;61.<pub-id pub-id-type=\"pmid\">30924507</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.14573/altex.1812101</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR54\"><label>54.</label><citation-alternatives><element-citation id=\"ec-CR54\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Costello</surname><given-names>Z</given-names></name><name name-style=\"western\"><surname>Martin</surname><given-names>HG</given-names></name></person-group><article-title>A machine learning approach to predict metabolic pathway dynamics from time-series multiomics data</article-title><source>NPJ Syst Biol Appl</source><year>2018</year><volume>4</volume><fpage>19</fpage><pub-id pub-id-type=\"doi\">10.1038/s41540-018-0054-3</pub-id><pub-id pub-id-type=\"pmid\">29872542</pub-id><pub-id pub-id-type=\"pmcid\">PMC5974308</pub-id></element-citation><mixed-citation id=\"mc-CR54\" publication-type=\"journal\">Costello Z, Martin HG. A machine learning approach to predict metabolic pathway dynamics from time-series multiomics data. NPJ Syst Biol Appl. 2018;4:19.<pub-id pub-id-type=\"pmid\">29872542</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1038/s41540-018-0054-3</pub-id><pub-id pub-id-type=\"pmcid\">PMC5974308</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR55\"><label>55.</label><citation-alternatives><element-citation id=\"ec-CR55\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Hartung</surname><given-names>T</given-names></name><name name-style=\"western\"><surname>Stephens</surname><given-names>M</given-names></name><name name-style=\"western\"><surname>Hoffmann</surname><given-names>S</given-names></name></person-group><article-title>Mechanistic validation</article-title><source>Altex</source><year>2013</year><volume>30</volume><fpage>119</fpage><lpage>130</lpage><pub-id pub-id-type=\"doi\">10.14573/altex.2013.2.119</pub-id><pub-id pub-id-type=\"pmid\">23665802</pub-id><pub-id pub-id-type=\"pmcid\">PMC4086802</pub-id></element-citation><mixed-citation id=\"mc-CR55\" publication-type=\"journal\">Hartung T, Stephens M, Hoffmann S. Mechanistic validation. Altex. 2013;30:119&#8211;30.<pub-id pub-id-type=\"pmid\">23665802</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.14573/altex.2013.2.119</pub-id><pub-id pub-id-type=\"pmcid\">PMC4086802</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR56\"><label>56.</label><citation-alternatives><element-citation id=\"ec-CR56\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>de Vries</surname><given-names>RBM</given-names></name><name name-style=\"western\"><surname>Angrish</surname><given-names>M</given-names></name><name name-style=\"western\"><surname>Browne</surname><given-names>P</given-names></name><name name-style=\"western\"><surname>Brozek</surname><given-names>J</given-names></name><name name-style=\"western\"><surname>Rooney</surname><given-names>AA</given-names></name><name name-style=\"western\"><surname>Wikoff</surname><given-names>DS</given-names></name><etal/></person-group><article-title>Applying evidence-based methods to the development and use of adverse outcome pathways construct mechanistic frameworks for the development and use of non-animal toxicity tests</article-title><source>Altex</source><year>2021</year><volume>38</volume><fpage>336</fpage><lpage>347</lpage><pub-id pub-id-type=\"pmid\">33837437</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.14573/altex.2101211</pub-id><pub-id pub-id-type=\"pmcid\">PMC9394185</pub-id></element-citation><mixed-citation id=\"mc-CR56\" publication-type=\"journal\">de Vries RBM, Angrish M, Browne P, Brozek J, Rooney AA, Wikoff DS, et al. Applying evidence-based methods to the development and use of adverse outcome pathways construct mechanistic frameworks for the development and use of non-animal toxicity tests. Altex. 2021;38:336&#8211;47.<pub-id pub-id-type=\"pmid\">33837437</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.14573/altex.2101211</pub-id><pub-id pub-id-type=\"pmcid\">PMC9394185</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR57\"><label>57.</label><citation-alternatives><element-citation id=\"ec-CR57\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Hartung</surname><given-names>T</given-names></name></person-group><article-title>Food for thought &#8230; on validation</article-title><source>Altex</source><year>2007</year><volume>24</volume><fpage>67</fpage><lpage>72</lpage><pub-id pub-id-type=\"doi\">10.14573/altex.2007.2.67</pub-id><pub-id pub-id-type=\"pmid\">17844647</pub-id></element-citation><mixed-citation id=\"mc-CR57\" publication-type=\"journal\">Hartung T. Food for thought &#8230; on validation. Altex. 2007;24:67&#8211;72.<pub-id pub-id-type=\"pmid\">17844647</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.14573/altex.2007.2.67</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR58\"><label>58.</label><citation-alternatives><element-citation id=\"ec-CR58\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Bhuller</surname><given-names>Y</given-names></name><name name-style=\"western\"><surname>Avey</surname><given-names>M</given-names></name><name name-style=\"western\"><surname>Deonandan</surname><given-names>R</given-names></name><name name-style=\"western\"><surname>Hartung</surname><given-names>T</given-names></name><name name-style=\"western\"><surname>Hilton</surname><given-names>GM</given-names></name><name name-style=\"western\"><surname>Marles</surname><given-names>RJ</given-names></name><etal/></person-group><article-title>Ethical principles for regulatory risk decision-making</article-title><source>Regul Toxicol Pharmacol</source><year>2025</year><volume>159</volume><fpage>105813</fpage><pub-id pub-id-type=\"doi\">10.1016/j.yrtph.2025.105813</pub-id><pub-id pub-id-type=\"pmid\">40122155</pub-id></element-citation><mixed-citation id=\"mc-CR58\" publication-type=\"journal\">Bhuller Y, Avey M, Deonandan R, Hartung T, Hilton GM, Marles RJ, et al. Ethical principles for regulatory risk decision-making. Regul Toxicol Pharmacol. 2025;159:105813.<pub-id pub-id-type=\"pmid\">40122155</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1016/j.yrtph.2025.105813</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR59\"><label>59.</label><citation-alternatives><element-citation id=\"ec-CR59\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Wiens</surname><given-names>J</given-names></name><name name-style=\"western\"><surname>Saria</surname><given-names>S</given-names></name><name name-style=\"western\"><surname>Sendak</surname><given-names>M</given-names></name><name name-style=\"western\"><surname>Ghassemi</surname><given-names>M</given-names></name><name name-style=\"western\"><surname>Liu</surname><given-names>VX</given-names></name><name name-style=\"western\"><surname>Doshi-Velez</surname><given-names>F</given-names></name><etal/></person-group><article-title>Do no harm: a roadmap for responsible machine learning for health care</article-title><source>Nat Med</source><year>2019</year><volume>25</volume><fpage>1337</fpage><lpage>1340</lpage><pub-id pub-id-type=\"doi\">10.1038/s41591-019-0548-6</pub-id><pub-id pub-id-type=\"pmid\">31427808</pub-id></element-citation><mixed-citation id=\"mc-CR59\" publication-type=\"journal\">Wiens J, Saria S, Sendak M, Ghassemi M, Liu VX, Doshi-Velez F, et al. Do no harm: a roadmap for responsible machine learning for health care. Nat Med. 2019;25:1337&#8211;40.<pub-id pub-id-type=\"pmid\">31427808</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1038/s41591-019-0548-6</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR60\"><label>60.</label><citation-alternatives><element-citation id=\"ec-CR60\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Hartung</surname><given-names>T</given-names></name><name name-style=\"western\"><surname>Hoffmann</surname><given-names>S</given-names></name><name name-style=\"western\"><surname>Whaley</surname><given-names>P</given-names></name></person-group><article-title>Assessing risk of bias in toxicological studies in the era of artificial intelligence</article-title><source>Arch Toxicol</source><year>2025</year><volume>99</volume><fpage>3065</fpage><lpage>3090</lpage><pub-id pub-id-type=\"doi\">10.1007/s00204-025-03978-5</pub-id><pub-id pub-id-type=\"pmid\">40615561</pub-id><pub-id pub-id-type=\"pmcid\">PMC12367879</pub-id></element-citation><mixed-citation id=\"mc-CR60\" publication-type=\"journal\">Hartung T, Hoffmann S, Whaley P. Assessing risk of bias in toxicological studies in the era of artificial intelligence. Arch Toxicol. 2025;99:3065&#8211;90.<pub-id pub-id-type=\"pmid\">40615561</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1007/s00204-025-03978-5</pub-id><pub-id pub-id-type=\"pmcid\">PMC12367879</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR61\"><label>61.</label><mixed-citation publication-type=\"other\">FDA. Artificial Intelligence and Machine Learning in Medical Devices. U.S. Food and Drug Administration. 2023. Available at: <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://www.fda.gov/medical-devices/software-medical-device-samd/artificial-intelligence-and-machine-learning-software-medical-device\">https://www.fda.gov/medical-devices/software-medical-device-samd/artificial-intelligence-and-machine-learning-software-medical-device</ext-link>. Accessed 25 Nov 2025.</mixed-citation></ref><ref id=\"CR62\"><label>62.</label><mixed-citation publication-type=\"other\">Stanford University. Artificial intelligence index report 2025. Stanford HAI. 2025. Available at: <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://hai.stanford.edu/ai-index/2025-ai-index-report\">https://hai.stanford.edu/ai-index/2025-ai-index-report</ext-link>. Accessed 25 Nov 2025.</mixed-citation></ref><ref id=\"CR63\"><label>63.</label><citation-alternatives><element-citation id=\"ec-CR63\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Christensen</surname><given-names>M</given-names></name><name name-style=\"western\"><surname>Vukadinovic</surname><given-names>M</given-names></name><name name-style=\"western\"><surname>Yuan</surname><given-names>N</given-names></name><name name-style=\"western\"><surname>Ouynag</surname><given-names>D</given-names></name></person-group><article-title>Vision&#8211;language foundation model for echocardiogram interpretation</article-title><source>Nat Med</source><year>2024</year><volume>30</volume><fpage>1481</fpage><lpage>1488</lpage><pub-id pub-id-type=\"doi\">10.1038/s41591-024-02959-y</pub-id><pub-id pub-id-type=\"pmid\">38689062</pub-id><pub-id pub-id-type=\"pmcid\">PMC11108770</pub-id></element-citation><mixed-citation id=\"mc-CR63\" publication-type=\"journal\">Christensen M, Vukadinovic M, Yuan N, Ouynag D. Vision&#8211;language foundation model for echocardiogram interpretation. Nat Med. 2024;30:1481&#8211;8.<pub-id pub-id-type=\"pmid\">38689062</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1038/s41591-024-02959-y</pub-id><pub-id pub-id-type=\"pmcid\">PMC11108770</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR64\"><label>64.</label><citation-alternatives><element-citation id=\"ec-CR64\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Bommasani</surname><given-names>R</given-names></name><name name-style=\"western\"><surname>Liang</surname><given-names>P</given-names></name><name name-style=\"western\"><surname>Lee</surname><given-names>T</given-names></name></person-group><article-title>Holistic evaluation of language models</article-title><source>Ann N Y Acad Sci</source><year>2023</year><volume>1525</volume><fpage>140</fpage><lpage>146</lpage><pub-id pub-id-type=\"doi\">10.1111/nyas.15007</pub-id><pub-id pub-id-type=\"pmid\">37230490</pub-id></element-citation><mixed-citation id=\"mc-CR64\" publication-type=\"journal\">Bommasani R, Liang P, Lee T. Holistic evaluation of language models. Ann N Y Acad Sci. 2023;1525:140&#8211;6.<pub-id pub-id-type=\"pmid\">37230490</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.1111/nyas.15007</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR65\"><label>65.</label><citation-alternatives><element-citation id=\"ec-CR65\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Pognan</surname><given-names>F</given-names></name><name name-style=\"western\"><surname>Steger-Hartmann</surname><given-names>T</given-names></name><name name-style=\"western\"><surname>D&#237;az</surname><given-names>C</given-names></name><name name-style=\"western\"><surname>Blomberg</surname><given-names>N</given-names></name><name name-style=\"western\"><surname>Bringezu</surname><given-names>F</given-names></name><name name-style=\"western\"><surname>Briggs</surname><given-names>K</given-names></name><etal/></person-group><article-title>The eTRANSAFE project on translational safety assessment through integrative knowledge management: achievements and perspectives</article-title><source>Pharmaceuticals</source><year>2021</year><volume>14</volume><fpage>237</fpage><pub-id pub-id-type=\"doi\">10.3390/ph14030237</pub-id><pub-id pub-id-type=\"pmid\">33800393</pub-id><pub-id pub-id-type=\"pmcid\">PMC7999019</pub-id></element-citation><mixed-citation id=\"mc-CR65\" publication-type=\"journal\">Pognan F, Steger-Hartmann T, D&#237;az C, Blomberg N, Bringezu F, Briggs K, et al. The eTRANSAFE project on translational safety assessment through integrative knowledge management: achievements and perspectives. Pharmaceuticals. 2021;14:237.<pub-id pub-id-type=\"pmid\">33800393</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.3390/ph14030237</pub-id><pub-id pub-id-type=\"pmcid\">PMC7999019</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR66\"><label>66.</label><citation-alternatives><element-citation id=\"ec-CR66\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Steger-Hartmann</surname><given-names>T</given-names></name><name name-style=\"western\"><surname>Duchateau-Nguyen</surname><given-names>G</given-names></name><name name-style=\"western\"><surname>Bringezu</surname><given-names>F</given-names></name><name name-style=\"western\"><surname>Onidi</surname><given-names>M</given-names></name><name name-style=\"western\"><surname>Stirn</surname><given-names>M</given-names></name></person-group><article-title>Virtual control groups in non-clinical toxicology &#8211; a replicability challenge</article-title><source>Altex</source><year>2025</year><volume>42</volume><issue>3</issue><fpage>538</fpage><lpage>542</lpage><pub-id pub-id-type=\"pmid\">40302301</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.14573/altex.2503061</pub-id></element-citation><mixed-citation id=\"mc-CR66\" publication-type=\"journal\">Steger-Hartmann T, Duchateau-Nguyen G, Bringezu F, Onidi M, Stirn M. Virtual control groups in non-clinical toxicology &#8211; a replicability challenge. Altex. 2025;42(3):538&#8211;42.<pub-id pub-id-type=\"pmid\">40302301</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.14573/altex.2503061</pub-id></mixed-citation></citation-alternatives></ref><ref id=\"CR67\"><label>67.</label><citation-alternatives><element-citation id=\"ec-CR67\" publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Golden</surname><given-names>E</given-names></name><name name-style=\"western\"><surname>Allen</surname><given-names>D</given-names></name><name name-style=\"western\"><surname>Amberg</surname><given-names>A</given-names></name><name name-style=\"western\"><surname>Anger</surname><given-names>LT</given-names></name><name name-style=\"western\"><surname>Baker</surname><given-names>E</given-names></name><name name-style=\"western\"><surname>Baran</surname><given-names>SW</given-names></name><etal/></person-group><article-title>Toward implementing virtual control groups in nonclinical safety studies: Workshop report and roadmap to implementation</article-title><source>Altex</source><year>2024</year><volume>41</volume><fpage>282</fpage><lpage>301</lpage><pub-id pub-id-type=\"pmid\">38043132</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.14573/altex.2310041</pub-id></element-citation><mixed-citation id=\"mc-CR67\" publication-type=\"journal\">Golden E, Allen D, Amberg A, Anger LT, Baker E, Baran SW, et al. Toward implementing virtual control groups in nonclinical safety studies: Workshop report and roadmap to implementation. Altex. 2024;41:282&#8211;301.<pub-id pub-id-type=\"pmid\">38043132</pub-id><pub-id pub-id-type=\"doi\" assigning-authority=\"pmc\">10.14573/altex.2310041</pub-id></mixed-citation></citation-alternatives></ref></ref-list></back></article></pmc-articleset>",
  "text": "pmc Curr Environ Health Rep Curr Environ Health Rep 365 springeropen Current Environmental Health Reports 2196-5412 pmc-is-collection-domain yes pmc-collection-title Springer PMC12680801 PMC12680801.1 12680801 12680801 41348304 10.1007/s40572-025-00514-6 514 1 Review Navigating the AI Frontier in Toxicology: Trends, Trust, and Transformation Luechtefeld Thomas 1 2 3 Hartung Thomas Thomas.Hartung@uni-konstanz.de 3 4 5 6 1 ToxTrack LLC, Bethesda, MD 20894 USA 2 grid.524916.d Insilica Inc., Rockville, MD 20848 USA 3 Center for Alternatives to Animal Testing (CAAT), Baltimore, MD 21205 USA 4 https://ror.org/00za53h95 grid.21107.35 0000 0001 2171 9311 Doerenkamp-Zbinden-Chair for Evidence-Based Toxicology, Johns Hopkins Bloomberg School of Public Health, 615 N Wolfe St, Baltimore, MD W703221201 USA 5 https://ror.org/0546hnb39 grid.9811.1 0000 0001 0658 7699 CAAT-Europe, University of Konstanz, Konstanz, 78464 Germany 6 CAATevents, Solingen, 42651 Germany 5 12 2025 2025 12 1 501979 51 17 6 2025 5 11 2025 05 12 2025 07 12 2025 07 12 2025 &#169; The Author(s) 2025 2025 https://creativecommons.org/licenses/by/4.0/ Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article&#8217;s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article&#8217;s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/ . Purpose of Review The integration of artificial intelligence (AI) into toxicology marks a profound paradigm shift in chemical safety science. No longer limited to automating traditional workflows, AI is redefining how we assess risk, interpret complex biological data, and inform regulatory decision-making. This article explores the convergence of AI and other new approach methodologies (NAMs), emphasizing key trends such as multimodal learning, causal inference, explainable AI (xAI), generative modeling, and federated learning. Recent Findings These technologies enable more human-relevant, mechanistically grounded, and ethically aligned toxicological predictions&#8212;surpassing the reproducibility and scalability of animal-based methods. However, the dynamic nature of AI models challenges traditional validation paradigms. To address this, we introduced the e-validation framework, which operationalizes the TREAT principles (Trustworthiness, Reproducibility, Explainability, Applicability, Transparency) and incorporates AI-powered modules for reference chemical selection, virtual study simulation, mechanistic cross-validation, and post-validation surveillance through companion agents. Ethical considerations&#8212;including bias audits, equity audits, and participatory governance&#8212;are also foregrounded as critical elements for responsible AI adoption. The emergence of a co-pilot model, where AI augments but does not replace human judgment, offers a pragmatic path forward. Supported by evidence from the 2025 Stanford AI Index and recent regulatory advances, we argue that the infrastructure, economics, and policy momentum are now aligned for global-scale deployment of AI-based toxicology. Summary The future of the field lies not in replicating legacy practices, but in reinventing toxicology as an adaptive, transparent, and ethically grounded science that delivers more accurate, inclusive, and human-centric safety assessments. Lay Summary Artificial intelligence (AI) is changing how we test chemicals for safety. Instead of using animals, new computer-based tools can predict how substances affect human health more quickly, accurately, and ethically. This article looks at how these technologies&#8212;like smart data systems, models that explain their reasoning, and even AI \"agents\" that run simulations&#8212;can improve toxicology. We also introduce a new idea called \"e-validation\", which uses AI to help validate these methods in real-time, not just once. This ensures the models stay up to date and reliable. But using AI safely means tackling big questions: Can we trust results we don't fully understand? How do we prevent unfairness or bias in the data? We suggest a \"co-pilot\" model, where AI supports, but doesn't replace, human experts. With better data sharing, strong ethics, and smarter oversight, AI can help make chemical safety testing more human-focused, fair, and effective. Keywords Artificial Intelligence (AI) Toxicology New Approach Methodologies (NAM) e-Validation Explainable AI (xAI) Chemical risk assessment Regulatory science Bias audit Digital twins Causal modeling Responsible AI Human relevance TREAT principles Ethical toxicology Federated learning Universit&#228;t Konstanz (3156) Open Access funding enabled and organized by Projekt DEAL. pmc-status-qastatus 0 pmc-status-live yes pmc-status-embargo no pmc-status-released yes pmc-prop-open-access yes pmc-prop-olf no pmc-prop-manuscript no pmc-prop-legally-suppressed no pmc-prop-has-pdf yes pmc-prop-has-supplement no pmc-prop-pdf-only no pmc-prop-suppress-copyright no pmc-prop-is-real-version no pmc-prop-is-scanned-article no pmc-prop-preprint no pmc-prop-in-epmc yes issue-copyright-statement &#169; Springer Nature Switzerland AG 2025 Introduction: A Paradigm Shift The integration of artificial intelligence (AI) into toxicology is no longer a speculative vision [ 1 ]; it is a scientific necessity. Over the past two decades, toxicology has evolved from a primarily observational discipline of black-box animal models and some human data to a data-rich science poised for algorithmic innovation. Fueled by the proliferation of big data from high-throughput screening,&#8201;~&#8201;omics, digital pathology, and curated chemical databases as well as machine-readable scientific literature, the field has entered a new era where AI is not merely a tool&#8212;it is a transformative force. This shift is underpinned by the convergence of three accelerating forces: the exponential growth of toxicological data, unprecedented gains in computational power, and rapid advances in machine learning algorithms [ 2 ]. Together, they are reshaping how we interrogate toxicity, predict risk, extract mechanistic insight, and ultimately make regulatory decisions. In this context, AI offers more than automation&#8212;it represents a redefinition of toxicological practice. Modern toxicology must now contend with the \"Five Vs\" of big data&#8212;volume, velocity, variety, veracity, and value [ 3 ]. These dimensions collectively exceed the capacity of traditional methods and demand scalable, adaptive computational approaches. AI excels at distilling signal from complexity, enabling predictive modeling across structurally diverse chemicals, integration of heterogeneous evidence streams, and synthesis of multi-omics and legacy data. At the forefront of this revolution are AI-based New Approach Methodologies (NAMs), which promise not only greater speed and cost efficiency, but also enhanced human relevance and ethical acceptability. Tools such as deep neural networks, graph-based learning, natural language processing, and generative models are enabling new paradigms&#8212;from automated read-across and mechanistic hypothesis generation to probabilistic risk assessment and evidence synthesis [ 4 ]. These emerging paradigms are being benchmarked through comparative validation studies. For instance, RASAR models achieved 87% balanced accuracy across nine OECD guideline endpoints&#8212;surpassing the&#8201;~&#8201;81% reproducibility of the respective animal studies [ 5 ]. Probabilistic read-across and causal-inference models similarly demonstrate enhanced mechanistic resolution and reproducibility over traditional toxicity tests. Such metrics provide quantitative evidence that AI-based NAMs outperform legacy paradigms while improving interpretability and consistency. However, this transformation is not without challenges. AI systems, particularly deep learning models, often suffer from interpretability issues, raising concerns about trust and transparency&#8212;core requirements in regulatory toxicology. Furthermore, biases in training data, lack of standardization, and gaps in cross-disciplinary expertise impede broader adoption. As emphasized in the TREAT framework [ 6 ] and e-validation paradigm [ 7 ], rigorous validation, explainability, and human oversight must be embedded throughout the model lifecycle. The maturation of AI-readiness in toxicology is evident: inference costs have dropped by over 280-fold in just two years, performance saturation is driving the shift from generic to domain-specific models, and regulatory precedents are being set, as seen in the FDA's approval of over 200 AI-enabled devices in 2023 [ 7 ]. Toxicology must now seize this momentum to define how AI can be responsibly, ethically, and scientifically integrated into every stage of chemical safety assessment. In short, toxicology stands at an inflection point. The discipline must evolve from merely adopting AI to actively co-developing it&#8212;ensuring that the next generation of safety science is not only data-driven, but also mechanistically grounded, socially responsible, and globally harmonized. Equally central to responsible innovation is the social dimension. Transitioning toward AI-enabled toxicology will not displace the scientific workforce but rather redirect expertise. Routine in-vivo assay technicians can transition toward data-curation, validation, and quality-assurance roles; regulatory scientists can specialize in AI oversight, bias auditing, and ethical governance. Investment in up-skilling and continuing education must therefore accompany technical deployment to ensure workforce sustainability and social responsibility. The Emerging AI Landscape: What's New in 2025? In Hartung &amp; Kleinstreuer (2025, Table 1 therein) [ 6 ] discussing AI-validation, we highlighted key AI trends poised to reshape toxicology. These include (Fig.&#160; 1 ): Fig.&#160;1 The Emerging AI Landscape and its Implications for Toxicology . A number of trends in AI technological developments were identified and their impact on toxicology is summarized. Boxes in blue indicate current trends, those in purple the longer-term impactors. The white box summarizes the expected impacts on the field Foundations: Data, Modeling, and Infrastructure Data-Centric AI and FAIRification &#8212;In contrast to model-centric AI approaches that focus on algorithmic sophistication, data-centric AI prioritizes dataset quality, curation, and infrastructure. This paradigm is particularly relevant to toxicology, where data heterogeneity, legacy formats, and annotation gaps often undermine model performance. Initiatives such as the EPA's CompTox Chemistry Dashboard, 1 OECD's QSAR Toolbox, 2 and NIEHS's Integrated Chemical Environment (ICE) 3 exemplify data FAIRification&#8212;making data findable, accessible, interoperable, and reusable. 4 Reusable FAIR Implementation Profiles [ 8 ] appear to be a way forward here [ 9 ]. AI systems built on curated, standardized, and semantically annotated data are not only more accurate but also more trustworthy and transparent. Moreover, data-centric workflows increasingly incorporate AI tools themselves to assist in cleaning, labeling, harmonizing, and flagging inconsistencies in toxicological datasets. These \"AI-curates-AI\" cycles are essential for scaling up robust, reproducible, and generalizable toxicology models across institutions, jurisdictions, and species. 5 The old mantra of trash in, trash out still holds, but it is no longer the humans sorting the trash but the machines. Equity-aware data governance is critical. Scenarios in which low-quality or biased &#8216;trash data&#8217; disproportionately represent specific ethnic or geographic sub-populations can perpetuate inequities. FAIRification efforts should therefore include demographic representativeness audits, targeted high-quality data collection where gaps exist, and alignment with CARE (Collective Benefit, Authority to Control, Responsibility, and Ethics) principles to ensure inclusive datasets. Self-supervised learning (SSL) offers a transformative advantage for toxicology, where data scarcity, label noise, and high annotation costs often limit the applicability of supervised machine learning. SSL leverages unlabeled data&#8212;abundant in toxicological literature, chemical registries, omics repositories, and legacy datasets&#8212;to learn useful data representations without requiring predefined labels. This pretraining process allows downstream tasks, such as toxicity prediction or chemical classification, to be fine-tuned on smaller, high-quality labeled datasets, dramatically enhancing model performance and generalizability. For instance, SSL techniques can extract embeddings from chemical graphs or transcriptomic time-series, which can then be used to cluster compounds, identify outliers, or predict missing annotations. Given the abundance of historical toxicology data that are incomplete or inconsistently labeled, SSL could unlock substantial latent value by turning raw, unlabeled information into a source of predictive insight [ 10 &#8211; 12 ]. Synthetic data generation&#8212;via methods such as generative adversarial networks (GANs), variational autoencoders, or large language models&#8212;is increasingly viewed as a practical solution to toxicology's chronic data scarcity and privacy constraints. Synthetic datasets can be used to augment training sets, simulate underrepresented scenarios, or generate in silico populations for probabilistic risk assessment. This approach has been particularly useful in drug discovery and genomics, where data sharing restrictions or rare events limit model training. However, the toxicological utility of synthetic data remains debated, particularly in terms of biological plausibility and statistical fidelity. Overfitting to synthetic artifacts, loss of real-world variance, and \"data nutritional deficiency\" are valid concerns. As such, rigorous quality assessment of synthetic datasets is required before they can be trusted for regulatory decision-making. Nonetheless, when carefully designed and benchmarked, synthetic data may become a valuable complement to traditional datasets&#8212;particularly in precompetitive or federated toxicology initiatives [ 13 , 14 ]. Foundation models &#8212;large-scale, pre-trained models developed on broad datasets&#8212; have become the backbone of modern AI. By pre-training on massive text, image, or biological sequence corpora, models such as GPT-4 (OpenAI, 2023)&#160;[ 15 ], Med-PaLM [ 16 ], and AlphaFold [ 17 ] capture rich general-purpose representations that can be fine-tuned or prompt-tuned for toxicology tasks&#8212;literature mining for adverse outcome pathways, graph-based chemical classification, or proteomic interaction prediction&#8212;without the resource intensity of training from scratch. However, their scale and opacity raise valid concerns about transparency, reproducibility, and regulatory suitability. To address this, the Foundation Model Transparency Index 6 provides a 100-indicator framework assessing model providers&#8217; disclosure practices, 7 while the Explainable AI Toolkit (XAITK) 8 offers modular xAI components (e.g., saliency maps [ 18 ], SHAP values, counterfactual explanations) that can be integrated into toxicology-focused pipelines to illuminate decision logic and satisfy interpretability requirements [ 19 ]. Zero-shot and few-shot learning methods represent a frontier for applying AI in underexplored areas of toxicology. Unlike traditional machine learning models, which require large, annotated datasets, zero-shot learning allows models to generalize to new toxicity endpoints or chemical classes without prior exposure to annotated examples (Fig. 2 ). This is achieved by leveraging semantic relationships, often via embeddings or prompt-based learning in large pre-trained models, such as foundation models like GPT-4 or Med-PaLM. 9 Few-shot learning, in contrast, allows for rapid model adaptation using only a small number of labeled instances, making it ideal for toxicological domains with limited training sets, such as developmental immunotoxicity or endocrine disruption [ 20 ]. These methods are particularly advantageous when assessing rare endpoints or substances, where high-quality labeled data is limited or difficult to generate. When coupled with domain-specific prompts or ontologies, large language or multimodal models can infer hazard potential, enabling applications like automated chemical grouping, virtual screening, and read-across with minimal empirical input [ 2 ]. Such techniques significantly enhance the scalability and agility of AI systems in (non-)regulatory toxicology (Fig.&#160; 2 ), offering a path forward for predictive toxicology that is both efficient and aligned with human-relevant outcomes. Prominent examples are regulatory read-across and grouping [ 21 , 22 ] and &#8220;benign-by-design&#8221;, in the EU called &#8220;safe and sustainable by design&#8221; (SSbD), framework of Green Toxicology [ 23 , 24 ], i.e., the toxicological aspects of Green Chemistry avoiding toxic liabilities early in the product development process. Fig.&#160;2 Zero- and few-shot learning for toxicology workflows . The graphic is visualizing how zero- and few-shot learning plug into toxicology workflows (e.g., data-sparse endpoints to regulatory read-across); Developmental Immunotoxicity and per- and polyfluoroalkyl substances (PFAS) are used as examples of being sparse for (good) data Parallel and Cloud-Based Compute Infrastructure &#8212;The integration of scalable compute resources&#8212;enabled by cloud services and parallel processing architectures&#8212;has lowered the entry barrier for toxicological AI. Cloud platforms like AWS, Azure, and Google Cloud allow rapid scaling of storage and compute power, enabling large-scale training on toxicological datasets or batch evaluations of QSAR models. Parallelization frameworks (e.g., Spark, 10 Ray, 11 or Dask 12 ) can accelerate high-throughput workflows, such as large-scale screening of virtual compound libraries or Monte Carlo simulations in probabilistic risk assessment. Importantly, this infrastructure supports collaborative toxicology through centralized data lakes, version control, and reproducible pipelines. By enabling real-time analysis, cross-institutional modeling, and continuous integration of new data, these tools facilitate a dynamic, open innovation ecosystem that advances both predictive capacity and transparency in toxicological research [ 25 ]. Modeling the Complexity of Toxicological Phenomena Multimodal AI represents one of the most powerful evolutions in toxicological modeling by enabling the integration of diverse data types&#8212;including text,&#8201;~&#8201;omics (genomics, transcriptomics, metabolomics), chemical structures, and imaging data&#8212;into a single analytical framework. In toxicology, this approach is particularly advantageous given the multifactorial nature of toxicity mechanisms, which often require correlating molecular-level perturbations with phenotypic or pathological endpoints. Applications of multimodal AI include digital pathology for objective tissue assessment, multi-omics integration to elucidate toxicity pathways, and real-time exposure monitoring through the fusion of environmental sensor data with biological responses. These capabilities significantly enhance the translational potential of AI-driven predictions, bridging the gap between high-content mechanistic data and regulatory endpoints. As toxicology transitions from apical observations to pathway-based assessments, multimodal architectures are poised to become the analytic backbone of next-generation safety science [ 26 ]. Causal AI marks a fundamental shift in the epistemological foundation of computational toxicology by moving beyond association-based models toward causation-based inference. Traditional AI models excel at identifying statistical correlations but often fall short when tasked with uncovering mechanistic pathways or predicting the consequences of perturbing biological systems. Causal inference frameworks&#8212;especially those grounded in directed acyclic graphs, structural equation models, or counterfactual analysis&#8212;enable the identification of key drivers within adverse outcome pathways (AOPs) [ 27 ], facilitating mechanistic validation and regulatory acceptance. LLM are increasingly capable of supporting mechanistic reasoning or for example the fulfillment of Bradford-Hill criteria for causality [ 28 ]. These tools allow toxicologists to simulate \"what-if\" scenarios, predict the effects of interventions, and prioritize molecular initiating events based on causal relevance rather than statistical association alone. Such capabilities are essential for risk assessment, hazard identification, and the development of human-relevant NAMs. As data-rich toxicology continues to mature, causal AI may redefine how safety science understands and quantifies chemical effects on biological systems [ 29 ]. Physics-informed AI (PI-AI), and actually more science-informed AI, combines data-driven learning with established mechanistic models&#8212;such as toxicokinetics, cell signaling, or biotransformation dynamics&#8212;to improve generalizability and credibility of predictions. These hybrid models incorporate differential equations or physical constraints into the AI learning process, ensuring that outputs remain scientifically plausible and interpretable. In toxicology, PI-AI could improve IVIVE (in-vitro-to-in-vivo-extrapolations) predictions [ 30 ], PBPK model accuracy, or dose&#8211;response extrapolations by embedding known pharmacodynamic principles. For regulators, the integration of first-principles modeling offers reassurance that AI systems are not just statistical correlations, but grounded in biological realism. This synthesis of mechanistic and statistical modeling represents a critical step toward harmonizing AI outputs with regulatory frameworks and translational toxicology needs [ 31 ]. Probabilistic Modeling and Uncertainty Quantification enables toxicological risk assessments to move beyond binary hazard classification toward nuanced, uncertainty-aware decision-making. AI models&#8212;especially Bayesian neural networks and ensemble learning systems&#8212;can provide confidence intervals and probabilistic risk estimates that account for biological variability, data gaps, and extrapolation uncertainty. These models support more robust safety margins and better-informed regulatory decisions, particularly for chemicals with sparse in vivo data. Advanced techniques in uncertainty quantification, such as Monte Carlo dropout, 13 deep ensembles, 14 or variational inference, 15 are waiting to be implemented in toxicology to identify influential parameters and prioritize data acquisition. Furthermore, probabilistic read-across and risk assessment (ProbRA) [ 20 , 32 , 33 ] models are being developed as a refinement of conventional structural analog approaches, incorporating prior knowledge and real-world exposure variance. These frameworks support a more human-centric and evidence-based toxicology [ 34 ]&#8212;critical for translating AI insights into risk governance. Democratizing Access and Building Adaptability Explainable AI (xAI) &#8212;Explainability is not merely a desirable feature for AI in toxicology&#8212;it is a prerequisite for regulatory trust, scientific rigor, and ethical accountability. While deep learning models may offer superior predictive performance, their \"black-box\" nature limits adoption in high-stakes domains like chemical safety assessment. Explainable AI (xAI) addresses this limitation by providing interpretive insights into model behavior, enabling users to understand why a prediction was made and what features contributed most to it. Techniques such as SHAP values, 16 i.e., a game-theoretic approach used to explain the output of any machine learning model, local interpretable model-agnostic explanations (LIME) [ 35 ], i.e., a method that explains the predictions of any machine learning model by approximating it locally with a simpler, interpretable model, as well as integrated gradients, and rule extraction methods can be used to illuminate complex model outputs. 17 xAI also facilitates alignment with mechanistic toxicology frameworks, such as adverse outcome pathways (AOPs), by linking predictions to plausible biological mechanisms. As emphasized by both DARPA and the OECD, explainability is increasingly viewed not just as a technical feature but as a governance requirement for the use of AI in toxicological risk assessment [ 36 ]. AutoML and No-Code AI &#8212;The rise of automated machine learning (AutoML) and no-code AI platforms democratizes (toxicological) modeling by lowering the barrier to entry. AutoML frameworks such as Google's Vertex AI, 18 H2O.ai, 19 or AutoSklearn 20 allow users to build, optimize, and validate machine learning pipelines with minimal manual intervention. For toxicology, this means domain experts without formal training in data science can rapidly develop predictive models for specific endpoints, such as hepatotoxicity or endocrine disruption. These tools automate tasks like feature selection, hyperparameter tuning, and performance benchmarking, freeing up resources and accelerating hypothesis generation. No-code platforms further can extend accessibility by offering drag-and-drop interfaces that support toxicological workflows from dataset ingestion to result visualization. While these tools promise to promote inclusivity and speed, they must be coupled with best practices in validation [ 7 , 37 ], reproducibility, and model documentation to ensure scientific integrity and regulatory alignment. Adaptive and continual learning systems enable AI models to evolve with new data&#8212;critical in a field like toxicology, where understanding of chemical mechanisms and regulations is constantly expanding: PubMed alone gives about 13,000 articles per year with the term&#8221;toxicology&#8221; over the last decade. These systems allow AI models to incrementally update their knowledge base, retrain with emerging evidence, and adapt to shifts in data distribution, such as new formulations or exposure routes. Companion AI agents for post-validation monitoring, as proposed in your e-validation framework [ 7 ], exemplify this trend by tracking model performance over time and signaling when retraining or recalibration is needed. Adaptive AI systems are also crucial for maintaining consistency in toxicological assessments as new AOPs are developed or reference standards change. These dynamic capabilities make continual learning indispensable for trustworthy, up-to-date safety decision support systems. Scaling Collaboration and Privacy-Preserving Analysis Edge AI , also known as on-device AI, and federated learning provide enabling architectures for decentralized toxicological modeling and privacy-preserving analysis. In scenarios where data cannot be centrally pooled&#8212;such as multi-center studies, proprietary industrial datasets, or human subject data&#8212;federated learning allows model training across distributed nodes without data transfer. Edge AI further extends this capability by enabling real-time toxicological inference at the site of data generation, such as sensors in environmental monitoring stations or wearable biosensors. These approaches reduce latency, enhance privacy, and facilitate context-aware modeling in situ. For instance, federated toxicology could harmonize predictive models across pharmaceutical partners without exposing proprietary compounds, while edge AI could power on-device exposure assessments in occupational health settings. These technologies align well with ethical data stewardship, especially under General Data Protection Regulation (GDPR) law of the European Union 21 and related frameworks, and offer scalable pathways toward global, collaborative toxicology without compromising privacy or security. However, decentralized computation introduces new disparities. To maintain result consistency across low- and high-resource nodes, federated frameworks should incorporate standardized validation toolkits, model cards, and inter-node proficiency testing. ISO 42001 22 and OECD AI 23 Principles provide templates for harmonizing quality control and ethical oversight in such distributed environments. Privacy-preserving AI technologies&#8212;such as homomorphic encryption, i.e., a type of encryption that allows computations to be performed on encrypted data without decrypting it first, secure multi-party computation (SMPC), 24 i.e., a cryptographic technique that allows multiple parties to collaboratively compute a function on their private inputs while keeping those inputs secret, and differential privacy, i.e., a technique that allows for data analysis and sharing while protecting the privacy of individual data points protects user data from being traced back to individual users&#8212;are increasingly critical in toxicology, particularly when handling sensitive human exposure or biomonitoring data. These techniques enable the training and deployment of AI models without direct access to raw data, thereby safeguarding propriety and confidentiality while still extracting value. Beyond de-identification, ethical deployment requires explicit consent for algorithmic data use. Dynamic consent models&#8212;allowing participants to grant, withdraw, or refine permission for AI-based analysis&#8212;should be embedded in toxicology data-collection workflows. Consent forms should transparently specify potential secondary uses of anonymized data by AI systems. In collaborative toxicological research or regulatory decision-making, where industry hesitancy over intellectual property and patient privacy concerns can limit data sharing, these approaches facilitate secure collaboration. Privacy-preserving AI also supports compliance with frameworks like the GDPR law of the European Union 25 or the US Health Insurance Portability and Accountability Act (HIPAA), 26 making it an essential component of trustworthy AI ecosystems. When combined with federated learning, these technologies could create secure, distributed toxicology infrastructures that transcend institutional and jurisdictional barriers. Advanced Horizons: Automation and New Hardware Agentic AI , or AI agents capable of autonomous reasoning and task execution, introduces the potential for self-directed workflows in toxicology&#8212;from literature review and study design to experimental optimization and data interpretation. These agents, built upon large language models and reinforcement learning frameworks, can plan, execute, and revise multistep procedures, offering a vision of fully automated toxicological pipelines. This is probably the most transformative part of current developments, as it changes the role of AI from a knowledge acquiring and digesting algorithm on command to an orchestrator of active inquiry and self-optimization. For instance, an AI agent might design a virtual screening experiment, adjust dose ranges based on early feedback, and generate preliminary risk assessments. However, the practical deployment of such systems remains constrained by current limitations in multistep reasoning accuracy. Error compounding across long agentic chains, coupled with challenges in uncertainty quantification and task-specific calibration, hinders their application in high-stakes regulatory contexts. First proof-of-concept demonstrations, however, without peer-review, exist [ 38 ], which introduces TxAgent, an AI agent designed for therapeutic reasoning that leverages multi-step reasoning and real-time biomedical knowledge retrieval across a toolbox of 211 tools. However, robust governance, validation frameworks, and error-mitigation strategies must be developed before agentic AI can become a mainstay in regulatory toxicology [ 7 ]. A critical caveat concerns hallucination&#8212;the generation of plausible but false outputs. Mitigation strategies include retrieval-augmented generation (RAG), ensemble verification, and mandatory human-in-the-loop review before high-impact conclusions are adopted. Continuous benchmark testing for factual accuracy should accompany every agentic deployment. Very soon, we will see agents capable of integrating and manipulating a wide range of tools&#8212;constantly running, dynamically scaling, and even cloning themselves in response to new signals. For toxicology, this could manifest as a continuous monitoring agent across the human exposome, capable of both interpreting exposure signals and initiating mitigation or hazard assessment actions. These agentic models will not just analyze data, but self-improve by interacting with real-world testing environments. Their value will hinge on access to experiments, not just pretraining. The ability to design, execute, and learn from minimally harmful yet maximally informative experiments will become a defining competitive advantage, especially compared to static models trained on legacy datasets. This ties directly to our points around bias, causality, and the epistemic limits of black-box AI. Experimental feedback loops can shift AI from correlation to true scientific inquiry. Latest development include Recursive Self-improving AI (RSI), 27 i.e., systems capable of autonomously enhancing their own intelligence, algorithms, and architecture through iterative self-modification cycles. Unlike traditional AI that requires human intervention for improvements, RSI systems improve their ability to self-improve, creating a feedback loop that can lead to exponential growth in intelligence and capabilities; their use is currently mostly limited to coding and solving mathematical problems, but they show a direction where AI independently finds problem solving strategies. Digital twins &#8212;computational replicas of biological systems informed by individual data&#8212;are emerging as powerful platforms for personalized and predictive toxicology. In combination with AI, digital twins can simulate chemical exposure scenarios, dynamically model organ-specific responses, and support patient-centric safety decisions. In toxicology, virtual twin systems are being developed using integrated PBPK (physiologically based pharmacokinetic) models, exposure datasets, and&#8201;~&#8201;omics signatures to predict real-time responses under different conditions. These models allow for scenario testing, dose extrapolation, and early identification of susceptible subpopulations. When implemented with cloud-based infrastructures, digital twins can also be embedded in decision-support systems for regulators or industry risk managers. The ONTOX project 28 [ 39 , 40 ] and NICEATM's Integrated Chemical Environment (ICE) 29 already use components of this paradigm, positioning it as a next-generation NAM for regulatory toxicology [ 32 ]. A broader EU Virtual Human Twins (VHT) Initiative 30 launched in 2023 to integrate multi-scale computational models of human physiology. It combines the EDITH 31 (Ecosystem for Digital Twins in Healthcare) roadmap for ecosystem development led by the Virtual Physiological Human Institute (VPHi) 32 and Horizon Europe funding (&#8364;80 million) for research on patient-specific disease models and a &#8364;24 million digital platform (Digital Europe Programme) for model integration and validation. The Initiative completed its first demonstration phase in mid-2025, validating cardiac and hepatic digital-twin modules within the EDITH WP2 framework. These milestones confirm that AI-driven virtual humans are moving from concept to early implementation in regulatory research. Generative AI , particularly transformer-based architectures such as generative adversarial networks (GANs) and large language models (LLMs), is reshaping toxicological workflows [ 14 , 41 ]. These models are capable of generating synthetic chemical structures, filling in missing exposure data, simulating literature summaries, and even producing mechanistic hypotheses. For example, GANs have been used to create synthetic toxicogenomic profiles that mirror real data distributions, providing additional training material for rare endpoints. LLMs can automate literature triage, protocol drafting, and annotation of legacy studies, thereby accelerating evidence synthesis. However, generative models must be carefully validated to prevent the propagation of artifacts or hallucinated outputs, especially when informing regulatory decisions. Nevertheless, their creative and data-augmentation capabilities make them powerful allies in addressing the data scarcity, heterogeneity, and synthesis [ 42 ] challenges endemic to toxicology [ 43 ]. Not all data types should be synthetically reproduced. Generation of identifiable human exposure records, proprietary in-vivo datasets, or clinical information without governance approval poses ethical and legal risks. Generative pipelines must therefore include safeguards and provenance tagging to prevent inadvertent re-creation of protected data. Neuromorphic and Quantum Computing &#8212;Emerging hardware paradigms such as neuromorphic computing and quantum computing offer long-term prospects for expanding the scope of AI in toxicology by increasing computational power. Neuromorphic chips mimic the architecture of biological neural systems, allowing energy-efficient processing of complex, temporal data such as electrophysiology or toxicokinetics. These systems could enable real-time learning from biosensors or in vitro time-course data, supporting dynamic toxicity assessment. Quantum computing, although still nascent, holds the potential to revolutionize molecular simulations, multi-objective optimization, and network-based causal inference&#8212;tasks that are computationally prohibitive for classical systems. For example, simulating toxicant interactions with protein networks or predicting emergent properties in chemical mixtures could benefit from the exponential speedup quantum algorithms promise. While practical deployment is years away, early investment in quantum-aware toxicology models and neuromorphic architecture optimization will prepare the field for next-generation breakthroughs. Ranking Ethical Priorities for AI in Toxicology We have recently described two visions for the future of AI-facilitated science, i.e., first a more and more AI-driven scAInce [ 44 ] and the development of toxicology toward a Human Exposome Project [ 45 ] through AI [ 46 ] with considerable ethical challenges [ 47 ]. To translate ethical discourse into action, we introduce a ranked priority matrix (Table&#160; 1 ) classifying immediacy of ethical concerns: short-term&#8212;bias and transparency; mid-term&#8212;consent, data sovereignty, and workforce impact; long-term&#8212;algorithmic autonomy and sustainability. This ranked matrix translates abstract ethical discourse into staged action priorities, providing regulators and researchers with a pragmatic roadmap for responsible AI integration in toxicology. This framing provides a practical roadmap for regulators and researchers. Table&#160;1 Ranked ethical priorities for AI in toxicology Time Horizon Ethical Focus Area Core Challenge Operational Imperative / Example Implementation Short-term (0&#8211;3 years) Bias and Fairness Historical toxicology data reflect systemic, methodological, or demographic biases that can propagate through AI models Conduct bias audits across datasets and algorithms; employ fairness metrics (e.g., demographic parity); establish independent oversight panels Transparency and Explainability Deep models act as &#8220;black boxes,&#8221; eroding trust and regulatory acceptance Mandate model documentation (model cards); adopt explainable-AI toolkits (e.g., SHAP, LIME); publish interpretability benchmarks per OECD AI Principles Mid-term (3&#8211;10 years) Consent and Data Sovereignty AI training often repurposes human or proprietary toxicology data without ongoing consent or governance Embed dynamic consent frameworks; align with GDPR/HIPAA; implement data-provenance tracking and CARE/FAIR compliance Workforce Impact and Accountability Automation shifts skill demands, risking displacement or deskilling of laboratory and regulatory personnel Invest in up-skilling programs for AI literacy; define shared human&#8211;machine accountability (&#8220;co-pilot&#8221; model) Long-term (10&#8201;+&#8201;years) Algorithmic Autonomy Agentic or self-improving AI may operate beyond human interpretability or oversight Require human-in-the-loop governance; implement continuous audit trails, sandboxed deployment, and ethical &#8220;kill switches.&#8221; Sustainability and Societal Equity Compute intensity and unequal access threaten environmental and global fairness goals Promote green AI metrics (energy transparency, carbon reporting); ensure equitable access for low-resource regulators through federated infrastructures Timelines To contextualize development timelines, near-term (2025&#8211;2030) adoption is expected for federated and xAI workflows; medium-term (2030&#8211;2035) for agentic and digital-twin integration; and long-term (&gt;&#8201;2035) for neuromorphic and quantum computing applications. These projections provide a temporal roadmap for research and regulatory preparation. From Validation Bottlenecks to E-Validation and Companion Agents The transformative potential of AI-based NAMs in toxicology is increasingly recognized, but it remains bottlenecked by legacy validation frameworks that were originally designed for static, animal-centric assays. Traditional validation&#8212;rooted in ring trials, protocol freezing, and one-to-one concordance with animal models&#8212;cannot accommodate the dynamism, complexity, and continuous learning capabilities of modern AI systems [ 7 ]. Similar validation bottlenecks are recognized in other domains such as radiology, genomics, and medical device software. The FDA&#8217;s continuous-learning framework and EMA&#8217;s adaptive evidence models offer instructive precedents for how performance-centric validation can coexist with regulatory rigor [ 38 , 48 ]. The urgent need for faster, more adaptive, and scientifically robust validation pathways has led to the emergence of the e-validation framework, which reimagines the validation process through the lens of AI, translational science, and mechanistic relevance. At the heart of e-validation are five interlocking AI-powered components [ 5 ]: Smart Reference Chemical Selection Instead of relying on historical reference compounds chosen by expert consensus&#8212;which often results in overused, biased, or mechanistically narrow test sets&#8212;e-validation deploys clustering algorithms (e.g., k-means, Density-Based Spatial Clustering of Applications with Noise (DBSCAN)) [ 49 ] to ensure structurally and mechanistically diverse chemical spaces are covered. Reference chemicals are selected not only for their availability and historical data but also for their relevance to human biology and the mechanistic diversity they represent. Chemical clustering leverages molecular fingerprints, bioactivity profiles, and AOP ontology embeddings to ensure mechanistic and structural diversity. This increases coverage of chemical space and improves transferability of validation results across compound classes. These selections can be iteratively refined as new data emerges, and integrated with public databases to ensure regulatory applicability. Simulation of Validation Study Outcomes Validation no longer needs to be confined to wet-lab trials with fixed endpoints. The e-validation framework [ 50 ] uses virtual validation studies that combine physiologically based pharmacokinetic (PBPK) and in vitro biokinetic modeling with QSAR predictions, systems biology networks, and statistical optimization to pre-test study designs [ 51 &#8211; 53 ]. By simulating experimental conditions&#8212;such as dosing ranges, time points, and replication schemes&#8212;AI-driven modeling enables scenario testing, power calculations, and sensitivity analyses before laboratory execution. This allows identification of designs with the highest informational yield and reproducibility, while minimizing resource demands and ethical costs. Simulated validation thus becomes an evidence-preparation stage that anticipates real-world outcomes, identifies key sources of uncertainty, and guides optimal experimental design [ 32 , 50 , 54 ]. Iterative simulations can compare study architectures across virtual populations, generating quantitative predictions of expected variance and robustness. The result is not a replacement for empirical testing but a refinement step that makes subsequent physical validation faster, more reproducible, and better aligned with human-relevant biology. Mechanistic Cross-Validation via Literature Mining Mechanistic validation [ 55 , 56 ], often under-emphasized in traditional frameworks, becomes a cornerstone of e-validation. AI&#8212;particularly large language models (LLMs) and graph neural networks&#8212;can mine the literature for evidence of pathway activation, AOP concordance, and causal inference [ 28 ]. Using tools like NLP-enhanced Bradford Hill assessments [ 28 ], mechanistic cross-validation aligns NAMs with human-relevant biological processes rather than simply mimicking animal results. AI-Enhanced Training Dashboards A core component of the validation process is ensuring consistent implementation across participating labs. AI-enhanced dashboards offer protocol customization, troubleshooting, video support, and live guidance for end users. This fosters consistency and transparency across validation studies while democratizing access to best practices. Post-validation, these dashboards serve as knowledge transfer tools for regulatory and industry uptake.&#160;Current exemplars include the OECD AI Platform 33 and NIH NAM-Navigator 34 platforms, which provide standardized dashboard hosting under neutral, multi-stakeholder governance. Such public&#8211;private stewardship minimizes conflicts of interest while ensuring transparent, auditable dissemination of training materials. Continuous Performance Monitoring and Companion Agents The concept of companion post-validation agents represents an evolution in how validated methods are maintained over time. These autonomous AI systems monitor performance metrics in real-world use, perform back-testing as new data accumulates, and flag when retraining or re-validation may be necessary. This marks a departure from the current static view of validation and introduces a lifecycle model where AI-based NAMs evolve alongside evidence and regulatory requirements [ 20 ]. This entire e-validation framework resonates with and operationalizes the TREAT criteria&#8212;Trustworthiness, Reproducibility, Explainability, Applicability, and Transparency&#8212;proposed for AI applications in regulatory contexts [ 6 ]. Importantly, e-validation complements the modular and fit-for-purpose concepts already gaining traction in validation science. It also aligns with the translational medicine paradigm, particularly through the use of qualified biomarkers to benchmark predictive and mechanistic validity, not merely historical concordance with animal models [ 32 ]. On a philosophical level, e-validation addresses key ethical and epistemological critiques of the existing validation paradigm. Validation, as discussed [ 38 ], must shift from being a static gatekeeper to a dynamic enabler&#8212;one that ensures scientific credibility without stifling innovation [ 33 ]. It must accommodate uncertainty, embrace adaptive designs, and prioritize human health relevance over legacy comparators. In sum, e-validation and companion agents together propose a paradigm shift from \"validate and forget\" to \"validate, monitor, and evolve.\" This approach offers not only a scientific upgrade but also an ethical one&#8212;aligning toxicology with the values of animal replacement, human relevance, and continuous improvement [ 34 ]. Importantly, AI need not imply immediate full replacement of animal studies. Progressive refinement and reduction through AI-enabled prioritization can drastically decrease animal use while maintaining data continuity. The e-validation framework thus supports all 3Rs&#8212;replacement, reduction, and refinement&#8212;within a unified strategy (Fig.&#160; 3 ). Fig.&#160;3 The concept of e-validation . The figure depicts the key components of an AI-facilitated validation process for in vitro, computational and AI-based methods [ 7 , 51 ] Bridging Innovation and Oversight The surge in AI capabilities for toxicology&#8212;spanning predictive modeling, data harmonization, mechanistic insight generation, and in silico experimentation&#8212;has transformed what is technically possible. However, this innovation outpaces existing validation, governance, and oversight structures, prompting a critical reckoning within regulatory science. Bridging this innovation-oversight divide is essential to harness AI's potential responsibly, credibly, and equitably. This section explores three central dimensions: trust and epistemology, governance frameworks, and the ethical&#8211;political context of regulatory AI [ 35 ]. Rethinking Trust in the Age of Algorithmic Prediction AI's epistemological disruption to toxicology centers on the tension between accuracy and understanding. Classical validation frameworks emphasize reproducibility, transparency, and mechanistic clarity. Yet many AI systems, particularly deep neural networks, offer robust performance without interpretable logic or consistent reproducibility, particularly when outputs depend on random initializations or iterative retraining [ 36 ]. This raises profound questions: Can we trust AI systems we do not fully understand? Should we prioritize empirical performance over mechanistic transparency? What constitutes sufficient evidence for regulatory confidence? While some argue that non-reproducible models cannot meet the standards of toxicology&#8212;a field long reliant on Good Laboratory Practice (GLP) and standard operating procedures&#8212;others propose a performance-centric validation, where a model is trusted if it consistently delivers accurate predictions under predefined conditions [ 37 ]. This tension recalls debates in medicine over \"black-box\" diagnostics that outperform clinicians but resist human explanation. One potential resolution is layered trust architecture, where models are conditionally accepted for tightly scoped use-cases (e.g., screening or prioritization) but require additional validation layers&#8212;such as explainable AI (xAI), post-deployment monitoring, and uncertainty quantification&#8212;for broader applications [ 38 ]. This reminds of the &#8220; incremental validation &#8221; we suggested earlier expanding applicability domains continuously [ 57 ]. Building Adaptive, Collaborative Oversight Frameworks To integrate AI safely into toxicology, oversight must evolve from static validation to adaptive lifecycle governance. This shift is already underway in adjacent sectors. The FDA's action plan for AI/ML-based software 35 emphasizes the continuous learning nature of these models and proposes pre-determined change control protocols, real-time monitoring, and transparency measures [ 39 ]. Similarly, OECD and EU initiatives now support modular, fit-for-purpose validation and the use of evidence-weighted frameworks that include biomarker performance, mechanistic validity, and confidence intervals, rather than binary concordance with animal models [ 40 ]. These initiatives are advancing steadily: the OECD modular validation pilot completed two inter-laboratory case studies in 2025, and the EU ONTOX project, pioneering a lot of AI use in toxicology, reached mid-term milestones including AOP alignment and a publicly released model catalogue. A centerpiece of this new oversight landscape is the e-validation framework (see above). This approach aligns with the TREAT principles&#8212;Trustworthiness, Reproducibility, Explainability, Applicability, and Transparency&#8212;which form an emerging gold standard for AI in safety&#8211;critical contexts. Rather than validating a model once and freezing it, the emphasis shifts to dynamic credibility, where validation is an ongoing, evidence-responsive process [ 6 ]. Global harmonization is also critical. Collaborative initiatives such as the Global Coalition for Regulatory Science Research (GCRSR) 36 and International Cooperation on Alternative Test Methods (ICATM) 37 aim to standardize AI validation expectations across borders, avoiding the emergence of divergent regulatory ecosystems that could fragment trust or stall progress. Ethics, Equity, and the Politics of Risk While the technical capabilities of AI-enabled NAMs continue to expand&#8212;delivering increasingly accurate, scalable, and human-relevant predictions&#8212;regulatory science must grapple with deep, foundational questions that challenge long-held assumptions about evidence, trust, and oversight [ 58 ]. One such question concerns the reliability of non-reproducible but consistently accurate AI models. Traditionally, reproducibility has been a cornerstone of toxicological validation, but AI models&#8212;especially those employing deep learning or probabilistic outputs&#8212;often operate with degrees of stochasticity that defy exact duplication. This calls for a paradigm shift in how reproducibility is defined and evaluated, especially if models demonstrate performance stability over time and across datasets [ 7 ]. Another core issue is the requirement for explainability. Should the ability to interpret an AI model's decision pathway be a precondition for regulatory acceptance, or is empirical accuracy alone sufficient in specific contexts? While many support explainability as a matter of transparency and trust, Bhuller et al. remind us that ethical principles such as autonomy and open decision-making also demand interpretability, especially in decisions that affect public health or environmental protection [ 50 ]. Ensuring that stakeholders can make informed choices about risk assessments aligns with both scientific integrity and moral norms around fairness and accountability. Equally pressing is the question of how to manage and correct for the biases embedded in legacy toxicological datasets, many of which were generated using outdated or ethically questionable practices. These datasets&#8212;often used to train AI models&#8212;carry forward implicit assumptions and structural disparities. Without active measures to audit and mitigate these biases, AI may amplify, rather than eliminate, existing inequities in risk assessment. Ethical principles such as \"reduce disparities\" and \"maintain respect and trust,\" as articulated in Bhuller et al.'s projector model, provide important guidance for navigating these challenges [ 50 ]. In response to these dilemmas, consensus is emerging around a \"co-pilot\" model for AI integration into regulatory workflows. Rather than replacing human expertise, AI is envisioned as an analytical assistant: augmenting human reasoning with speed, scope, and statistical rigor, while keeping the final decision authority with human risk assessors. This reflects an ethic of adaptability and shared decision-making, balancing innovation with oversight in a way that aligns with both public trust and institutional responsibility. Moreover, bridging innovation and oversight requires active participation in global harmonization initiatives. Regulatory bodies such as the U.S. FDA are setting new precedents with their lifecycle-based principles for AI/ML models, emphasizing continual model monitoring, retraining protocols, and transparency obligations [ 59 ]. Meanwhile, the OECD and its members have adopted flexible, tiered validation strategies that accommodate emerging technologies and uphold principles like \"fit-for-purpose\" and \"evidence-based decision-making.\" Global platforms such as the GCRSR promote capacity-building through training and joint guidance efforts, ensuring that both high- and low-resource countries can participate in and benefit from the AI transformation of toxicology. These developments represent not only a modernization of regulatory science, but also a reassertion of its ethical mandate. As emphasized in the projector model proposed by Bhuller et al., ethical principles such as openness, stakeholder engagement, fairness, and the One Health perspective must be integral to every phase of risk decision-making&#8212;from problem formulation and data generation to model deployment and post-validation monitoring [ 50 ]. In this light, oversight is not an obstacle to innovation, but its ethical scaffold&#8212;ensuring that new technologies serve not only efficiency and accuracy but also justice, transparency, and the collective well-being of humans, animals, and the environment. To navigate these tensions, ethical AI for toxicology must embed: Bias audits and data provenance tracking , to ensure inclusivity and accuracy across subpopulations, xAI methods to explain predictions in human-understandable terms, Participatory governance , involving civil society, regulators, scientists, and industry in model design, deployment, and oversight, and Tiered access mechanisms , ensuring that low-resource regulatory agencies can benefit from AI without ceding sovereignty to commercial or technical gatekeepers. Bias audits are rapidly becoming an essential component of both traditional and AI-driven toxicological workflows, offering a structured way to identify and mitigate systematic errors that can distort study findings and mislead regulatory decisions. As discussed by Hartung et al. (2025), these audits focus on detecting various forms of bias&#8212;such as selection, performance, detection, attrition, and reporting biases&#8212;in experimental and computational studies [ 60 ]. In the context of AI-enabled toxicology, bias audits must expand beyond classical risk of bias tools to also interrogate data provenance, model assumptions, algorithmic fairness, and outcome reproducibility. This is critical given the susceptibility of AI systems to data bias (e.g., non-representative training sets), algorithmic bias (e.g., overfitting, feature selection bias), and institutional bias (e.g., confirmation bias embedded during model development). As such, effective bias audits should integrate human-led domain expertise with automated tools for bias detection&#8212;such as SHAP or LIME for model explainability, or AI-enabled protocol checkers for methodological consistency. The goal is not only to flag risks, but to estimate the probabilistic impact and direction of those biases on predicted outcomes, ultimately guiding safer, more equitable chemical assessments. Moreover, as discussed already, a co-pilot paradigm is gaining favor, where AI may offer expansive data integration, mechanistic modeling, and scenario simulation, but final decisions remain with expert risk assessors who can weigh context, uncertainty, and ethical nuance. This co-pilot model provides a pragmatic equilibrium between innovation and oversight, autonomy and control, speed and trust. 38 In conclusion, bridging innovation and oversight requires nothing less than a rethinking of what validation means in the age of AI. Static frameworks must give way to dynamic ecosystems. Reproducibility must be complemented by robustness. Trust must be earned through transparency, feedback, and performance. Only then can toxicology fully benefit from the predictive power of AI while remaining true to its ethical commitments and societal mandate [ 6 , 61 ]. AI Readiness Landscape: From Capacity to Consequence The evolving landscape of AI readiness&#8212;spanning technological capacity, cost, trust, and institutional adoption&#8212;signals a pivotal moment for its integration into toxicology. The 2025 Stanford AI Index Report [ 62 ] provides a comprehensive, global benchmark of this transformation, with findings that directly reinforce the feasibility and urgency of embedding AI into toxicological science and regulatory decision-making. Scaling with Affordability and Accessibility One of the most striking developments is the dramatic drop in inference cost for large language models. A system performing at the level of GPT-3.5 now costs less than $0.07 per million tokens, down from $20 in late 2022&#8212;a&#8201;&gt;&#8201;280-fold reduction in 18&#160;months [ 54 ]. This cost democratization, coupled with the rise of small, efficient models (e.g., Microsoft's Phi-3-mini with 3.8B parameters), expands access for academic labs, startups, and public health agencies alike. Meanwhile, model performance is saturating at the frontier: the Elo score gap between the top and 10th-ranked models has narrowed from 11.9% to just 5.4% in one year, and the top two models are now separated by only 0.7%. This convergence marks a transition from raw power to domain specialization, interpretability, and real-world integration&#8212;a shift that favors toxicology applications where explainability and regulatory trust are paramount [ 54 ]. Institutionalization of AI in Biomedicine AI is increasingly embedded in real-world health technologies. In 2023 alone, the FDA approved 223 AI-enabled medical devices, up from just 6 in 2015 [ 54 ]. Simultaneously, domain-specific foundation models like Med-Gemini, 39 ChexAgent, 40 and EchoCLIP [ 63 ] are redefining how AI processes clinical, radiological, and&#8201;~&#8201;omics data. These developments parallel trends in toxicology, where in silico predictions, high-content screening, and organoid data require robust interpretive frameworks. The normalization of AI across regulatory medicine validates the prospect of similar uptake in chemical risk assessment&#8212;particularly for evidence-weighted read-across, developmental neurotoxicity, and adverse outcome pathway (AOP) modeling [ 7 ]. Trust Gaps and the Rise of Responsible AI Benchmarks Despite technical advances, responsible AI (RAI) practice lags behind deployment. The number of reported AI incidents increased by over 56% in 2024 [ 54 ], while only a fraction of models are evaluated on emerging safety and transparency benchmarks like HELM Safety 41 [ 64 ] or Fact-Checking Transparency Benchmarks (FACTS). 42 Noteworthy, AIR-Bench 2024 43 is a benchmark based on risk categories from regulations and policies evaluates models on a comprehensive taxonomy of AI risks (currently 8 government regulations and 16 company policies into a four-tiered safety taxonomy with 314 granular risk categories) enabling standardized evaluation of AI model safety across jurisdictions and regulatory frameworks. They provide standardized benchmarks, open-source code, and public leaderboards to ensure transparency in evaluating AI models, especially Large Language Models, including aspects like safety, bias, and toxicity (N.B., &#8220;toxicity&#8221; in the context of AI models refers to the generation or amplification of harmful, offensive, or malicious content by an artificial intelligence system). We will have to explore how this translates to possible benchmarks for AI in the safety sciences and it underscores the relevance of the proposed TREAT framework (Trustworthiness, Reproducibility, Explainability, Applicability, Transparency) [ 6 ]. The AI Index data supports the notion that post-validation companion agents and continuous uncertainty monitoring are not aspirational concepts&#8212;but necessary guardrails for high-stakes applications [ 7 ]. Strategic Implications for Toxicology The convergence of accelerated compute capabilities, diminishing inference costs, plateauing performance across frontier models, and the mainstreaming of regulatory frameworks for AI has created fertile ground for the transformation of toxicology. What once appeared speculative&#8212;AI-enabled predictive toxicology replacing traditional animal-based paradigms&#8212;is now increasingly feasible. These developments reflect not just a shift in technology, but a profound maturation in the infrastructure and collective mindset surrounding AI in the life sciences. As such, the field stands at a pivotal moment: the readiness for large-scale adoption of AI-based toxicology is no longer a question of possibility, but of strategy. It is now more about trust building and change management than about technological development. To seize this momentum, coordinated action is essential across several key fronts. First, the development and deployment of benchmarking frameworks tailored to toxicological applications is crucial. Tools like HELM and AIR-Bench, originally developed for broader AI model safety evaluations, must be adapted to encompass toxicology-specific endpoints, such as genotoxicity, developmental neurotoxicity, or organ-specific adverse effects. Such benchmarks will provide standardized, comparative performance metrics and foster trust in AI-based predictions across regulatory and research domains. Second, model auditability must become a cornerstone of AI deployment in toxicology. Integrating explainable AI (xAI) techniques&#8212;such as SHAP values, saliency maps, i.e., visual or numerical representations that highlight the most important regions of an input that significantly influence a machine learning model&#8217;s prediction, or feature attribution tools, i.e., methods and software that help interpret and explain the predictions of complex machine learning models by quantifying the contribution of each input feature to a given prediction,&#8212;will help regulators, scientists, and other stakeholders interpret predictions and trace them back to specific data inputs or mechanistic reasoning. This integration is not merely a technical enhancement; it is an accountability mechanism that ensures AI models remain interpretable, responsive to feedback, and transparent in their assumptions and outputs. Third, achieving the full promise of AI-based toxicology requires robust global data-sharing frameworks. Given the distributed nature of toxicological data&#8212;ranging from industry submissions to academic omics studies and regulatory exposure registries&#8212;traditional centralized databases are no longer sufficient. Federated learning and encrypted collaboration platforms offer a way forward, enabling decentralized toxicology consortia to jointly train models without compromising proprietary or sensitive information. This is particularly promising for applications like chemical similarity learning, read-across modeling, and transfer learning for rare or novel endpoints. Increasingly, experience is gained from large pharma consortia on toxicology data sharing and analysis such as eTox, 44 eTRANSAFE 45 [ 65 ] and VICT3R 46 [ 66 ] by the Innovative Medicines Initiative (IMI), now Innovative Health Initiative (IHI). eTox created a large, shared toxicology database (eTOXsys) containing information from over 8,000 studies on nearly 2,000 compounds. eTRANSAFE integrated over 10,000 pharmacological studies from pharmaceutical companies into a unified system, called ToxHub. VICT3R is a public&#8211;private partnership launched in 2024 dedicated to reducing animal use in toxicology research by developing Virtual Control Groups (VCGs) based on data sharing by 23 pharmaceutical companies and an increasing number of Contract Research Organizations (CRO). It was developed out of a workshop organized by our center [ 67 ]. These projects set a new standard for data sharing in pharmaceutical safety by building a secure, standardized, and collaborative data ecosystem that will continue to benefit drug development and regulatory science. Nonetheless, federated learning complicates standardization and auditability. Harmonized metadata ontologies, cryptographically signed model updates, and inter-node proficiency testing are needed to ensure quality control and consistent ethical compliance across decentralized infrastructures. Finally, no discussion of strategy is complete without addressing ethical oversight. As AI systems become embedded in regulatory and public health decisions, the inclusion of equity audits in the design and deployment of new approach methodologies (NAMs) is essential. These audits should examine not only the technical performance of AI models across demographic subgroups, but also the representativeness of training datasets, the inclusiveness of development processes, and the potential for disproportionate impacts on vulnerable populations. Ethical governance must be integrated from the outset&#8212;not as an afterthought, but as a core design principle. Together, these actions form a blueprint for scaling AI in toxicology both responsibly and effectively. They recognize that readiness is not only about technological capability, but about cultural, regulatory, and ethical alignment. As the field advances, these pillars will shape the transition from fragmented innovation to a harmonized, global infrastructure for human-relevant safety science. Outlook: From Disruption to Reinvention Artificial intelligence is poised not merely to streamline existing toxicological methods but to fundamentally transform how we approach chemical safety assessment. In the regulatory context, AI-based NAMs are expected to integrate directly into the pre-clinical&#8211;to&#8211;clinical continuum. Digital-twin and probabilistic simulation models can inform micro-dosing, adaptive trial design, and post-market pharmacovigilance, bridging current gaps between toxicology and clinical risk evaluation. Rather than replicating the outcomes of traditional animal studies, the true potential of AI lies in generating human-relevant, mechanistically informed predictions that are more accurate, ethical, and actionable. This shift represents a reinvention of toxicology itself, aligning the field with the imperatives of precision public health, sustainable innovation, and evidence-based policy. Realizing this vision requires a comprehensive reevaluation of the data that drive toxicological inference. It begins with a decisive commitment to improving data quality&#8212;not only in terms of statistical robustness or completeness, but also in how representative datasets are of human biology, diverse populations, and realistic exposure scenarios. Poorly curated or biased training data can entrench historical errors, particularly when drawn from outdated or poorly standardized animal studies. Therefore, the toxicology community must invest in systematic data FAIRification, curated repositories, and the inclusion of underrepresented endpoints and vulnerable subpopulations. Parallel to this, the field must advance xAI and causal modeling frameworks that move beyond correlational outputs toward biological intelligibility. Unlike traditional black-box models, xAI tools can identify the mechanistic underpinnings of predicted effects, providing transparency that fosters both regulatory trust and scientific insight. Causal inference frameworks&#8212;such as counterfactual reasoning, graphical models, and pathway reconstruction&#8212;enable researchers to trace predicted outcomes back to molecular initiating events or key events in adverse outcome pathways. This mechanistic clarity is not only scientifically rigorous, but also essential for replacing animal models with human-relevant, ethically grounded alternatives. Equally transformative is the need to embrace validation paradigms that are dynamic, iterative, and performance-centered. The e-validation framework exemplifies this shift by integrating AI tools for reference compound selection, simulation-based protocol design, and post-validation surveillance. Rather than freezing test methods at a single point in time, adaptive validation enables continuous learning, uncertainty monitoring, and context-specific calibration. This is particularly vital for AI models, which evolve with incoming data and may respond to environmental, demographic, or regulatory changes in real-time. Ultimately, the reinvention of toxicology through AI demands a reimagining of regulatory science itself&#8212;not as a rigid gatekeeper of past standards, but as a co-evolving, evidence-driven system capable of learning and adapting alongside the tools it evaluates. Regulatory frameworks must shift from static validation checklists to lifecycle governance models, incorporating probabilistic risk estimates, digital trust audits, and stakeholder-centered transparency protocols. As AI systems increasingly power both prediction and decision-support, the role of regulators will expand to include oversight of algorithmic integrity, post-market surveillance, and equitable deployment. This reinvention is not merely a technological upgrade&#8212;it is a paradigm shift. It offers an opportunity to align toxicology with 21st-century values: replacing harm with prevention, opacity with transparency, and extrapolation with human specificity. In doing so, AI can fulfill its promise not only to accelerate toxicological science, but to transform it into a more just, responsive, and human-centered discipline. Conclusions Artificial intelligence is no longer a distant promise for toxicology&#8212;it is the transformative force now shaping the discipline's future. Over the course of this review, we have mapped the landscape of AI-driven change in toxicology across technical, regulatory, ethical, and strategic dimensions. These developments mark a critical inflection point: toxicology is transitioning from adapting AI to co-evolving with it, entering a new era of mechanistically grounded, human-relevant, and dynamically validated safety science. Central to this transformation is the recognition that AI does not merely automate legacy workflows&#8212;it reinvents them. Multimodal AI, causal inference, generative modeling, and physics-informed learning have expanded the predictive and interpretive capabilities of toxicology beyond what animal models can achieve. Combined with real-time data access, edge computing, and federated learning, these tools have made toxicology more responsive, personalized, and ethically aligned. The emergence of digital twins and agentic AI systems further signals the rise of intelligent, autonomous toxicology pipelines, capable of simulation, prediction, and adaptation at unprecedented scale. However, the realization of AI's full potential demands more than technical readiness&#8212;it requires a transformation in how toxicology conceptualizes validation, governance, and trus t . The e-validation framework, grounded in the TREAT principles, exemplifies this shift [ 6 ]. It introduces adaptive, AI-powered modules for selecting reference chemicals, simulating outcomes, cross-validating mechanisms, and ensuring lifecycle monitoring through post-validation companion agents [ 7 ]. At the same time, the ethical landscape must evolve alongside the technical. Bias audits, participatory governance, and equity-aware development practices are no longer optional&#8212;they are foundational. As AI systems increasingly shape regulatory decisions, these systems must be interrogated for their fairness, representativeness, and inclusivity. The co-pilot model&#8212;where AI augments rather than replaces human judgment&#8212;offers a pragmatic path forward, one that combines the scale and speed of algorithms with the contextual, moral, and experiential insights of human decision-makers. The global readiness for AI in toxicology is accelerating. With inference costs plummeting, model performance stabilizing, and regulatory precedent expanding&#8212;most notably through the FDA's endorsement of AI-enabled diagnostics&#8212;the infrastructure is now in place. The challenge ahead lies in coordination: establishing shared benchmarks, harmonized validation frameworks, secure data-sharing ecosystems, and inclusive ethical oversight. These are not merely supporting structures; they are the scaffolds upon which the future of responsible AI-driven toxicology will be built. In sum, this moment offers more than an opportunity for innovation&#8212;it demands reinvention. AI offers the means not just to do toxicology faster or cheaper, but to do it better: with more precision, with greater relevance to human biology, and with deeper ethical integrity. It challenges the field to move beyond inherited paradigms of animal testing and binary endpoints, toward a future where chemical safety science is data-rich, mechanistically informed, and globally inclusive. If this vision is realized&#8212;through science, governance, and trust&#8212;AI will not merely assist toxicology. It will elevate it. And in doing so, it will help build a future where the assessment of chemical risk is not only smarter, but safer, more equitable, and fundamentally more humane. Key References Hartung T, Kleinstreuer NC. Challenges and opportunities for validation of AI-based new approach methods. ALTEX 2025;42(1):3-21. &#9675; Conceptual paper on validation of AI-facilitated methods coauthored with the then head of the US validation body. Hartung T, Whelan, Tong W, Califf RM. Is Regulatory Science Ready for Artificial Intelligence? NPJ Digital Medicine 2025;8:200 &#9675; Opinion piece on the prospects of building trust into the regulatory use of AI coauthored with at the time FDA leadership and head of the EU validation body. Kleinstreuer N, Hartung T. Artificial Intelligence (AI) &#8211; it&#8217;s the end of the tox as we know it (and I feel fine)&#8212;AI for Predictive Toxicology. Arch Toxicol. 2024;98:735&#8211;754 &#9675; Extensive review of the history, current examples and future prospects of AI in toxicology coauthored with the then head of the US validation body. 1 https://comptox.epa.gov/dashboard/ 2 https://qsartoolbox.org 3 https://ntp.niehs.nih.gov/whatwestudy/niceatm/comptox/ct-ice/ice 4 https://worldfair-project.eu/fair-implementation-profiles/ 5 FDA. Artificial Intelligence and Machine Learning (AI/ML) Medical Devices. U.S. Food and Drug Administration Annual Report. 2024. Available at: https://www.fda.gov/medical-devices/software-medical-device-samd/artificial-intelligence-and-machine-learning-aiml-enabled-medical-devices (last accessed 25 Apr 2025). 6 https://crfm.stanford.edu/fmti/May-2024/index.html 7 Bommasani et al., 2024, https://crfm.stanford.edu/fmti/paper.pdf 8 https://xaitk.org 9 https://sites.research.google/med-palm/ 10 https://spark.apache.org/docs/latest/index.html 11 https://www.ray.io 12 https://www.dask.org 13 https://www.geeksforgeeks.org/deep-learning/what-is-monte-carlo-mc-dropout/ 14 https://docs.aws.amazon.com/prescriptive-guidance/latest/ml-quantifying-uncertainty/deep-ensembles.html 15 https://ermongroup.github.io/cs228-notes/inference/variational/ 16 https://shap.readthedocs.io/en/latest/index.html 17 https://christophm.github.io/interpretable-ml-book/overview.html 18 https://cloud.google.com/vertex-ai 19 https://h2o.ai 20 https://www.automl.org/automl-for-x/tabular-data/auto-sklearn/ 21 https://eur-lex.europa.eu/eli/reg/2016/679/oj 22 https://www.iso.org/standard/42001 23 https://www.oecd.org/en/topics/sub-issues/ai-principles.html 24 https://chain.link/education-hub/secure-multiparty-computation-mcp 25 https://eur-lex.europa.eu/eli/reg/2016/679/oj . 26 https://www.govinfo.gov/content/pkg/PLAW-104publ191/pdf/PLAW-104publ191.pdf 27 https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/AlphaEvolve.pdf 28 https://ontox-project.eu 29 https://ice.ntp.niehs.nih.gov 30 https://digital-strategy.ec.europa.eu/en/policies/virtual-human-twins 31 https://vito.be/en/projects/edith 32 https://www.vph-institute.org 33 https://oecd.ai/en/ 34 https://oacu.oir.nih.gov/new-approach-methodologies 35 https://www.fda.gov/medical-devices/software-medical-device-samd/artificial-intelligence-and-machine-learning-software-medical-device 36 https://gcrsr.net 37 https://ntp.niehs.nih.gov/whatwestudy/niceatm/iccvam/international-partnerships/icatm 38 https://medium.com/data-science/top-10-data-ai-trends-for-2025-4ed785cafe16 39 https://research.google/blog/advancing-medical-ai-with-med-gemini/ 40 https://stanford-aimi.github.io/chexagent.html 41 https://github.com/stanford-crfm/helm/blob/main/README.md 42 https://arxiv.org/html/2410.15135v2 43 https://arxiv.org/html/2407.17436v2 44 https://www.ihi.europa.eu/projects-results/project-factsheets/etox 45 https://etransafe.eu 46 https://www.vict3r.eu Publisher's Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Acknowledgements The editors would like to thank Monica Espinoza for assisting with the review of this manuscript. Author Contribution T.H. drafted the manuscript and all authors reviewed the manuscript. Funding Open Access funding enabled and organized by Projekt DEAL. Funding was received from the European Union&#8217;s Horizon 2020 research and innovation program under grant agreement No.963845 (ONTOX) to both authors. Support by VICT3R to THA is gratefully acknowledged; VICT3R is supported by the Innovative Health Initiative Joint Undertaking (IHI JU) under grant agreement No 101172693. The JU receives support from the European Union&#8217;s Horizon Europe research and innovation programme and COCIR, EFPIA, EuropaBio, MedTech Europe, Vaccines Europe, and Instem Scientific Limited. Funded by the European Union, the private members, and those contributing partners of the IHI JU. Views and opinions expressed are, however, those of the author(s) only and do not necessarily reflect those of the aforementioned parties. Neither of the aforementioned parties can be held responsible for them. TL acknowledges funding for BioBricks from NIEHS (1R43ES036069-01) and NSF (# 2333728). Data Availability Data sharing is not applicable to this article as no datasets were generated or analyzed during the current study. Declarations Ethics Approval Not applicable. Consent to Participate Not applicable. Consent for Publication Not applicable. Competing interests Thomas Luechtefeld is founder and owner of Tox-Track Inc. and Insilica LLC. Thomas Hartung holds stock options in and consults ToxTrack Inc. and Insilica LLC. Both are consultant for computational toxicology for Underwriters Laboratories (UL) and receive shares of their respective sales. Thomas Hartung is a member of Apple&#8217;s Green Chemistry Advisory Board. Thomas Hartung is the founder and owner of the non-profit CAATevents gGmbH, Solingen, Germany. References 1. Luechtefeld T Hartung T Computational approaches to chemical hazard assessment Altex 2017 34 459 478 10.14573/altex.1710141 29101769 PMC5848496 Luechtefeld T, Hartung T. Computational approaches to chemical hazard assessment. Altex. 2017;34:459&#8211;78. 29101769 10.14573/altex.1710141 PMC5848496 2. Kleinstreuer N Hartung T Artificial intelligence (AI) &#8211; it&#8217;s the end of the tox as we know it (and I feel fine) - AI for predictive toxicology Arch Toxicol 2024 98 735 754 10.1007/s00204-023-03666-2 38244040 PMC10861653 Kleinstreuer N, Hartung T. Artificial intelligence (AI) &#8211; it&#8217;s the end of the tox as we know it (and I feel fine) - AI for predictive toxicology. Arch Toxicol. 2024;98:735&#8211;54. 38244040 10.1007/s00204-023-03666-2 PMC10861653 3. Hartung T ToxAIcology - the evolving role of artificial intelligence in advancing toxicology and modernizing regulatory science Altex 2023 40 559 570 10.14573/altex.2309191 37889187 Hartung T. ToxAIcology - the evolving role of artificial intelligence in advancing toxicology and modernizing regulatory science. Altex. 2023;40:559&#8211;70. 37889187 10.14573/altex.2309191 4. Bender A Cortes-Ciriano I Artificial intelligence in drug discovery: what is realistic, what are illusions? Part 1: Ways to make an impact, and why we are not there yet Drug Discov Today 2021 26 511 524 10.1016/j.drudis.2020.12.009 33346134 Bender A, Cortes-Ciriano I. Artificial intelligence in drug discovery: what is realistic, what are illusions? Part 1: Ways to make an impact, and why we are not there yet. Drug Discov Today. 2021;26:511&#8211;24. 33346134 10.1016/j.drudis.2020.12.009 5. Luechtefeld T Marsh D Rowlands C Hartung T Machine learning of toxicological big data enables read-across structure activity relationships (RASAR) outperforming animal test reproducibility Toxicol Sci 2018 165 198 212 10.1093/toxsci/kfy152 30007363 PMC6135638 Luechtefeld T, Marsh D, Rowlands C, Hartung T. Machine learning of toxicological big data enables read-across structure activity relationships (RASAR) outperforming animal test reproducibility. Toxicol Sci. 2018;165:198&#8211;212. 30007363 10.1093/toxsci/kfy152 PMC6135638 6. Hartung T, Whelan, Tong W, Califf RM. Is Regulatory Science Ready for Artificial Intelligence?. NPJ Dig Med 2025;8:200. 10.1038/s41746-025-01596-0 PMC11985935 40210953 7. Hartung T Kleinstreuer NC Challenges and opportunities for validation of AI-based new approach methods Altex 2025 42 1 3 21 39815689 10.14573/altex.2412291 Hartung T, Kleinstreuer NC. Challenges and opportunities for validation of AI-based new approach methods. Altex. 2025;42(1):3&#8211;21. 39815689 10.14573/altex.2412291 8. Schultes E, Magagna B, Hettne K, Pergl R, Such&#225;nek M, Kuhn T. Reusable FAIR implementation profiles as accelerators of FAIR convergence. 2020. 10.1007/978-3-030-65847-2_13. 9. Schultes E, Magagna B, Hettne KM, Pergl R, Such&#225;nek M, Kuhn T. Reusable FAIR implementation profiles as accelerators of FAIR convergence. In: Grossmann G, Ram S (eds) Advances in Conceptual Modeling. ER 2020. Lecture Notes in Computer Science. Springer, Cham. 2020; p. 12584. 10. Chen J Si YW Un CW Siu SWI Chemical toxicity prediction based on semi-supervised learning and graph convolutional neural network J Cheminform 2021 13 93 10.1186/s13321-021-00570-8 34838140 PMC8627024 Chen J, Si YW, Un CW, Siu SWI. Chemical toxicity prediction based on semi-supervised learning and graph convolutional neural network. J Cheminform. 2021;13:93. 34838140 10.1186/s13321-021-00570-8 PMC8627024 11. Zhang J Zhao L Wang W Xing DF Wang ZX Ma J New trend on chemical structure representation learning in toxicology: in reviews of machine learning model methodology Crit Rev Environ Sci Technol 2025 55 951 976 10.1080/10643389.2025.2469868 Zhang J, Zhao L, Wang W, Xing DF, Wang ZX, Ma J, et al. New trend on chemical structure representation learning in toxicology: in reviews of machine learning model methodology. Crit Rev Environ Sci Technol. 2025;55:951&#8211;76. 12. Li X Makarov I Kiselev D Predicting molecule toxicity via descriptor-based graph self-supervised learning IEEE Access. 2023 11 91842 91849 10.1109/ACCESS.2023.3308203 Li X, Makarov I, Kiselev D. Predicting molecule toxicity via descriptor-based graph self-supervised learning. IEEE Access. 2023;11:91842&#8211;9. 13. Chen X Roberts R Liu Z Toing W A generative adversarial network model alternative to animal studies for clinical pathology assessment Nat Commun 2023 14 7141 10.1038/s41467-023-42933-9 37932302 PMC10628291 Chen X, Roberts R, Liu Z, Toing W. A generative adversarial network model alternative to animal studies for clinical pathology assessment. Nat Commun. 2023;14:7141. 37932302 10.1038/s41467-023-42933-9 PMC10628291 14. Chen X Roberts R Tong W Liu Z Tox-GAN: an artificial intelligence approach alternative to animal studies-a case study with toxicogenomics Toxicol Sci 2022 186 242 259 10.1093/toxsci/kfab157 34971401 Chen X, Roberts R, Tong W, Liu Z. Tox-GAN: an artificial intelligence approach alternative to animal studies-a case study with toxicogenomics. Toxicol Sci. 2022;186:242&#8211;59. 34971401 10.1093/toxsci/kfab157 15. OpenAI. GPT-4 Technical Report. 2023. Available at: https://cdn.openai.com/papers/gpt-4.pdf . Accessed 25 Nov 2025. 16. Singhal K Azizi S Tu T Mahdavi SS Wie J Chung HW Large language models encode clinical knowledge Nature 2023 620 172 180 10.1038/s41586-023-06291-2 37438534 PMC10396962 Singhal K, Azizi S, Tu T, Mahdavi SS, Wie J, Chung HW, et al. Large language models encode clinical knowledge. Nature. 2023;620:172&#8211;80. 37438534 10.1038/s41586-023-06291-2 PMC10396962 17. Jumper J Evans R Pritzel A Green T Figurnov M Ronneberger O Highly accurate protein structure prediction with AlphaFold Nature 2021 596 583 589 10.1038/s41586-021-03819-2 34265844 PMC8371605 Jumper J, Evans R, Pritzel A, Green T, Figurnov M, Ronneberger O, et al. Highly accurate protein structure prediction with AlphaFold. Nature. 2021;596:583&#8211;9. 34265844 10.1038/s41586-021-03819-2 PMC8371605 18. Szczepankiewicz K, Popowicz A, CharkiewiczK, Na&#322;&#281;cz-Charkiewicz K, Szczepankiewicz M, Lasota S, et al. Ground truth based comparison of saliency maps algorithms. Sci Rep. 2023;13:16887 10.1038/s41598-023-42946-w PMC10558518 37803108 19. Hu B Tunison P Vasu B Menon N Collins R Hoogs A XAITK: The explainable AI toolkit Appl AI Lett 2021 2 e40 10.1002/ail2.40 Hu B, Tunison P, Vasu B, Menon N, Collins R, Hoogs A. XAITK: The explainable AI toolkit. Appl AI Lett. 2021;2:e40. 20. Maertens A Golden E Luechtefeld TH Hoffmann S Tsaioun K Hartung T Probabilistic risk assessment &#8211; the keystone for the future of toxicology Altex 2022 39 3 29 10.14573/altex.2201081 35034131 PMC8906258 Maertens A, Golden E, Luechtefeld TH, Hoffmann S, Tsaioun K, Hartung T. Probabilistic risk assessment &#8211; the keystone for the future of toxicology. Altex. 2022;39:3&#8211;29. 35034131 10.14573/altex.2201081 PMC8906258 21. Ball N Cronin MTD Shen J Adenuga MD Blackburn K Booth ED Toward good read-across practice (GRAP) guidance Altex 2016 33 149 166 10.14573/altex.1601251 26863606 PMC5581000 Ball N, Cronin MTD, Shen J, Adenuga MD, Blackburn K, Booth ED, et al. Toward good read-across practice (GRAP) guidance. Altex. 2016;33:149&#8211;66. 26863606 10.14573/altex.1601251 PMC5581000 22. Zhu H Bouhifd M Kleinstreuer N Kroese ED Liu Z Luechtefeld T Supporting read-across using biological data Altex 2016 33 167 182 10.14573/altex.1601252 26863516 PMC4834201 Zhu H, Bouhifd M, Kleinstreuer N, Kroese ED, Liu Z, Luechtefeld T, et al. Supporting read-across using biological data. Altex. 2016;33:167&#8211;82. 26863516 10.14573/altex.1601252 PMC4834201 23. Maertens A Hartung T Green toxicology &#8211; know early about and avoid toxic product liabilities Toxicol Sci 2018 161 285 289 10.1093/toxsci/kfx243 29267930 Maertens A, Hartung T. Green toxicology &#8211; know early about and avoid toxic product liabilities. Toxicol Sci. 2018;161:285&#8211;9. 29267930 10.1093/toxsci/kfx243 24. Maertens A Luechtefeld T Hartung T Alternative methods go green! Green toxicology as a sustainable approach for assessing chemical safety and designing safer chemicals Altex 2024 41 3 19 38194639 10.14573/altex.2312291 Maertens A, Luechtefeld T, Hartung T. Alternative methods go green! Green toxicology as a sustainable approach for assessing chemical safety and designing safer chemicals. Altex. 2024;41:3&#8211;19. 38194639 10.14573/altex.2312291 25. Kone&#269;n&#253; J McMahan HB Yu FX Suresh AT Bacon D Federated learning: strategies for improving communication efficiency Commun ACM 2022 65 86 94 Kone&#269;n&#253; J, McMahan HB, Yu FX, Suresh AT, Bacon D. Federated learning: strategies for improving communication efficiency. Commun ACM. 2022;65:86&#8211;94. 26. Kaissis GA Makowski MR R&#252;ckert D Braren RF Secure, privacy-preserving and federated machine learning in medical imaging Nat Mach Intell 2020 2 305 311 10.1038/s42256-020-0186-1 Kaissis GA, Makowski MR, R&#252;ckert D, Braren RF. Secure, privacy-preserving and federated machine learning in medical imaging. Nat Mach Intell. 2020;2:305&#8211;11. 27. Leist M Ghallab A Graepel R Marchan R Hassan R Hougaard Bennekou S Adverse outcome pathways: opportunities, limitations and open questions Archives Toxicology 2017 31 221 229 10.1007/s00204-017-2045-3 29051992 Leist M, Ghallab A, Graepel R, Marchan R, Hassan R, Hougaard Bennekou S, et al. Adverse outcome pathways: opportunities, limitations and open questions. Archives Toxicology. 2017;31:221&#8211;9. 10.1007/s00204-017-2045-3 29051992 28. Corradi M Luechtefeld T de Haan AM Pieters R Freedman JH Vanhaecke T The application of natural language processing for the extraction of mechanistic information in toxicology Front Toxicol 2024 6 1393662 10.3389/ftox.2024.1393662 38800806 PMC11116573 Corradi M, Luechtefeld T, de Haan AM, Pieters R, Freedman JH, Vanhaecke T, et al. The application of natural language processing for the extraction of mechanistic information in toxicology. Front Toxicol. 2024;6:1393662. 38800806 10.3389/ftox.2024.1393662 PMC11116573 29. Park D, Ramesh A, Goldstein T, Ringel Morris M, Liang P, Bernstein MS. Generative agents: Interactive simulacra of human behavior. Proc 36th Ann ACM Symp Interface Softw Technol. 2023;2:1&#8211;22. 30. Hartung T Perspectives on in vitro to in vivo extrapolations Appl In Vitro Toxicol 2018 4 305 316 10.1089/aivt.2016.0026 31890748 PMC6309130 Hartung T. Perspectives on in vitro to in vivo extrapolations. Appl In Vitro Toxicol. 2018;4:305&#8211;16. 31890748 10.1089/aivt.2016.0026 PMC6309130 31. Chou WC Lin Z Machine learning and artificial intelligence in physiologically based pharmacokinetic modeling Toxicol Sci 2023 191 1 14 10.1093/toxsci/kfac101 36156156 PMC9887681 Chou WC, Lin Z. Machine learning and artificial intelligence in physiologically based pharmacokinetic modeling. Toxicol Sci. 2023;191:1&#8211;14. 36156156 10.1093/toxsci/kfac101 PMC9887681 32. Maertens A Antignac E Benfenati E Bloch D Fritsche E Hoffmann S The probable future of toxicology - probabilistic risk assessment Altex 2024 41 273 281 38215352 10.14573/altex.2310301 Maertens A, Antignac E, Benfenati E, Bloch D, Fritsche E, Hoffmann S, et al. The probable future of toxicology - probabilistic risk assessment. Altex. 2024;41:273&#8211;81. 38215352 10.14573/altex.2310301 33. Maertens A, Kincaid B, Bridgeford E, Brochot C, de Carvalho e Silva A, Dorne J-LCM, et al. From cellular perturbation to probabilistic risk assessments. ALTEX. 2025;42:413&#8211;434. 10.14573/altex.2501291 40418784 34. Hartung T Tsaioun K Evidence-based approaches in toxicology: their origins, challenges, and future directions Evid-Based Toxicol 2024 2 1 2421187 10.1080/2833373X.2024.2421187 Hartung T, Tsaioun K. Evidence-based approaches in toxicology: their origins, challenges, and future directions. Evid-Based Toxicol. 2024;2(1):2421187. 35. Ribeiro MT, Singh S, Guestrin C. Model-agnostic interpretability of machine learning. arXiv Preprint. 2016. arXiv:1606.05386 . 36. Bueso-Bordils JI Ant&#243;n-Fos GM Mart&#237;n-Algarra R Alem&#225;n-L&#243;pez PA Overview of computational toxicology methods applied in drug and green chemical discovery J Xenobiotics 2024 14 1901 1918 10.3390/jox14040101 PMC11677645 39728409 Bueso-Bordils JI, Ant&#243;n-Fos GM, Mart&#237;n-Algarra R, Alem&#225;n-L&#243;pez PA. Overview of computational toxicology methods applied in drug and green chemical discovery. J Xenobiotics. 2024;14:1901&#8211;18. 10.3390/jox14040101 PMC11677645 39728409 37. Hartung T The validation of regulatory test methods &#8211; conceptual, ethical, and philosophical foundations Altex 2024 41 525 544 39440637 10.14573/altex.2409271 Hartung T. The validation of regulatory test methods &#8211; conceptual, ethical, and philosophical foundations. Altex. 2024;41:525&#8211;44. 39440637 10.14573/altex.2409271 38. Gao S, Zhu R, Kong Z, Noori A, Su X, Ginder C, et al. TxAgent: an AI agent for therapeutic reasoning across a universe of tools. arXiv:2503.10970 39. Vinken M Benfenati E Busquet F Castell J Clevert D-A de Kok T Safer chemicals using less animals: kick-off of the European ONTOX project Toxicology 2021 458 152846 10.1016/j.tox.2021.152846 34216698 Vinken M, Benfenati E, Busquet F, Castell J, Clevert D-A, de Kok T, et al. Safer chemicals using less animals: kick-off of the European ONTOX project. Toxicology. 2021;458:152846. 34216698 10.1016/j.tox.2021.152846 40. Diemar M Vinken M Teunis M Krul C Busquet F Zajac J Report of the first ONTOX stakeholder network meeting: digging under the surface of ONTOX together with the stakeholders Altern Lab Anim 2024 52 117 131 10.1177/02611929231225730 38235727 Diemar M, Vinken M, Teunis M, Krul C, Busquet F, Zajac J, et al. Report of the first ONTOX stakeholder network meeting: digging under the surface of ONTOX together with the stakeholders. Altern Lab Anim. 2024;52:117&#8211;31. 38235727 10.1177/02611929231225730 41. Chen X Roberts R Liu Z Tong W A generative adversarial network model alternative to animal studies for clinical pathology assessment Nat Commun 2023 14 7141 10.1038/s41467-023-42933-9 37932302 PMC10628291 Chen X, Roberts R, Liu Z, Tong W. A generative adversarial network model alternative to animal studies for clinical pathology assessment. Nat Commun. 2023;14:7141. 37932302 10.1038/s41467-023-42933-9 PMC10628291 42. Meyers J Fabian B Brown N De novo molecular design and generative models Drug Discov Today 2021 26 2707 2715 10.1016/j.drudis.2021.05.019 34082136 Meyers J, Fabian B, Brown N. De novo molecular design and generative models. Drug Discov Today. 2021;26:2707&#8211;15. 34082136 10.1016/j.drudis.2021.05.019 43. Hartung T. AI as the new frontier in chemical risk assessment. Front AI, Sec. Med Pub Health. 2023;6:1269932. 10.3389/frai.2023.1269932 PMC10616238 37915539 44. Hartung T AI, agentic models and lab automation for scientific discovery &#8211; the beginning of scAInce Frontiers in AI 2025 8 1649155 10.3389/frai.2025.1649155 PMC12426084 40951330 Hartung T. AI, agentic models and lab automation for scientific discovery &#8211; the beginning of scAInce. Frontiers in AI. 2025;8:1649155. 10.3389/frai.2025.1649155 PMC12426084 40951330 45. Hartung T A call for a human exposome project Altex 2023 40 4 33 10.14573/altex.2301061 36648285 Hartung T. A call for a human exposome project. Altex. 2023;40:4&#8211;33. 36648285 10.14573/altex.2301061 46. Hartung T How AI can deliver the human exposome project Nat Med 2025 31 1738 10.1038/s41591-025-03749-w 40514463 Hartung T. How AI can deliver the human exposome project. Nat Med. 2025;31:1738. 40514463 10.1038/s41591-025-03749-w 47. Sill&#233; FCM, Belkadi M, Koehler K, Ali J, Vasiliou V, Sagigiannis D, Hartung T. Charting exposomoethics: A roadmap for the ethical foundations of the human exposome project, human genomics, revised. 48. Hartung T King N Kleinstreuer N Leist M Tagle D Leveraging biomarkers and translational medicine for preclinical safety - lessons for advancing the validation of alternatives to animal testing Altex 2024 41 545 566 39440996 10.14573/altex.2410011 Hartung T, King N, Kleinstreuer N, Leist M, Tagle D. Leveraging biomarkers and translational medicine for preclinical safety - lessons for advancing the validation of alternatives to animal testing. Altex. 2024;41:545&#8211;66. 39440996 10.14573/altex.2410011 49. Ezugwu AE Ikotun AM Oyelade OO Abualigah L Agushaka JO Eke CI Akinyelu AA A comprehensive survey of clustering algorithms: state-of-the-art machine learning applications, taxonomy, challenges, and future research prospects Eng Appl Artif Intell 2022 110 104743 10.1016/j.engappai.2022.104743 Ezugwu AE, Ikotun AM, Oyelade OO, Abualigah L, Agushaka JO, Eke CI, et al. A comprehensive survey of clustering algorithms: state-of-the-art machine learning applications, taxonomy, challenges, and future research prospects. Eng Appl Artif Intell. 2022;110:104743. 50. Hartung T Maertens A Luechtefeld T E-validation &#8211; unleashing AI for validation Altex 2024 41 567 587 39444208 10.14573/altex.2409211 Hartung T, Maertens A, Luechtefeld T. E-validation &#8211; unleashing AI for validation. Altex. 2024;41:567&#8211;87. 39444208 10.14573/altex.2409211 51. Bouvier d&#8217;Yvoire M Prieto P Blaauboer BJ Bois FY Boobis A Brochot C Physiologically-based kinetic modelling (PBK modelling): Meeting the 3Rs agenda. The report and recommendations of ECVAM workshop 63 Altern Lab Anim 2007 35 661 671 10.1177/026119290703500606 18186671 Bouvier d&#8217;Yvoire M, Prieto P, Blaauboer BJ, Bois FY, Boobis A, Brochot C, et al. Physiologically-based kinetic modelling (PBK modelling): Meeting the 3Rs agenda. The report and recommendations of ECVAM workshop 63. Altern Lab Anim. 2007;35:661&#8211;71. 18186671 10.1177/026119290703500606 52. Blaauboer BJ Biokinetic modeling and in vitro-in vivo extrapolations J Toxicol Environ Health B 2010 13 242 252 10.1080/10937404.2010.483940 20574900 Blaauboer BJ. Biokinetic modeling and in vitro-in vivo extrapolations. J Toxicol Environ Health B. 2010;13:242&#8211;52. 10.1080/10937404.2010.483940 20574900 53. Proen&#231;a S Paini A Joossens E Sala Benito JV Berggren E Worth A Insights into in vitro biokinetics using virtual cell based assay simulations Altex 2019 36 447 461 30924507 10.14573/altex.1812101 Proen&#231;a S, Paini A, Joossens E, Sala Benito JV, Berggren E, Worth A, et al. Insights into in vitro biokinetics using virtual cell based assay simulations. Altex. 2019;36:447&#8211;61. 30924507 10.14573/altex.1812101 54. Costello Z Martin HG A machine learning approach to predict metabolic pathway dynamics from time-series multiomics data NPJ Syst Biol Appl 2018 4 19 10.1038/s41540-018-0054-3 29872542 PMC5974308 Costello Z, Martin HG. A machine learning approach to predict metabolic pathway dynamics from time-series multiomics data. NPJ Syst Biol Appl. 2018;4:19. 29872542 10.1038/s41540-018-0054-3 PMC5974308 55. Hartung T Stephens M Hoffmann S Mechanistic validation Altex 2013 30 119 130 10.14573/altex.2013.2.119 23665802 PMC4086802 Hartung T, Stephens M, Hoffmann S. Mechanistic validation. Altex. 2013;30:119&#8211;30. 23665802 10.14573/altex.2013.2.119 PMC4086802 56. de Vries RBM Angrish M Browne P Brozek J Rooney AA Wikoff DS Applying evidence-based methods to the development and use of adverse outcome pathways construct mechanistic frameworks for the development and use of non-animal toxicity tests Altex 2021 38 336 347 33837437 10.14573/altex.2101211 PMC9394185 de Vries RBM, Angrish M, Browne P, Brozek J, Rooney AA, Wikoff DS, et al. Applying evidence-based methods to the development and use of adverse outcome pathways construct mechanistic frameworks for the development and use of non-animal toxicity tests. Altex. 2021;38:336&#8211;47. 33837437 10.14573/altex.2101211 PMC9394185 57. Hartung T Food for thought &#8230; on validation Altex 2007 24 67 72 10.14573/altex.2007.2.67 17844647 Hartung T. Food for thought &#8230; on validation. Altex. 2007;24:67&#8211;72. 17844647 10.14573/altex.2007.2.67 58. Bhuller Y Avey M Deonandan R Hartung T Hilton GM Marles RJ Ethical principles for regulatory risk decision-making Regul Toxicol Pharmacol 2025 159 105813 10.1016/j.yrtph.2025.105813 40122155 Bhuller Y, Avey M, Deonandan R, Hartung T, Hilton GM, Marles RJ, et al. Ethical principles for regulatory risk decision-making. Regul Toxicol Pharmacol. 2025;159:105813. 40122155 10.1016/j.yrtph.2025.105813 59. Wiens J Saria S Sendak M Ghassemi M Liu VX Doshi-Velez F Do no harm: a roadmap for responsible machine learning for health care Nat Med 2019 25 1337 1340 10.1038/s41591-019-0548-6 31427808 Wiens J, Saria S, Sendak M, Ghassemi M, Liu VX, Doshi-Velez F, et al. Do no harm: a roadmap for responsible machine learning for health care. Nat Med. 2019;25:1337&#8211;40. 31427808 10.1038/s41591-019-0548-6 60. Hartung T Hoffmann S Whaley P Assessing risk of bias in toxicological studies in the era of artificial intelligence Arch Toxicol 2025 99 3065 3090 10.1007/s00204-025-03978-5 40615561 PMC12367879 Hartung T, Hoffmann S, Whaley P. Assessing risk of bias in toxicological studies in the era of artificial intelligence. Arch Toxicol. 2025;99:3065&#8211;90. 40615561 10.1007/s00204-025-03978-5 PMC12367879 61. FDA. Artificial Intelligence and Machine Learning in Medical Devices. U.S. Food and Drug Administration. 2023. Available at: https://www.fda.gov/medical-devices/software-medical-device-samd/artificial-intelligence-and-machine-learning-software-medical-device . Accessed 25 Nov 2025. 62. Stanford University. Artificial intelligence index report 2025. Stanford HAI. 2025. Available at: https://hai.stanford.edu/ai-index/2025-ai-index-report . Accessed 25 Nov 2025. 63. Christensen M Vukadinovic M Yuan N Ouynag D Vision&#8211;language foundation model for echocardiogram interpretation Nat Med 2024 30 1481 1488 10.1038/s41591-024-02959-y 38689062 PMC11108770 Christensen M, Vukadinovic M, Yuan N, Ouynag D. Vision&#8211;language foundation model for echocardiogram interpretation. Nat Med. 2024;30:1481&#8211;8. 38689062 10.1038/s41591-024-02959-y PMC11108770 64. Bommasani R Liang P Lee T Holistic evaluation of language models Ann N Y Acad Sci 2023 1525 140 146 10.1111/nyas.15007 37230490 Bommasani R, Liang P, Lee T. Holistic evaluation of language models. Ann N Y Acad Sci. 2023;1525:140&#8211;6. 37230490 10.1111/nyas.15007 65. Pognan F Steger-Hartmann T D&#237;az C Blomberg N Bringezu F Briggs K The eTRANSAFE project on translational safety assessment through integrative knowledge management: achievements and perspectives Pharmaceuticals 2021 14 237 10.3390/ph14030237 33800393 PMC7999019 Pognan F, Steger-Hartmann T, D&#237;az C, Blomberg N, Bringezu F, Briggs K, et al. The eTRANSAFE project on translational safety assessment through integrative knowledge management: achievements and perspectives. Pharmaceuticals. 2021;14:237. 33800393 10.3390/ph14030237 PMC7999019 66. Steger-Hartmann T Duchateau-Nguyen G Bringezu F Onidi M Stirn M Virtual control groups in non-clinical toxicology &#8211; a replicability challenge Altex 2025 42 3 538 542 40302301 10.14573/altex.2503061 Steger-Hartmann T, Duchateau-Nguyen G, Bringezu F, Onidi M, Stirn M. Virtual control groups in non-clinical toxicology &#8211; a replicability challenge. Altex. 2025;42(3):538&#8211;42. 40302301 10.14573/altex.2503061 67. Golden E Allen D Amberg A Anger LT Baker E Baran SW Toward implementing virtual control groups in nonclinical safety studies: Workshop report and roadmap to implementation Altex 2024 41 282 301 38043132 10.14573/altex.2310041 Golden E, Allen D, Amberg A, Anger LT, Baker E, Baran SW, et al. Toward implementing virtual control groups in nonclinical safety studies: Workshop report and roadmap to implementation. Altex. 2024;41:282&#8211;301. 38043132 10.14573/altex.2310041"
}