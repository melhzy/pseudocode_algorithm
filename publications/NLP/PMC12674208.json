{
  "pmcid": "PMC12674208",
  "source": "PMC",
  "download_date": "2025-12-09T16:37:22.910210",
  "metadata": {
    "journal_title": "Findings of ACL. ACL",
    "journal_nlm_ta": "Find ACL ACL",
    "journal": "Findings of ACL. ACL",
    "pmcid": "PMC12674208",
    "pmid": "41346453",
    "doi": "10.18653/v1/2024.findings-acl.380",
    "title": "Too Big to Fail: Larger Language Models are Disproportionately Resilient to Induction of Dementia-Related Linguistic Anomalies",
    "authors": [
      "Li Changye",
      "Sheng Zhecheng",
      "Cohen Trevor",
      "Pakhomov Serguei"
    ],
    "abstract": "As artificial neural networks grow in complexity, understanding their inner workings becomes increasingly challenging, which is particularly important in healthcare applications. The intrinsic evaluation metrics of autoregressive neural language models (NLMs), perplexity (PPL), can reflect how “surprised” an NLM model is at novel input. PPL has been widely used to understand the behavior of NLMs. Previous findings show that changes in PPL when masking attention layers in pre-trained transformer-based NLMs reflect linguistic anomalies associated with Alzheimer’s disease dementia. Building upon this, we explore a novel bidirectional attention head ablation method that exhibits properties attributed to the concepts of cognitive and brain reserve in human brain studies, which postulate that people with more neurons in the brain and more efficient processing are more resilient to neurodegeneration. Our results show that larger GPT-2 models require a disproportionately larger share of attention heads to be masked/ablated to display degradation of similar magnitude to masking in smaller models. These results suggest that the attention mechanism in transformer models may present an analogue to the notions of cognitive and brain reserve and could potentially be used to model certain aspects of the progression of neurodegenerative disorders and aging."
  },
  "xml": "<?xml version=\"1.0\"  ?><!DOCTYPE pmc-articleset PUBLIC \"-//NLM//DTD ARTICLE SET 2.0//EN\" \"https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd\"><pmc-articleset><article xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:ali=\"http://www.niso.org/schemas/ali/1.0/\" xml:lang=\"en\" article-type=\"research-article\" dtd-version=\"1.4\"><!--The publisher of this article does not allow downloading of the full text in XML form.--><front><journal-meta><journal-id journal-id-type=\"nlm-ta\">Find ACL ACL</journal-id><journal-id journal-id-type=\"pmc-domain-id\">319</journal-id><journal-id journal-id-type=\"pmc-domain\">nihpa</journal-id><journal-title-group><journal-title>Findings of ACL. ACL</journal-title></journal-title-group><custom-meta-group><custom-meta><meta-name>pmc-is-collection-domain</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-collection-title</meta-name><meta-value>NIHPA Author Manuscripts</meta-value></custom-meta></custom-meta-group></journal-meta><article-meta><article-id pub-id-type=\"pmcid\">PMC12674208</article-id><article-id pub-id-type=\"pmcid-ver\">PMC12674208.1</article-id><article-id pub-id-type=\"pmcaid\">12674208</article-id><article-id pub-id-type=\"pmcaiid\">12674208</article-id><article-id pub-id-type=\"manuscript-id\">NIHMS2047163</article-id><article-id pub-id-type=\"pmid\">41346453</article-id><article-id pub-id-type=\"doi\">10.18653/v1/2024.findings-acl.380</article-id><article-id pub-id-type=\"manuscript-id-alternative\">NIHMS2047163</article-id><article-id pub-id-type=\"manuscript-id-alternative\">NIHPA2047163</article-id><article-version article-version-type=\"pmc-version\">1</article-version><article-categories><subj-group subj-group-type=\"heading\"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Too Big to Fail: Larger Language Models are Disproportionately Resilient to Induction of Dementia-Related Linguistic Anomalies</article-title></title-group><contrib-group><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Li</surname><given-names initials=\"C\">Changye</given-names></name><xref rid=\"A1\" ref-type=\"aff\">1</xref></contrib><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Sheng</surname><given-names initials=\"Z\">Zhecheng</given-names></name><xref rid=\"A1\" ref-type=\"aff\">1</xref></contrib><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Cohen</surname><given-names initials=\"T\">Trevor</given-names></name><xref rid=\"A2\" ref-type=\"aff\">2</xref></contrib><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Pakhomov</surname><given-names initials=\"S\">Serguei</given-names></name><xref rid=\"A1\" ref-type=\"aff\">1</xref></contrib></contrib-group><aff id=\"A1\"><label>1</label>University of Minnesota</aff><aff id=\"A2\"><label>2</label>University of Washington</aff><author-notes><corresp id=\"CR1\"><email>lixx3013@umn.edu</email></corresp></author-notes><pub-date pub-type=\"ppub\"><month>8</month><year>2024</year></pub-date><volume>2024</volume><issue-id pub-id-type=\"pmc-issue-id\">501735</issue-id><fpage>6363</fpage><lpage>6377</lpage><pub-history><event event-type=\"nihms-submitted\"><date><day>26</day><month>11</month><year>2025</year></date></event><event event-type=\"pmc-release\"><date><day>04</day><month>12</month><year>2025</year></date></event><event event-type=\"pmc-live\"><date><day>04</day><month>12</month><year>2025</year></date></event><event event-type=\"pmc-last-change\"><date iso-8601-date=\"2025-12-06 05:25:13.350\"><day>06</day><month>12</month><year>2025</year></date></event></pub-history><self-uri xmlns:xlink=\"http://www.w3.org/1999/xlink\" content-type=\"pmc-pdf\" xlink:href=\"nihms-2047163.pdf\"/><abstract id=\"ABS1\"><p id=\"P1\">As artificial neural networks grow in complexity, understanding their inner workings becomes increasingly challenging, which is particularly important in healthcare applications. The intrinsic evaluation metrics of autoregressive neural language models (NLMs), perplexity (PPL), can reflect how &#8220;surprised&#8221; an NLM model is at novel input. PPL has been widely used to understand the behavior of NLMs. Previous findings show that changes in PPL when masking attention layers in pre-trained transformer-based NLMs reflect linguistic anomalies associated with Alzheimer&#8217;s disease dementia. Building upon this, we explore a novel bidirectional attention head ablation method that exhibits properties attributed to the concepts of cognitive and brain reserve in human brain studies, which postulate that people with more neurons in the brain and more efficient processing are more resilient to neurodegeneration. Our results show that larger GPT-2 models require a disproportionately larger share of attention heads to be masked/ablated to display degradation of similar magnitude to masking in smaller models. These results suggest that the attention mechanism in transformer models may present an analogue to the notions of cognitive and brain reserve and could potentially be used to model certain aspects of the progression of neurodegenerative disorders and aging.</p></abstract><custom-meta-group><custom-meta><meta-name>pmc-status-qastatus</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>pmc-status-live</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-status-embargo</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-status-released</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-open-access</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-olf</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-manuscript</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-legally-suppressed</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-pdf</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-supplement</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-pdf-only</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-suppress-copyright</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-real-version</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-scanned-article</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-preprint</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-in-epmc</meta-name><meta-value>yes</meta-value></custom-meta></custom-meta-group></article-meta></front></article></pmc-articleset>",
  "text": "Find ACL ACL 319 nihpa Findings of ACL. ACL pmc-is-collection-domain yes pmc-collection-title NIHPA Author Manuscripts PMC12674208 PMC12674208.1 12674208 12674208 NIHMS2047163 41346453 10.18653/v1/2024.findings-acl.380 NIHMS2047163 NIHPA2047163 1 Article Too Big to Fail: Larger Language Models are Disproportionately Resilient to Induction of Dementia-Related Linguistic Anomalies Li Changye 1 Sheng Zhecheng 1 Cohen Trevor 2 Pakhomov Serguei 1 1 University of Minnesota 2 University of Washington lixx3013@umn.edu 8 2024 2024 501735 6363 6377 26 11 2025 04 12 2025 04 12 2025 06 12 2025 As artificial neural networks grow in complexity, understanding their inner workings becomes increasingly challenging, which is particularly important in healthcare applications. The intrinsic evaluation metrics of autoregressive neural language models (NLMs), perplexity (PPL), can reflect how &#8220;surprised&#8221; an NLM model is at novel input. PPL has been widely used to understand the behavior of NLMs. Previous findings show that changes in PPL when masking attention layers in pre-trained transformer-based NLMs reflect linguistic anomalies associated with Alzheimer&#8217;s disease dementia. Building upon this, we explore a novel bidirectional attention head ablation method that exhibits properties attributed to the concepts of cognitive and brain reserve in human brain studies, which postulate that people with more neurons in the brain and more efficient processing are more resilient to neurodegeneration. Our results show that larger GPT-2 models require a disproportionately larger share of attention heads to be masked/ablated to display degradation of similar magnitude to masking in smaller models. These results suggest that the attention mechanism in transformer models may present an analogue to the notions of cognitive and brain reserve and could potentially be used to model certain aspects of the progression of neurodegenerative disorders and aging. pmc-status-qastatus 0 pmc-status-live yes pmc-status-embargo no pmc-status-released yes pmc-prop-open-access no pmc-prop-olf no pmc-prop-manuscript yes pmc-prop-legally-suppressed no pmc-prop-has-pdf yes pmc-prop-has-supplement no pmc-prop-pdf-only no pmc-prop-suppress-copyright no pmc-prop-is-real-version no pmc-prop-is-scanned-article no pmc-prop-preprint no pmc-prop-in-epmc yes"
}