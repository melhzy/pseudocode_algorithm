{
  "pmcid": "PMC12677091",
  "source": "PMC",
  "download_date": "2025-12-09T16:37:20.462968",
  "metadata": {
    "journal_title": "... Workshop on Computational Linguistics and Clinical Psychology",
    "journal_nlm_ta": "Workshop Comput Linguist Clin Psychol",
    "journal": "... Workshop on Computational Linguistics and Clinical Psychology",
    "pmcid": "PMC12677091",
    "pmid": "41356494",
    "doi": "10.18653/v1/2025.clpsych-1.8",
    "title": "Bigger But Not Better: Small Neural Language Models Outperform Large Language Models in Detection of Thought Disorder",
    "authors": [
      "Li Changye",
      "Xu Weizhe",
      "Pakhomov Serguei",
      "Bradley Ellen",
      "Ben-Zeev Dror",
      "Cohen Trevor"
    ],
    "abstract": "Disorganized thinking is a key diagnostic indicator of schizophrenia-spectrum disorders. Recently, clinical estimates of the severity of disorganized thinking have been shown to correlate with measures of how difficult speech transcripts would be for large language models (LLMs) to predict. However, LLMs’ deployment challenges – including privacy concerns, computational and financial costs, and lack of transparency of training data – limit their clinical utility. We investigate whether smaller neural language models can serve as effective alternatives for detecting positive formal thought disorder, using the same sliding window based perplexity measurements that proved effective with larger models. Surprisingly, our results show that smaller models are more sensitive to linguistic differences associated with formal thought disorder than their larger counterparts. Detection capability declines beyond a certain model size and context length, challenging the common assumption of “bigger is better” for LLM-based applications. Our findings generalize across audio diaries and clinical interview speech samples from individuals with psychotic symptoms, suggesting a promising direction for developing efficient, cost-effective, and privacy-preserving screening tools that can be deployed in both clinical and naturalistic settings."
  },
  "xml": "<?xml version=\"1.0\"  ?><!DOCTYPE pmc-articleset PUBLIC \"-//NLM//DTD ARTICLE SET 2.0//EN\" \"https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd\"><pmc-articleset><article xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:ali=\"http://www.niso.org/schemas/ali/1.0/\" xml:lang=\"en\" article-type=\"research-article\" dtd-version=\"1.4\"><!--The publisher of this article does not allow downloading of the full text in XML form.--><front><journal-meta><journal-id journal-id-type=\"nlm-ta\">Workshop Comput Linguist Clin Psychol</journal-id><journal-id journal-id-type=\"pmc-domain-id\">319</journal-id><journal-id journal-id-type=\"pmc-domain\">nihpa</journal-id><journal-title-group><journal-title>... Workshop on Computational Linguistics and Clinical Psychology</journal-title></journal-title-group><custom-meta-group><custom-meta><meta-name>pmc-is-collection-domain</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-collection-title</meta-name><meta-value>NIHPA Author Manuscripts</meta-value></custom-meta></custom-meta-group></journal-meta><article-meta><article-id pub-id-type=\"pmcid\">PMC12677091</article-id><article-id pub-id-type=\"pmcid-ver\">PMC12677091.1</article-id><article-id pub-id-type=\"pmcaid\">12677091</article-id><article-id pub-id-type=\"pmcaiid\">12677091</article-id><article-id pub-id-type=\"manuscript-id\">NIHMS2090661</article-id><article-id pub-id-type=\"pmid\">41356494</article-id><article-id pub-id-type=\"doi\">10.18653/v1/2025.clpsych-1.8</article-id><article-id pub-id-type=\"manuscript-id-alternative\">NIHMS2090661</article-id><article-id pub-id-type=\"manuscript-id-alternative\">NIHPA2090661</article-id><article-version article-version-type=\"pmc-version\">1</article-version><article-categories><subj-group subj-group-type=\"heading\"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Bigger But Not Better: Small Neural Language Models Outperform Large Language Models in Detection of Thought Disorder</article-title></title-group><contrib-group><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Li</surname><given-names initials=\"C\">Changye</given-names></name><xref rid=\"A1\" ref-type=\"aff\">1</xref><xref rid=\"FN1\" ref-type=\"author-notes\">*</xref></contrib><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Xu</surname><given-names initials=\"W\">Weizhe</given-names></name><xref rid=\"A1\" ref-type=\"aff\">1</xref><xref rid=\"FN1\" ref-type=\"author-notes\">*</xref></contrib><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Pakhomov</surname><given-names initials=\"S\">Serguei</given-names></name><xref rid=\"A2\" ref-type=\"aff\">2</xref></contrib><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Bradley</surname><given-names initials=\"E\">Ellen</given-names></name><xref rid=\"A3\" ref-type=\"aff\">3</xref></contrib><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Ben-Zeev</surname><given-names initials=\"D\">Dror</given-names></name><xref rid=\"A1\" ref-type=\"aff\">1</xref></contrib><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Cohen</surname><given-names initials=\"T\">Trevor</given-names></name><xref rid=\"A1\" ref-type=\"aff\">1</xref></contrib></contrib-group><aff id=\"A1\"><label>1</label>University of Washington</aff><aff id=\"A2\"><label>2</label>University of Minnesota</aff><aff id=\"A3\"><label>3</label>University of California, San Francisco</aff><author-notes><fn fn-type=\"con\" id=\"FN1\"><label>*</label><p id=\"P1\">Equal contribution</p></fn><corresp id=\"CR1\"><email>changyel@uw.edu</email>, <email>xuweizhe@uw.edu</email></corresp></author-notes><pub-date pub-type=\"ppub\"><month>5</month><year>2025</year></pub-date><volume>2025</volume><issue-id pub-id-type=\"pmc-issue-id\">501805</issue-id><fpage>90</fpage><lpage>105</lpage><pub-history><event event-type=\"nihms-submitted\"><date><day>29</day><month>11</month><year>2025</year></date></event><event event-type=\"pmc-release\"><date><day>05</day><month>12</month><year>2025</year></date></event><event event-type=\"pmc-live\"><date><day>05</day><month>12</month><year>2025</year></date></event><event event-type=\"pmc-last-change\"><date iso-8601-date=\"2025-12-09 05:25:13.847\"><day>09</day><month>12</month><year>2025</year></date></event></pub-history><self-uri xmlns:xlink=\"http://www.w3.org/1999/xlink\" content-type=\"pmc-pdf\" xlink:href=\"nihms-2090661.pdf\"/><abstract id=\"ABS1\"><p id=\"P2\">Disorganized thinking is a key diagnostic indicator of schizophrenia-spectrum disorders. Recently, clinical estimates of the severity of disorganized thinking have been shown to correlate with measures of how difficult speech transcripts would be for large language models (LLMs) to predict. However, LLMs&#8217; deployment challenges &#8211; including privacy concerns, computational and financial costs, and lack of transparency of training data &#8211; limit their clinical utility. We investigate whether smaller neural language models can serve as effective alternatives for detecting positive formal thought disorder, using the same sliding window based perplexity measurements that proved effective with larger models. Surprisingly, our results show that smaller models are more sensitive to linguistic differences associated with formal thought disorder than their larger counterparts. Detection capability declines beyond a certain model size and context length, challenging the common assumption of &#8220;bigger is better&#8221; for LLM-based applications. Our findings generalize across audio diaries and clinical interview speech samples from individuals with psychotic symptoms, suggesting a promising direction for developing efficient, cost-effective, and privacy-preserving screening tools that can be deployed in both clinical and naturalistic settings.</p></abstract><custom-meta-group><custom-meta><meta-name>pmc-status-qastatus</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>pmc-status-live</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-status-embargo</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-status-released</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-open-access</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-olf</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-manuscript</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-legally-suppressed</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-pdf</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-supplement</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-pdf-only</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-suppress-copyright</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-real-version</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-scanned-article</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-preprint</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-in-epmc</meta-name><meta-value>yes</meta-value></custom-meta></custom-meta-group></article-meta></front></article></pmc-articleset>",
  "text": "Workshop Comput Linguist Clin Psychol 319 nihpa ... Workshop on Computational Linguistics and Clinical Psychology pmc-is-collection-domain yes pmc-collection-title NIHPA Author Manuscripts PMC12677091 PMC12677091.1 12677091 12677091 NIHMS2090661 41356494 10.18653/v1/2025.clpsych-1.8 NIHMS2090661 NIHPA2090661 1 Article Bigger But Not Better: Small Neural Language Models Outperform Large Language Models in Detection of Thought Disorder Li Changye 1 * Xu Weizhe 1 * Pakhomov Serguei 2 Bradley Ellen 3 Ben-Zeev Dror 1 Cohen Trevor 1 1 University of Washington 2 University of Minnesota 3 University of California, San Francisco * Equal contribution changyel@uw.edu , xuweizhe@uw.edu 5 2025 2025 501805 90 105 29 11 2025 05 12 2025 05 12 2025 09 12 2025 Disorganized thinking is a key diagnostic indicator of schizophrenia-spectrum disorders. Recently, clinical estimates of the severity of disorganized thinking have been shown to correlate with measures of how difficult speech transcripts would be for large language models (LLMs) to predict. However, LLMs&#8217; deployment challenges &#8211; including privacy concerns, computational and financial costs, and lack of transparency of training data &#8211; limit their clinical utility. We investigate whether smaller neural language models can serve as effective alternatives for detecting positive formal thought disorder, using the same sliding window based perplexity measurements that proved effective with larger models. Surprisingly, our results show that smaller models are more sensitive to linguistic differences associated with formal thought disorder than their larger counterparts. Detection capability declines beyond a certain model size and context length, challenging the common assumption of &#8220;bigger is better&#8221; for LLM-based applications. Our findings generalize across audio diaries and clinical interview speech samples from individuals with psychotic symptoms, suggesting a promising direction for developing efficient, cost-effective, and privacy-preserving screening tools that can be deployed in both clinical and naturalistic settings. pmc-status-qastatus 0 pmc-status-live yes pmc-status-embargo no pmc-status-released yes pmc-prop-open-access no pmc-prop-olf no pmc-prop-manuscript yes pmc-prop-legally-suppressed no pmc-prop-has-pdf yes pmc-prop-has-supplement no pmc-prop-pdf-only no pmc-prop-suppress-copyright no pmc-prop-is-real-version no pmc-prop-is-scanned-article no pmc-prop-preprint no pmc-prop-in-epmc yes"
}