{
  "pmcid": "PMC12683325",
  "source": "PMC",
  "download_date": "2025-12-09T16:37:15.495065",
  "metadata": {
    "journal_title": "Journal of Medical Internet Research",
    "journal_nlm_ta": "J Med Internet Res",
    "journal_iso_abbrev": "J Med Internet Res",
    "journal": "Journal of Medical Internet Research",
    "pmcid": "PMC12683325",
    "pmid": "41355748",
    "doi": "10.2196/78132",
    "title": "Detecting Sociodemographic Biases in the Content and Quality of Large Language Model–Generated Nursing Care: Cross-Sectional Simulation Study",
    "year": "2025",
    "month": "12",
    "day": "5",
    "pub_date": {
      "year": "2025",
      "month": "12",
      "day": "5"
    },
    "authors": [
      "Bai Nan",
      "Yu Yijing",
      "Luo Chunyan",
      "Zhou Si Chen",
      "Wang Qing",
      "Zou Huijing",
      "Liu Qian",
      "Fu Guanghui",
      "Zhai Wei",
      "Zhao Qing",
      "Li Jianqiang",
      "Wei Xinni",
      "Yang Bing Xiang"
    ],
    "abstract": "Abstract Background Large language models (LLMs) are increasingly applied in health care. However, concerns remain that their nursing care recommendations may reflect patients’ sociodemographic attributes rather than clinical needs. While this risk is acknowledged, there is a lack of empirical evidence evaluating sociodemographic bias in LLM-generated nursing care plans. Objective To investigate potential biases in nursing care plans generated by LLMs, we focused on whether outputs differ systematically based on patients’ sociodemographic characteristics and assessed the implications for equitable nursing care. Methods We used a mixed methods simulation study. A standardized clinical vignette experiment was used to prompt GPT-4 to generate 9600 nursing care plans for 96 patient profiles with varying sociodemographic characteristics (eg, sex, age, income, education, and residence). We first conducted a quantitative analysis of all plans, assessing variations in thematic content. Subsequently, a panel of senior nursing experts evaluated the clinical quality (eg, safety, applicability, and completeness) of a stratified subsample of 500 plans. Results We analyzed 9600 LLM-generated nursing care plans and identified 8 consistent themes. Communication and Education (99.98%) and Emotional Support (99.97%) were nearly universal, while Nurse Training and Event Analysis were least frequent (39.3%). Multivariable analyses revealed systematic sociodemographic disparities. Care plans generated for low-income patient profiles were less likely to include the theme Environmental Adjustment (adjusted relative risk [aRR] 0.90). Profiles with lower education were associated with an increased likelihood of including Family Support (aRR 1.10). Similarly, plans generated for older patient profiles were more likely to contain recommendations for Pain Management (aRR 1.33) and Family Support (aRR 1.62) but were less likely to mention Nurse Training (aRR 0.78). Sex and regional differences were also significant. Expert review of 500 plans showed high overall quality (mean 4.47), with strong interrater reliability (κ=0.76‐0.81). However, urban profiles had higher completeness ( β =.22) and applicability ( β =.14) but lower safety scores (β=–0.09). These findings demonstrate that LLM-generated care plans exhibit systematic sociodemographic bias, raising important implications for fairness and safe deployment in nursing practice. Conclusions This study identified that LLMs systematically reproduce sociodemographic biases in the generation of nursing care plans. These biases appear in two forms: they shape the thematic content and influence expert-rated clinical quality. These findings reveal a substantial risk that such models may reinforce existing health inequities. To our knowledge, this is the first empirical evidence documenting these nuanced biases in nursing. The study also contributes a replicable framework for evaluating LLM-generated care plans. Finally, it underscores the critical need for robust human oversight to ensure that artificial intelligence serves as a tool for advancing equity rather than perpetuating disparities.",
    "keywords": [
      "sociodemographic",
      "biases",
      "large language models",
      "health care equity",
      "nursing care",
      "mixed methods study"
    ]
  },
  "xml": "<?xml version=\"1.0\"  ?><!DOCTYPE pmc-articleset PUBLIC \"-//NLM//DTD ARTICLE SET 2.0//EN\" \"https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd\"><pmc-articleset><article xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:ali=\"http://www.niso.org/schemas/ali/1.0/\" xml:lang=\"en\" article-type=\"research-article\" dtd-version=\"1.4\"><processing-meta base-tagset=\"archiving\" mathml-version=\"3.0\" table-model=\"xhtml\" tagset-family=\"jats\"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type=\"nlm-ta\">J Med Internet Res</journal-id><journal-id journal-id-type=\"iso-abbrev\">J Med Internet Res</journal-id><journal-id journal-id-type=\"pmc-domain-id\">224</journal-id><journal-id journal-id-type=\"pmc-domain\">jmir</journal-id><journal-id journal-id-type=\"publisher-id\">jmir</journal-id><journal-title-group><journal-title>Journal of Medical Internet Research</journal-title></journal-title-group><issn pub-type=\"ppub\">1439-4456</issn><issn pub-type=\"epub\">1438-8871</issn><publisher><publisher-name>JMIR Publications Inc.</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type=\"pmcid\">PMC12683325</article-id><article-id pub-id-type=\"pmcid-ver\">PMC12683325.1</article-id><article-id pub-id-type=\"pmcaid\">12683325</article-id><article-id pub-id-type=\"pmcaiid\">12683325</article-id><article-id pub-id-type=\"pmid\">41355748</article-id><article-id pub-id-type=\"doi\">10.2196/78132</article-id><article-id pub-id-type=\"publisher-id\">78132</article-id><article-version article-version-type=\"pmc-version\">1</article-version><article-categories><subj-group subj-group-type=\"primary-section\"><subject>Ethics, Privacy, and Legal Issues</subject></subj-group><subj-group subj-group-type=\"secondary-section\"><subject>Machine Learning</subject></subj-group><subj-group subj-group-type=\"secondary-section\"><subject>Nursing</subject></subj-group><subj-group subj-group-type=\"secondary-section\"><subject>Nursing and Public Health</subject></subj-group><subj-group subj-group-type=\"secondary-section\"><subject>Use and User Demographics of mHealth</subject></subj-group><subj-group subj-group-type=\"heading\"><subject>Original Paper</subject></subj-group></article-categories><title-group><article-title>Detecting Sociodemographic Biases in the Content and Quality of Large Language Model&#8211;Generated Nursing Care: Cross-Sectional Simulation Study</article-title></title-group><contrib-group><contrib contrib-type=\"author\" equal-contrib=\"yes\"><contrib-id contrib-id-type=\"orcid\" authenticated=\"false\">https://orcid.org/0000-0002-8655-5888</contrib-id><name name-style=\"western\"><surname>Bai</surname><given-names initials=\"N\">Nan</given-names></name><degrees>MSc</degrees><xref rid=\"aff1\" ref-type=\"aff\">1</xref><xref rid=\"equal-contrib1\" ref-type=\"author-notes\">*</xref></contrib><contrib contrib-type=\"author\" equal-contrib=\"yes\"><contrib-id contrib-id-type=\"orcid\" authenticated=\"false\">https://orcid.org/0009-0002-0951-6823</contrib-id><name name-style=\"western\"><surname>Yu</surname><given-names initials=\"Y\">Yijing</given-names></name><degrees>BSc</degrees><xref rid=\"aff1\" ref-type=\"aff\">1</xref><xref rid=\"equal-contrib1\" ref-type=\"author-notes\">*</xref></contrib><contrib contrib-type=\"author\" equal-contrib=\"yes\"><contrib-id contrib-id-type=\"orcid\" authenticated=\"false\">https://orcid.org/0009-0001-8283-9015</contrib-id><name name-style=\"western\"><surname>Luo</surname><given-names initials=\"C\">Chunyan</given-names></name><degrees>BSc</degrees><xref rid=\"aff1\" ref-type=\"aff\">1</xref><xref rid=\"equal-contrib1\" ref-type=\"author-notes\">*</xref></contrib><contrib contrib-type=\"author\"><contrib-id contrib-id-type=\"orcid\" authenticated=\"false\">https://orcid.org/0000-0001-7793-6876</contrib-id><name name-style=\"western\"><surname>Zhou</surname><given-names initials=\"SC\">Si Chen</given-names></name><degrees>MSc</degrees><xref rid=\"aff1\" ref-type=\"aff\">1</xref></contrib><contrib contrib-type=\"author\"><contrib-id contrib-id-type=\"orcid\" authenticated=\"false\">https://orcid.org/0009-0008-8091-3809</contrib-id><name name-style=\"western\"><surname>Wang</surname><given-names initials=\"Q\">Qing</given-names></name><degrees>BSc</degrees><xref rid=\"aff1\" ref-type=\"aff\">1</xref></contrib><contrib contrib-type=\"author\"><contrib-id contrib-id-type=\"orcid\" authenticated=\"false\">https://orcid.org/0000-0002-5656-5364</contrib-id><name name-style=\"western\"><surname>Zou</surname><given-names initials=\"H\">Huijing</given-names></name><degrees>PhD</degrees><xref rid=\"aff1\" ref-type=\"aff\">1</xref></contrib><contrib contrib-type=\"author\"><contrib-id contrib-id-type=\"orcid\" authenticated=\"false\">https://orcid.org/0000-0001-6833-6131</contrib-id><name name-style=\"western\"><surname>Liu</surname><given-names initials=\"Q\">Qian</given-names></name><degrees>PhD</degrees><xref rid=\"aff1\" ref-type=\"aff\">1</xref></contrib><contrib contrib-type=\"author\"><contrib-id contrib-id-type=\"orcid\" authenticated=\"false\">https://orcid.org/0000-0002-6391-5983</contrib-id><name name-style=\"western\"><surname>Fu</surname><given-names initials=\"G\">Guanghui</given-names></name><degrees>PhD</degrees><xref rid=\"aff2\" ref-type=\"aff\">2</xref></contrib><contrib contrib-type=\"author\"><contrib-id contrib-id-type=\"orcid\" authenticated=\"false\">https://orcid.org/0009-0009-1762-9570</contrib-id><name name-style=\"western\"><surname>Zhai</surname><given-names initials=\"W\">Wei</given-names></name><degrees>ME</degrees><xref rid=\"aff3\" ref-type=\"aff\">3</xref></contrib><contrib contrib-type=\"author\"><contrib-id contrib-id-type=\"orcid\" authenticated=\"false\">https://orcid.org/0000-0001-9570-9546</contrib-id><name name-style=\"western\"><surname>Zhao</surname><given-names initials=\"Q\">Qing</given-names></name><degrees>PhD</degrees><xref rid=\"aff3\" ref-type=\"aff\">3</xref></contrib><contrib contrib-type=\"author\"><contrib-id contrib-id-type=\"orcid\" authenticated=\"false\">https://orcid.org/0000-0003-1995-9249</contrib-id><name name-style=\"western\"><surname>Li</surname><given-names initials=\"J\">Jianqiang</given-names></name><degrees>PhD</degrees><xref rid=\"aff3\" ref-type=\"aff\">3</xref></contrib><contrib contrib-type=\"author\"><contrib-id contrib-id-type=\"orcid\" authenticated=\"false\">https://orcid.org/0000-0003-2986-012X</contrib-id><name name-style=\"western\"><surname>Wei</surname><given-names initials=\"X\">Xinni</given-names></name><degrees>PhD</degrees><xref rid=\"aff1\" ref-type=\"aff\">1</xref></contrib><contrib contrib-type=\"author\" corresp=\"yes\"><contrib-id contrib-id-type=\"orcid\" authenticated=\"false\">https://orcid.org/0000-0002-0227-4342</contrib-id><name name-style=\"western\"><surname>Yang</surname><given-names initials=\"BX\">Bing Xiang</given-names></name><degrees>PhD</degrees><xref rid=\"aff1\" ref-type=\"aff\">1</xref><xref rid=\"aff4\" ref-type=\"aff\">4</xref><xref rid=\"aff5\" ref-type=\"aff\">5</xref><xref rid=\"cor1\" ref-type=\"corresp\"/></contrib><aff id=\"aff1\"><label>1</label><institution content-type=\"department\">Center for Wise Information Technology of Mental Health Nursing Research</institution>, <institution>School of Nursing, Wuhan University</institution>, <addr-line>No. 115, Donghu Road, Wuchang District</addr-line>, <addr-line content-type=\"city\">Wuhan</addr-line>, <addr-line content-type=\"state\">Hubei</addr-line>, <country>China</country>, <phone>+86 15902731922</phone></aff><aff id=\"aff2\"><label>2</label><institution>Sorbonne Universit&#233;, Institut du Cerveau - Paris Brain Institute - ICM, CNRS, Inria, Inserm, AP-HP, H&#244;pital de la Piti&#233; Salp&#234;tri&#232;re</institution>, <addr-line content-type=\"city\">Paris</addr-line>, <country>France</country></aff><aff id=\"aff3\"><label>3</label><institution content-type=\"department\">College of Computer Science</institution>, <institution>Beijing University of Technology</institution>, <addr-line content-type=\"city\">Beijing</addr-line>, <country>China</country></aff><aff id=\"aff4\"><label>4</label><institution content-type=\"department\">Department of Psychiatry</institution>, <institution>Renmin Hospital of Wuhan University</institution>, <addr-line content-type=\"city\">Wuhan</addr-line>, <country>China</country></aff><aff id=\"aff5\"><label>5</label><institution content-type=\"department\">Research Center for Lifespan Health</institution>, <institution>Wuhan University</institution>, <addr-line content-type=\"city\">Wuhan</addr-line>, <country>China</country></aff></contrib-group><contrib-group><contrib contrib-type=\"editor\"><name name-style=\"western\"><surname>Stone</surname><given-names initials=\"A\">Alicia</given-names></name></contrib></contrib-group><author-notes><corresp id=\"cor1\">Bing Xiang Yang, PhD, Center for Wise Information Technology of Mental Health Nursing Research, School of Nursing, Wuhan University, No. 115, Donghu Road, Wuchang District, Wuhan, Hubei, China, <phone>+86 15902731922</phone>; <email xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"00009312@whu.edu.cn\">00009312@whu.edu.cn</email></corresp><fn fn-type=\"equal\" id=\"equal-contrib1\"><label>*</label><p>these authors contributed equally</p></fn></author-notes><pub-date pub-type=\"collection\"><year>2025</year></pub-date><pub-date pub-type=\"epub\"><day>5</day><month>12</month><year>2025</year></pub-date><volume>27</volume><issue-id pub-id-type=\"pmc-issue-id\">479700</issue-id><elocation-id>e78132</elocation-id><history><date date-type=\"received\"><day>27</day><month>5</month><year>2025</year></date><date date-type=\"rev-recd\"><day>06</day><month>11</month><year>2025</year></date><date date-type=\"accepted\"><day>10</day><month>11</month><year>2025</year></date></history><pub-history><event event-type=\"pmc-release\"><date><day>05</day><month>12</month><year>2025</year></date></event><event event-type=\"pmc-live\"><date><day>09</day><month>12</month><year>2025</year></date></event><event event-type=\"pmc-last-change\"><date iso-8601-date=\"2025-12-09 14:25:12.950\"><day>09</day><month>12</month><year>2025</year></date></event></pub-history><permissions><copyright-statement>Copyright &#169; Nan Bai, Yijing Yu, Chunyan Luo, Si Chen Zhou, Qing Wang, Huijing Zou, Qian Liu, Guanghui Fu, Wei Zhai, Qing Zhao, Jianqiang Li, Xinni Wei, Bing Xiang Yang. Originally published in the Journal of Medical Internet Research (https://www.jmir.org)</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref specific-use=\"textmining\" content-type=\"ccbylicense\">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (<ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://creativecommons.org/licenses/by/4.0/\">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published in the Journal of Medical Internet Research (ISSN 1438-8871), is properly cited. The complete bibliographic information, a link to the original publication on <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://www.jmir.org/\">https://www.jmir.org/</ext-link>, as well as this copyright and license information must be included.</license-p></license></permissions><self-uri xmlns:xlink=\"http://www.w3.org/1999/xlink\" content-type=\"pmc-pdf\" xlink:href=\"jmir-v27-e78132.pdf\"/><self-uri xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:title=\"pdf\" xlink:href=\"jmir-v27-e78132.pdf\"/><abstract><title>Abstract</title><sec><title>Background</title><p>Large language models (LLMs) are increasingly applied in health care. However, concerns remain that their nursing care recommendations may reflect patients&#8217; sociodemographic attributes rather than clinical needs. While this risk is acknowledged, there is a lack of empirical evidence evaluating sociodemographic bias in LLM-generated nursing care plans.</p></sec><sec><title>Objective</title><p>To investigate potential biases in nursing care plans generated by LLMs, we focused on whether outputs differ systematically based on patients&#8217; sociodemographic characteristics and assessed the implications for equitable nursing care.</p></sec><sec><title>Methods</title><p>We used a mixed methods simulation study. A standardized clinical vignette experiment was used to prompt GPT-4 to generate 9600 nursing care plans for 96 patient profiles with varying sociodemographic characteristics (eg, sex, age, income, education, and residence). We first conducted a quantitative analysis of all plans, assessing variations in thematic content. Subsequently, a panel of senior nursing experts evaluated the clinical quality (eg, safety, applicability, and completeness) of a stratified subsample of 500 plans.</p></sec><sec><title>Results</title><p>We analyzed 9600 LLM-generated nursing care plans and identified 8 consistent themes. Communication and Education (99.98%) and Emotional Support (99.97%) were nearly universal, while Nurse Training and Event Analysis were least frequent (39.3%). Multivariable analyses revealed systematic sociodemographic disparities. Care plans generated for low-income patient profiles were less likely to include the theme Environmental Adjustment (adjusted relative risk [aRR] 0.90). Profiles with lower education were associated with an increased likelihood of including Family Support (aRR 1.10). Similarly, plans generated for older patient profiles were more likely to contain recommendations for Pain Management (aRR 1.33) and Family Support (aRR 1.62) but were less likely to mention Nurse Training (aRR 0.78). Sex and regional differences were also significant. Expert review of 500 plans showed high overall quality (mean 4.47), with strong interrater reliability (&#954;=0.76&#8208;0.81). However, urban profiles had higher completeness (<italic toggle=\"yes\">&#946;</italic>=.22) and applicability (<italic toggle=\"yes\">&#946;</italic>=.14) but lower safety scores (&#946;=&#8211;0.09). These findings demonstrate that LLM-generated care plans exhibit systematic sociodemographic bias, raising important implications for fairness and safe deployment in nursing practice.</p></sec><sec><title>Conclusions</title><p>This study identified that LLMs systematically reproduce sociodemographic biases in the generation of nursing care plans. These biases appear in two forms: they shape the thematic content and influence expert-rated clinical quality. These findings reveal a substantial risk that such models may reinforce existing health inequities. To our knowledge, this is the first empirical evidence documenting these nuanced biases in nursing. The study also contributes a replicable framework for evaluating LLM-generated care plans. Finally, it underscores the critical need for robust human oversight to ensure that artificial intelligence serves as a tool for advancing equity rather than perpetuating disparities.</p></sec></abstract><kwd-group kwd-group-type=\"author-keywords\"><title>Keywords</title><kwd>sociodemographic</kwd><kwd>biases</kwd><kwd>large language models</kwd><kwd>health care equity</kwd><kwd>nursing care</kwd><kwd>mixed methods study</kwd></kwd-group><custom-meta-group><custom-meta><meta-name>pmc-status-qastatus</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>pmc-status-live</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-status-embargo</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-status-released</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-open-access</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-olf</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-manuscript</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-legally-suppressed</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-pdf</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-supplement</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-pdf-only</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-suppress-copyright</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-real-version</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-scanned-article</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-preprint</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-in-epmc</meta-name><meta-value>yes</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec sec-type=\"intro\" id=\"s1\"><title>Introduction</title><p>In recent years, large language models (LLMs) have garnered significant attention across various fields, emerging as transformative tools in sectors such as health care [<xref rid=\"R1\" ref-type=\"bibr\">1</xref>]. Over the past decade, research output focusing on LLM applications in medical and health domains has grown exponentially [<xref rid=\"R2\" ref-type=\"bibr\">2</xref>]. Advances in natural language processing and deep learning, particularly the Transformer architecture and its core self-attention mechanism [<xref rid=\"R3\" ref-type=\"bibr\">3</xref>], have enabled the increasing application of LLMs, such as ChatGPT, in clinical nursing practice. These systems support real-time triage [<xref rid=\"R4\" ref-type=\"bibr\">4</xref>], generate diagnostic recommendations [<xref rid=\"R5\" ref-type=\"bibr\">5</xref>], recommend nursing interventions [<xref rid=\"R6\" ref-type=\"bibr\">6</xref><xref rid=\"R7\" ref-type=\"bibr\">7</xref>], and develop health education plans [<xref rid=\"R8\" ref-type=\"bibr\">8</xref>], thereby improving nursing efficiency. The effectiveness of LLMs in clinical care has been well-documented by several studies [<xref rid=\"R9\" ref-type=\"bibr\">9-11</xref>], demonstrating their potential to improve patient outcomes and care quality.</p><p>Sociodemographic factors critically influence the quality and accessibility of nursing care, with pervasive disparities documented across key demographic variables, including age, sex identity, geographic location, educational attainment, and socioeconomic status [<xref rid=\"R2\" ref-type=\"bibr\">2</xref>]. For example, labeling female patients as &#8220;demanding&#8221; or &#8220;overly sensitive&#8221; may skew symptom management decisions, resulting in disparities in care [<xref rid=\"R12\" ref-type=\"bibr\">12</xref><xref rid=\"R13\" ref-type=\"bibr\">13</xref>]. Similarly, ageism may influence nursing decisions, where older patients are stereotyped as &#8220;fragile&#8221; and may receive either excessive protective care or inadequate treatment due to perceptions that they are &#8220;too old to benefit significantly&#8221; [<xref rid=\"R14\" ref-type=\"bibr\">14</xref><xref rid=\"R15\" ref-type=\"bibr\">15</xref>]. Moreover, patients from socioeconomically disadvantaged backgrounds often face barriers to care compared to wealthier patients, exacerbating disparities in health care outcomes [<xref rid=\"R16\" ref-type=\"bibr\">16</xref>]. These documented human cognitive biases in nursing practice may be inadvertently encoded into LLMs through their training on historical clinical narratives and decision records [<xref rid=\"R17\" ref-type=\"bibr\">17</xref>].</p><p>The technical validation of LLMs in nursing has progressed rapidly. Previous studies have demonstrated superior accuracy of nurses in tracheostomy care protocol execution [<xref rid=\"R7\" ref-type=\"bibr\">7</xref>] and in generating basic mental health care plans [<xref rid=\"R18\" ref-type=\"bibr\">18</xref>]. However, the field remains predominantly focused on validating clinical competency rather than auditing algorithmic equity. Recently, a systematic review of 30 nursing LLM studies revealed that the majority of studies prioritized technical performance metrics (eg, diagnostic accuracy and response consistency), with only a small number addressing ethical risks, such as algorithmic bias [<xref rid=\"R19\" ref-type=\"bibr\">19</xref>]. This trend indicates a research landscape heavily skewed toward performance validation while largely neglecting equity auditing. Furthermore, these limited discussions on bias are primarily found in opinion pieces and reviews rather than empirical investigation [<xref rid=\"R11\" ref-type=\"bibr\">11</xref><xref rid=\"R20\" ref-type=\"bibr\">20</xref>]. To date, few original studies have used rigorous quantitative experimental methodologies to explore the potential biases embedded within LLM-generated nursing care plans.</p><p>Although previous studies have identified algorithmic bias in other domains of medical artificial intelligence (AI), such as Convolutional Neural Network-based medical imaging analysis [<xref rid=\"R21\" ref-type=\"bibr\">21</xref><xref rid=\"R22\" ref-type=\"bibr\">22</xref>], traditional machine learning models (eg, support vector machines or random forests) for clinical diagnostics [<xref rid=\"R23\" ref-type=\"bibr\">23</xref>], and disease prediction [<xref rid=\"R24\" ref-type=\"bibr\">24</xref>], most have primarily focused on racial, ethnic, and sex factors. Other sociodemographic dimensions, such as education, income, and place of residence, also have a great impact on health care resource utilization [<xref rid=\"R25\" ref-type=\"bibr\">25-27</xref>]. This focus highlights a critical gap concerning the fairness of generative models such as LLMs, whose unique capacity for narrative text generation introduces distinct ethical challenges not fully addressed by research on these earlier models. Despite the need to ensure fairness has been widely recognized, serving as a cornerstone of the World Health Organization&#8217;s LLMs management framework [<xref rid=\"R28\" ref-type=\"bibr\">28</xref>], empirical fairness evaluations specific to nursing care planning remain limited, and systematic audits that include education, income, and urban-rural residence are still uncommon.</p><p>While prior research has documented bias in AI diagnostics, the extent to which generative models introduce sociodemographic bias into the complex narrative of clinical care plans has remained a critical gap. To our knowledge, this study represents the first large-scale evaluation (N=9600) to use a mixed methods approach. By inputting specific prompts based on real clinical scenarios, we systematically investigated biases in both the thematic content and the expert-rated quality of LLM-generated nursing care plans. Therefore, this study aimed to systematically evaluate whether GPT-4 reproduces sociodemographic biases in nursing care plan generation and to identify how these biases manifest across linguistic and clinical dimensions. Through this mixed methods design, we sought to provide empirical evidence on the fairness, risks, and limitations of generative AI in nursing contexts, thereby informing its fair, responsible, and effective integration into future nursing practice.</p></sec><sec sec-type=\"methods\" id=\"s2\"><title>Methods</title><sec id=\"s2-1\"><title>Study Design</title><p>This study used a sequential explanatory mixed methods design to investigate sociodemographic bias in LLM-generated nursing care plans. First, a quantitative analysis was conducted to assess whether the thematic content of care plans varied by patient sociodemographic factors. Subsequently, a qualitative assessment was used to explain these findings, wherein a panel of nursing experts rated a subsample of plans on their clinical quality. Our study integrated 2 distinct research methods. The primary goal was to identify potential biases in the presence or absence of specific care themes. Beyond this, we aimed to understand if the clinical quality of the provided care also differed systematically across demographic groups.</p></sec><sec id=\"s2-2\"><title>Clinical Scenario Design and Experiment Setup</title><sec id=\"s2-2-1\"><title>Selection of Clinical Scenario and Methodological Rationale</title><p>This study used a standardized clinical vignette experiment, an established methodology in behavioral and health care research. To be clear, we did not use real patient charts or identifiable data from any hospital. Our scenario was a standardized tool designed for rigorous experimental control, not a case report of an individual patient.</p><p>We chose this established method for 2 core reasons. First, it ensures scientific rigor by eliminating the confounding variables found in unique patient cases. This allows us to isolate the effects of the manipulated sociodemographic variables. Second, the method upholds strict ethical standards by avoiding the use of any protected health information.</p><p>Our vignette depicts a cardiac patient becoming agitated after multiple failed attempts at IV insertion. This scenario design parallels the approach of prior research, such as Guo and Zhang (2021) [<xref rid=\"R29\" ref-type=\"bibr\">29</xref>], which used a similar common clinical conflict to investigate bias in doctor-patient relationships. It was then reviewed and validated by our panel of senior nursing experts to ensure its clinical realism. This experimental paradigm is a standard and accepted method for investigating attitudes and biases in behavioral sciences and health care research [<xref rid=\"R30\" ref-type=\"bibr\">30</xref>].</p></sec><sec id=\"s2-2-2\"><title>Patient Demographics</title><p>This study examines potential biases in LLM-generated nursing care plans related to key patient sociodemographic characteristics, including sex, age, residence, educational attainment, and income. These are widely recognized as social determinants of health that directly influence nursing care delivery and patient outcomes [<xref rid=\"R31\" ref-type=\"bibr\">31</xref>]. As these factors have long shaped traditional nursing practice, it is reasonable to anticipate that they may similarly affect the recommendations generated by LLMs.</p><p>Sex (male vs female) may impact both the emotional tone and the clinical content of nursing care plans, as previous research indicates that health care providers may unconsciously manage similar symptoms differently depending on the patient&#8217;s sex. Specifically, female patients are more likely to be recommended psychological support, whereas male patients may receive more pharmacological or technical interventions under similar clinical scenarios [<xref rid=\"R32\" ref-type=\"bibr\">32</xref>].</p><p>Age (categorized as youth, middle-aged, older middle-aged, and elderly) is a critical factor affecting nursing care needs. We defined youth as 18 to 29 years, middle-aged as 30 to 49 years, older middle-aged as 50 to 64 years, and elderly as &#8805;65 years [<xref rid=\"R33\" ref-type=\"bibr\">33</xref>]. Older patients often require more complex, chronic condition management and personalized interventions [<xref rid=\"R34\" ref-type=\"bibr\">34</xref>].</p><p>Residence (urban vs rural) is another significant variable, as patients in rural areas often face limited access to health care resources compared to their urban counterparts [<xref rid=\"R35\" ref-type=\"bibr\">35</xref>].</p><p>Income level (categorized as high, middle, or low) plays a critical role in determining both the accessibility of health care services and the complexity of care provided. Specifically, low income was defined as falling below the 25th percentile of the sample distribution, middle income between the 25th and 75th percentiles, and high income above the 75th percentile. Patients with lower income may be more likely to receive standardized care that overlooks individual needs or preferences [<xref rid=\"R36\" ref-type=\"bibr\">36</xref>].</p><p>Educational background (higher education vs lower education) influences a patient&#8217;s understanding of care instructions and their level of engagement with the health care process. In this study, higher education was defined as holding a bachelor&#8217;s degree or above, whereas lower education referred to individuals with less than a bachelor&#8217;s degree. Patients with higher education may be more proactive in managing their care, whereas those with lower education may require more guidance and support [<xref rid=\"R37\" ref-type=\"bibr\">37</xref>].</p></sec></sec><sec id=\"s2-3\"><title>AI Model and Experimental Tools</title><p>This study used GPT-4 to generate nursing care plans through the Azure OpenAI API, a widely accessible and cost-effective platform that is freely available for use, making it easier for health care providers to adopt in clinical practice. A temperature parameter of 0.7 was set to balance creativity and stability in the generated content, ensuring moderate randomness without compromising quality or consistency [<xref rid=\"R38\" ref-type=\"bibr\">38</xref>].</p></sec><sec id=\"s2-4\"><title>Experimental Procedure</title><sec id=\"s2-4-1\"><title>Patient Profile Input</title><p>The LLMs received a patient profile that includes the following key demographic characteristics: age, sex, income level, educational background, and residence, along with a detailed clinical scenario. For example, 1 prompt describes a 28-year-old male cardiac patient, a high-income earner with a bachelor&#8217;s degree residing in an urban area, who requires an intravenous infusion. During the procedure, the nurse was unable to locate the vein, resulting in a failed puncture attempt. The patient subsequently became emotionally distressed and verbally insulted the nurse. The full text of the clinical vignette, the base prompt template, and a detailed table of all variable substitution rules are provided in <xref rid=\"SAP1\" ref-type=\"supplementary-material\">Multimedia Appendix 1</xref>.</p></sec><sec id=\"s2-4-2\"><title>AI Model Prompt</title><p>For each combination of patient profile, the LLMs generated a nursing care plan in response to a structured prompt. The prompt instructed the model to provide an appropriate nursing care plan based on the described clinical scenario. <xref rid=\"F1\" ref-type=\"fig\">Figure 1</xref> illustrates the workflow for LLM-based nursing care plan generation, outlining the process from patient data input to care plan output. All 9600 nursing care plans were generated via the API between August 29 and August 30, 2025.</p><fig position=\"float\" id=\"F1\" fig-type=\"figure\" orientation=\"portrait\"><label>Figure 1.</label><caption><title> Flowchart of the LLM-generated nursing care plan generation process. LLM: large language model.</title></caption><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" position=\"float\" orientation=\"portrait\" xlink:href=\"jmir-v27-e78132-g001.jpg\"/></fig></sec><sec id=\"s2-4-3\"><title>Prompt Design and Standardization</title><p>To minimize output variability arising from prompt phrasing and inherent model randomness [<xref rid=\"R39\" ref-type=\"bibr\">39</xref>] and thereby isolate the effect of sociodemographic factors, we implemented a rigorous standardization protocol. This protocol involved three key strategies: (1) using a single, consistent clinical vignette for all tests; (2) using a uniform prompt structure across all tests; and (3) performing 100 repeated queries for each of the 96 unique patient profiles to account for natural fluctuations in the model&#8217;s output.</p></sec><sec id=\"s2-4-4\"><title>Repetition and Testing</title><p>For each clinical scenario, we designed multiple prompts to reflect all unique combinations of patients&#8217; identity characteristics. Consequently, it contained 96 unique combinations (2&#215;4 &#215; 2&#215;3 &#215; 2), derived from sex (2 levels), age (4 levels), residence (2 levels), income level (3 levels), and educational background (2 levels). To reduce potential bias from prompt phrasing, each combination was tested 100 times, yielding a total of 9600 prompt-based care plan generations.</p></sec></sec><sec id=\"s2-5\"><title>Data Collection and Analysis</title><sec id=\"s2-5-1\"><title>Thematic Analysis and Framework Development</title><p>We analyzed data using thematic analysis, following Braun and Clarke&#8217;s approach [<xref rid=\"R40\" ref-type=\"bibr\">40</xref>]. In the first stage, 2 trained qualitative researchers independently reviewed approximately 1000 LLM-generated nursing care plans. This initial review continued until thematic saturation was reached. They conducted line-by-line inductive coding during this stage and read these care plans repeatedly to get familiar with the data. Initial codes were generated independently and then reconciled through consensus discussions. Using constant comparison, conceptually similar codes were organized into candidate themes and iteratively reviewed for coherence with the corpus and key excerpts, with refinement by splitting, merging, or renaming as needed. This process yielded a finalized codebook consisting of 8 recurrent themes.</p><p>In the second stage, using the finalized codebook, the same 2 researchers manually coded all 9600 care plans in the corpus. Both researchers coded each plan for the presence of each predefined theme, recording a binary indicator (1=present and 0=absent). Coding consistency was ensured through regular consensus meetings; any discrepancies were resolved by discussion until agreement was reached. An audit trail of analytic notes and coding decisions was maintained to support transparency. These binary indicators were subsequently used in the quantitative analyses (see <xref rid=\"SAP2\" ref-type=\"supplementary-material\">Multimedia Appendix 2</xref> for the detailed coding manual).</p></sec><sec id=\"s2-5-2\"><title>Analysis of Thematic Distribution and Associated Factors</title><p>All statistical analyses were performed in Python (version 3.12). Every statistical test was 2-sided, and a <italic toggle=\"yes\">P</italic> value (<italic toggle=\"yes\">q</italic> value) adjusted for the False Discovery Rate of less than .05 was considered significant.</p><p>Descriptive statistics were used to summarize the data. Categorical variables were reported as frequencies and percentages, and the prevalence of each theme was calculated with 95% CIs via the Clopper-Pearson exact method.</p><p>We first explored the associations between demographic characteristics and theme occurrence using the Chi-square or Fisher exact test. We then calculated Cramer V to measure the strength of these associations and applied the Benjamini-Hochberg procedure to the resulting <italic toggle=\"yes\">P</italic> values to control for multiple comparisons.</p><p>To delineate the independent predictors for each theme, we constructed multivariable regression models. Our primary strategy was logistic regression, yielding adjusted odds ratios and 95% CIs. For any models that failed to converge, we used modified Poisson regression with robust SEs to obtain adjusted relative risks (aRRs). Finally, all <italic toggle=\"yes\">P</italic> values from the model coefficients were adjusted using the Benjamini-Hochberg method, and the key findings were visualized in forest plots.</p></sec><sec id=\"s2-5-3\"><title>Expert Assessment of Quality and Bias Analysis</title><sec id=\"s2-5-3-1\"><title>Overview</title><p>Following the quantitative thematic analysis, we conducted a qualitative expert review to explain and add clinical depth to the observed patterns. A sample size of 500 was determined a priori through a power analysis to ensure sufficient statistical power for the subsequent multivariable regression models.</p><p>To ensure this subsample was representative and unbiased, we used a stratified random sampling strategy. We stratified the full sample of 9600 plans by the 96 unique sociodemographic profiles and then randomly selected approximately 5 plans from each stratum.</p><p>The expert review was conducted at Renmin Hospital of Wuhan University. The panel consisted of 2 independent registered nurses from the Department of Cardiology, each with more than 15 years of direct inpatient cardiovascular nursing experience. Panel members were identified by the nursing director and recruited via departmental email. Participation was entirely voluntary, and no financial compensation was provided. Each plan was rated on a 5-point Likert scale (1=very poor to 5=excellent) across three core dimensions derived from established quality frameworks: safety, clinical applicability, and completeness. These dimensions were adapted from the Institute of Medicine&#8217;s established framework for health care quality [<xref rid=\"R41\" ref-type=\"bibr\">41</xref>]. To ensure a standardized assessment, a comprehensive rating manual containing detailed operational definitions and anchored scale descriptors was developed. Furthermore, the panel completed a formal calibration exercise before the main review to ensure a shared understanding of the criteria (see <xref rid=\"SAP3\" ref-type=\"supplementary-material\">Multimedia Appendix 3</xref>).</p></sec><sec id=\"s2-5-3-2\"><title>Data Analysis</title><p>Interrater reliability of the initial, independent ratings was quantified using two complementary metrics: the intraclass correlation coefficient (ICC) and the quadratically weighted kappa coefficient (&#954;). We used a 2-way random effects model for absolute agreement to calculate the single-rater ICC (ICC [2,1]) [<xref rid=\"R42\" ref-type=\"bibr\">42</xref>]. On the basis of the established benchmarks, reliability values between 0.61 and 0.80 are interpreted as &#8216;substantial&#8217; agreement, whereas values from 0.81 to 1.00 represent &#8216;near-perfect&#8217; agreement [<xref rid=\"R43\" ref-type=\"bibr\">43</xref>]. After confirming reliability, a final quality score was determined for each case: for cases with a major disagreement (a rating difference of &#8805;2 points), a third senior expert adjudicated to assign a consensus score; for all other cases, the mean of the 2 experts&#8217; scores was used. These final scores then served as the continuous dependent variables in a series of multivariable linear regression models, which assessed the independent association between patient demographic characteristics and expert-assigned quality.</p></sec></sec></sec><sec id=\"s2-6\"><title>Ethical Considerations</title><p>The standardized clinical vignette used in this study is a synthetic material, constructed by the authors for this research. The Biomedical Institutional Review Board of Wuhan University reviewed the project and determined that it does not constitute human subjects; therefore, formal institutional review board approval and informed consent were not required.</p></sec></sec><sec sec-type=\"results\" id=\"s3\"><title>Results</title><sec id=\"s3-1\"><title>Descriptive Characteristics of the Sample and Themes</title><p>A total of 9600 nursing care plans generated by the LLM were included in the analysis. The sociodemographic characteristics of the corresponding patient profiles are detailed in <xref rid=\"T1\" ref-type=\"table\">Table 1</xref>. Regarding the thematic content, 8 consistent nursing themes were identified across these outputs. Communication and Education and Emotional Support and Stress Management were nearly universal, appearing in 99.98% (95% CI 99.92%&#8208;100%) and 99.97% (95% CI 99.91%&#8208;99.99%) of cases. Other highly frequent themes included Technical Support and IV Management (91.69%) and Safety Management with Risk Control (89.31%). In contrast, Family Support (72.81%), Environmental Adjustment (68.42%), and Pain and Medication Management (47.85%) appeared less frequently. The least common theme was Nurse Training and Event Analysis, which was present in only 39.32% (95% CI 38.34%&#8208;40.31%). The overall distribution of nursing themes is summarized in <xref rid=\"T1\" ref-type=\"table\">Tables1 </xref><xref rid=\"T2\" ref-type=\"table\"> 2</xref> and visualized in <xref rid=\"F2\" ref-type=\"fig\">Figure 2</xref>.</p><table-wrap position=\"float\" id=\"T1\" orientation=\"portrait\"><label>Table 1.</label><caption><title> Sociodemographic characteristics of the sample (N=9600).</title></caption><table frame=\"hsides\" rules=\"groups\"><thead><tr><th align=\"justify\" valign=\"bottom\" rowspan=\"1\" colspan=\"1\">Variable and grouping</th><th align=\"justify\" valign=\"bottom\" rowspan=\"1\" colspan=\"1\">Sample size, n (%)</th></tr></thead><tbody><tr><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">Sex (female)</td><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">4800 (50)</td></tr><tr><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">Age</td><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\"/></tr><tr><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\"><break/>&#8195;Youth</td><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">2400 (25)</td></tr><tr><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">&#8195;Middle-aged</td><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">2400 (25)</td></tr><tr><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">&#8195;Older middle-aged</td><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">2400 (25)</td></tr><tr><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">&#8195;Elderly</td><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">2400 (25)</td></tr><tr><td valign=\"top\" rowspan=\"1\" colspan=\"1\">Residence</td><td valign=\"top\" rowspan=\"1\" colspan=\"1\"/></tr><tr><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\"><break/>&#8195;Rural</td><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">4800 (50)</td></tr><tr><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">&#8195;Urban</td><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">4800 (50)</td></tr><tr><td valign=\"top\" rowspan=\"1\" colspan=\"1\">Education</td><td valign=\"top\" rowspan=\"1\" colspan=\"1\"/></tr><tr><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\"><break/>&#8195;Lower education</td><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">4800 (50)</td></tr><tr><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">&#8195;Higher education</td><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">4800 (50)</td></tr><tr><td valign=\"top\" rowspan=\"1\" colspan=\"1\">Income</td><td valign=\"top\" rowspan=\"1\" colspan=\"1\"/></tr><tr><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\"><break/>&#8195;Low income</td><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">3200 (33.33)</td></tr><tr><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">&#8195;Middle income</td><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">3200 (33.33)</td></tr><tr><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">&#8195;High income</td><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">3200 (33.33)</td></tr></tbody></table></table-wrap><table-wrap position=\"float\" id=\"T2\" orientation=\"portrait\"><label>Table 2.</label><caption><title>Overall prevalence of nursing care themes (N=9600).</title></caption><table frame=\"hsides\" rules=\"groups\"><thead><tr><th valign=\"top\" rowspan=\"1\" colspan=\"1\">Theme</th><th valign=\"top\" rowspan=\"1\" colspan=\"1\">Occurrence (n)</th><th valign=\"top\" rowspan=\"1\" colspan=\"1\">Sample size (n)</th><th valign=\"top\" rowspan=\"1\" colspan=\"1\">Rate (%)</th><th valign=\"top\" align=\"char\" rowspan=\"1\" colspan=\"1\">95% CI</th></tr></thead><tbody><tr><td valign=\"top\" rowspan=\"1\" colspan=\"1\">Communication and Education</td><td valign=\"top\" align=\"char\" rowspan=\"1\" colspan=\"1\">9598</td><td valign=\"top\" align=\"char\" rowspan=\"1\" colspan=\"1\">9600</td><td valign=\"top\" align=\"char\" rowspan=\"1\" colspan=\"1\">99.98</td><td valign=\"top\" align=\"char\" rowspan=\"1\" colspan=\"1\">99.92-100</td></tr><tr><td valign=\"top\" rowspan=\"1\" colspan=\"1\">Emotional Support and Stress Management</td><td valign=\"top\" align=\"char\" rowspan=\"1\" colspan=\"1\">9597</td><td valign=\"top\" align=\"char\" rowspan=\"1\" colspan=\"1\">9600</td><td valign=\"top\" align=\"char\" rowspan=\"1\" colspan=\"1\">99.97</td><td valign=\"top\" align=\"char\" rowspan=\"1\" colspan=\"1\">99.91-99.99</td></tr><tr><td valign=\"top\" rowspan=\"1\" colspan=\"1\">Technical Support and IV Management</td><td valign=\"top\" align=\"char\" rowspan=\"1\" colspan=\"1\">8802</td><td valign=\"top\" align=\"char\" rowspan=\"1\" colspan=\"1\">9600</td><td valign=\"top\" align=\"char\" rowspan=\"1\" colspan=\"1\">91.69</td><td valign=\"top\" align=\"char\" rowspan=\"1\" colspan=\"1\">91.12-92.23</td></tr><tr><td valign=\"top\" rowspan=\"1\" colspan=\"1\">Safety Management with Risk Control</td><td valign=\"top\" align=\"char\" rowspan=\"1\" colspan=\"1\">8574</td><td valign=\"top\" align=\"char\" rowspan=\"1\" colspan=\"1\">9600</td><td valign=\"top\" align=\"char\" rowspan=\"1\" colspan=\"1\">89.31</td><td valign=\"top\" align=\"char\" rowspan=\"1\" colspan=\"1\">88.68-89.92</td></tr><tr><td valign=\"top\" rowspan=\"1\" colspan=\"1\">Family Support</td><td valign=\"top\" align=\"char\" rowspan=\"1\" colspan=\"1\">6990</td><td valign=\"top\" align=\"char\" rowspan=\"1\" colspan=\"1\">9600</td><td valign=\"top\" align=\"char\" rowspan=\"1\" colspan=\"1\">72.81</td><td valign=\"top\" align=\"char\" rowspan=\"1\" colspan=\"1\">71.91-73.70</td></tr><tr><td valign=\"top\" rowspan=\"1\" colspan=\"1\">Environmental Adjustment</td><td valign=\"top\" align=\"char\" rowspan=\"1\" colspan=\"1\">6568</td><td valign=\"top\" align=\"char\" rowspan=\"1\" colspan=\"1\">9600</td><td valign=\"top\" align=\"char\" rowspan=\"1\" colspan=\"1\">68.42</td><td valign=\"top\" align=\"char\" rowspan=\"1\" colspan=\"1\">67.48&#8208;69.35</td></tr><tr><td valign=\"top\" rowspan=\"1\" colspan=\"1\">Pain and Medication Management</td><td valign=\"top\" align=\"char\" rowspan=\"1\" colspan=\"1\">4594</td><td valign=\"top\" align=\"char\" rowspan=\"1\" colspan=\"1\">9600</td><td valign=\"top\" align=\"char\" rowspan=\"1\" colspan=\"1\">47.85</td><td valign=\"top\" align=\"char\" rowspan=\"1\" colspan=\"1\">46.85-48.86</td></tr><tr><td valign=\"top\" rowspan=\"1\" colspan=\"1\">Nurse Training and Event Analysis</td><td valign=\"top\" align=\"char\" rowspan=\"1\" colspan=\"1\">3775</td><td valign=\"top\" align=\"char\" rowspan=\"1\" colspan=\"1\">9600</td><td valign=\"top\" align=\"char\" rowspan=\"1\" colspan=\"1\">39.32</td><td valign=\"top\" align=\"char\" rowspan=\"1\" colspan=\"1\">38.34-40.31</td></tr></tbody></table></table-wrap><fig position=\"float\" id=\"F2\" fig-type=\"figure\" orientation=\"portrait\"><label>Figure 2.</label><caption><title>Overall distribution of nursing themes across 9600 outputs. Note: The 95% CIs for the &#8216;communication and education&#8217; (99.92%&#8208;100%) and 'Emotional Support and Stress Management&#8217; (99.91%&#8208;99.99%) themes are very narrow due to their high occurrence rates and may not be fully visible in the chart.</title></caption><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" position=\"float\" orientation=\"portrait\" xlink:href=\"jmir-v27-e78132-g002.jpg\"/></fig></sec><sec id=\"s3-2\"><title>Associations Between Demographics and Thematic Content</title><sec id=\"s3-2-1\"><title>Univariate Analysis of Thematic Distribution</title><p>The univariate associations between sociodemographic characteristics and the prevalence of the 8 nursing themes are detailed in Table S1 in <xref rid=\"SAP4\" ref-type=\"supplementary-material\">Multimedia Appendix 4</xref>. The analysis revealed that several themes were linked to a wide array of demographic factors.</p><p>For instance, Safety Management with Risk Control was significantly associated with all 5 tested factors: sex, age group, geographic region, and income level (all <italic toggle=\"yes\">q</italic>&lt;0.001), as well as educational attainment (<italic toggle=\"yes\">q</italic>=0.002). Specifically, male profiles showed a higher prevalence of Safety Management with Risk Control compared to female profiles (Cramer V=0.15, <italic toggle=\"yes\">q</italic>&lt;0.001). Low-income profiles exhibited a lower prevalence of safety management compared to middle-income and high-income profiles (Cramer V=0.08, <italic toggle=\"yes\">q</italic>&lt;0.001). A similar pattern of widespread association was observed for Technical Support and IV Management, which was significantly linked to sex, age group, region, and income level (all <italic toggle=\"yes\">q</italic>&lt;0.001), in addition to education (<italic toggle=\"yes\">q</italic>=0.030).</p></sec><sec id=\"s3-2-2\"><title>Multivariable Analysis of Factors Associated With Theme Presence</title><p>Our multivariable analysis adjusted for all sociodemographic factors. The results revealed systematic and complex patterns of bias in the LLM&#8217;s outputs (<xref rid=\"F3\" ref-type=\"fig\">Figure 3</xref> and Table S2 in <xref rid=\"SAP4\" ref-type=\"supplementary-material\">Multimedia Appendix 4</xref>). Several nursing themes showed strong sensitivity to socioeconomic and demographic characteristics. These findings highlighted a clear disparity.</p><fig position=\"float\" id=\"F3\" fig-type=\"figure\" orientation=\"portrait\"><label>Figure 3.</label><caption><title>Forest plots of multivariable analysis for factors associated with thematic presence.</title></caption><graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" position=\"float\" orientation=\"portrait\" xlink:href=\"jmir-v27-e78132-g003.jpg\"/></fig><p>Income level was an important source of disparity in the generated content. Care plans generated for low-income profiles were significantly less likely to include the theme of Environmental Adjustment (aRR 0.90, 95% CI 0.87-0.93; <italic toggle=\"yes\">q</italic>&lt;0.001) compared to high-income profiles.</p><p>Educational attainment was also associated with systematic differences. Plans generated for profiles with lower educational attainment were more likely to include Family Support (aRR 1.10, 95% CI 1.08-1.13; <italic toggle=\"yes\">q</italic>&lt;0.001).</p><p>Patient age was also a strong predictor of thematic content. Care plans generated for older age groups were more likely to include themes focused on direct patient care. For elderly profiles, generated plans were significantly more likely to contain Pain and Medication Management (aRR 1.33, 95% CI 1.26-1.41; <italic toggle=\"yes\">q</italic>&lt;0.001) and Family Support (aRR 1.62, 95% CI 1.56-1.68; <italic toggle=\"yes\">q</italic>&lt;0.001). Conversely, plans for these same elderly profiles were less likely to include themes related to care processes, such as Nurse Training (aRR 0.78, 95% CI 0.73-0.84; <italic toggle=\"yes\">q</italic>&lt;0.001).</p><p>Sex was a significant predictor. Care plans generated for female profiles had a higher likelihood of including Environmental Adjustment (aRR 1.14, 95% CI 1.11-1.17; <italic toggle=\"yes\">q</italic>&lt;0.001), these same profiles were linked to a lower likelihood of including Safety Management (aRR 0.90, 95% CI 0.89-0.91; <italic toggle=\"yes\">q</italic>&lt;0.001) and Nurse Training (aRR 0.86, 95% CI 0.82-0.90; <italic toggle=\"yes\">q</italic>&lt;0.001).</p><p>The geographic region also showed independent effects. Care plans generated for rural profiles were more likely to include Family Support (aRR 1.23, 95% CI 1.20-1.26; <italic toggle=\"yes\">q</italic>&lt;0.001). In contrast, these plans were less likely to mention Nurse Training (aRR 0.78, 95% CI 0.74-0.82; <italic toggle=\"yes\">q</italic>&lt;0.001).</p><p>Finally, the themes of Communication and Education and Emotional Support and Stress Management showed no significant independent associations with any tested demographic factor after adjustment.</p></sec></sec><sec id=\"s3-3\"><title>Expert Assessment of Care Plan Quality</title><sec id=\"s3-3-1\"><title>Subsample Characteristics and Overall Quality Scores</title><p>The stratified subsample selected for expert review comprised 500 nursing care plans. The sociodemographic profile of this subsample is detailed in Table S3 in <xref rid=\"SAP4\" ref-type=\"supplementary-material\">Multimedia Appendix 4</xref>. The distribution was nearly balanced for sex (female: n=247, 49.4%) and education ( lower education: n=248, 49.6%). Age groups were also almost equally represented, spanning youth (n=124), middle-aged (n=125), older middle-aged (n=125), and the elderly (n=126). There was a slight majority of urban profiles (n=260, 52.0%), and the 3 income tiers were comparable in size.</p><p>The descriptive statistics for the expert-assigned quality scores are presented in Table S3 in <xref rid=\"SAP4\" ref-type=\"supplementary-material\">Multimedia Appendix 4</xref>. The overall mean quality score across all dimensions was 4.47 (SD 0.26). Among the 3 dimensions, Safety received the highest average rating (mean 4.55, SD 0.47), followed by Completeness (mean 4.49, SD 0.48) and Clinical Applicability (mean 4.37, SD 0.46). Normality tests confirmed that the distributions of all 4 score metrics significantly deviated from a normal distribution (<italic toggle=\"yes\">P</italic>&lt;.001 for all).</p><p>To aid interpretation of the expert-rated scores, we provide illustrative excerpts in <xref rid=\"SAP5\" ref-type=\"supplementary-material\">Multimedia Appendix 5</xref>. These include deidentified examples of care plan text that received high versus low ratings for each of the 3 expert-rated dimensions (safety, clinical applicability, and completeness). All excerpts were lightly edited for brevity.</p></sec><sec id=\"s3-3-2\"><title>Interrater Reliability</title><p>The interrater reliability for the quality assessment was confirmed to be robust. The quadratically weighted kappa (&#954;) values indicated substantial to near-perfect agreement, with a &#954; of 0.81 (95% CI 0.762&#8208;0.867) for Completeness, 0.773 (95% CI 0.704&#8208;0.831) for Clinical Applicability, and 0.761 (95% CI 0.704&#8208;0.813) for Safety.</p><p>This high level of consistency was further supported by the single-rater ICC [1,2], which showed a highly similar pattern of reliability (Completeness: 0.817, Applicability: 0.773, and Safety: 0.762). Such robust agreement provided a strong justification for using the mean of the 2 expert ratings in subsequent analyses.</p></sec><sec id=\"s3-3-3\"><title>Associations Between Demographics and Quality Scores</title><p>To identify independent predictors of care plan quality, we constructed a series of multivariable linear regression models. After adjusting for all sociodemographic factors, several characteristics emerged as significant predictors for different quality dimensions (<xref rid=\"T3\" ref-type=\"table\">Table 3</xref>). In these models, &#946; coefficients represent the unstandardized mean difference in expert-rated scores between each subgroup and its reference category, adjusting for all other covariates. For example, a &#946; of .22 for urban versus rural in the Completeness model indicates that care plans for urban profiles received, on average, 0.22 points higher completeness scores (on the 5-point scale) than those for rural profiles.</p><table-wrap position=\"float\" id=\"T3\" orientation=\"portrait\"><label>Table 3.</label><caption><title>Multivariable linear regression models of factors associated with expert-rated quality scores. Notes: &#946; represents unstandardized regression coefficients estimated using ordinary least squares (OLS) regression with robust SEs. Reference categories were female for sex, middle aged for age group, rural for region, low education for education, and middle income for income level.</title></caption><table frame=\"hsides\" rules=\"groups\"><thead><tr><th valign=\"bottom\" rowspan=\"1\" colspan=\"1\">Predictor</th><th valign=\"bottom\" rowspan=\"1\" colspan=\"1\">Completeness,<break/>&#946; (95% CI)</th><th valign=\"bottom\" rowspan=\"1\" colspan=\"1\">Clinical applicability,<break/>&#946; (95% CI)</th><th valign=\"bottom\" rowspan=\"1\" colspan=\"1\">Safety, &#946; (95% CI)</th></tr></thead><tbody><tr><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">Sex</td><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\"/><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\"/><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\"/></tr><tr><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">&#8195;Male versus female (Ref.<xref rid=\"T3_FN4\" ref-type=\"table-fn\"><sup>a</sup></xref>)</td><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">0.05 (&#8722;0.02 to 0.13)</td><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">&#8722;0.02 (&#8722;0.10 to 0.05)</td><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">0.34 (0.26 to 0.42)<xref rid=\"T3_FN3\" ref-type=\"table-fn\"><sup>b</sup></xref></td></tr><tr><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">Age group</td><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\"/><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\"/><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\"/></tr><tr><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">&#8195;Young adult versus middle aged (Ref.)</td><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">&#8722;0.09 (&#8722;0.20 to 0.02)</td><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">&#8722;0.12 (&#8722;0.23 to 0.01)<xref rid=\"T3_FN3\" ref-type=\"table-fn\"><sup>b</sup></xref></td><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">0.09 (&#8722;0.02 to 0.20)</td></tr><tr><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">&#8195;Older middle aged versus middle aged (Ref.)</td><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">0.00 (&#8722;0.11 to 0.12)</td><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">&#8722;0.02 (&#8722;0.14 to 0.09)</td><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">&#8722;0.03 (&#8722;0.14 to 0.08)</td></tr><tr><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">&#8195;Elderly versus middle-aged (Ref)</td><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">0.10 (&#8722;0.01 to 0.21)</td><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">&#8722;0.09 (&#8722;0.20 to 0.02)</td><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">&#8722;0.03 (&#8722;0.14 to 0.08)</td></tr><tr><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">Region</td><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\"/><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\"/><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\"/></tr><tr><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">&#8195;Urban versus rural (Ref.)</td><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">0.22 (0.14 to 0.30)<xref rid=\"T3_FN3\" ref-type=\"table-fn\"><sup>b</sup></xref></td><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">0.14 (0.07 to 0.22)<xref rid=\"T3_FN3\" ref-type=\"table-fn\"><sup>b</sup></xref></td><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">&#8722;0.09 (&#8722;0.17 to 0.01)<xref rid=\"T3_FN3\" ref-type=\"table-fn\"><sup>b</sup></xref></td></tr><tr><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">Education</td><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\"/><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\"/><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\"/></tr><tr><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">&#8195;High education versus low (Ref.)</td><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">&#8722;0.07 (&#8722;0.15 to 0.01)</td><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">&#8722;0.03 (&#8722;0.11 to 0.05)</td><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">&#8722;0.02 (&#8722;0.10 to 0.06)</td></tr><tr><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">Income level</td><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\"/><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\"/><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\"/></tr><tr><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">&#8195;Low income versus middle (Ref.)</td><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">0.33 (0.23 to 0.43)<xref rid=\"T3_FN3\" ref-type=\"table-fn\"><sup>b</sup></xref></td><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">0.18 (0.08 to 0.28)<xref rid=\"T3_FN3\" ref-type=\"table-fn\"><sup>b</sup></xref></td><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">&#8722;0.02 (&#8722;0.12 to 0.07)</td></tr><tr><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">&#8195;High income versus middle (Ref.)</td><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">0.01 (&#8722;0.08 to 0.11)</td><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">&#8722;0.04 (0.13 to 0.06)</td><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">&#8722;0.02 (&#8722;0.11 to 0.07)</td></tr></tbody></table><table-wrap-foot><fn id=\"T3_FN4\" fn-type=\"other\"><label>a</label><p>Ref.: reference.</p></fn><fn id=\"T3_FN3\" fn-type=\"other\"><label>b</label><p>*<italic toggle=\"yes\">P</italic>&lt;.05.</p></fn></table-wrap-foot></table-wrap><p>The Completeness of care plans was the most strongly affected dimension. It was significantly higher in plans for urban profiles compared to rural ones (<italic toggle=\"yes\">&#946;</italic>=.22, 95% CI 0.14-0.30; <italic toggle=\"yes\">P</italic>&lt;.001). Additionally, low-income profiles were associated with significantly higher Completeness scores compared to the middle-income reference group (<italic toggle=\"yes\">&#946;</italic>=.33, 95% CI 0.23-0.43; <italic toggle=\"yes\">P</italic>&lt;.001).</p><p>For Clinical Applicability, urban residence (<italic toggle=\"yes\">&#946;</italic>=.14, 95% CI 0.07-0.22; <italic toggle=\"yes\">P</italic>=.001) and low-income status (<italic toggle=\"yes\">&#946;</italic>=.18, 95% CI 0.08-0.28; <italic toggle=\"yes\">P</italic>=.002) were also predictors of higher scores. Furthermore, plans for youth (18&#8208;29 y) received significantly lower Applicability scores compared to the middle-aged reference group (<italic toggle=\"yes\">&#946;</italic>=&#8722;.12, 95% CI &#8722;0.23 to &#8722;0.01; <italic toggle=\"yes\">P</italic>=.05).</p><p>Finally, the safety of care plans was significantly associated with two factors. Plans for male profiles received significantly higher scores than those for female profiles (<italic toggle=\"yes\">&#946;</italic>=.34, 95% CI 0.26-0.42; <italic toggle=\"yes\">P</italic>&lt;.001). In contrast, plans for urban profiles were associated with significantly lower Safety scores (<italic toggle=\"yes\">&#946;</italic>=&#8722;.09, 95% CI &#8722;0.17 to &#8722;0.01; <italic toggle=\"yes\">P</italic>=.048). No significant associations were found for educational attainment in any of the final models.</p><p>Throughout this evaluation process, the expert reviewers confirmed that the generated content was clinically relevant to the scenario, with no observed significant AI hallucinations.</p></sec></sec></sec><sec sec-type=\"discussion\" id=\"s4\"><title>Discussion</title><sec id=\"s4-1\"><title>Principal Findings</title><p>This study investigated sociodemographic bias in nursing care plans generated by GPT-4. This is a critical area of inquiry, as AI-generated care plans impact patient safety and health equity. While bias in AI-driven diagnostics is well documented, the fairness of generative models in complex clinical narratives remains underexplored. Using a novel mixed methods approach, we found that GPT-4 may reflect underlying societal patterns present in its training data, which can influence both the thematic content and expert-rated clinical quality of care plans. Rather than rejecting the use of AI in health care, our findings underscore the importance of responsible deployment and expert oversight. Our findings reveal a dual form of bias. First, the model allocated core nursing themes inequitably across different demographic profiles. Second, we found a paradoxical pattern. Plans for socially advantaged groups were rated by experts as significantly lower in clinical safety. With transparent evaluation and human guidance, such models can become valuable tools that enhance clinical efficiency and equity, rather than inadvertently reinforcing disparities.</p><p>Thematic analysis revealed the first layer of bias through the inequitable allocation of core nursing themes. This disparity was most pronounced along socioeconomic lines, as low-income profiles had a significantly lower likelihood of including crucial themes such as Family Support and Environmental Adjustment. This pattern of underrepresentation extended to other characteristics, with female profiles receiving less content on Safety Management. These patterns are unlikely to be a random artifact. They reflect a digital reproduction of structural inequities learned from the model&#8217;s training data. This raises a critical concern. If deployed uncritically, this LLM may perpetuate a cycle of underresourced care for already vulnerable populations. While novel in the context of nursing care generation, our findings align with a substantial body of evidence on algorithmic bias. For example, prior work has established lower diagnostic accuracy on chest X-rays for minority populations [<xref rid=\"R44\" ref-type=\"bibr\">44</xref><xref rid=\"R45\" ref-type=\"bibr\">45</xref>]. In clinical NLP, models have replicated sexed language, describing female patients with more emotional terms and male patients with technical ones [<xref rid=\"R46\" ref-type=\"bibr\">46</xref>]. Predictive algorithms have also systematically underestimated health care costs for low-income patients due to historical underresourcing [<xref rid=\"R47\" ref-type=\"bibr\">47</xref>]. Our findings demonstrate that LLMs embed these disparities directly into patient care recommendations, thereby extending concerns about algorithmic bias to the domain of generative clinical narratives.</p><p>The expert quality review added a deeper and more complex layer to our findings. It revealed that the biases are not limited to the presence or absence of themes but extend to the clinical quality of the generated text itself. Our analysis of the expert scores uncovered a series of counterintuitive patterns. For example, while care plans for urban profiles were often thematically richer, experts rated them as significantly lower in terms of Safety. Most strikingly, profiles with low income, which received fewer thematic mentions in the initial analysis, paradoxically received substantially higher quality scores for both Clinical Applicability and Completeness.</p><p>A possible explanation for the inverse relationship between thematic quantity and perceived quality involves the LLM&#8217;s use of different generative heuristics. Such heuristics can cause AI models to internalize and apply societal stereotypes, as documented in prior literature [<xref rid=\"R48\" ref-type=\"bibr\">48</xref><xref rid=\"R49\" ref-type=\"bibr\">49</xref>]. Our findings suggest the model applied different approaches to different profiles. For socially advantaged profiles (eg, urban, higher income), it tended to generate thematically dense plans. The increased complexity of these plans may introduce more potential for error, a known principle in safety science [<xref rid=\"R50\" ref-type=\"bibr\">50</xref>]. This could explain their lower expert-rated safety scores. Conversely, for socially disadvantaged profiles (eg, low income), the model appeared to generate shorter and more prescriptive plans. This output style is strikingly analogous to what medical sociology terms paternalistic communication. This communication pattern is characterized by providing direct, simplified instructions while omitting complex rationales or shared decision-making options, often based on an implicit assumption about the patient&#8217;s lower health literacy or agency [<xref rid=\"R51\" ref-type=\"bibr\">51</xref>]. The model&#8217;s tendency to produce a focused but less explanatory plan for these groups could be an algorithmic manifestation of this paternalistic pattern. The focused nature of these less complex plans may be why experts rated them higher on Clinical Applicability and Completeness.</p><p>The direct clinical implication of our findings is that current-generation LLMs such as GPT-4 are not yet suitable for fully autonomous use in generating nursing care plans [<xref rid=\"R52\" ref-type=\"bibr\">52</xref>]. Our results demonstrate that deploying these models without a robust human-in-the-loop review process could introduce significant risks [<xref rid=\"R53\" ref-type=\"bibr\">53</xref>]. Specifically, it may lead to the provision of care that is systematically biased [<xref rid=\"R54\" ref-type=\"bibr\">54</xref>], either through the omission of key nursing themes or through qualitatively substandard recommendations for certain patient groups. This means that algorithmic fairness is not just a technical problem for computer scientists. It is a fundamental issue of patient safety. If AI is to be used safely in health care, fairness should not be an afterthought. It should be a core, required metric in the design, testing, and monitoring of these systems.</p><p>This study also contributes a methodological framework for auditing generative AI in health care. We propose a dual-assessment framework that combines quantitative thematic analysis with expert-rated clinical quality. Compared with conventional text similarity or automated metrics, this framework enables a more comprehensive and clinically relevant assessment of model performance. Importantly, it accounts for the variable quality of generative outputs, which may differ in completeness, applicability, and safety, rather than conforming to a simple correct or incorrect dichotomy.</p><p>Our findings identify several priority areas for future investigation. First, it is essential to apply the proposed dual-assessment framework to other state-of-the-art LLMs (eg, Claude, Llama) to evaluate the generalizability of the observed bias patterns. Second, validating these results with real-world clinical data represents a critical step toward establishing their practical relevance. Third, future research should systematically compare LLM-generated biases with well-documented human biases to determine whether these systems primarily reproduce existing disparities or instead exacerbate them. Finally, subsequent work should focus on the design and empirical testing of both technical and educational interventions aimed at mitigating the biases identified in this study.</p></sec><sec id=\"s4-2\"><title>Strengths and Limitations</title><p>This study offers notable strengths. Its primary strength is the novel mixed methods design, which combines a large-scale quantitative analysis (n=9600) with a rigorous, expert-led quality assessment (n=500). This dual-assessment framework provides a more holistic view of AI-generated bias than relying on simplistic text-based metrics alone. The use of a state-of-the-art model (GPT-4) and a robust expert review process with prespecified reliability criteria further enhances the relevance and validity of our findings.</p><p>However, we must acknowledge several limitations. First, the analysis was conducted in a simulation setting rather than actual patient encounters, which may limit ecological validity and fail to capture the full complexity of real clinical decision-making. Second, our study focused on 5 specific sociodemographic factors and did not include other critical dimensions, such as race, ethnicity, or disability status, which are well-documented sources of health disparities. Third, our evaluation was restricted to one primary model (GPT-4); findings may not generalize to other emerging LLMs. Fourth, our study was based on a single, specific clinical scenario; patterns of bias may manifest differently in other types of clinical contexts, such as chronic disease management, end-of-life care, or psychiatric nursing. Examining these contexts represents an important direction for future research. Finally, although expert ratings provide valuable insights, they are inherently subjective. Future work should incorporate multisite, multidisciplinary validation as well as objective patient outcome data.</p></sec><sec id=\"s4-3\"><title>Conclusions</title><p>Our research demonstrates that a state-of-the-art LLM systematically reproduces complex sociodemographic biases when generating nursing care plans. These biases manifest not only in the thematic content but also, paradoxically, in the expert-rated clinical quality of the outputs. This finding challenges the view of LLMs as neutral tools. It highlights a significant risk. Without critical oversight, these technologies could perpetuate, and perhaps even exacerbate, existing health inequities. Therefore, we should ensure clinical AI serves as an instrument of equity, not a magnifier of disparity. Our findings underscore the essential need for a new evaluation paradigm. This new approach should be multifaceted, continuous, and deeply integrated with the principles of clinical quality and fairness.</p></sec></sec><sec sec-type=\"supplementary-material\" id=\"s5\"><title>Supplementary material</title><supplementary-material id=\"SAP1\" position=\"float\" content-type=\"local-data\" orientation=\"portrait\"><object-id pub-id-type=\"doi\">10.2196/78132</object-id><label>Multimedia Appendix 1</label><caption><title>Experimental design and prompt materials.</title></caption><media xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"jmir-v27-e78132-s001.docx\" xlink:title=\"DOCX File, 16 KB\" id=\"d67e1158\" position=\"anchor\" orientation=\"portrait\"/></supplementary-material><supplementary-material id=\"SAP2\" position=\"float\" content-type=\"local-data\" orientation=\"portrait\"><object-id pub-id-type=\"doi\">10.2196/78132</object-id><label>Multimedia Appendix 2</label><caption><title>Thematic analysis coding manual.</title></caption><media xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"jmir-v27-e78132-s002.docx\" xlink:title=\"DOCX File, 17 KB\" id=\"d67e1165\" position=\"anchor\" orientation=\"portrait\"/></supplementary-material><supplementary-material id=\"SAP3\" position=\"float\" content-type=\"local-data\" orientation=\"portrait\"><object-id pub-id-type=\"doi\">10.2196/78132</object-id><label>Multimedia Appendix 3</label><caption><title>Expert rating manual.</title></caption><media xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"jmir-v27-e78132-s003.docx\" xlink:title=\"DOCX File, 15 KB\" id=\"d67e1172\" position=\"anchor\" orientation=\"portrait\"/></supplementary-material><supplementary-material id=\"SAP4\" position=\"float\" content-type=\"local-data\" orientation=\"portrait\"><object-id pub-id-type=\"doi\">10.2196/78132</object-id><label>Multimedia Appendix 4</label><caption><title>Univariate and multivariate analyses.</title></caption><media xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"jmir-v27-e78132-s004.docx\" xlink:title=\"DOCX File, 38 KB\" id=\"d67e1179\" position=\"anchor\" orientation=\"portrait\"/></supplementary-material><supplementary-material id=\"SAP5\" position=\"float\" content-type=\"local-data\" orientation=\"portrait\"><object-id pub-id-type=\"doi\">10.2196/78132</object-id><label>Multimedia Appendix 5</label><caption><title>Illustrative examples of expert ratings.</title></caption><media xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"jmir-v27-e78132-s005.docx\" xlink:title=\"DOCX File, 16 KB\" id=\"d67e1186\" position=\"anchor\" orientation=\"portrait\"/></supplementary-material></sec></body><back><ack><title>Acknowledgments</title><p>The authors declare the use of generative artificial intelligence tools during manuscript preparation. According to the GAIDeT taxonomy (2025), the task delegated to generative artificial intelligence under full human supervision was language editing (polishing). The tool used was GPT-5.0. Responsibility for the final content lies entirely with the authors. GAI tools are not listed as authors and do not bear responsibility for the final outcomes.</p></ack><fn-group><fn fn-type=\"financial-disclosure\"><p><bold>Funding:</bold> This study was supported by the National Natural Science Foundation of China (grant 72474166).</p></fn><fn fn-type=\"other\"><p><bold>Data Availability:</bold> The datasets generated or analyzed during this study are available from the corresponding author on reasonable request.</p></fn><fn fn-type=\"other\"><p><bold>Authors&#8217; Contributions:</bold> Data curation, investigation: NB, YY, CL, SCZ, QW, and HZ</p><p>Formal analysis, software, methodology, visualization: NB, QL, GF, WZ, QZ, and JL</p><p>Project administration: XW and BXY</p><p>Funding acquisition: BXY</p><p>Supervision: XW and BXY</p><p>Writing and original draft preparation: all authors</p><p>XW and BXY contributed equally as the corresponding authors of this manuscript</p></fn><fn fn-type=\"COI-statement\"><p><bold>Conflicts of Interest:</bold> None declared.</p></fn></fn-group><notes><def-list><title>Abbreviations</title><def-item><term>AI</term><def><p>artificial intelligence</p></def></def-item><def-item><term>aRR</term><def><p>adjusted relative risk</p></def></def-item><def-item><term>ICC</term><def><p>intraclass correlation coefficient</p></def></def-item><def-item><term>LLM</term><def><p>large language model</p></def></def-item></def-list></notes><ref-list><title>References</title><ref id=\"R1\"><label>1.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Reddy</surname><given-names>S</given-names></name></person-group><article-title>Generative AI in healthcare: an implementation science informed translational path on application, integration and governance</article-title><source>Implement Sci</source><month>Mar</month><day>15</day><year>2024</year><volume>19</volume><issue>1</issue><elocation-id>27</elocation-id><comment>doi</comment><pub-id pub-id-type=\"doi\">10.1186/s13012-024-01357-9</pub-id><comment>Medline</comment><pub-id pub-id-type=\"pmid\">38491544</pub-id><pub-id pub-id-type=\"pmcid\">PMC10941464</pub-id></element-citation></ref><ref id=\"R2\"><label>2.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>von Gerich</surname><given-names>H</given-names></name><name name-style=\"western\"><surname>Moen</surname><given-names>H</given-names></name><name name-style=\"western\"><surname>Block</surname><given-names>LJ</given-names></name><etal>et al</etal></person-group><article-title>Artificial Intelligence-based technologies in nursing: a scoping literature review of the evidence</article-title><source>Int J Nurs Stud</source><month>Mar</month><year>2022</year><volume>127</volume><fpage>104153</fpage><comment>doi</comment><pub-id pub-id-type=\"doi\">10.1016/j.ijnurstu.2021.104153</pub-id><comment>Medline</comment><pub-id pub-id-type=\"pmid\">35092870</pub-id></element-citation></ref><ref id=\"R3\"><label>3.</label><element-citation publication-type=\"book\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Vaswani</surname><given-names>A</given-names></name><name name-style=\"western\"><surname>Shazeer</surname><given-names>N</given-names></name><name name-style=\"western\"><surname>Parmar</surname><given-names>N</given-names></name><etal>et al</etal></person-group><part-title>Attention is all you need</part-title><source>Adv Neural Inf Process Syst</source><year>2017</year><comment>URL</comment><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html\" ext-link-type=\"uri\">https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html</ext-link><comment>Accessed</comment><date-in-citation>01-10-2025</date-in-citation></element-citation></ref><ref id=\"R4\"><label>4.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Zaboli</surname><given-names>A</given-names></name><name name-style=\"western\"><surname>Brigo</surname><given-names>F</given-names></name><name name-style=\"western\"><surname>Sibilio</surname><given-names>S</given-names></name><name name-style=\"western\"><surname>Mian</surname><given-names>M</given-names></name><name name-style=\"western\"><surname>Turcato</surname><given-names>G</given-names></name></person-group><article-title>Human intelligence versus Chat-GPT: who performs better in correctly classifying patients in triage?</article-title><source>Am J Emerg Med</source><month>05</month><year>2024</year><volume>79</volume><fpage>44</fpage><lpage>47</lpage><comment>doi</comment><pub-id pub-id-type=\"doi\">10.1016/j.ajem.2024.02.008</pub-id><comment>Medline</comment><pub-id pub-id-type=\"pmid\">38341993</pub-id></element-citation></ref><ref id=\"R5\"><label>5.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Luo</surname><given-names>S</given-names></name><name name-style=\"western\"><surname>Canavese</surname><given-names>F</given-names></name><name name-style=\"western\"><surname>Aroojis</surname><given-names>A</given-names></name><etal>et al</etal></person-group><article-title>Are generative pretrained transformer 4 responses to developmental dysplasia of the hip clinical scenarios universal? An international review</article-title><source>J Pediatr Orthop</source><month>07</month><day>1</day><year>2024</year><volume>44</volume><issue>6</issue><fpage>e504</fpage><lpage>e511</lpage><comment>doi</comment><pub-id pub-id-type=\"doi\">10.1097/BPO.0000000000002682</pub-id><comment>Medline</comment><pub-id pub-id-type=\"pmid\">38597198</pub-id></element-citation></ref><ref id=\"R6\"><label>6.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Karacan</surname><given-names>E</given-names></name></person-group><article-title>Evaluating the quality of postpartum hemorrhage nursing care plans generated by artificial intelligence models</article-title><source>J Nurs Care Qual</source><year>2024</year><volume>39</volume><issue>3</issue><fpage>206</fpage><lpage>211</lpage><comment>doi</comment><pub-id pub-id-type=\"doi\">10.1097/NCQ.0000000000000766</pub-id><comment>Medline</comment><pub-id pub-id-type=\"pmid\">38701406</pub-id></element-citation></ref><ref id=\"R7\"><label>7.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Wang</surname><given-names>T</given-names></name><name name-style=\"western\"><surname>Mu</surname><given-names>J</given-names></name><name name-style=\"western\"><surname>Chen</surname><given-names>J</given-names></name><name name-style=\"western\"><surname>Lin</surname><given-names>CC</given-names></name></person-group><article-title>Comparing ChatGPT and clinical nurses&#8217; performances on tracheostomy care: a cross-sectional study</article-title><source>Int J Nurs Stud Adv</source><month>Jun</month><year>2024</year><volume>6</volume><elocation-id>100181</elocation-id><comment>doi</comment><pub-id pub-id-type=\"doi\">10.1016/j.ijnsa.2024.100181</pub-id><comment>Medline</comment><pub-id pub-id-type=\"pmid\">38746816</pub-id><pub-id pub-id-type=\"pmcid\">PMC11080343</pub-id></element-citation></ref><ref id=\"R8\"><label>8.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Luo</surname><given-names>Y</given-names></name><name name-style=\"western\"><surname>Miao</surname><given-names>Y</given-names></name><name name-style=\"western\"><surname>Zhao</surname><given-names>Y</given-names></name><etal>et al</etal></person-group><article-title>Comparing the accuracy of two generated large language models in identifying health-related rumors or misconceptions and the applicability in health science popularization: proof-of-concept study</article-title><source>JMIR Form Res</source><month>Dec</month><day>2</day><year>2024</year><volume>8</volume><elocation-id>e63188</elocation-id><comment>doi</comment><pub-id pub-id-type=\"doi\">10.2196/63188</pub-id><comment>Medline</comment><pub-id pub-id-type=\"pmid\">39622076</pub-id><pub-id pub-id-type=\"pmcid\">PMC11627524</pub-id></element-citation></ref><ref id=\"R9\"><label>9.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Han</surname><given-names>KD</given-names></name><name name-style=\"western\"><surname>Jaafar</surname><given-names>MA</given-names></name><name name-style=\"western\"><surname>Moin</surname><given-names>KA</given-names></name><name name-style=\"western\"><surname>Hoopes</surname><given-names>PC</given-names></name><name name-style=\"western\"><surname>Moshirfar</surname><given-names>M</given-names></name></person-group><article-title>Assessing the role of artificial intelligence in the creation of patient educational videos for corneal refractive surgery</article-title><source>Cureus</source><month>Oct</month><year>2024</year><volume>16</volume><issue>10</issue><elocation-id>e71447</elocation-id><comment>doi</comment><pub-id pub-id-type=\"doi\">10.7759/cureus.71447</pub-id><comment>Medline</comment><pub-id pub-id-type=\"pmid\">39539900</pub-id><pub-id pub-id-type=\"pmcid\">PMC11559605</pub-id></element-citation></ref><ref id=\"R10\"><label>10.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Moura</surname><given-names>L</given-names></name><name name-style=\"western\"><surname>Jones</surname><given-names>DT</given-names></name><name name-style=\"western\"><surname>Sheikh</surname><given-names>IS</given-names></name><etal>et al</etal></person-group><article-title>Implications of large language models for quality and efficiency of neurologic care</article-title><source>Neurology (ECronicon)</source><month>Jun</month><day>11</day><year>2024</year><volume>102</volume><issue>11</issue><elocation-id>e209497</elocation-id><comment>doi</comment><pub-id pub-id-type=\"doi\">10.1212/WNL.0000000000209497</pub-id><pub-id pub-id-type=\"pmid\">38759131</pub-id></element-citation></ref><ref id=\"R11\"><label>11.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Nashwan</surname><given-names>AJ</given-names></name><name name-style=\"western\"><surname>Abujaber</surname><given-names>AA</given-names></name></person-group><article-title>Harnessing large language models in nursing care planning: opportunities, challenges, and ethical considerations</article-title><source>Cureus</source><month>Jun</month><year>2023</year><volume>15</volume><issue>6</issue><elocation-id>e40542</elocation-id><comment>doi</comment><pub-id pub-id-type=\"doi\">10.7759/cureus.40542</pub-id><pub-id pub-id-type=\"pmid\">37465807</pub-id><pub-id pub-id-type=\"pmcid\">PMC10350541</pub-id></element-citation></ref><ref id=\"R12\"><label>12.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Naamany</surname><given-names>E</given-names></name><name name-style=\"western\"><surname>Reis</surname><given-names>D</given-names></name><name name-style=\"western\"><surname>Zuker-Herman</surname><given-names>R</given-names></name><name name-style=\"western\"><surname>Drescher</surname><given-names>M</given-names></name><name name-style=\"western\"><surname>Glezerman</surname><given-names>M</given-names></name><name name-style=\"western\"><surname>Shiber</surname><given-names>S</given-names></name></person-group><article-title>Is there gender discrimination in acute renal colic pain management? A retrospective analysis in an emergency department setting</article-title><source>Pain Manag Nurs</source><month>Dec</month><year>2019</year><volume>20</volume><issue>6</issue><fpage>633</fpage><lpage>638</lpage><comment>doi</comment><pub-id pub-id-type=\"doi\">10.1016/j.pmn.2019.03.004</pub-id><comment>Medline</comment><pub-id pub-id-type=\"pmid\">31175043</pub-id></element-citation></ref><ref id=\"R13\"><label>13.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Shoqirat</surname><given-names>N</given-names></name><name name-style=\"western\"><surname>Mahasneh</surname><given-names>D</given-names></name><name name-style=\"western\"><surname>Singh</surname><given-names>C</given-names></name><name name-style=\"western\"><surname>Al Hadid</surname><given-names>L</given-names></name></person-group><article-title>Do surgical patients&#8217; characteristics and behaviours affect nurses&#8217; pain management decisions? A qualitative inquiry</article-title><source>Int J Nurs Pract</source><month>Dec</month><year>2019</year><volume>25</volume><issue>6</issue><elocation-id>e12779</elocation-id><comment>doi</comment><pub-id pub-id-type=\"doi\">10.1111/ijn.12779</pub-id><comment>Medline</comment><pub-id pub-id-type=\"pmid\">31496014</pub-id></element-citation></ref><ref id=\"R14\"><label>14.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Allu&#233;-Sierra</surname><given-names>L</given-names></name><name name-style=\"western\"><surname>Ant&#243;n-Solanas</surname><given-names>I</given-names></name><name name-style=\"western\"><surname>Rodr&#237;guez-Roca</surname><given-names>B</given-names></name><etal>et al</etal></person-group><article-title>Ageism and nursing students, past or reality?: a systematic review</article-title><source>Nurse Educ Today</source><month>Mar</month><year>2023</year><volume>122</volume><fpage>105739</fpage><comment>doi</comment><pub-id pub-id-type=\"doi\">10.1016/j.nedt.2023.105739</pub-id><comment>Medline</comment><pub-id pub-id-type=\"pmid\">36731247</pub-id></element-citation></ref><ref id=\"R15\"><label>15.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Henry</surname><given-names>JD</given-names></name><name name-style=\"western\"><surname>Coundouris</surname><given-names>SP</given-names></name><name name-style=\"western\"><surname>Nangle</surname><given-names>MR</given-names></name></person-group><article-title>Breaking the links between ageism and health: an integrated perspective</article-title><source>Ageing Res Rev</source><month>Mar</month><year>2024</year><volume>95</volume><fpage>102212</fpage><comment>doi</comment><pub-id pub-id-type=\"doi\">10.1016/j.arr.2024.102212</pub-id><comment>Medline</comment><pub-id pub-id-type=\"pmid\">38307423</pub-id></element-citation></ref><ref id=\"R16\"><label>16.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Dickman</surname><given-names>SL</given-names></name><name name-style=\"western\"><surname>Himmelstein</surname><given-names>DU</given-names></name><name name-style=\"western\"><surname>Woolhandler</surname><given-names>S</given-names></name></person-group><article-title>Inequality and the health-care system in the USA</article-title><source>The Lancet</source><month>Apr</month><year>2017</year><volume>389</volume><issue>10077</issue><fpage>1431</fpage><lpage>1441</lpage><comment>doi</comment><pub-id pub-id-type=\"doi\">10.1016/S0140-6736(17)30398-7</pub-id><pub-id pub-id-type=\"pmid\">28402825</pub-id></element-citation></ref><ref id=\"R17\"><label>17.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Tran</surname><given-names>L</given-names></name><name name-style=\"western\"><surname>Kandel</surname><given-names>H</given-names></name><name name-style=\"western\"><surname>Sari</surname><given-names>D</given-names></name><name name-style=\"western\"><surname>Chiu</surname><given-names>CH</given-names></name><name name-style=\"western\"><surname>Watson</surname><given-names>SL</given-names></name></person-group><article-title>Artificial intelligence and ophthalmic clinical registries</article-title><source>Am J Ophthalmol</source><month>Dec</month><year>2024</year><volume>268</volume><fpage>263</fpage><lpage>274</lpage><comment>doi</comment><pub-id pub-id-type=\"doi\">10.1016/j.ajo.2024.07.039</pub-id><comment>Medline</comment><pub-id pub-id-type=\"pmid\">39111520</pub-id></element-citation></ref><ref id=\"R18\"><label>18.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Woodnutt</surname><given-names>S</given-names></name><name name-style=\"western\"><surname>Allen</surname><given-names>C</given-names></name><name name-style=\"western\"><surname>Snowden</surname><given-names>J</given-names></name><etal>et al</etal></person-group><article-title>Could artificial intelligence write mental health nursing care plans?</article-title><source>J Psychiatr Ment Health Nurs</source><month>Feb</month><year>2024</year><volume>31</volume><issue>1</issue><fpage>79</fpage><lpage>86</lpage><comment>doi</comment><pub-id pub-id-type=\"doi\">10.1111/jpm.12965</pub-id><comment>Medline</comment><pub-id pub-id-type=\"pmid\">37538021</pub-id></element-citation></ref><ref id=\"R19\"><label>19.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Hobensack</surname><given-names>M</given-names></name><name name-style=\"western\"><surname>von Gerich</surname><given-names>H</given-names></name><name name-style=\"western\"><surname>Vyas</surname><given-names>P</given-names></name><etal>et al</etal></person-group><article-title>A rapid review on current and potential uses of large language models in nursing</article-title><source>Int J Nurs Stud</source><month>Jun</month><year>2024</year><volume>154</volume><fpage>104753</fpage><comment>doi</comment><pub-id pub-id-type=\"doi\">10.1016/j.ijnurstu.2024.104753</pub-id><comment>Medline</comment><pub-id pub-id-type=\"pmid\">38560958</pub-id></element-citation></ref><ref id=\"R20\"><label>20.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>McGrow</surname><given-names>K</given-names></name></person-group><article-title>Artificial intelligence: essentials for nursing</article-title><source>Nursing (Lond)</source><month>Sep</month><year>2019</year><volume>49</volume><issue>9</issue><fpage>46</fpage><lpage>49</lpage><comment>doi</comment><pub-id pub-id-type=\"doi\">10.1097/01.NURSE.0000577716.57052.8d</pub-id><pub-id pub-id-type=\"pmcid\">PMC6716553</pub-id><pub-id pub-id-type=\"pmid\">31365455</pub-id></element-citation></ref><ref id=\"R21\"><label>21.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Glocker</surname><given-names>B</given-names></name><name name-style=\"western\"><surname>Jones</surname><given-names>C</given-names></name><name name-style=\"western\"><surname>Bernhardt</surname><given-names>M</given-names></name><name name-style=\"western\"><surname>Winzeck</surname><given-names>S</given-names></name></person-group><article-title>Algorithmic encoding of protected characteristics in chest X-ray disease detection models</article-title><source>EBioMedicine</source><month>Mar</month><year>2023</year><volume>89</volume><elocation-id>104467</elocation-id><comment>doi</comment><pub-id pub-id-type=\"doi\">10.1016/j.ebiom.2023.104467</pub-id><comment>Medline</comment><pub-id pub-id-type=\"pmid\">36791660</pub-id><pub-id pub-id-type=\"pmcid\">PMC10025760</pub-id></element-citation></ref><ref id=\"R22\"><label>22.</label><element-citation publication-type=\"preprint\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Zhang</surname><given-names>H</given-names></name><name name-style=\"western\"><surname>Dullerud</surname><given-names>N</given-names></name><name name-style=\"western\"><surname>Roth</surname><given-names>K</given-names></name><name name-style=\"western\"><surname>Oakden-Rayner</surname><given-names>L</given-names></name><name name-style=\"western\"><surname>Pfohl</surname><given-names>SR</given-names></name><name name-style=\"western\"><surname>Ghassemi</surname><given-names>M</given-names></name></person-group><article-title>Improving the fairness of chest x-ray classifiers</article-title><source>arXiv</source><comment>Preprint posted online on</comment><month>Mar</month><day>23</day><year>2022</year><comment>doi</comment><pub-id pub-id-type=\"doi\">10.48550/arXiv.2203.12609</pub-id></element-citation></ref><ref id=\"R23\"><label>23.</label><element-citation publication-type=\"confproc\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Raizman</surname><given-names>E</given-names></name><name name-style=\"western\"><surname>Peng</surname><given-names>Y</given-names></name><name name-style=\"western\"><surname>Deng</surname><given-names>A</given-names></name></person-group><article-title>Towards equitable diagnosis: bias evaluation and mitigation in skin cancer classification</article-title><comment>Presented at</comment><conf-name>2024 IEEE Conference on Computational Intelligence in Bioinformatics and Computational Biology (CIBCB)</conf-name><conf-date>Aug 27-29, 2024</conf-date><publisher-name>IEEE</publisher-name><fpage>1</fpage><lpage>9</lpage><conf-loc>Natal, Brazil</conf-loc><comment>doi</comment><pub-id pub-id-type=\"doi\">10.1109/CIBCB58642.2024.10702173</pub-id></element-citation></ref><ref id=\"R24\"><label>24.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Pennington</surname><given-names>J</given-names></name><name name-style=\"western\"><surname>Rasnick</surname><given-names>E</given-names></name><name name-style=\"western\"><surname>Martin</surname><given-names>LJ</given-names></name><etal>et al</etal></person-group><article-title>Racial fairness in precision medicine: pediatric asthma prediction algorithms</article-title><source>Am J Health Promot</source><month>Feb</month><year>2023</year><volume>37</volume><issue>2</issue><fpage>239</fpage><lpage>242</lpage><comment>doi</comment><pub-id pub-id-type=\"doi\">10.1177/08901171221121639</pub-id><comment>Medline</comment><pub-id pub-id-type=\"pmid\">35973209</pub-id></element-citation></ref><ref id=\"R25\"><label>25.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Kachmar</surname><given-names>AG</given-names></name><name name-style=\"western\"><surname>Watson</surname><given-names>RS</given-names></name><name name-style=\"western\"><surname>Wypij</surname><given-names>D</given-names></name><name name-style=\"western\"><surname>Perry</surname><given-names>MA</given-names></name><name name-style=\"western\"><surname>Curley</surname><given-names>MAQ</given-names></name><collab>Randomized Evaluation of Sedation Titration for Respiratory Failure (RESTORE) Investigative Team</collab></person-group><article-title>Association of socioeconomic status with postdischarge pediatric resource use and quality of life</article-title><source>Crit Care Med</source><month>Feb</month><day>1</day><year>2022</year><volume>50</volume><issue>2</issue><fpage>e117</fpage><lpage>e128</lpage><comment>doi</comment><pub-id pub-id-type=\"doi\">10.1097/CCM.0000000000005261</pub-id><comment>Medline</comment><pub-id pub-id-type=\"pmid\">34495879</pub-id><pub-id pub-id-type=\"pmcid\">PMC8810731</pub-id></element-citation></ref><ref id=\"R26\"><label>26.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Li</surname><given-names>SS</given-names></name><name name-style=\"western\"><surname>Schuldt</surname><given-names>R</given-names></name><name name-style=\"western\"><surname>Zafar</surname><given-names>F</given-names></name><etal>et al</etal></person-group><article-title>Effects of socioeconomic status and healthcare resource availability on survival in older (&#8805;66 years) non-Hispanic Black patients versus non-Hispanic White patients with multiple myeloma</article-title><source>Clin Lymphoma Myeloma Leuk</source><month>Apr</month><year>2025</year><volume>25</volume><issue>4</issue><fpage>285</fpage><lpage>292</lpage><comment>doi</comment><pub-id pub-id-type=\"doi\">10.1016/j.clml.2024.11.011</pub-id><comment>Medline</comment><pub-id pub-id-type=\"pmid\">39694783</pub-id></element-citation></ref><ref id=\"R27\"><label>27.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Tang</surname><given-names>Y</given-names></name><name name-style=\"western\"><surname>Fu</surname><given-names>R</given-names></name><name name-style=\"western\"><surname>Noguchi</surname><given-names>H</given-names></name></person-group><article-title>Impact of medical insurance integration on reducing urban-rural health disparity: evidence from China</article-title><source>Soc Sci Med</source><month>Sep</month><year>2024</year><volume>357</volume><fpage>117163</fpage><comment>doi</comment><pub-id pub-id-type=\"doi\">10.1016/j.socscimed.2024.117163</pub-id><comment>Medline</comment><pub-id pub-id-type=\"pmid\">39121565</pub-id></element-citation></ref><ref id=\"R28\"><label>28.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>DeCamp</surname><given-names>M</given-names></name><name name-style=\"western\"><surname>Lindvall</surname><given-names>C</given-names></name></person-group><article-title>Mitigating bias in AI at the point of care</article-title><source>Science</source><month>07</month><day>14</day><year>2023</year><volume>381</volume><issue>6654</issue><fpage>150</fpage><lpage>152</lpage><comment>doi</comment><pub-id pub-id-type=\"doi\">10.1126/science.adh2713</pub-id><comment>Medline</comment><pub-id pub-id-type=\"pmid\">37440631</pub-id><pub-id pub-id-type=\"pmcid\">PMC10680368</pub-id></element-citation></ref><ref id=\"R29\"><label>29.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Guo</surname><given-names>ZS</given-names></name><name name-style=\"western\"><surname>Zhang</surname><given-names>SW</given-names></name></person-group><article-title>Does &#8220;discrimination&#8221; exist in the doctor-patient relationship? An experimental investigation on &#8220;behavior&#8221;</article-title><source>J Guangxi Norm Univ</source><year>2021</year><volume>57</volume><issue>5</issue><fpage>32</fpage><lpage>44</lpage><comment>doi</comment><pub-id pub-id-type=\"doi\">10.16088/j.issn.1001-6597.2021.05.003</pub-id></element-citation></ref><ref id=\"R30\"><label>30.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>FitzGerald</surname><given-names>C</given-names></name><name name-style=\"western\"><surname>Hurst</surname><given-names>S</given-names></name></person-group><article-title>Implicit bias in healthcare professionals: a systematic review</article-title><source>BMC Med Ethics</source><month>Mar</month><day>1</day><year>2017</year><volume>18</volume><issue>1</issue><elocation-id>19</elocation-id><comment>doi</comment><pub-id pub-id-type=\"doi\">10.1186/s12910-017-0179-8</pub-id><comment>Medline</comment><pub-id pub-id-type=\"pmid\">28249596</pub-id><pub-id pub-id-type=\"pmcid\">PMC5333436</pub-id></element-citation></ref><ref id=\"R31\"><label>31.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Marmot</surname><given-names>M</given-names></name><name name-style=\"western\"><surname>Friel</surname><given-names>S</given-names></name><name name-style=\"western\"><surname>Bell</surname><given-names>R</given-names></name><name name-style=\"western\"><surname>Houweling</surname><given-names>TAJ</given-names></name><name name-style=\"western\"><surname>Taylor</surname><given-names>S</given-names></name></person-group><article-title>Closing the gap in a generation: health equity through action on the social determinants of health</article-title><source>The Lancet</source><month>Nov</month><year>2008</year><volume>372</volume><issue>9650</issue><fpage>1661</fpage><lpage>1669</lpage><comment>doi</comment><pub-id pub-id-type=\"doi\">10.1016/S0140-6736(08)61690-6</pub-id><pub-id pub-id-type=\"pmid\">18994664</pub-id></element-citation></ref><ref id=\"R32\"><label>32.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Hamberg</surname><given-names>K</given-names></name><name name-style=\"western\"><surname>Risberg</surname><given-names>G</given-names></name><name name-style=\"western\"><surname>Johansson</surname><given-names>EE</given-names></name><name name-style=\"western\"><surname>Westman</surname><given-names>G</given-names></name></person-group><article-title>Gender bias in physicians&#8217; management of neck pain: a study of the answers in a swedish national examination</article-title><source>J Womens Health Gend Based Med</source><month>Sep</month><year>2002</year><volume>11</volume><issue>7</issue><fpage>653</fpage><lpage>666</lpage><comment>doi</comment><pub-id pub-id-type=\"doi\">10.1089/152460902760360595</pub-id><comment>Medline</comment><pub-id pub-id-type=\"pmid\">12396897</pub-id></element-citation></ref><ref id=\"R33\"><label>33.</label><element-citation publication-type=\"webpage\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Tyson</surname><given-names>A</given-names></name><name name-style=\"western\"><surname>Pasquini</surname><given-names>G</given-names></name><name name-style=\"western\"><surname>Spencer</surname><given-names>A</given-names></name><name name-style=\"western\"><surname>Funk</surname><given-names>C</given-names></name></person-group><article-title>60% of americans would be uncomfortable with provider relying on AI in their own health care</article-title><source>Pew Research Center</source><month>01</month><day>2</day><year>2023</year><comment>URL</comment><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"https://www.pewresearch.org/science/2023/02/22/60-of-americans-would-be-uncomfortable-with-provider-relying-on-ai-in-their-own-health-care/\" ext-link-type=\"uri\">https://www.pewresearch.org/science/2023/02/22/60-of-americans-would-be-uncomfortable-with-provider-relying-on-ai-in-their-own-health-care/</ext-link><comment>Accessed</comment><date-in-citation>05-11-2025</date-in-citation></element-citation></ref><ref id=\"R34\"><label>34.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Malfait</surname><given-names>S</given-names></name><name name-style=\"western\"><surname>Van Hecke</surname><given-names>A</given-names></name><name name-style=\"western\"><surname>Van Biesen</surname><given-names>W</given-names></name><name name-style=\"western\"><surname>Eeckloo</surname><given-names>K</given-names></name></person-group><article-title>A systematic review of patient participation during bedside handovers on wards with older patients indicates evidence is urgently needed</article-title><source>Int J Older People Nurs</source><month>Jun</month><year>2019</year><volume>14</volume><issue>2</issue><elocation-id>e12226</elocation-id><comment>doi</comment><pub-id pub-id-type=\"doi\">10.1111/opn.12226</pub-id><comment>Medline</comment><pub-id pub-id-type=\"pmid\">30768854</pub-id></element-citation></ref><ref id=\"R35\"><label>35.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Liepins</surname><given-names>T</given-names></name><name name-style=\"western\"><surname>Nixon</surname><given-names>G</given-names></name><name name-style=\"western\"><surname>Stokes</surname><given-names>T</given-names></name></person-group><article-title>Rural-urban differences in health service utilization in upper-middle and high-income countries: a scoping review</article-title><source>Int J Equity Health</source><month>Sep</month><day>18</day><year>2024</year><volume>23</volume><issue>1</issue><elocation-id>188</elocation-id><comment>doi</comment><pub-id pub-id-type=\"doi\">10.1186/s12939-024-02261-w</pub-id><comment>Medline</comment><pub-id pub-id-type=\"pmid\">39294622</pub-id><pub-id pub-id-type=\"pmcid\">PMC11409755</pub-id></element-citation></ref><ref id=\"R36\"><label>36.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Mazenda</surname><given-names>A</given-names></name><name name-style=\"western\"><surname>Lubinga</surname><given-names>M</given-names></name></person-group><article-title>Healthcare access and deprivation in low-income urban households</article-title><source>Discov Soc Sci Health</source><month>Oct</month><day>1</day><year>2024</year><volume>4</volume><issue>1</issue><fpage>47</fpage><comment>doi</comment><pub-id pub-id-type=\"doi\">10.1007/s44155-024-00108-x</pub-id></element-citation></ref><ref id=\"R37\"><label>37.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Yuen</surname><given-names>E</given-names></name><name name-style=\"western\"><surname>Winter</surname><given-names>N</given-names></name><name name-style=\"western\"><surname>Savira</surname><given-names>F</given-names></name><etal>et al</etal></person-group><article-title>Digital health literacy and its association with sociodemographic characteristics, health resource use, and health outcomes: rapid review</article-title><source>Interact J Med Res</source><month>07</month><day>26</day><year>2024</year><volume>13</volume><issue>1</issue><elocation-id>e46888</elocation-id><comment>doi</comment><pub-id pub-id-type=\"doi\">10.2196/46888</pub-id><comment>Medline</comment><pub-id pub-id-type=\"pmid\">39059006</pub-id><pub-id pub-id-type=\"pmcid\">PMC11316163</pub-id></element-citation></ref><ref id=\"R38\"><label>38.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Zack</surname><given-names>T</given-names></name><name name-style=\"western\"><surname>Lehman</surname><given-names>E</given-names></name><name name-style=\"western\"><surname>Suzgun</surname><given-names>M</given-names></name><etal>et al</etal></person-group><article-title>Assessing the potential of GPT-4 to perpetuate racial and gender biases in health care: a model evaluation study</article-title><source>Lancet Digit Health</source><month>01</month><year>2024</year><volume>6</volume><issue>1</issue><fpage>e12</fpage><lpage>e22</lpage><comment>doi</comment><pub-id pub-id-type=\"doi\">10.1016/S2589-7500(23)00225-X</pub-id><comment>Medline</comment><pub-id pub-id-type=\"pmid\">38123252</pub-id></element-citation></ref><ref id=\"R39\"><label>39.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Omar</surname><given-names>M</given-names></name><name name-style=\"western\"><surname>Soffer</surname><given-names>S</given-names></name><name name-style=\"western\"><surname>Agbareia</surname><given-names>R</given-names></name><etal>et al</etal></person-group><article-title>Sociodemographic biases in medical decision making by large language models</article-title><source>Nat Med</source><month>Jun</month><year>2025</year><volume>31</volume><issue>6</issue><fpage>1873</fpage><lpage>1881</lpage><comment>doi</comment><pub-id pub-id-type=\"doi\">10.1038/s41591-025-03626-6</pub-id><comment>Medline</comment><pub-id pub-id-type=\"pmid\">40195448</pub-id></element-citation></ref><ref id=\"R40\"><label>40.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Braun</surname><given-names>V</given-names></name><name name-style=\"western\"><surname>Clarke</surname><given-names>V</given-names></name></person-group><article-title>Is thematic analysis used well in health psychology? A critical review of published research, with recommendations for quality practice and reporting</article-title><source>Health Psychol Rev</source><month>Dec</month><year>2023</year><volume>17</volume><issue>4</issue><fpage>695</fpage><lpage>718</lpage><comment>doi</comment><pub-id pub-id-type=\"doi\">10.1080/17437199.2022.2161594</pub-id><comment>Medline</comment><pub-id pub-id-type=\"pmid\">36656762</pub-id></element-citation></ref><ref id=\"R41\"><label>41.</label><element-citation publication-type=\"book\"><person-group person-group-type=\"author\"><collab>Institute of Medicine (US) Committee on Quality of Health Care in America</collab></person-group><source>Crossing the Quality Chasm: A New Health System for the 21st Century</source><publisher-name>National Academies Press</publisher-name><comment>URL</comment><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"http://www.ncbi.nlm.nih.gov/books/NBK222274/\" ext-link-type=\"uri\">http://www.ncbi.nlm.nih.gov/books/NBK222274/</ext-link><comment>Accessed</comment><date-in-citation>28-09-2025</date-in-citation><comment>doi</comment><pub-id pub-id-type=\"doi\">10.17226/10027</pub-id><pub-id pub-id-type=\"pmid\">25057539</pub-id></element-citation></ref><ref id=\"R42\"><label>42.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Shrout</surname><given-names>PE</given-names></name><name name-style=\"western\"><surname>Fleiss</surname><given-names>JL</given-names></name></person-group><article-title>Intraclass correlations: uses in assessing rater reliability</article-title><source>Psychol Bull</source><month>Mar</month><year>1979</year><volume>86</volume><issue>2</issue><fpage>420</fpage><lpage>428</lpage><comment>doi</comment><pub-id pub-id-type=\"doi\">10.1037//0033-2909.86.2.420</pub-id><comment>Medline</comment><pub-id pub-id-type=\"pmid\">18839484</pub-id></element-citation></ref><ref id=\"R43\"><label>43.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Landis</surname><given-names>JR</given-names></name><name name-style=\"western\"><surname>Koch</surname><given-names>GG</given-names></name></person-group><article-title>The measurement of observer agreement for categorical data</article-title><source>Biometrics</source><month>Mar</month><year>1977</year><volume>33</volume><issue>1</issue><fpage>159</fpage><lpage>174</lpage><comment>doi</comment><pub-id pub-id-type=\"doi\">10.2307/2529310</pub-id><comment>Medline</comment><pub-id pub-id-type=\"pmid\">843571</pub-id></element-citation></ref><ref id=\"R44\"><label>44.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Gichoya</surname><given-names>JW</given-names></name><name name-style=\"western\"><surname>Banerjee</surname><given-names>I</given-names></name><name name-style=\"western\"><surname>Bhimireddy</surname><given-names>AR</given-names></name><etal>et al</etal></person-group><article-title>AI recognition of patient race in medical imaging: a modelling study</article-title><source>Lancet Digit Health</source><month>Jun</month><year>2022</year><volume>4</volume><issue>6</issue><fpage>e406</fpage><lpage>e414</lpage><comment>doi</comment><pub-id pub-id-type=\"doi\">10.1016/S2589-7500(22)00063-2</pub-id><comment>Medline</comment><pub-id pub-id-type=\"pmid\">35568690</pub-id><pub-id pub-id-type=\"pmcid\">PMC9650160</pub-id></element-citation></ref><ref id=\"R45\"><label>45.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Larrazabal</surname><given-names>AJ</given-names></name><name name-style=\"western\"><surname>Nieto</surname><given-names>N</given-names></name><name name-style=\"western\"><surname>Peterson</surname><given-names>V</given-names></name><name name-style=\"western\"><surname>Milone</surname><given-names>DH</given-names></name><name name-style=\"western\"><surname>Ferrante</surname><given-names>E</given-names></name></person-group><article-title>Gender imbalance in medical imaging datasets produces biased classifiers for computer-aided diagnosis</article-title><source>Proc Natl Acad Sci U S A</source><month>Jun</month><day>9</day><year>2020</year><volume>117</volume><issue>23</issue><fpage>12592</fpage><lpage>12594</lpage><comment>doi</comment><pub-id pub-id-type=\"doi\">10.1073/pnas.1919012117</pub-id><comment>Medline</comment><pub-id pub-id-type=\"pmid\">32457147</pub-id><pub-id pub-id-type=\"pmcid\">PMC7293650</pub-id></element-citation></ref><ref id=\"R46\"><label>46.</label><element-citation publication-type=\"preprint\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Sogancioglu</surname><given-names>G</given-names></name><name name-style=\"western\"><surname>Mijsters</surname><given-names>F</given-names></name><name name-style=\"western\"><surname>van Uden</surname><given-names>A</given-names></name><name name-style=\"western\"><surname>Peperzak</surname><given-names>J</given-names></name></person-group><article-title>Sex bias in (non)-contextual clinical word embeddings for stereotypical medical categories</article-title><source>arXiv</source><comment>Preprint posted online on</comment><year>2022</year><comment>URL</comment><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"http://arxiv.org/abs/2208.01341\" ext-link-type=\"uri\">http://arxiv.org/abs/2208.01341</ext-link><comment>Accessed</comment><date-in-citation>01-10-2025</date-in-citation></element-citation></ref><ref id=\"R47\"><label>47.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Obermeyer</surname><given-names>Z</given-names></name><name name-style=\"western\"><surname>Powers</surname><given-names>B</given-names></name><name name-style=\"western\"><surname>Vogeli</surname><given-names>C</given-names></name><name name-style=\"western\"><surname>Mullainathan</surname><given-names>S</given-names></name></person-group><article-title>Dissecting racial bias in an algorithm used to manage the health of populations</article-title><source>Science</source><month>Oct</month><day>25</day><year>2019</year><volume>366</volume><issue>6464</issue><fpage>447</fpage><lpage>453</lpage><comment>doi</comment><pub-id pub-id-type=\"doi\">10.1126/science.aax2342</pub-id><comment>Medline</comment><pub-id pub-id-type=\"pmid\">31649194</pub-id></element-citation></ref><ref id=\"R48\"><label>48.</label><element-citation publication-type=\"preprint\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Jeoung</surname><given-names>S</given-names></name><name name-style=\"western\"><surname>Ge</surname><given-names>Y</given-names></name><name name-style=\"western\"><surname>Wang</surname><given-names>H</given-names></name><name name-style=\"western\"><surname>Diesner</surname><given-names>J</given-names></name></person-group><article-title>Examining alignment of large language models through representative heuristics: the case of political stereotypes</article-title><source>arXiv</source><comment>Preprint posted online on</comment><year>2025</year><comment>URL</comment><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"http://arxiv.org/abs/2501.14294\" ext-link-type=\"uri\">http://arxiv.org/abs/2501.14294</ext-link><comment>Accessed</comment><date-in-citation>30-09-2025</date-in-citation></element-citation></ref><ref id=\"R49\"><label>49.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Suri</surname><given-names>G</given-names></name><name name-style=\"western\"><surname>Slater</surname><given-names>LR</given-names></name><name name-style=\"western\"><surname>Ziaee</surname><given-names>A</given-names></name><name name-style=\"western\"><surname>Nguyen</surname><given-names>M</given-names></name></person-group><article-title>Do large language models show decision heuristics similar to humans? A case study using GPT-3.5</article-title><source>J Exp Psychol Gen</source><month>Apr</month><year>2024</year><volume>153</volume><issue>4</issue><fpage>1066</fpage><lpage>1075</lpage><comment>doi</comment><pub-id pub-id-type=\"doi\">10.1037/xge0001547</pub-id><comment>Medline</comment><pub-id pub-id-type=\"pmid\">38330366</pub-id></element-citation></ref><ref id=\"R50\"><label>50.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Campbell</surname><given-names>H</given-names></name><name name-style=\"western\"><surname>Goldman</surname><given-names>S</given-names></name><name name-style=\"western\"><surname>Markey</surname><given-names>PM</given-names></name></person-group><article-title>Artificial intelligence and human decision making: exploring similarities in cognitive bias</article-title><source>Comput Human Behav Artif Humans</source><month>05</month><year>2025</year><volume>4</volume><fpage>100138</fpage><comment>doi</comment><pub-id pub-id-type=\"doi\">10.1016/j.chbah.2025.100138</pub-id></element-citation></ref><ref id=\"R51\"><label>51.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Davoudi</surname><given-names>N</given-names></name><name name-style=\"western\"><surname>Nayeri</surname><given-names>ND</given-names></name><name name-style=\"western\"><surname>Zokaei</surname><given-names>MS</given-names></name><name name-style=\"western\"><surname>Fazeli</surname><given-names>N</given-names></name><name name-style=\"western\"><surname>Carspecken</surname><given-names>PF</given-names></name></person-group><article-title>Culture of paternalism in the emergency department: a critical ethnographic study</article-title><source>BMC Health Serv Res</source><month>Aug</month><day>12</day><year>2025</year><volume>25</volume><issue>1</issue><elocation-id>1068</elocation-id><comment>doi</comment><pub-id pub-id-type=\"doi\">10.1186/s12913-025-13282-8</pub-id><comment>Medline</comment><pub-id pub-id-type=\"pmid\">40797195</pub-id><pub-id pub-id-type=\"pmcid\">PMC12344830</pub-id></element-citation></ref><ref id=\"R52\"><label>52.</label><element-citation publication-type=\"webpage\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Zea</surname><given-names>J</given-names></name></person-group><article-title>Patients and clinicians: llms achieve high QA accuracy but require human evaluation for clinical safety</article-title><source>ArkangelAI</source><comment>URL</comment><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"https://arkangel.ai/research/patients-and-clinicians-llms-achieve-high-qa-accuracy-but-require-human-evaluation-for-clinical-safety?utm_source=chatgpt.com\" ext-link-type=\"uri\">https://arkangel.ai/research/patients-and-clinicians-llms-achieve-high-qa-accuracy-but-require-human-evaluation-for-clinical-safety?utm_source=chatgpt.com</ext-link><comment>Accessed</comment><date-in-citation>30-09-2025</date-in-citation></element-citation></ref><ref id=\"R53\"><label>53.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>van Voorst</surname><given-names>R</given-names></name></person-group><article-title>Challenges and limitations of human oversight in ethical artificial intelligence implementation in health care: balancing digital literacy and professional strain</article-title><source>Mayo Clin Proc Digit Health</source><month>Dec</month><year>2024</year><volume>2</volume><issue>4</issue><fpage>559</fpage><lpage>563</lpage><comment>doi</comment><pub-id pub-id-type=\"doi\">10.1016/j.mcpdig.2024.08.004</pub-id><comment>Medline</comment><pub-id pub-id-type=\"pmid\">40206522</pub-id><pub-id pub-id-type=\"pmcid\">PMC11976012</pub-id></element-citation></ref><ref id=\"R54\"><label>54.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Mackin</surname><given-names>S</given-names></name><name name-style=\"western\"><surname>Major</surname><given-names>VJ</given-names></name><name name-style=\"western\"><surname>Chunara</surname><given-names>R</given-names></name><name name-style=\"western\"><surname>Newton-Dame</surname><given-names>R</given-names></name></person-group><article-title>Identifying and mitigating algorithmic bias in the safety net</article-title><source>NPJ Digit Med</source><month>Jun</month><day>5</day><year>2025</year><volume>8</volume><issue>1</issue><elocation-id>335</elocation-id><comment>doi</comment><pub-id pub-id-type=\"doi\">10.1038/s41746-025-01732-w</pub-id><comment>Medline</comment><pub-id pub-id-type=\"pmid\">40473916</pub-id><pub-id pub-id-type=\"pmcid\">PMC12141433</pub-id></element-citation></ref></ref-list></back></article></pmc-articleset>",
  "text": "pmc J Med Internet Res J Med Internet Res 224 jmir jmir Journal of Medical Internet Research 1439-4456 1438-8871 JMIR Publications Inc. PMC12683325 PMC12683325.1 12683325 12683325 41355748 10.2196/78132 78132 1 Ethics, Privacy, and Legal Issues Machine Learning Nursing Nursing and Public Health Use and User Demographics of mHealth Original Paper Detecting Sociodemographic Biases in the Content and Quality of Large Language Model&#8211;Generated Nursing Care: Cross-Sectional Simulation Study https://orcid.org/0000-0002-8655-5888 Bai Nan MSc 1 * https://orcid.org/0009-0002-0951-6823 Yu Yijing BSc 1 * https://orcid.org/0009-0001-8283-9015 Luo Chunyan BSc 1 * https://orcid.org/0000-0001-7793-6876 Zhou Si Chen MSc 1 https://orcid.org/0009-0008-8091-3809 Wang Qing BSc 1 https://orcid.org/0000-0002-5656-5364 Zou Huijing PhD 1 https://orcid.org/0000-0001-6833-6131 Liu Qian PhD 1 https://orcid.org/0000-0002-6391-5983 Fu Guanghui PhD 2 https://orcid.org/0009-0009-1762-9570 Zhai Wei ME 3 https://orcid.org/0000-0001-9570-9546 Zhao Qing PhD 3 https://orcid.org/0000-0003-1995-9249 Li Jianqiang PhD 3 https://orcid.org/0000-0003-2986-012X Wei Xinni PhD 1 https://orcid.org/0000-0002-0227-4342 Yang Bing Xiang PhD 1 4 5 1 Center for Wise Information Technology of Mental Health Nursing Research , School of Nursing, Wuhan University , No. 115, Donghu Road, Wuchang District , Wuhan , Hubei , China , +86 15902731922 2 Sorbonne Universit&#233;, Institut du Cerveau - Paris Brain Institute - ICM, CNRS, Inria, Inserm, AP-HP, H&#244;pital de la Piti&#233; Salp&#234;tri&#232;re , Paris , France 3 College of Computer Science , Beijing University of Technology , Beijing , China 4 Department of Psychiatry , Renmin Hospital of Wuhan University , Wuhan , China 5 Research Center for Lifespan Health , Wuhan University , Wuhan , China Stone Alicia Bing Xiang Yang, PhD, Center for Wise Information Technology of Mental Health Nursing Research, School of Nursing, Wuhan University, No. 115, Donghu Road, Wuchang District, Wuhan, Hubei, China, +86 15902731922 ; 00009312@whu.edu.cn * these authors contributed equally 2025 5 12 2025 27 479700 e78132 27 5 2025 06 11 2025 10 11 2025 05 12 2025 09 12 2025 09 12 2025 Copyright &#169; Nan Bai, Yijing Yu, Chunyan Luo, Si Chen Zhou, Qing Wang, Huijing Zou, Qian Liu, Guanghui Fu, Wei Zhai, Qing Zhao, Jianqiang Li, Xinni Wei, Bing Xiang Yang. Originally published in the Journal of Medical Internet Research (https://www.jmir.org) 2025 https://creativecommons.org/licenses/by/4.0/ This is an open-access article distributed under the terms of the Creative Commons Attribution License ( https://creativecommons.org/licenses/by/4.0/ ), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published in the Journal of Medical Internet Research (ISSN 1438-8871), is properly cited. The complete bibliographic information, a link to the original publication on https://www.jmir.org/ , as well as this copyright and license information must be included. Abstract Background Large language models (LLMs) are increasingly applied in health care. However, concerns remain that their nursing care recommendations may reflect patients&#8217; sociodemographic attributes rather than clinical needs. While this risk is acknowledged, there is a lack of empirical evidence evaluating sociodemographic bias in LLM-generated nursing care plans. Objective To investigate potential biases in nursing care plans generated by LLMs, we focused on whether outputs differ systematically based on patients&#8217; sociodemographic characteristics and assessed the implications for equitable nursing care. Methods We used a mixed methods simulation study. A standardized clinical vignette experiment was used to prompt GPT-4 to generate 9600 nursing care plans for 96 patient profiles with varying sociodemographic characteristics (eg, sex, age, income, education, and residence). We first conducted a quantitative analysis of all plans, assessing variations in thematic content. Subsequently, a panel of senior nursing experts evaluated the clinical quality (eg, safety, applicability, and completeness) of a stratified subsample of 500 plans. Results We analyzed 9600 LLM-generated nursing care plans and identified 8 consistent themes. Communication and Education (99.98%) and Emotional Support (99.97%) were nearly universal, while Nurse Training and Event Analysis were least frequent (39.3%). Multivariable analyses revealed systematic sociodemographic disparities. Care plans generated for low-income patient profiles were less likely to include the theme Environmental Adjustment (adjusted relative risk [aRR] 0.90). Profiles with lower education were associated with an increased likelihood of including Family Support (aRR 1.10). Similarly, plans generated for older patient profiles were more likely to contain recommendations for Pain Management (aRR 1.33) and Family Support (aRR 1.62) but were less likely to mention Nurse Training (aRR 0.78). Sex and regional differences were also significant. Expert review of 500 plans showed high overall quality (mean 4.47), with strong interrater reliability (&#954;=0.76&#8208;0.81). However, urban profiles had higher completeness ( &#946; =.22) and applicability ( &#946; =.14) but lower safety scores (&#946;=&#8211;0.09). These findings demonstrate that LLM-generated care plans exhibit systematic sociodemographic bias, raising important implications for fairness and safe deployment in nursing practice. Conclusions This study identified that LLMs systematically reproduce sociodemographic biases in the generation of nursing care plans. These biases appear in two forms: they shape the thematic content and influence expert-rated clinical quality. These findings reveal a substantial risk that such models may reinforce existing health inequities. To our knowledge, this is the first empirical evidence documenting these nuanced biases in nursing. The study also contributes a replicable framework for evaluating LLM-generated care plans. Finally, it underscores the critical need for robust human oversight to ensure that artificial intelligence serves as a tool for advancing equity rather than perpetuating disparities. Keywords sociodemographic biases large language models health care equity nursing care mixed methods study pmc-status-qastatus 0 pmc-status-live yes pmc-status-embargo no pmc-status-released yes pmc-prop-open-access yes pmc-prop-olf no pmc-prop-manuscript no pmc-prop-legally-suppressed no pmc-prop-has-pdf no pmc-prop-has-supplement yes pmc-prop-pdf-only no pmc-prop-suppress-copyright no pmc-prop-is-real-version no pmc-prop-is-scanned-article no pmc-prop-preprint no pmc-prop-in-epmc yes Introduction In recent years, large language models (LLMs) have garnered significant attention across various fields, emerging as transformative tools in sectors such as health care [ 1 ]. Over the past decade, research output focusing on LLM applications in medical and health domains has grown exponentially [ 2 ]. Advances in natural language processing and deep learning, particularly the Transformer architecture and its core self-attention mechanism [ 3 ], have enabled the increasing application of LLMs, such as ChatGPT, in clinical nursing practice. These systems support real-time triage [ 4 ], generate diagnostic recommendations [ 5 ], recommend nursing interventions [ 6 7 ], and develop health education plans [ 8 ], thereby improving nursing efficiency. The effectiveness of LLMs in clinical care has been well-documented by several studies [ 9-11 ], demonstrating their potential to improve patient outcomes and care quality. Sociodemographic factors critically influence the quality and accessibility of nursing care, with pervasive disparities documented across key demographic variables, including age, sex identity, geographic location, educational attainment, and socioeconomic status [ 2 ]. For example, labeling female patients as &#8220;demanding&#8221; or &#8220;overly sensitive&#8221; may skew symptom management decisions, resulting in disparities in care [ 12 13 ]. Similarly, ageism may influence nursing decisions, where older patients are stereotyped as &#8220;fragile&#8221; and may receive either excessive protective care or inadequate treatment due to perceptions that they are &#8220;too old to benefit significantly&#8221; [ 14 15 ]. Moreover, patients from socioeconomically disadvantaged backgrounds often face barriers to care compared to wealthier patients, exacerbating disparities in health care outcomes [ 16 ]. These documented human cognitive biases in nursing practice may be inadvertently encoded into LLMs through their training on historical clinical narratives and decision records [ 17 ]. The technical validation of LLMs in nursing has progressed rapidly. Previous studies have demonstrated superior accuracy of nurses in tracheostomy care protocol execution [ 7 ] and in generating basic mental health care plans [ 18 ]. However, the field remains predominantly focused on validating clinical competency rather than auditing algorithmic equity. Recently, a systematic review of 30 nursing LLM studies revealed that the majority of studies prioritized technical performance metrics (eg, diagnostic accuracy and response consistency), with only a small number addressing ethical risks, such as algorithmic bias [ 19 ]. This trend indicates a research landscape heavily skewed toward performance validation while largely neglecting equity auditing. Furthermore, these limited discussions on bias are primarily found in opinion pieces and reviews rather than empirical investigation [ 11 20 ]. To date, few original studies have used rigorous quantitative experimental methodologies to explore the potential biases embedded within LLM-generated nursing care plans. Although previous studies have identified algorithmic bias in other domains of medical artificial intelligence (AI), such as Convolutional Neural Network-based medical imaging analysis [ 21 22 ], traditional machine learning models (eg, support vector machines or random forests) for clinical diagnostics [ 23 ], and disease prediction [ 24 ], most have primarily focused on racial, ethnic, and sex factors. Other sociodemographic dimensions, such as education, income, and place of residence, also have a great impact on health care resource utilization [ 25-27 ]. This focus highlights a critical gap concerning the fairness of generative models such as LLMs, whose unique capacity for narrative text generation introduces distinct ethical challenges not fully addressed by research on these earlier models. Despite the need to ensure fairness has been widely recognized, serving as a cornerstone of the World Health Organization&#8217;s LLMs management framework [ 28 ], empirical fairness evaluations specific to nursing care planning remain limited, and systematic audits that include education, income, and urban-rural residence are still uncommon. While prior research has documented bias in AI diagnostics, the extent to which generative models introduce sociodemographic bias into the complex narrative of clinical care plans has remained a critical gap. To our knowledge, this study represents the first large-scale evaluation (N=9600) to use a mixed methods approach. By inputting specific prompts based on real clinical scenarios, we systematically investigated biases in both the thematic content and the expert-rated quality of LLM-generated nursing care plans. Therefore, this study aimed to systematically evaluate whether GPT-4 reproduces sociodemographic biases in nursing care plan generation and to identify how these biases manifest across linguistic and clinical dimensions. Through this mixed methods design, we sought to provide empirical evidence on the fairness, risks, and limitations of generative AI in nursing contexts, thereby informing its fair, responsible, and effective integration into future nursing practice. Methods Study Design This study used a sequential explanatory mixed methods design to investigate sociodemographic bias in LLM-generated nursing care plans. First, a quantitative analysis was conducted to assess whether the thematic content of care plans varied by patient sociodemographic factors. Subsequently, a qualitative assessment was used to explain these findings, wherein a panel of nursing experts rated a subsample of plans on their clinical quality. Our study integrated 2 distinct research methods. The primary goal was to identify potential biases in the presence or absence of specific care themes. Beyond this, we aimed to understand if the clinical quality of the provided care also differed systematically across demographic groups. Clinical Scenario Design and Experiment Setup Selection of Clinical Scenario and Methodological Rationale This study used a standardized clinical vignette experiment, an established methodology in behavioral and health care research. To be clear, we did not use real patient charts or identifiable data from any hospital. Our scenario was a standardized tool designed for rigorous experimental control, not a case report of an individual patient. We chose this established method for 2 core reasons. First, it ensures scientific rigor by eliminating the confounding variables found in unique patient cases. This allows us to isolate the effects of the manipulated sociodemographic variables. Second, the method upholds strict ethical standards by avoiding the use of any protected health information. Our vignette depicts a cardiac patient becoming agitated after multiple failed attempts at IV insertion. This scenario design parallels the approach of prior research, such as Guo and Zhang (2021) [ 29 ], which used a similar common clinical conflict to investigate bias in doctor-patient relationships. It was then reviewed and validated by our panel of senior nursing experts to ensure its clinical realism. This experimental paradigm is a standard and accepted method for investigating attitudes and biases in behavioral sciences and health care research [ 30 ]. Patient Demographics This study examines potential biases in LLM-generated nursing care plans related to key patient sociodemographic characteristics, including sex, age, residence, educational attainment, and income. These are widely recognized as social determinants of health that directly influence nursing care delivery and patient outcomes [ 31 ]. As these factors have long shaped traditional nursing practice, it is reasonable to anticipate that they may similarly affect the recommendations generated by LLMs. Sex (male vs female) may impact both the emotional tone and the clinical content of nursing care plans, as previous research indicates that health care providers may unconsciously manage similar symptoms differently depending on the patient&#8217;s sex. Specifically, female patients are more likely to be recommended psychological support, whereas male patients may receive more pharmacological or technical interventions under similar clinical scenarios [ 32 ]. Age (categorized as youth, middle-aged, older middle-aged, and elderly) is a critical factor affecting nursing care needs. We defined youth as 18 to 29 years, middle-aged as 30 to 49 years, older middle-aged as 50 to 64 years, and elderly as &#8805;65 years [ 33 ]. Older patients often require more complex, chronic condition management and personalized interventions [ 34 ]. Residence (urban vs rural) is another significant variable, as patients in rural areas often face limited access to health care resources compared to their urban counterparts [ 35 ]. Income level (categorized as high, middle, or low) plays a critical role in determining both the accessibility of health care services and the complexity of care provided. Specifically, low income was defined as falling below the 25th percentile of the sample distribution, middle income between the 25th and 75th percentiles, and high income above the 75th percentile. Patients with lower income may be more likely to receive standardized care that overlooks individual needs or preferences [ 36 ]. Educational background (higher education vs lower education) influences a patient&#8217;s understanding of care instructions and their level of engagement with the health care process. In this study, higher education was defined as holding a bachelor&#8217;s degree or above, whereas lower education referred to individuals with less than a bachelor&#8217;s degree. Patients with higher education may be more proactive in managing their care, whereas those with lower education may require more guidance and support [ 37 ]. AI Model and Experimental Tools This study used GPT-4 to generate nursing care plans through the Azure OpenAI API, a widely accessible and cost-effective platform that is freely available for use, making it easier for health care providers to adopt in clinical practice. A temperature parameter of 0.7 was set to balance creativity and stability in the generated content, ensuring moderate randomness without compromising quality or consistency [ 38 ]. Experimental Procedure Patient Profile Input The LLMs received a patient profile that includes the following key demographic characteristics: age, sex, income level, educational background, and residence, along with a detailed clinical scenario. For example, 1 prompt describes a 28-year-old male cardiac patient, a high-income earner with a bachelor&#8217;s degree residing in an urban area, who requires an intravenous infusion. During the procedure, the nurse was unable to locate the vein, resulting in a failed puncture attempt. The patient subsequently became emotionally distressed and verbally insulted the nurse. The full text of the clinical vignette, the base prompt template, and a detailed table of all variable substitution rules are provided in Multimedia Appendix 1 . AI Model Prompt For each combination of patient profile, the LLMs generated a nursing care plan in response to a structured prompt. The prompt instructed the model to provide an appropriate nursing care plan based on the described clinical scenario. Figure 1 illustrates the workflow for LLM-based nursing care plan generation, outlining the process from patient data input to care plan output. All 9600 nursing care plans were generated via the API between August 29 and August 30, 2025. Figure 1. Flowchart of the LLM-generated nursing care plan generation process. LLM: large language model. Prompt Design and Standardization To minimize output variability arising from prompt phrasing and inherent model randomness [ 39 ] and thereby isolate the effect of sociodemographic factors, we implemented a rigorous standardization protocol. This protocol involved three key strategies: (1) using a single, consistent clinical vignette for all tests; (2) using a uniform prompt structure across all tests; and (3) performing 100 repeated queries for each of the 96 unique patient profiles to account for natural fluctuations in the model&#8217;s output. Repetition and Testing For each clinical scenario, we designed multiple prompts to reflect all unique combinations of patients&#8217; identity characteristics. Consequently, it contained 96 unique combinations (2&#215;4 &#215; 2&#215;3 &#215; 2), derived from sex (2 levels), age (4 levels), residence (2 levels), income level (3 levels), and educational background (2 levels). To reduce potential bias from prompt phrasing, each combination was tested 100 times, yielding a total of 9600 prompt-based care plan generations. Data Collection and Analysis Thematic Analysis and Framework Development We analyzed data using thematic analysis, following Braun and Clarke&#8217;s approach [ 40 ]. In the first stage, 2 trained qualitative researchers independently reviewed approximately 1000 LLM-generated nursing care plans. This initial review continued until thematic saturation was reached. They conducted line-by-line inductive coding during this stage and read these care plans repeatedly to get familiar with the data. Initial codes were generated independently and then reconciled through consensus discussions. Using constant comparison, conceptually similar codes were organized into candidate themes and iteratively reviewed for coherence with the corpus and key excerpts, with refinement by splitting, merging, or renaming as needed. This process yielded a finalized codebook consisting of 8 recurrent themes. In the second stage, using the finalized codebook, the same 2 researchers manually coded all 9600 care plans in the corpus. Both researchers coded each plan for the presence of each predefined theme, recording a binary indicator (1=present and 0=absent). Coding consistency was ensured through regular consensus meetings; any discrepancies were resolved by discussion until agreement was reached. An audit trail of analytic notes and coding decisions was maintained to support transparency. These binary indicators were subsequently used in the quantitative analyses (see Multimedia Appendix 2 for the detailed coding manual). Analysis of Thematic Distribution and Associated Factors All statistical analyses were performed in Python (version 3.12). Every statistical test was 2-sided, and a P value ( q value) adjusted for the False Discovery Rate of less than .05 was considered significant. Descriptive statistics were used to summarize the data. Categorical variables were reported as frequencies and percentages, and the prevalence of each theme was calculated with 95% CIs via the Clopper-Pearson exact method. We first explored the associations between demographic characteristics and theme occurrence using the Chi-square or Fisher exact test. We then calculated Cramer V to measure the strength of these associations and applied the Benjamini-Hochberg procedure to the resulting P values to control for multiple comparisons. To delineate the independent predictors for each theme, we constructed multivariable regression models. Our primary strategy was logistic regression, yielding adjusted odds ratios and 95% CIs. For any models that failed to converge, we used modified Poisson regression with robust SEs to obtain adjusted relative risks (aRRs). Finally, all P values from the model coefficients were adjusted using the Benjamini-Hochberg method, and the key findings were visualized in forest plots. Expert Assessment of Quality and Bias Analysis Overview Following the quantitative thematic analysis, we conducted a qualitative expert review to explain and add clinical depth to the observed patterns. A sample size of 500 was determined a priori through a power analysis to ensure sufficient statistical power for the subsequent multivariable regression models. To ensure this subsample was representative and unbiased, we used a stratified random sampling strategy. We stratified the full sample of 9600 plans by the 96 unique sociodemographic profiles and then randomly selected approximately 5 plans from each stratum. The expert review was conducted at Renmin Hospital of Wuhan University. The panel consisted of 2 independent registered nurses from the Department of Cardiology, each with more than 15 years of direct inpatient cardiovascular nursing experience. Panel members were identified by the nursing director and recruited via departmental email. Participation was entirely voluntary, and no financial compensation was provided. Each plan was rated on a 5-point Likert scale (1=very poor to 5=excellent) across three core dimensions derived from established quality frameworks: safety, clinical applicability, and completeness. These dimensions were adapted from the Institute of Medicine&#8217;s established framework for health care quality [ 41 ]. To ensure a standardized assessment, a comprehensive rating manual containing detailed operational definitions and anchored scale descriptors was developed. Furthermore, the panel completed a formal calibration exercise before the main review to ensure a shared understanding of the criteria (see Multimedia Appendix 3 ). Data Analysis Interrater reliability of the initial, independent ratings was quantified using two complementary metrics: the intraclass correlation coefficient (ICC) and the quadratically weighted kappa coefficient (&#954;). We used a 2-way random effects model for absolute agreement to calculate the single-rater ICC (ICC [2,1]) [ 42 ]. On the basis of the established benchmarks, reliability values between 0.61 and 0.80 are interpreted as &#8216;substantial&#8217; agreement, whereas values from 0.81 to 1.00 represent &#8216;near-perfect&#8217; agreement [ 43 ]. After confirming reliability, a final quality score was determined for each case: for cases with a major disagreement (a rating difference of &#8805;2 points), a third senior expert adjudicated to assign a consensus score; for all other cases, the mean of the 2 experts&#8217; scores was used. These final scores then served as the continuous dependent variables in a series of multivariable linear regression models, which assessed the independent association between patient demographic characteristics and expert-assigned quality. Ethical Considerations The standardized clinical vignette used in this study is a synthetic material, constructed by the authors for this research. The Biomedical Institutional Review Board of Wuhan University reviewed the project and determined that it does not constitute human subjects; therefore, formal institutional review board approval and informed consent were not required. Results Descriptive Characteristics of the Sample and Themes A total of 9600 nursing care plans generated by the LLM were included in the analysis. The sociodemographic characteristics of the corresponding patient profiles are detailed in Table 1 . Regarding the thematic content, 8 consistent nursing themes were identified across these outputs. Communication and Education and Emotional Support and Stress Management were nearly universal, appearing in 99.98% (95% CI 99.92%&#8208;100%) and 99.97% (95% CI 99.91%&#8208;99.99%) of cases. Other highly frequent themes included Technical Support and IV Management (91.69%) and Safety Management with Risk Control (89.31%). In contrast, Family Support (72.81%), Environmental Adjustment (68.42%), and Pain and Medication Management (47.85%) appeared less frequently. The least common theme was Nurse Training and Event Analysis, which was present in only 39.32% (95% CI 38.34%&#8208;40.31%). The overall distribution of nursing themes is summarized in Tables1 2 and visualized in Figure 2 . Table 1. Sociodemographic characteristics of the sample (N=9600). Variable and grouping Sample size, n (%) Sex (female) 4800 (50) Age &#8195;Youth 2400 (25) &#8195;Middle-aged 2400 (25) &#8195;Older middle-aged 2400 (25) &#8195;Elderly 2400 (25) Residence &#8195;Rural 4800 (50) &#8195;Urban 4800 (50) Education &#8195;Lower education 4800 (50) &#8195;Higher education 4800 (50) Income &#8195;Low income 3200 (33.33) &#8195;Middle income 3200 (33.33) &#8195;High income 3200 (33.33) Table 2. Overall prevalence of nursing care themes (N=9600). Theme Occurrence (n) Sample size (n) Rate (%) 95% CI Communication and Education 9598 9600 99.98 99.92-100 Emotional Support and Stress Management 9597 9600 99.97 99.91-99.99 Technical Support and IV Management 8802 9600 91.69 91.12-92.23 Safety Management with Risk Control 8574 9600 89.31 88.68-89.92 Family Support 6990 9600 72.81 71.91-73.70 Environmental Adjustment 6568 9600 68.42 67.48&#8208;69.35 Pain and Medication Management 4594 9600 47.85 46.85-48.86 Nurse Training and Event Analysis 3775 9600 39.32 38.34-40.31 Figure 2. Overall distribution of nursing themes across 9600 outputs. Note: The 95% CIs for the &#8216;communication and education&#8217; (99.92%&#8208;100%) and 'Emotional Support and Stress Management&#8217; (99.91%&#8208;99.99%) themes are very narrow due to their high occurrence rates and may not be fully visible in the chart. Associations Between Demographics and Thematic Content Univariate Analysis of Thematic Distribution The univariate associations between sociodemographic characteristics and the prevalence of the 8 nursing themes are detailed in Table S1 in Multimedia Appendix 4 . The analysis revealed that several themes were linked to a wide array of demographic factors. For instance, Safety Management with Risk Control was significantly associated with all 5 tested factors: sex, age group, geographic region, and income level (all q &lt;0.001), as well as educational attainment ( q =0.002). Specifically, male profiles showed a higher prevalence of Safety Management with Risk Control compared to female profiles (Cramer V=0.15, q &lt;0.001). Low-income profiles exhibited a lower prevalence of safety management compared to middle-income and high-income profiles (Cramer V=0.08, q &lt;0.001). A similar pattern of widespread association was observed for Technical Support and IV Management, which was significantly linked to sex, age group, region, and income level (all q &lt;0.001), in addition to education ( q =0.030). Multivariable Analysis of Factors Associated With Theme Presence Our multivariable analysis adjusted for all sociodemographic factors. The results revealed systematic and complex patterns of bias in the LLM&#8217;s outputs ( Figure 3 and Table S2 in Multimedia Appendix 4 ). Several nursing themes showed strong sensitivity to socioeconomic and demographic characteristics. These findings highlighted a clear disparity. Figure 3. Forest plots of multivariable analysis for factors associated with thematic presence. Income level was an important source of disparity in the generated content. Care plans generated for low-income profiles were significantly less likely to include the theme of Environmental Adjustment (aRR 0.90, 95% CI 0.87-0.93; q &lt;0.001) compared to high-income profiles. Educational attainment was also associated with systematic differences. Plans generated for profiles with lower educational attainment were more likely to include Family Support (aRR 1.10, 95% CI 1.08-1.13; q &lt;0.001). Patient age was also a strong predictor of thematic content. Care plans generated for older age groups were more likely to include themes focused on direct patient care. For elderly profiles, generated plans were significantly more likely to contain Pain and Medication Management (aRR 1.33, 95% CI 1.26-1.41; q &lt;0.001) and Family Support (aRR 1.62, 95% CI 1.56-1.68; q &lt;0.001). Conversely, plans for these same elderly profiles were less likely to include themes related to care processes, such as Nurse Training (aRR 0.78, 95% CI 0.73-0.84; q &lt;0.001). Sex was a significant predictor. Care plans generated for female profiles had a higher likelihood of including Environmental Adjustment (aRR 1.14, 95% CI 1.11-1.17; q &lt;0.001), these same profiles were linked to a lower likelihood of including Safety Management (aRR 0.90, 95% CI 0.89-0.91; q &lt;0.001) and Nurse Training (aRR 0.86, 95% CI 0.82-0.90; q &lt;0.001). The geographic region also showed independent effects. Care plans generated for rural profiles were more likely to include Family Support (aRR 1.23, 95% CI 1.20-1.26; q &lt;0.001). In contrast, these plans were less likely to mention Nurse Training (aRR 0.78, 95% CI 0.74-0.82; q &lt;0.001). Finally, the themes of Communication and Education and Emotional Support and Stress Management showed no significant independent associations with any tested demographic factor after adjustment. Expert Assessment of Care Plan Quality Subsample Characteristics and Overall Quality Scores The stratified subsample selected for expert review comprised 500 nursing care plans. The sociodemographic profile of this subsample is detailed in Table S3 in Multimedia Appendix 4 . The distribution was nearly balanced for sex (female: n=247, 49.4%) and education ( lower education: n=248, 49.6%). Age groups were also almost equally represented, spanning youth (n=124), middle-aged (n=125), older middle-aged (n=125), and the elderly (n=126). There was a slight majority of urban profiles (n=260, 52.0%), and the 3 income tiers were comparable in size. The descriptive statistics for the expert-assigned quality scores are presented in Table S3 in Multimedia Appendix 4 . The overall mean quality score across all dimensions was 4.47 (SD 0.26). Among the 3 dimensions, Safety received the highest average rating (mean 4.55, SD 0.47), followed by Completeness (mean 4.49, SD 0.48) and Clinical Applicability (mean 4.37, SD 0.46). Normality tests confirmed that the distributions of all 4 score metrics significantly deviated from a normal distribution ( P &lt;.001 for all). To aid interpretation of the expert-rated scores, we provide illustrative excerpts in Multimedia Appendix 5 . These include deidentified examples of care plan text that received high versus low ratings for each of the 3 expert-rated dimensions (safety, clinical applicability, and completeness). All excerpts were lightly edited for brevity. Interrater Reliability The interrater reliability for the quality assessment was confirmed to be robust. The quadratically weighted kappa (&#954;) values indicated substantial to near-perfect agreement, with a &#954; of 0.81 (95% CI 0.762&#8208;0.867) for Completeness, 0.773 (95% CI 0.704&#8208;0.831) for Clinical Applicability, and 0.761 (95% CI 0.704&#8208;0.813) for Safety. This high level of consistency was further supported by the single-rater ICC [1,2], which showed a highly similar pattern of reliability (Completeness: 0.817, Applicability: 0.773, and Safety: 0.762). Such robust agreement provided a strong justification for using the mean of the 2 expert ratings in subsequent analyses. Associations Between Demographics and Quality Scores To identify independent predictors of care plan quality, we constructed a series of multivariable linear regression models. After adjusting for all sociodemographic factors, several characteristics emerged as significant predictors for different quality dimensions ( Table 3 ). In these models, &#946; coefficients represent the unstandardized mean difference in expert-rated scores between each subgroup and its reference category, adjusting for all other covariates. For example, a &#946; of .22 for urban versus rural in the Completeness model indicates that care plans for urban profiles received, on average, 0.22 points higher completeness scores (on the 5-point scale) than those for rural profiles. Table 3. Multivariable linear regression models of factors associated with expert-rated quality scores. Notes: &#946; represents unstandardized regression coefficients estimated using ordinary least squares (OLS) regression with robust SEs. Reference categories were female for sex, middle aged for age group, rural for region, low education for education, and middle income for income level. Predictor Completeness, &#946; (95% CI) Clinical applicability, &#946; (95% CI) Safety, &#946; (95% CI) Sex &#8195;Male versus female (Ref. a ) 0.05 (&#8722;0.02 to 0.13) &#8722;0.02 (&#8722;0.10 to 0.05) 0.34 (0.26 to 0.42) b Age group &#8195;Young adult versus middle aged (Ref.) &#8722;0.09 (&#8722;0.20 to 0.02) &#8722;0.12 (&#8722;0.23 to 0.01) b 0.09 (&#8722;0.02 to 0.20) &#8195;Older middle aged versus middle aged (Ref.) 0.00 (&#8722;0.11 to 0.12) &#8722;0.02 (&#8722;0.14 to 0.09) &#8722;0.03 (&#8722;0.14 to 0.08) &#8195;Elderly versus middle-aged (Ref) 0.10 (&#8722;0.01 to 0.21) &#8722;0.09 (&#8722;0.20 to 0.02) &#8722;0.03 (&#8722;0.14 to 0.08) Region &#8195;Urban versus rural (Ref.) 0.22 (0.14 to 0.30) b 0.14 (0.07 to 0.22) b &#8722;0.09 (&#8722;0.17 to 0.01) b Education &#8195;High education versus low (Ref.) &#8722;0.07 (&#8722;0.15 to 0.01) &#8722;0.03 (&#8722;0.11 to 0.05) &#8722;0.02 (&#8722;0.10 to 0.06) Income level &#8195;Low income versus middle (Ref.) 0.33 (0.23 to 0.43) b 0.18 (0.08 to 0.28) b &#8722;0.02 (&#8722;0.12 to 0.07) &#8195;High income versus middle (Ref.) 0.01 (&#8722;0.08 to 0.11) &#8722;0.04 (0.13 to 0.06) &#8722;0.02 (&#8722;0.11 to 0.07) a Ref.: reference. b * P &lt;.05. The Completeness of care plans was the most strongly affected dimension. It was significantly higher in plans for urban profiles compared to rural ones ( &#946; =.22, 95% CI 0.14-0.30; P &lt;.001). Additionally, low-income profiles were associated with significantly higher Completeness scores compared to the middle-income reference group ( &#946; =.33, 95% CI 0.23-0.43; P &lt;.001). For Clinical Applicability, urban residence ( &#946; =.14, 95% CI 0.07-0.22; P =.001) and low-income status ( &#946; =.18, 95% CI 0.08-0.28; P =.002) were also predictors of higher scores. Furthermore, plans for youth (18&#8208;29 y) received significantly lower Applicability scores compared to the middle-aged reference group ( &#946; =&#8722;.12, 95% CI &#8722;0.23 to &#8722;0.01; P =.05). Finally, the safety of care plans was significantly associated with two factors. Plans for male profiles received significantly higher scores than those for female profiles ( &#946; =.34, 95% CI 0.26-0.42; P &lt;.001). In contrast, plans for urban profiles were associated with significantly lower Safety scores ( &#946; =&#8722;.09, 95% CI &#8722;0.17 to &#8722;0.01; P =.048). No significant associations were found for educational attainment in any of the final models. Throughout this evaluation process, the expert reviewers confirmed that the generated content was clinically relevant to the scenario, with no observed significant AI hallucinations. Discussion Principal Findings This study investigated sociodemographic bias in nursing care plans generated by GPT-4. This is a critical area of inquiry, as AI-generated care plans impact patient safety and health equity. While bias in AI-driven diagnostics is well documented, the fairness of generative models in complex clinical narratives remains underexplored. Using a novel mixed methods approach, we found that GPT-4 may reflect underlying societal patterns present in its training data, which can influence both the thematic content and expert-rated clinical quality of care plans. Rather than rejecting the use of AI in health care, our findings underscore the importance of responsible deployment and expert oversight. Our findings reveal a dual form of bias. First, the model allocated core nursing themes inequitably across different demographic profiles. Second, we found a paradoxical pattern. Plans for socially advantaged groups were rated by experts as significantly lower in clinical safety. With transparent evaluation and human guidance, such models can become valuable tools that enhance clinical efficiency and equity, rather than inadvertently reinforcing disparities. Thematic analysis revealed the first layer of bias through the inequitable allocation of core nursing themes. This disparity was most pronounced along socioeconomic lines, as low-income profiles had a significantly lower likelihood of including crucial themes such as Family Support and Environmental Adjustment. This pattern of underrepresentation extended to other characteristics, with female profiles receiving less content on Safety Management. These patterns are unlikely to be a random artifact. They reflect a digital reproduction of structural inequities learned from the model&#8217;s training data. This raises a critical concern. If deployed uncritically, this LLM may perpetuate a cycle of underresourced care for already vulnerable populations. While novel in the context of nursing care generation, our findings align with a substantial body of evidence on algorithmic bias. For example, prior work has established lower diagnostic accuracy on chest X-rays for minority populations [ 44 45 ]. In clinical NLP, models have replicated sexed language, describing female patients with more emotional terms and male patients with technical ones [ 46 ]. Predictive algorithms have also systematically underestimated health care costs for low-income patients due to historical underresourcing [ 47 ]. Our findings demonstrate that LLMs embed these disparities directly into patient care recommendations, thereby extending concerns about algorithmic bias to the domain of generative clinical narratives. The expert quality review added a deeper and more complex layer to our findings. It revealed that the biases are not limited to the presence or absence of themes but extend to the clinical quality of the generated text itself. Our analysis of the expert scores uncovered a series of counterintuitive patterns. For example, while care plans for urban profiles were often thematically richer, experts rated them as significantly lower in terms of Safety. Most strikingly, profiles with low income, which received fewer thematic mentions in the initial analysis, paradoxically received substantially higher quality scores for both Clinical Applicability and Completeness. A possible explanation for the inverse relationship between thematic quantity and perceived quality involves the LLM&#8217;s use of different generative heuristics. Such heuristics can cause AI models to internalize and apply societal stereotypes, as documented in prior literature [ 48 49 ]. Our findings suggest the model applied different approaches to different profiles. For socially advantaged profiles (eg, urban, higher income), it tended to generate thematically dense plans. The increased complexity of these plans may introduce more potential for error, a known principle in safety science [ 50 ]. This could explain their lower expert-rated safety scores. Conversely, for socially disadvantaged profiles (eg, low income), the model appeared to generate shorter and more prescriptive plans. This output style is strikingly analogous to what medical sociology terms paternalistic communication. This communication pattern is characterized by providing direct, simplified instructions while omitting complex rationales or shared decision-making options, often based on an implicit assumption about the patient&#8217;s lower health literacy or agency [ 51 ]. The model&#8217;s tendency to produce a focused but less explanatory plan for these groups could be an algorithmic manifestation of this paternalistic pattern. The focused nature of these less complex plans may be why experts rated them higher on Clinical Applicability and Completeness. The direct clinical implication of our findings is that current-generation LLMs such as GPT-4 are not yet suitable for fully autonomous use in generating nursing care plans [ 52 ]. Our results demonstrate that deploying these models without a robust human-in-the-loop review process could introduce significant risks [ 53 ]. Specifically, it may lead to the provision of care that is systematically biased [ 54 ], either through the omission of key nursing themes or through qualitatively substandard recommendations for certain patient groups. This means that algorithmic fairness is not just a technical problem for computer scientists. It is a fundamental issue of patient safety. If AI is to be used safely in health care, fairness should not be an afterthought. It should be a core, required metric in the design, testing, and monitoring of these systems. This study also contributes a methodological framework for auditing generative AI in health care. We propose a dual-assessment framework that combines quantitative thematic analysis with expert-rated clinical quality. Compared with conventional text similarity or automated metrics, this framework enables a more comprehensive and clinically relevant assessment of model performance. Importantly, it accounts for the variable quality of generative outputs, which may differ in completeness, applicability, and safety, rather than conforming to a simple correct or incorrect dichotomy. Our findings identify several priority areas for future investigation. First, it is essential to apply the proposed dual-assessment framework to other state-of-the-art LLMs (eg, Claude, Llama) to evaluate the generalizability of the observed bias patterns. Second, validating these results with real-world clinical data represents a critical step toward establishing their practical relevance. Third, future research should systematically compare LLM-generated biases with well-documented human biases to determine whether these systems primarily reproduce existing disparities or instead exacerbate them. Finally, subsequent work should focus on the design and empirical testing of both technical and educational interventions aimed at mitigating the biases identified in this study. Strengths and Limitations This study offers notable strengths. Its primary strength is the novel mixed methods design, which combines a large-scale quantitative analysis (n=9600) with a rigorous, expert-led quality assessment (n=500). This dual-assessment framework provides a more holistic view of AI-generated bias than relying on simplistic text-based metrics alone. The use of a state-of-the-art model (GPT-4) and a robust expert review process with prespecified reliability criteria further enhances the relevance and validity of our findings. However, we must acknowledge several limitations. First, the analysis was conducted in a simulation setting rather than actual patient encounters, which may limit ecological validity and fail to capture the full complexity of real clinical decision-making. Second, our study focused on 5 specific sociodemographic factors and did not include other critical dimensions, such as race, ethnicity, or disability status, which are well-documented sources of health disparities. Third, our evaluation was restricted to one primary model (GPT-4); findings may not generalize to other emerging LLMs. Fourth, our study was based on a single, specific clinical scenario; patterns of bias may manifest differently in other types of clinical contexts, such as chronic disease management, end-of-life care, or psychiatric nursing. Examining these contexts represents an important direction for future research. Finally, although expert ratings provide valuable insights, they are inherently subjective. Future work should incorporate multisite, multidisciplinary validation as well as objective patient outcome data. Conclusions Our research demonstrates that a state-of-the-art LLM systematically reproduces complex sociodemographic biases when generating nursing care plans. These biases manifest not only in the thematic content but also, paradoxically, in the expert-rated clinical quality of the outputs. This finding challenges the view of LLMs as neutral tools. It highlights a significant risk. Without critical oversight, these technologies could perpetuate, and perhaps even exacerbate, existing health inequities. Therefore, we should ensure clinical AI serves as an instrument of equity, not a magnifier of disparity. Our findings underscore the essential need for a new evaluation paradigm. This new approach should be multifaceted, continuous, and deeply integrated with the principles of clinical quality and fairness. Supplementary material 10.2196/78132 Multimedia Appendix 1 Experimental design and prompt materials. 10.2196/78132 Multimedia Appendix 2 Thematic analysis coding manual. 10.2196/78132 Multimedia Appendix 3 Expert rating manual. 10.2196/78132 Multimedia Appendix 4 Univariate and multivariate analyses. 10.2196/78132 Multimedia Appendix 5 Illustrative examples of expert ratings. Acknowledgments The authors declare the use of generative artificial intelligence tools during manuscript preparation. According to the GAIDeT taxonomy (2025), the task delegated to generative artificial intelligence under full human supervision was language editing (polishing). The tool used was GPT-5.0. Responsibility for the final content lies entirely with the authors. GAI tools are not listed as authors and do not bear responsibility for the final outcomes. Funding: This study was supported by the National Natural Science Foundation of China (grant 72474166). Data Availability: The datasets generated or analyzed during this study are available from the corresponding author on reasonable request. Authors&#8217; Contributions: Data curation, investigation: NB, YY, CL, SCZ, QW, and HZ Formal analysis, software, methodology, visualization: NB, QL, GF, WZ, QZ, and JL Project administration: XW and BXY Funding acquisition: BXY Supervision: XW and BXY Writing and original draft preparation: all authors XW and BXY contributed equally as the corresponding authors of this manuscript Conflicts of Interest: None declared. Abbreviations AI artificial intelligence aRR adjusted relative risk ICC intraclass correlation coefficient LLM large language model References 1. Reddy S Generative AI in healthcare: an implementation science informed translational path on application, integration and governance Implement Sci Mar 15 2024 19 1 27 doi 10.1186/s13012-024-01357-9 Medline 38491544 PMC10941464 2. von Gerich H Moen H Block LJ et al Artificial Intelligence-based technologies in nursing: a scoping literature review of the evidence Int J Nurs Stud Mar 2022 127 104153 doi 10.1016/j.ijnurstu.2021.104153 Medline 35092870 3. Vaswani A Shazeer N Parmar N et al Attention is all you need Adv Neural Inf Process Syst 2017 URL https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html Accessed 01-10-2025 4. Zaboli A Brigo F Sibilio S Mian M Turcato G Human intelligence versus Chat-GPT: who performs better in correctly classifying patients in triage? Am J Emerg Med 05 2024 79 44 47 doi 10.1016/j.ajem.2024.02.008 Medline 38341993 5. Luo S Canavese F Aroojis A et al Are generative pretrained transformer 4 responses to developmental dysplasia of the hip clinical scenarios universal? An international review J Pediatr Orthop 07 1 2024 44 6 e504 e511 doi 10.1097/BPO.0000000000002682 Medline 38597198 6. Karacan E Evaluating the quality of postpartum hemorrhage nursing care plans generated by artificial intelligence models J Nurs Care Qual 2024 39 3 206 211 doi 10.1097/NCQ.0000000000000766 Medline 38701406 7. Wang T Mu J Chen J Lin CC Comparing ChatGPT and clinical nurses&#8217; performances on tracheostomy care: a cross-sectional study Int J Nurs Stud Adv Jun 2024 6 100181 doi 10.1016/j.ijnsa.2024.100181 Medline 38746816 PMC11080343 8. Luo Y Miao Y Zhao Y et al Comparing the accuracy of two generated large language models in identifying health-related rumors or misconceptions and the applicability in health science popularization: proof-of-concept study JMIR Form Res Dec 2 2024 8 e63188 doi 10.2196/63188 Medline 39622076 PMC11627524 9. Han KD Jaafar MA Moin KA Hoopes PC Moshirfar M Assessing the role of artificial intelligence in the creation of patient educational videos for corneal refractive surgery Cureus Oct 2024 16 10 e71447 doi 10.7759/cureus.71447 Medline 39539900 PMC11559605 10. Moura L Jones DT Sheikh IS et al Implications of large language models for quality and efficiency of neurologic care Neurology (ECronicon) Jun 11 2024 102 11 e209497 doi 10.1212/WNL.0000000000209497 38759131 11. Nashwan AJ Abujaber AA Harnessing large language models in nursing care planning: opportunities, challenges, and ethical considerations Cureus Jun 2023 15 6 e40542 doi 10.7759/cureus.40542 37465807 PMC10350541 12. Naamany E Reis D Zuker-Herman R Drescher M Glezerman M Shiber S Is there gender discrimination in acute renal colic pain management? A retrospective analysis in an emergency department setting Pain Manag Nurs Dec 2019 20 6 633 638 doi 10.1016/j.pmn.2019.03.004 Medline 31175043 13. Shoqirat N Mahasneh D Singh C Al Hadid L Do surgical patients&#8217; characteristics and behaviours affect nurses&#8217; pain management decisions? A qualitative inquiry Int J Nurs Pract Dec 2019 25 6 e12779 doi 10.1111/ijn.12779 Medline 31496014 14. Allu&#233;-Sierra L Ant&#243;n-Solanas I Rodr&#237;guez-Roca B et al Ageism and nursing students, past or reality?: a systematic review Nurse Educ Today Mar 2023 122 105739 doi 10.1016/j.nedt.2023.105739 Medline 36731247 15. Henry JD Coundouris SP Nangle MR Breaking the links between ageism and health: an integrated perspective Ageing Res Rev Mar 2024 95 102212 doi 10.1016/j.arr.2024.102212 Medline 38307423 16. Dickman SL Himmelstein DU Woolhandler S Inequality and the health-care system in the USA The Lancet Apr 2017 389 10077 1431 1441 doi 10.1016/S0140-6736(17)30398-7 28402825 17. Tran L Kandel H Sari D Chiu CH Watson SL Artificial intelligence and ophthalmic clinical registries Am J Ophthalmol Dec 2024 268 263 274 doi 10.1016/j.ajo.2024.07.039 Medline 39111520 18. Woodnutt S Allen C Snowden J et al Could artificial intelligence write mental health nursing care plans? J Psychiatr Ment Health Nurs Feb 2024 31 1 79 86 doi 10.1111/jpm.12965 Medline 37538021 19. Hobensack M von Gerich H Vyas P et al A rapid review on current and potential uses of large language models in nursing Int J Nurs Stud Jun 2024 154 104753 doi 10.1016/j.ijnurstu.2024.104753 Medline 38560958 20. McGrow K Artificial intelligence: essentials for nursing Nursing (Lond) Sep 2019 49 9 46 49 doi 10.1097/01.NURSE.0000577716.57052.8d PMC6716553 31365455 21. Glocker B Jones C Bernhardt M Winzeck S Algorithmic encoding of protected characteristics in chest X-ray disease detection models EBioMedicine Mar 2023 89 104467 doi 10.1016/j.ebiom.2023.104467 Medline 36791660 PMC10025760 22. Zhang H Dullerud N Roth K Oakden-Rayner L Pfohl SR Ghassemi M Improving the fairness of chest x-ray classifiers arXiv Preprint posted online on Mar 23 2022 doi 10.48550/arXiv.2203.12609 23. Raizman E Peng Y Deng A Towards equitable diagnosis: bias evaluation and mitigation in skin cancer classification Presented at 2024 IEEE Conference on Computational Intelligence in Bioinformatics and Computational Biology (CIBCB) Aug 27-29, 2024 IEEE 1 9 Natal, Brazil doi 10.1109/CIBCB58642.2024.10702173 24. Pennington J Rasnick E Martin LJ et al Racial fairness in precision medicine: pediatric asthma prediction algorithms Am J Health Promot Feb 2023 37 2 239 242 doi 10.1177/08901171221121639 Medline 35973209 25. Kachmar AG Watson RS Wypij D Perry MA Curley MAQ Randomized Evaluation of Sedation Titration for Respiratory Failure (RESTORE) Investigative Team Association of socioeconomic status with postdischarge pediatric resource use and quality of life Crit Care Med Feb 1 2022 50 2 e117 e128 doi 10.1097/CCM.0000000000005261 Medline 34495879 PMC8810731 26. Li SS Schuldt R Zafar F et al Effects of socioeconomic status and healthcare resource availability on survival in older (&#8805;66 years) non-Hispanic Black patients versus non-Hispanic White patients with multiple myeloma Clin Lymphoma Myeloma Leuk Apr 2025 25 4 285 292 doi 10.1016/j.clml.2024.11.011 Medline 39694783 27. Tang Y Fu R Noguchi H Impact of medical insurance integration on reducing urban-rural health disparity: evidence from China Soc Sci Med Sep 2024 357 117163 doi 10.1016/j.socscimed.2024.117163 Medline 39121565 28. DeCamp M Lindvall C Mitigating bias in AI at the point of care Science 07 14 2023 381 6654 150 152 doi 10.1126/science.adh2713 Medline 37440631 PMC10680368 29. Guo ZS Zhang SW Does &#8220;discrimination&#8221; exist in the doctor-patient relationship? An experimental investigation on &#8220;behavior&#8221; J Guangxi Norm Univ 2021 57 5 32 44 doi 10.16088/j.issn.1001-6597.2021.05.003 30. FitzGerald C Hurst S Implicit bias in healthcare professionals: a systematic review BMC Med Ethics Mar 1 2017 18 1 19 doi 10.1186/s12910-017-0179-8 Medline 28249596 PMC5333436 31. Marmot M Friel S Bell R Houweling TAJ Taylor S Closing the gap in a generation: health equity through action on the social determinants of health The Lancet Nov 2008 372 9650 1661 1669 doi 10.1016/S0140-6736(08)61690-6 18994664 32. Hamberg K Risberg G Johansson EE Westman G Gender bias in physicians&#8217; management of neck pain: a study of the answers in a swedish national examination J Womens Health Gend Based Med Sep 2002 11 7 653 666 doi 10.1089/152460902760360595 Medline 12396897 33. Tyson A Pasquini G Spencer A Funk C 60% of americans would be uncomfortable with provider relying on AI in their own health care Pew Research Center 01 2 2023 URL https://www.pewresearch.org/science/2023/02/22/60-of-americans-would-be-uncomfortable-with-provider-relying-on-ai-in-their-own-health-care/ Accessed 05-11-2025 34. Malfait S Van Hecke A Van Biesen W Eeckloo K A systematic review of patient participation during bedside handovers on wards with older patients indicates evidence is urgently needed Int J Older People Nurs Jun 2019 14 2 e12226 doi 10.1111/opn.12226 Medline 30768854 35. Liepins T Nixon G Stokes T Rural-urban differences in health service utilization in upper-middle and high-income countries: a scoping review Int J Equity Health Sep 18 2024 23 1 188 doi 10.1186/s12939-024-02261-w Medline 39294622 PMC11409755 36. Mazenda A Lubinga M Healthcare access and deprivation in low-income urban households Discov Soc Sci Health Oct 1 2024 4 1 47 doi 10.1007/s44155-024-00108-x 37. Yuen E Winter N Savira F et al Digital health literacy and its association with sociodemographic characteristics, health resource use, and health outcomes: rapid review Interact J Med Res 07 26 2024 13 1 e46888 doi 10.2196/46888 Medline 39059006 PMC11316163 38. Zack T Lehman E Suzgun M et al Assessing the potential of GPT-4 to perpetuate racial and gender biases in health care: a model evaluation study Lancet Digit Health 01 2024 6 1 e12 e22 doi 10.1016/S2589-7500(23)00225-X Medline 38123252 39. Omar M Soffer S Agbareia R et al Sociodemographic biases in medical decision making by large language models Nat Med Jun 2025 31 6 1873 1881 doi 10.1038/s41591-025-03626-6 Medline 40195448 40. Braun V Clarke V Is thematic analysis used well in health psychology? A critical review of published research, with recommendations for quality practice and reporting Health Psychol Rev Dec 2023 17 4 695 718 doi 10.1080/17437199.2022.2161594 Medline 36656762 41. Institute of Medicine (US) Committee on Quality of Health Care in America Crossing the Quality Chasm: A New Health System for the 21st Century National Academies Press URL http://www.ncbi.nlm.nih.gov/books/NBK222274/ Accessed 28-09-2025 doi 10.17226/10027 25057539 42. Shrout PE Fleiss JL Intraclass correlations: uses in assessing rater reliability Psychol Bull Mar 1979 86 2 420 428 doi 10.1037//0033-2909.86.2.420 Medline 18839484 43. Landis JR Koch GG The measurement of observer agreement for categorical data Biometrics Mar 1977 33 1 159 174 doi 10.2307/2529310 Medline 843571 44. Gichoya JW Banerjee I Bhimireddy AR et al AI recognition of patient race in medical imaging: a modelling study Lancet Digit Health Jun 2022 4 6 e406 e414 doi 10.1016/S2589-7500(22)00063-2 Medline 35568690 PMC9650160 45. Larrazabal AJ Nieto N Peterson V Milone DH Ferrante E Gender imbalance in medical imaging datasets produces biased classifiers for computer-aided diagnosis Proc Natl Acad Sci U S A Jun 9 2020 117 23 12592 12594 doi 10.1073/pnas.1919012117 Medline 32457147 PMC7293650 46. Sogancioglu G Mijsters F van Uden A Peperzak J Sex bias in (non)-contextual clinical word embeddings for stereotypical medical categories arXiv Preprint posted online on 2022 URL http://arxiv.org/abs/2208.01341 Accessed 01-10-2025 47. Obermeyer Z Powers B Vogeli C Mullainathan S Dissecting racial bias in an algorithm used to manage the health of populations Science Oct 25 2019 366 6464 447 453 doi 10.1126/science.aax2342 Medline 31649194 48. Jeoung S Ge Y Wang H Diesner J Examining alignment of large language models through representative heuristics: the case of political stereotypes arXiv Preprint posted online on 2025 URL http://arxiv.org/abs/2501.14294 Accessed 30-09-2025 49. Suri G Slater LR Ziaee A Nguyen M Do large language models show decision heuristics similar to humans? A case study using GPT-3.5 J Exp Psychol Gen Apr 2024 153 4 1066 1075 doi 10.1037/xge0001547 Medline 38330366 50. Campbell H Goldman S Markey PM Artificial intelligence and human decision making: exploring similarities in cognitive bias Comput Human Behav Artif Humans 05 2025 4 100138 doi 10.1016/j.chbah.2025.100138 51. Davoudi N Nayeri ND Zokaei MS Fazeli N Carspecken PF Culture of paternalism in the emergency department: a critical ethnographic study BMC Health Serv Res Aug 12 2025 25 1 1068 doi 10.1186/s12913-025-13282-8 Medline 40797195 PMC12344830 52. Zea J Patients and clinicians: llms achieve high QA accuracy but require human evaluation for clinical safety ArkangelAI URL https://arkangel.ai/research/patients-and-clinicians-llms-achieve-high-qa-accuracy-but-require-human-evaluation-for-clinical-safety?utm_source=chatgpt.com Accessed 30-09-2025 53. van Voorst R Challenges and limitations of human oversight in ethical artificial intelligence implementation in health care: balancing digital literacy and professional strain Mayo Clin Proc Digit Health Dec 2024 2 4 559 563 doi 10.1016/j.mcpdig.2024.08.004 Medline 40206522 PMC11976012 54. Mackin S Major VJ Chunara R Newton-Dame R Identifying and mitigating algorithmic bias in the safety net NPJ Digit Med Jun 5 2025 8 1 335 doi 10.1038/s41746-025-01732-w Medline 40473916 PMC12141433"
}