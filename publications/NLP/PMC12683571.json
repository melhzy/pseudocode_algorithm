{
  "pmcid": "PMC12683571",
  "source": "PMC",
  "download_date": "2025-12-09T16:37:14.996691",
  "metadata": {
    "journal_title": "Indian Journal of Critical Care Medicine : Peer-reviewed, Official Publication of Indian Society of Critical Care Medicine",
    "journal_nlm_ta": "Indian J Crit Care Med",
    "journal_iso_abbrev": "Indian J Crit Care Med",
    "journal": "Indian Journal of Critical Care Medicine : Peer-reviewed, Official Publication of Indian Society of Critical Care Medicine",
    "pmcid": "PMC12683571",
    "doi": "10.5005/jp-journals-10071-25074",
    "title": "Comparison of Artificial Intelligence Chatbots (ChatGPT vs Google Gemini) for Informed Consent Quality: A Cross-sectional Evaluation",
    "year": "2025",
    "month": "11",
    "day": "18",
    "pub_date": {
      "year": "2025",
      "month": "11",
      "day": "18"
    },
    "authors": [
      "Chilkoti Geetanjali T",
      "Jain Swati",
      "Gondode Prakash G"
    ],
    "abstract": "A bstract Background and aims Obtaining informed consent (IC) for tracheostomy is a frequent and essential process in the intensive care unit (ICU). With the increasing use of artificial intelligence (AI) in health care, chatbots such as ChatGPT and Google Gemini (GG) are being explored as potential tools to assist in drafting IC documents. Methods In this cross-sectional study, IC drafts for tracheostomy were generated by ChatGPT and GG. Fifteen experienced intensivists independently evaluated these drafts for accuracy, completeness, readability, and sentiment. Readability was measured using the Flesch Reading Ease (FRE) score, while sentiment analysis assessed the emotional tone of the text. Results No statistically significant differences were observed in terms of accuracy or completeness between the two chatbots. The inter-rater reliability was assessed using the intraclass correlation (ICC). The ICC for completeness and accuracy ratings between ChatGPT and GG were 0.85 (95% CI: 0.75–0.92) and 0.80 (95% CI: 0.68–0.89), respectively, suggesting excellent to good inter-rater reliability between the two Chatbots. However, ChatGPT drafts had higher FRE scores (76.46 vs 60.04), indicating better readability. Sentiment analysis revealed that both drafts were predominantly neutral, with GG incorporating slightly more positive expressions. Conclusion Both ChatGPT and GG can generate clinically appropriate IC content for tracheostomy. ChatGPT appears to have an advantage in producing more readable and patient-friendly material, highlighting its potential utility in clinical communication. How to cite this article Chilkoti GT, Jain S, Gondode PG. Comparison of Artificial Intelligence Chatbots (ChatGPT vs Google Gemini) for Informed Consent Quality: A Cross-sectional Evaluation. Indian J Crit Care Med 2025;29(11):967–969.",
    "keywords": [
      "Artificial intelligence",
      "ChatGPT",
      "Google Gemini",
      "Informed consent",
      "Intensive care unit"
    ]
  },
  "xml": "<?xml version=\"1.0\"  ?><!DOCTYPE pmc-articleset PUBLIC \"-//NLM//DTD ARTICLE SET 2.0//EN\" \"https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd\"><pmc-articleset><article xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:ali=\"http://www.niso.org/schemas/ali/1.0/\" xml:lang=\"en\" article-type=\"research-article\" dtd-version=\"1.4\"><processing-meta base-tagset=\"archiving\" mathml-version=\"3.0\" table-model=\"xhtml\" tagset-family=\"jats\"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type=\"nlm-ta\">Indian J Crit Care Med</journal-id><journal-id journal-id-type=\"iso-abbrev\">Indian J Crit Care Med</journal-id><journal-id journal-id-type=\"pmc-domain-id\">939</journal-id><journal-id journal-id-type=\"pmc-domain\">ijccm</journal-id><journal-id journal-id-type=\"publisher-id\">IJCCM</journal-id><journal-title-group><journal-title>Indian Journal of Critical Care Medicine : Peer-reviewed, Official Publication of Indian Society of Critical Care Medicine</journal-title></journal-title-group><issn pub-type=\"ppub\">0972-5229</issn><issn pub-type=\"epub\">1998-359X</issn><publisher><publisher-name>Indian Society of Critical Care Medicine</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type=\"pmcid\">PMC12683571</article-id><article-id pub-id-type=\"pmcid-ver\">PMC12683571.1</article-id><article-id pub-id-type=\"pmcaid\">12683571</article-id><article-id pub-id-type=\"pmcaiid\">12683571</article-id><article-id pub-id-type=\"doi\">10.5005/jp-journals-10071-25074</article-id><article-version article-version-type=\"pmc-version\">1</article-version><article-categories><subj-group subj-group-type=\"heading\"><subject>Brief Communication</subject></subj-group></article-categories><title-group><article-title>Comparison of Artificial Intelligence Chatbots (ChatGPT vs Google Gemini) for Informed Consent Quality: A Cross-sectional Evaluation</article-title></title-group><contrib-group><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Chilkoti</surname><given-names initials=\"GT\">Geetanjali T</given-names></name><xref rid=\"aff1\" ref-type=\"aff\">1</xref><contrib-id contrib-id-type=\"orcid\" authenticated=\"false\">https://orcid.org/0000-0002-2436-0444</contrib-id></contrib><contrib contrib-type=\"author\" corresp=\"yes\"><name name-style=\"western\"><surname>Jain</surname><given-names initials=\"S\">Swati</given-names></name><xref rid=\"cor1\" ref-type=\"corresp\"/><xref rid=\"aff1\" ref-type=\"aff\">2</xref><contrib-id contrib-id-type=\"orcid\" authenticated=\"false\">https://orcid.org/0000-0002-4660-1712</contrib-id></contrib><contrib contrib-type=\"author\"><name name-style=\"western\"><surname>Gondode</surname><given-names initials=\"PG\">Prakash G</given-names></name><xref rid=\"aff2\" ref-type=\"aff\">3</xref><contrib-id contrib-id-type=\"orcid\" authenticated=\"false\">https://orcid.org/0000-0003-1014-8407</contrib-id></contrib></contrib-group><aff id=\"aff1\"><label>1,2</label>Department of Anaesthesiology and Critical Care, University College of Medical Sciences and Guru Teg Bahadur Hospital, Shahdara, New Delhi, India</aff><aff id=\"aff2\"><label>3</label>Department of Anaesthesiology and Critical Care, AIIMS, New Delhi, India</aff><author-notes><corresp id=\"cor1\">Swati Jain, Department of Anaesthesiology and Critical Care, University College of Medical Sciences and Guru Teg Bahadur Hospital, Shahdara, New Delhi, India, Phone: +91 9810613597, e-mail: <email>drswatijain273@gmail.com</email></corresp></author-notes><pub-date pub-type=\"ppub\"><month>11</month><year>2025</year></pub-date><pub-date pub-type=\"epub\"><day>18</day><month>11</month><year>2025</year></pub-date><volume>29</volume><issue>11</issue><issue-id pub-id-type=\"pmc-issue-id\">502053</issue-id><fpage>967</fpage><lpage>969</lpage><history><date date-type=\"received\"><day>27</day><month>5</month><year>2025</year></date><date date-type=\"accepted\"><day>04</day><month>10</month><year>2025</year></date></history><pub-history><event event-type=\"pmc-release\"><date><day>01</day><month>11</month><year>2025</year></date></event><event event-type=\"pmc-live\"><date><day>09</day><month>12</month><year>2025</year></date></event><event event-type=\"pmc-last-change\"><date iso-8601-date=\"2025-12-09 00:25:14.317\"><day>09</day><month>12</month><year>2025</year></date></event></pub-history><permissions><copyright-statement>Copyright &#169; 2025; The Author(s).</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref specific-use=\"textmining\" content-type=\"ccbynclicense\">https://creativecommons.org/licenses/by-nc/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (<ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://creativecommons.org/licenses/by-nc/4.0/\">https://creativecommons.org/licenses/by-nc/4.0/</ext-link>), which permits unrestricted use, distribution, and non-commercial reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver (<ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://creativecommons.org/publicdomain/zero/1.0/\">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated.</license-p></license></permissions><self-uri xmlns:xlink=\"http://www.w3.org/1999/xlink\" content-type=\"pmc-pdf\" xlink:href=\"ijccm-29-11-967.pdf\"/><abstract><title>A<sc>bstract</sc></title><sec><title>Background and aims</title><p>Obtaining informed consent (IC) for tracheostomy is a frequent and essential process in the intensive care unit (ICU). With the increasing use of artificial intelligence (AI) in health care, chatbots such as ChatGPT and Google Gemini (GG) are being explored as potential tools to assist in drafting IC documents.</p></sec><sec><title>Methods</title><p>In this cross-sectional study, IC drafts for tracheostomy were generated by ChatGPT and GG. Fifteen experienced intensivists independently evaluated these drafts for accuracy, completeness, readability, and sentiment. Readability was measured using the Flesch Reading Ease (FRE) score, while sentiment analysis assessed the emotional tone of the text.</p></sec><sec><title>Results</title><p>No statistically significant differences were observed in terms of accuracy or completeness between the two chatbots. The inter-rater reliability was assessed using the intraclass correlation (ICC). The ICC for completeness and accuracy ratings between ChatGPT and GG were 0.85 (95% CI: 0.75&#8211;0.92) and 0.80 (95% CI: 0.68&#8211;0.89), respectively, suggesting excellent to good inter-rater reliability between the two Chatbots. However, ChatGPT drafts had higher FRE scores (76.46 vs 60.04), indicating better readability. Sentiment analysis revealed that both drafts were predominantly neutral, with GG incorporating slightly more positive expressions.</p></sec><sec><title>Conclusion</title><p>Both ChatGPT and GG can generate clinically appropriate IC content for tracheostomy. ChatGPT appears to have an advantage in producing more readable and patient-friendly material, highlighting its potential utility in clinical communication.</p></sec><sec><title>How to cite this article</title><p>Chilkoti GT, Jain S, Gondode PG. Comparison of Artificial Intelligence Chatbots (ChatGPT vs Google Gemini) for Informed Consent Quality: A Cross-sectional Evaluation. Indian J Crit Care Med 2025;29(11):967&#8211;969.</p></sec></abstract><kwd-group><title>Keywords</title><kwd>Artificial intelligence</kwd><kwd>ChatGPT</kwd><kwd>Google Gemini</kwd><kwd>Informed consent</kwd><kwd>Intensive care unit</kwd></kwd-group><custom-meta-group><custom-meta><meta-name>pmc-status-qastatus</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>pmc-status-live</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-status-embargo</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-status-released</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-open-access</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-olf</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-manuscript</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-legally-suppressed</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-pdf</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-supplement</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-pdf-only</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-suppress-copyright</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-real-version</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-scanned-article</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-preprint</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-in-epmc</meta-name><meta-value>yes</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec sec-type=\"highlights\"><title>H<sc>ighlights</sc></title><list list-type=\"bullet\"><list-item><p>Informed consent (IC) is crucial in critical care settings, especially for procedures like tracheostomy.</p></list-item><list-item><p>We compared ChatGPT (v3.5) and Google Gemini (GG) in drafting IC for tracheostomy in the ICU in terms of their accuracy, completeness, readability, and emotional tone.</p></list-item><list-item><p>Both chatbots performed similarly in accuracy and content completeness; however, ChatGPT demonstrated better readability, making it more suitable for patient-centered communication.</p></list-item></list></sec><sec sec-type=\"introduction\"><title>I<sc>ntroduction</sc></title><p>Informed consent is a foundational element of medical ethics and an integral part of patient care. Informed consent in the intensive care unit (ICU) is an ethical and communicative process that ensures that patients (or their surrogates) understand and agree to the interventions and the associated risks. A simple and easily understandable consent improves the trust and reliability of the treating physician, and the plain language saves the physicians from any future legal implications. Percutaneous tracheostomy performed by anesthesiologists in an ICU setting is a life-saving procedure and is viewed with a lot of emotional, psychological, and physical impact by the attendants of any patient. Informed consent for tracheostomy is commonly indicated in cases of severe respiratory failure, prolonged mechanical ventilation, or airway obstruction in the ICU. Readable medical consent forms are a legal, ethical, and practical necessity to protect patients and ensure high-quality care, especially for vulnerable populations.</p><p>Artificial intelligence (AI) chatbots are becoming increasingly popular in healthcare as they provide automated assistance and use natural language processing (NLP) and machine learning to simulate human conversation and help with a wide range of tasks. Various studies have evaluated the role of AI in generating patient information leaflets (PILs); however, only a single study has evaluated the IC using various AI Chatbots.<sup><xref rid=\"B1\" ref-type=\"bibr\">1</xref>&#8211;<xref rid=\"B3\" ref-type=\"bibr\">3</xref></sup></p><p>The present study is being undertaken to assess the comparative performance of two commonly used AI Chatbots, i.e., ChatGPT (version 3.5) and GG, in drafting a tracheostomy consent by analyzing accuracy, readability, and emotional tone. This research specifically aims to evaluate how well AI-generated responses align with the goal of intending to guide the development of patient-centered communication tools. Beyond tracheostomy, the findings may help improve consent documents for other procedures and patient groups, ensuring they are clear, sensitive, and supportive of decision-making.</p></sec><sec sec-type=\"methods\"><title>M<sc>ethods</sc></title><p>The present cross-sectional study was conducted between May and July 2025. The IC for tracheostomy was drafted using two AI Chatbots, i.e., ChatGPT and Google Gemini, using the same prompts, i.e., &#8220;Informed consent for tracheostomy in ICU.&#8221; The IC generated by AI Chatbots was assessed by 15 experienced intensivists/raters, with more than 10 years of experience in critical care. This study was conducted and reported in accordance with the Strengthening the Reporting of Observational Studies in Epidemiology (STROBE) guidelines for observational research.</p><p>To reduce bias, raters were blinded to which AI Chatbot produced which draft. Each rater evaluated both AI-generated ICs. Raters received a short, standardized instruction sheet and one practice example before they initiated rating. Assessment was based on two criteria, i.e., accuracy and completeness, using a standardized 1&#8211;10 Likert scale. For accuracy, all experts were instructed to rate the accuracy of IC, ensuring that all facts were correct and clinically relevant. Similarly, for completeness, the experts were again instructed to assess whether it covers all necessary aspects.</p><p>The readability of the text was assessed using the Flesch Reading Ease (FRE) metric, which considers the total number of words, sentences, and syllables.<sup><xref rid=\"B4\" ref-type=\"bibr\">4</xref></sup> This score ranges from 0 to 100, with higher values indicating easier readability, where a higher score (90&#8211;100) indicates easy readability, corresponding to that of a United States school level of 5th grade, while lower scores (0&#8211;10) indicate the content to be more difficult to read, which matches that of a professionally qualified person. The formula for calculating FRE is as follows: FRE = 206.835 &#8211; (1.015 &#215; average sentence length) &#8211; (84.6 &#215; average syllables per word).</p><p>Additionally, sentiment analysis was conducted to evaluate the emotional tone of the text, categorizing it as neutral, positive, or negative.<sup><xref rid=\"B5\" ref-type=\"bibr\">5</xref></sup> No formal power calculation was performed; the sample size (15 raters) reflects institutional feasibility.</p><sec><title>Statistical Analysis</title><p>The content analysis was done by analyzing the mean scores with standard deviation (SD) using one-way ANOVA. <italic toggle=\"yes\">Post-hoc</italic> Tukey HSD test was used to explore significant differences between the two AI chatbots. Inter-rater reliability across the 15 raters was assessed using the intraclass correlation (ICC) coefficient (ICC, two-way random effects, absolute agreement) and Kendall's W as a supplementary ordinal measure.</p></sec><sec><title>Ethical Considerations</title><p>Since patients were not directly involved in this study, and considering the nature of our research, the ethics committee approval was not deemed necessary.</p></sec></sec><sec sec-type=\"results\"><title>R<sc>esults</sc></title><p>All 15 raters completed the evaluation of both drafts successfully, and none were excluded.</p><p>The mean accuracy scores for ChatGPT draft and GG draft were 8.1 (SD = 0.7) and 8.3 (SD = 0.8), respectively. The mean completeness scores were 8.3 (SD = 0.6) for ChatGPT draft and 8.5 (SD = 0.7) for GG draft. The one-way ANOVA revealed no significant difference in accuracy [F1 (1, 28) = 0.45, <italic toggle=\"yes\">p</italic> = 0.51] or completeness [F1 (1, 28) = 0.36, <italic toggle=\"yes\">p</italic> = 0.55] between the two drafts. Consequently, the Tukey HSD test indicated that there were no significant differences between the drafts in either category. The GG draft showed slightly higher mean scores in both accuracy and completeness; however, the differences were not statistically significant.</p><p>The ICC for Completeness ratings between ChatGPT and Google Gemini was found to be 0.85 (95% CI: 0.75&#8211; 0.92), indicating excellent agreement between the two raters. For Accuracy ratings, the ICC was calculated to be 0.80 (95% CI: 0.68&#8211;0.89), suggesting good reliability in the ratings between the two. These results highlight the consistency of the ratings between the two AI chatbots (<xref rid=\"T1\" ref-type=\"table\">Table 1</xref>).</p><table-wrap position=\"float\" id=\"T1\" orientation=\"portrait\"><label>Table 1</label><caption><p>Summary of ratings for accuracy and completeness between the two AI chatbots</p></caption><table frame=\"hsides\" rules=\"groups\" cellpadding=\"10\" cellspacing=\"0\"><thead><tr><th align=\"left\" valign=\"bottom\" rowspan=\"1\" colspan=\"1\">\n<italic toggle=\"yes\">Measure</italic>\n</th><th align=\"left\" valign=\"bottom\" rowspan=\"1\" colspan=\"1\">\n<italic toggle=\"yes\">Metric</italic>\n</th><th align=\"center\" valign=\"bottom\" rowspan=\"1\" colspan=\"1\">\n<italic toggle=\"yes\">ChatGPT</italic>\n</th><th align=\"center\" valign=\"bottom\" rowspan=\"1\" colspan=\"1\">\n<italic toggle=\"yes\">Google Gemini</italic>\n</th></tr></thead><tbody><tr><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">Accuracy</td><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">Mean (SD)</td><td align=\"center\" valign=\"top\" rowspan=\"1\" colspan=\"1\">8.07 (0.73)</td><td align=\"center\" valign=\"top\" rowspan=\"1\" colspan=\"1\">8.07 (0.73)</td></tr><tr><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\"/><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">Minimum and maximum</td><td align=\"center\" valign=\"top\" rowspan=\"1\" colspan=\"1\">7.0 and 9.5</td><td align=\"center\" valign=\"top\" rowspan=\"1\" colspan=\"1\">7.0 and 10.0</td></tr><tr><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">Completeness</td><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">Mean (SD)</td><td align=\"center\" valign=\"top\" rowspan=\"1\" colspan=\"1\">8.07 (0.73)</td><td align=\"center\" valign=\"top\" rowspan=\"1\" colspan=\"1\">8.47 (0.73)</td></tr><tr><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\"/><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">Minimum and Maximum</td><td align=\"center\" valign=\"top\" rowspan=\"1\" colspan=\"1\">7.0 and 9.5</td><td align=\"center\" valign=\"top\" rowspan=\"1\" colspan=\"1\">7.0 and 10.0</td></tr><tr><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">Overall ICC</td><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">Accuracy</td><td align=\"center\" valign=\"top\" rowspan=\"1\" colspan=\"1\">0.80 (95% CI: 0.68&#8211;0.89)</td><td align=\"center\" valign=\"top\" rowspan=\"1\" colspan=\"1\">&#8211;</td></tr><tr><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\"/><td align=\"left\" valign=\"top\" rowspan=\"1\" colspan=\"1\">Completeness</td><td align=\"center\" valign=\"top\" rowspan=\"1\" colspan=\"1\">0.85 (95% CI: 0.75&#8211;0.92)</td><td align=\"center\" valign=\"top\" rowspan=\"1\" colspan=\"1\">&#8211;</td></tr></tbody></table><table-wrap-foot><fn><p>CI, confidence interval; ICC, intraclass correlation; SD, standard deviation</p></fn></table-wrap-foot></table-wrap><p>Readability evaluation was done by using the FRE score. ChatGPT draft had a FRE score of 76.56, indicating that it is fairly easy to read. The sentiment analysis categorizes the tone as neutral, which is appropriate for an IC document. The FRE score of the GG draft is approximately 60.04 (moderately difficult), and sentiment analysis is neutral with positive elements regarding the benefits of the procedure.</p></sec><sec sec-type=\"discussion\"><title>D<sc>iscussion</sc></title><p>The present study observed that the accuracy, completeness, and sentiment quotients were comparable between both AI chatbots; however, the readability was better with ChatGPT.</p><p>As far as the use of AI in formulating ICs is concerned, it can help automate the personalized ICs based on a patient's condition and treatment plan. Natural language processing can be used to generate and clarify medical language, making it easier for patients to understand complex medical jargon. In addition, AI-powered systems can guide healthcare professionals in ensuring that all key aspects of IC are covered. The AI Chatbots or interactive systems can walk patients through their options and provide information in real time, answering questions about procedures, side effects, and potential outcomes.</p><p>The present research on evaluating and comparing the accuracy and readability of informed consent documents in the ICU using AI chatbots like ChatGPT and Google Gemini is timely and significant. Two studies have compared the AI chatbots for their role in preparing patient information leaflets for end-of-life care, and for local anesthesia in eye surgery (87) and triaging trauma patients (9).<sup><xref rid=\"B6\" ref-type=\"bibr\">6</xref>,<xref rid=\"B7\" ref-type=\"bibr\">7</xref></sup> The former study showed that GG leaflets exhibited superior readability and actionability, while both demonstrated high accuracy and completeness.<sup><xref rid=\"B8\" ref-type=\"bibr\">8</xref>,<xref rid=\"B9\" ref-type=\"bibr\">9</xref></sup> The latter study showed that AI chatbots provided simplified language and high understandability; whereas, traditional leaflets excelled in completeness.</p><p>There has been a single study comparing AI-generated IC documents (ChatGPT-4, Bard Gemini Advanced, and human-written consents) for oral surgery procedures. In this study, ChatGPT-4 consistently outperformed both Bard and human-written consents in accuracy, completeness, and readability.<sup><xref rid=\"B3\" ref-type=\"bibr\">3</xref></sup></p><p>These aforementioned studies highlight the potential of AI chatbots in enhancing patient education materials across various medical fields. However, it's essential to note that AI-generated content may sometimes contain inaccuracies and may raise data security issues. For instance, the British Broadcasting Corporation (BBC) found that AI chatbots, including ChatGPT and Google Gemini, frequently produced distorted summaries with significant issues.<sup><xref rid=\"B8\" ref-type=\"bibr\">8</xref>,<xref rid=\"B10\" ref-type=\"bibr\">10</xref></sup> Given these findings, integrating AI-generated content with human oversight is crucial to ensure accuracy and reliability in patient education materials.</p><p>The risks associated with AI-generated ICs include missing key details, privacy breaches, and legal challenges. Given these findings, integrating AI-generated content with human oversight is crucial to ensure accuracy and reliability in patient education materials.</p><p>The use of AI can help standardize information, but doctors remain legally responsible for ensuring patient understanding.<sup><xref rid=\"B11\" ref-type=\"bibr\">11</xref></sup> They should be used only as supportive tools, with physician oversight, transparency, and proper documentation to ensure legal validity.</p><p>The present study has certain limitations. First, it is a single-center study with a relatively small sample size. Second, the evaluation of IC was limited to English, without the inclusion of patient attendants or the use of regional languages. Future multicenter studies involving larger cohorts, local languages, and family participation with ICs for other procedures are recommended to enhance the generalizability and impact of the findings.</p></sec><sec sec-type=\"conclusion\"><title>C<sc>onclusion</sc></title><p>The present study observed that the tracheostomy IC generated by both AI Chatbots was comparable with respect to the accuracy, completeness, and sentiment quotient; however, the readability was better with ChatGPT. The use of AI in the IC process offers great potential to improve accuracy, accessibility, and efficiency, but under direct human supervision.</p></sec><sec sec-type=\"author contributions\"><title>A<sc>uthor</sc> C<sc>ontributions</sc></title><p>GC, SJ, and PG were involved in the concept, design, definition of intellectual content, literature search, data acquisition, data analysis, statistical analysis, manuscript preparation, manuscript editing, and manuscript review.</p></sec><sec sec-type=\"orcid\"><title>O<sc>rcid</sc></title><p><italic toggle=\"yes\">Geetanjali T Chilkoti</italic>\n<uri xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"https://orcid.org/0000-0002-2436-0444\" content-type=\"orcid\">https://orcid.org/0000-0002-2436-0444</uri></p><p><italic toggle=\"yes\">Swati Jain</italic>\n<uri xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"https://orcid.org/0000-0002-4660-1712\" content-type=\"orcid\">https://orcid.org/0000-0002-4660-1712</uri></p><p><italic toggle=\"yes\">Prakash G Gondode</italic>\n<uri xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"https://orcid.org/0000-0003-1014-8407\" content-type=\"orcid\">https://orcid.org/0000-0003-1014-8407</uri></p></sec></body><back><fn-group><fn id=\"fn1\" fn-type=\"COI-statement\"><p><bold>Source of support:</bold> Nil</p><p content-type=\"COI-statement\"><bold>Conflict of interest:</bold> None</p></fn></fn-group><ref-list><title>R<sc>eferences</sc></title><ref id=\"B1\"><label>1.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Rahsepar</surname><given-names>AA</given-names></name><name name-style=\"western\"><surname>Tavakoli</surname><given-names>N</given-names></name><name name-style=\"western\"><surname>Kim</surname><given-names>GHJ</given-names></name><name name-style=\"western\"><surname>Hassani</surname><given-names>C</given-names></name><name name-style=\"western\"><surname>Abtin</surname><given-names>F</given-names></name><name name-style=\"western\"><surname>Bedayat</surname><given-names>A</given-names></name></person-group><article-title>How AI responds to common lung cancer questions: ChatGPT vs Google Bard</article-title><source>Radiology</source><year>2023</year><volume>307</volume><issue>5</issue><fpage>e230922</fpage><pub-id pub-id-type=\"doi\">10.1148/radiol.230922</pub-id><pub-id pub-id-type=\"pmid\">37310252</pub-id></element-citation></ref><ref id=\"B2\"><label>2.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Gondode</surname><given-names>PG</given-names></name><name name-style=\"western\"><surname>Singh</surname><given-names>R</given-names></name><name name-style=\"western\"><surname>Mehta</surname><given-names>S</given-names></name><name name-style=\"western\"><surname>Singh</surname><given-names>S</given-names></name><name name-style=\"western\"><surname>Kumar</surname><given-names>S</given-names></name><name name-style=\"western\"><surname>Nayak</surname><given-names>SS</given-names></name></person-group><article-title>Artificial intelligence chatbots versus traditional medical resources for patient education on &#8220;Labor Epidurals&#8221;: An evaluation of accuracy, emotional tone, and readability</article-title><source>Int J Obstet Anesth</source><year>2025</year><volume>61</volume><fpage>104302</fpage><pub-id pub-id-type=\"doi\">10.1016/j.ijoa.2024.104302</pub-id><pub-id pub-id-type=\"pmid\">39657284</pub-id></element-citation></ref><ref id=\"B3\"><label>3.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Vaira</surname><given-names>LA</given-names></name><name name-style=\"western\"><surname>Lechien</surname><given-names>JR</given-names></name><name name-style=\"western\"><surname>Maniaci</surname><given-names>A</given-names></name><name name-style=\"western\"><surname>Tanda</surname><given-names>G</given-names></name><name name-style=\"western\"><surname>Abbate</surname><given-names>V</given-names></name><name name-style=\"western\"><surname>Allevi</surname><given-names>F</given-names></name><etal>et al.</etal></person-group><article-title>Evaluating AI-Generated informed consent documents in oral surgery: A comparative study of ChatGPT-4, Bard Gemini advanced, and human-written consents</article-title><source>J Craniomaxillofac Surg</source><year>2025</year><volume>53</volume><issue>1</issue><fpage>18</fpage><lpage>23</lpage><pub-id pub-id-type=\"doi\">10.1016/j.jcms.2024.10.002</pub-id><pub-id pub-id-type=\"pmid\">39490345</pub-id></element-citation></ref><ref id=\"B4\"><label>4.</label><element-citation publication-type=\"book\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Scott</surname><given-names>Brian</given-names></name></person-group><year>2024</year><part-title>Readability formulas.</part-title><comment>[online] Available from:</comment><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"https://readabilityformulas.com/\" ext-link-type=\"uri\">https://readabilityformulas.com/</ext-link><comment>[Last accessed October, 2024]</comment></element-citation></ref><ref id=\"B5\"><label>5.</label><element-citation publication-type=\"book\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Soper</surname><given-names>D</given-names></name></person-group><year>2001</year><part-title>Free sentiment analyzer.</part-title><comment>[online] Available from:</comment><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"https://www.danielsoper.com/sentimentanalysis/default.aspx\" ext-link-type=\"uri\">https://www.danielsoper.com/sentimentanalysis/default.aspx</ext-link><comment>[Last accessed October, 2024]</comment></element-citation></ref><ref id=\"B6\"><label>6.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Gondode</surname><given-names>PG</given-names></name><name name-style=\"western\"><surname>Mahor</surname><given-names>V</given-names></name><name name-style=\"western\"><surname>Rani</surname><given-names>D</given-names></name><name name-style=\"western\"><surname>Ramkumar</surname><given-names>R</given-names></name><name name-style=\"western\"><surname>Yadav</surname><given-names>P</given-names></name></person-group><article-title>Debunking palliative care myths: Assessing the performance of artificial intelligence chatbots (ChatGPT vs</article-title><source>Google Gemini). Indian J Palliat Care</source><year>2024</year><volume>30</volume><issue>3</issue><fpage>284</fpage><lpage>287</lpage><pub-id pub-id-type=\"doi\">10.25259/IJPC_44_2024</pub-id><pub-id pub-id-type=\"pmid\">39371498</pub-id><pub-id pub-id-type=\"pmcid\">PMC11450875</pub-id></element-citation></ref><ref id=\"B7\"><label>7.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Gondode</surname><given-names>PG</given-names></name><name name-style=\"western\"><surname>Sharma</surname><given-names>P</given-names></name><name name-style=\"western\"><surname>Duggal</surname><given-names>S</given-names></name><name name-style=\"western\"><surname>Garg</surname><given-names>N</given-names></name></person-group><article-title>End-of-life care patient information leaflets&#8212;A comparative evaluation of artificial intelligence-generated content for readability, sentiment, accuracy, completeness, and suitability: ChatGPT vs Google Gemini</article-title><source>Indian J Crit Care Med</source><year>2024</year><volume>28</volume><issue>6</issue><fpage>561</fpage><lpage>568</lpage><pub-id pub-id-type=\"doi\">10.5005/jp-journals-10071-24725</pub-id><pub-id pub-id-type=\"pmid\">39130387</pub-id><pub-id pub-id-type=\"pmcid\">PMC11310687</pub-id></element-citation></ref><ref id=\"B8\"><label>8.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Mihalache</surname><given-names>A</given-names></name><name name-style=\"western\"><surname>Popovic</surname><given-names>MM</given-names></name><name name-style=\"western\"><surname>Muni</surname><given-names>RH</given-names></name></person-group><part-title>Performance of an artificial intelligence chatbot in ophthalmic knowledge assessment.</part-title><source>JAMA Ophthalmol</source><year>2023</year><volume>1;141</volume><issue>6</issue><fpage>589</fpage><lpage>597</lpage><pub-id pub-id-type=\"doi\">10.1001/jamaophthalmol.2023.1144</pub-id><pub-id pub-id-type=\"pmid\">37103928</pub-id><pub-id pub-id-type=\"pmcid\">PMC10141269</pub-id></element-citation></ref><ref id=\"B9\"><label>9.</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Jacob</surname><given-names>J</given-names></name></person-group><article-title>ChatGPT: Friend or foe?-Utility in Trauma Triage</article-title><source>Indian J Crit Care Med</source><year>2023</year><volume>27</volume><issue>8</issue><fpage>563</fpage><lpage>566</lpage><pub-id pub-id-type=\"doi\">10.5005/jp-journals-10071-24498</pub-id><pub-id pub-id-type=\"pmid\">37636841</pub-id><pub-id pub-id-type=\"pmcid\">PMC10452764</pub-id></element-citation></ref><ref id=\"B10\"><label>10.</label><element-citation publication-type=\"book\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Rahman-Jones</surname><given-names>I</given-names></name></person-group><year>2025</year><part-title>AI chatbots produce distorted summaries with significant issues, study finds.</part-title><comment>[online] Available from:</comment><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"https://www.bbc.com/news/articles/c0m17d8827ko\" ext-link-type=\"uri\">https://www.bbc.com/news/articles/c0m17d8827ko</ext-link><comment>[Last accessed March, 2025]</comment></element-citation></ref><ref id=\"B11\"><label>11.</label><element-citation publication-type=\"book\"><person-group person-group-type=\"author\"><name name-style=\"western\"><surname>Cohen</surname><given-names>IG</given-names></name><name name-style=\"western\"><surname>Slottje</surname><given-names>A</given-names></name></person-group><part-title>Artificial intelligence and the law of informed consent.</part-title><person-group person-group-type=\"editor\"><name name-style=\"western\"><surname>Solaiman</surname><given-names>B</given-names></name><name name-style=\"western\"><surname>Cohen</surname><given-names>IG</given-names></name></person-group><publisher-loc>Research Handbook on Health, AI and the Law. Cheltenham, UK</publisher-loc><publisher-name>Edward Elgar Publishing Ltd</publisher-name><year>2024</year><month>Jul</month><day>16</day><comment>Chapter 10.</comment><ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"40245217\" ext-link-type=\"pmid\">40245217</ext-link><pub-id pub-id-type=\"pmid\">40245217</pub-id></element-citation></ref></ref-list></back></article></pmc-articleset>",
  "text": "pmc Indian J Crit Care Med Indian J Crit Care Med 939 ijccm IJCCM Indian Journal of Critical Care Medicine : Peer-reviewed, Official Publication of Indian Society of Critical Care Medicine 0972-5229 1998-359X Indian Society of Critical Care Medicine PMC12683571 PMC12683571.1 12683571 12683571 10.5005/jp-journals-10071-25074 1 Brief Communication Comparison of Artificial Intelligence Chatbots (ChatGPT vs Google Gemini) for Informed Consent Quality: A Cross-sectional Evaluation Chilkoti Geetanjali T 1 https://orcid.org/0000-0002-2436-0444 Jain Swati 2 https://orcid.org/0000-0002-4660-1712 Gondode Prakash G 3 https://orcid.org/0000-0003-1014-8407 1,2 Department of Anaesthesiology and Critical Care, University College of Medical Sciences and Guru Teg Bahadur Hospital, Shahdara, New Delhi, India 3 Department of Anaesthesiology and Critical Care, AIIMS, New Delhi, India Swati Jain, Department of Anaesthesiology and Critical Care, University College of Medical Sciences and Guru Teg Bahadur Hospital, Shahdara, New Delhi, India, Phone: +91 9810613597, e-mail: drswatijain273@gmail.com 11 2025 18 11 2025 29 11 502053 967 969 27 5 2025 04 10 2025 01 11 2025 09 12 2025 09 12 2025 Copyright &#169; 2025; The Author(s). 2025 https://creativecommons.org/licenses/by-nc/4.0/ This article is distributed under the terms of the Creative Commons Attribution 4.0 International License ( https://creativecommons.org/licenses/by-nc/4.0/ ), which permits unrestricted use, distribution, and non-commercial reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver ( http://creativecommons.org/publicdomain/zero/1.0/ ) applies to the data made available in this article, unless otherwise stated. A bstract Background and aims Obtaining informed consent (IC) for tracheostomy is a frequent and essential process in the intensive care unit (ICU). With the increasing use of artificial intelligence (AI) in health care, chatbots such as ChatGPT and Google Gemini (GG) are being explored as potential tools to assist in drafting IC documents. Methods In this cross-sectional study, IC drafts for tracheostomy were generated by ChatGPT and GG. Fifteen experienced intensivists independently evaluated these drafts for accuracy, completeness, readability, and sentiment. Readability was measured using the Flesch Reading Ease (FRE) score, while sentiment analysis assessed the emotional tone of the text. Results No statistically significant differences were observed in terms of accuracy or completeness between the two chatbots. The inter-rater reliability was assessed using the intraclass correlation (ICC). The ICC for completeness and accuracy ratings between ChatGPT and GG were 0.85 (95% CI: 0.75&#8211;0.92) and 0.80 (95% CI: 0.68&#8211;0.89), respectively, suggesting excellent to good inter-rater reliability between the two Chatbots. However, ChatGPT drafts had higher FRE scores (76.46 vs 60.04), indicating better readability. Sentiment analysis revealed that both drafts were predominantly neutral, with GG incorporating slightly more positive expressions. Conclusion Both ChatGPT and GG can generate clinically appropriate IC content for tracheostomy. ChatGPT appears to have an advantage in producing more readable and patient-friendly material, highlighting its potential utility in clinical communication. How to cite this article Chilkoti GT, Jain S, Gondode PG. Comparison of Artificial Intelligence Chatbots (ChatGPT vs Google Gemini) for Informed Consent Quality: A Cross-sectional Evaluation. Indian J Crit Care Med 2025;29(11):967&#8211;969. Keywords Artificial intelligence ChatGPT Google Gemini Informed consent Intensive care unit pmc-status-qastatus 0 pmc-status-live yes pmc-status-embargo no pmc-status-released yes pmc-prop-open-access yes pmc-prop-olf no pmc-prop-manuscript no pmc-prop-legally-suppressed no pmc-prop-has-pdf yes pmc-prop-has-supplement no pmc-prop-pdf-only no pmc-prop-suppress-copyright no pmc-prop-is-real-version no pmc-prop-is-scanned-article no pmc-prop-preprint no pmc-prop-in-epmc yes H ighlights Informed consent (IC) is crucial in critical care settings, especially for procedures like tracheostomy. We compared ChatGPT (v3.5) and Google Gemini (GG) in drafting IC for tracheostomy in the ICU in terms of their accuracy, completeness, readability, and emotional tone. Both chatbots performed similarly in accuracy and content completeness; however, ChatGPT demonstrated better readability, making it more suitable for patient-centered communication. I ntroduction Informed consent is a foundational element of medical ethics and an integral part of patient care. Informed consent in the intensive care unit (ICU) is an ethical and communicative process that ensures that patients (or their surrogates) understand and agree to the interventions and the associated risks. A simple and easily understandable consent improves the trust and reliability of the treating physician, and the plain language saves the physicians from any future legal implications. Percutaneous tracheostomy performed by anesthesiologists in an ICU setting is a life-saving procedure and is viewed with a lot of emotional, psychological, and physical impact by the attendants of any patient. Informed consent for tracheostomy is commonly indicated in cases of severe respiratory failure, prolonged mechanical ventilation, or airway obstruction in the ICU. Readable medical consent forms are a legal, ethical, and practical necessity to protect patients and ensure high-quality care, especially for vulnerable populations. Artificial intelligence (AI) chatbots are becoming increasingly popular in healthcare as they provide automated assistance and use natural language processing (NLP) and machine learning to simulate human conversation and help with a wide range of tasks. Various studies have evaluated the role of AI in generating patient information leaflets (PILs); however, only a single study has evaluated the IC using various AI Chatbots. 1 &#8211; 3 The present study is being undertaken to assess the comparative performance of two commonly used AI Chatbots, i.e., ChatGPT (version 3.5) and GG, in drafting a tracheostomy consent by analyzing accuracy, readability, and emotional tone. This research specifically aims to evaluate how well AI-generated responses align with the goal of intending to guide the development of patient-centered communication tools. Beyond tracheostomy, the findings may help improve consent documents for other procedures and patient groups, ensuring they are clear, sensitive, and supportive of decision-making. M ethods The present cross-sectional study was conducted between May and July 2025. The IC for tracheostomy was drafted using two AI Chatbots, i.e., ChatGPT and Google Gemini, using the same prompts, i.e., &#8220;Informed consent for tracheostomy in ICU.&#8221; The IC generated by AI Chatbots was assessed by 15 experienced intensivists/raters, with more than 10 years of experience in critical care. This study was conducted and reported in accordance with the Strengthening the Reporting of Observational Studies in Epidemiology (STROBE) guidelines for observational research. To reduce bias, raters were blinded to which AI Chatbot produced which draft. Each rater evaluated both AI-generated ICs. Raters received a short, standardized instruction sheet and one practice example before they initiated rating. Assessment was based on two criteria, i.e., accuracy and completeness, using a standardized 1&#8211;10 Likert scale. For accuracy, all experts were instructed to rate the accuracy of IC, ensuring that all facts were correct and clinically relevant. Similarly, for completeness, the experts were again instructed to assess whether it covers all necessary aspects. The readability of the text was assessed using the Flesch Reading Ease (FRE) metric, which considers the total number of words, sentences, and syllables. 4 This score ranges from 0 to 100, with higher values indicating easier readability, where a higher score (90&#8211;100) indicates easy readability, corresponding to that of a United States school level of 5th grade, while lower scores (0&#8211;10) indicate the content to be more difficult to read, which matches that of a professionally qualified person. The formula for calculating FRE is as follows: FRE = 206.835 &#8211; (1.015 &#215; average sentence length) &#8211; (84.6 &#215; average syllables per word). Additionally, sentiment analysis was conducted to evaluate the emotional tone of the text, categorizing it as neutral, positive, or negative. 5 No formal power calculation was performed; the sample size (15 raters) reflects institutional feasibility. Statistical Analysis The content analysis was done by analyzing the mean scores with standard deviation (SD) using one-way ANOVA. Post-hoc Tukey HSD test was used to explore significant differences between the two AI chatbots. Inter-rater reliability across the 15 raters was assessed using the intraclass correlation (ICC) coefficient (ICC, two-way random effects, absolute agreement) and Kendall's W as a supplementary ordinal measure. Ethical Considerations Since patients were not directly involved in this study, and considering the nature of our research, the ethics committee approval was not deemed necessary. R esults All 15 raters completed the evaluation of both drafts successfully, and none were excluded. The mean accuracy scores for ChatGPT draft and GG draft were 8.1 (SD = 0.7) and 8.3 (SD = 0.8), respectively. The mean completeness scores were 8.3 (SD = 0.6) for ChatGPT draft and 8.5 (SD = 0.7) for GG draft. The one-way ANOVA revealed no significant difference in accuracy [F1 (1, 28) = 0.45, p = 0.51] or completeness [F1 (1, 28) = 0.36, p = 0.55] between the two drafts. Consequently, the Tukey HSD test indicated that there were no significant differences between the drafts in either category. The GG draft showed slightly higher mean scores in both accuracy and completeness; however, the differences were not statistically significant. The ICC for Completeness ratings between ChatGPT and Google Gemini was found to be 0.85 (95% CI: 0.75&#8211; 0.92), indicating excellent agreement between the two raters. For Accuracy ratings, the ICC was calculated to be 0.80 (95% CI: 0.68&#8211;0.89), suggesting good reliability in the ratings between the two. These results highlight the consistency of the ratings between the two AI chatbots ( Table 1 ). Table 1 Summary of ratings for accuracy and completeness between the two AI chatbots Measure Metric ChatGPT Google Gemini Accuracy Mean (SD) 8.07 (0.73) 8.07 (0.73) Minimum and maximum 7.0 and 9.5 7.0 and 10.0 Completeness Mean (SD) 8.07 (0.73) 8.47 (0.73) Minimum and Maximum 7.0 and 9.5 7.0 and 10.0 Overall ICC Accuracy 0.80 (95% CI: 0.68&#8211;0.89) &#8211; Completeness 0.85 (95% CI: 0.75&#8211;0.92) &#8211; CI, confidence interval; ICC, intraclass correlation; SD, standard deviation Readability evaluation was done by using the FRE score. ChatGPT draft had a FRE score of 76.56, indicating that it is fairly easy to read. The sentiment analysis categorizes the tone as neutral, which is appropriate for an IC document. The FRE score of the GG draft is approximately 60.04 (moderately difficult), and sentiment analysis is neutral with positive elements regarding the benefits of the procedure. D iscussion The present study observed that the accuracy, completeness, and sentiment quotients were comparable between both AI chatbots; however, the readability was better with ChatGPT. As far as the use of AI in formulating ICs is concerned, it can help automate the personalized ICs based on a patient's condition and treatment plan. Natural language processing can be used to generate and clarify medical language, making it easier for patients to understand complex medical jargon. In addition, AI-powered systems can guide healthcare professionals in ensuring that all key aspects of IC are covered. The AI Chatbots or interactive systems can walk patients through their options and provide information in real time, answering questions about procedures, side effects, and potential outcomes. The present research on evaluating and comparing the accuracy and readability of informed consent documents in the ICU using AI chatbots like ChatGPT and Google Gemini is timely and significant. Two studies have compared the AI chatbots for their role in preparing patient information leaflets for end-of-life care, and for local anesthesia in eye surgery (87) and triaging trauma patients (9). 6 , 7 The former study showed that GG leaflets exhibited superior readability and actionability, while both demonstrated high accuracy and completeness. 8 , 9 The latter study showed that AI chatbots provided simplified language and high understandability; whereas, traditional leaflets excelled in completeness. There has been a single study comparing AI-generated IC documents (ChatGPT-4, Bard Gemini Advanced, and human-written consents) for oral surgery procedures. In this study, ChatGPT-4 consistently outperformed both Bard and human-written consents in accuracy, completeness, and readability. 3 These aforementioned studies highlight the potential of AI chatbots in enhancing patient education materials across various medical fields. However, it's essential to note that AI-generated content may sometimes contain inaccuracies and may raise data security issues. For instance, the British Broadcasting Corporation (BBC) found that AI chatbots, including ChatGPT and Google Gemini, frequently produced distorted summaries with significant issues. 8 , 10 Given these findings, integrating AI-generated content with human oversight is crucial to ensure accuracy and reliability in patient education materials. The risks associated with AI-generated ICs include missing key details, privacy breaches, and legal challenges. Given these findings, integrating AI-generated content with human oversight is crucial to ensure accuracy and reliability in patient education materials. The use of AI can help standardize information, but doctors remain legally responsible for ensuring patient understanding. 11 They should be used only as supportive tools, with physician oversight, transparency, and proper documentation to ensure legal validity. The present study has certain limitations. First, it is a single-center study with a relatively small sample size. Second, the evaluation of IC was limited to English, without the inclusion of patient attendants or the use of regional languages. Future multicenter studies involving larger cohorts, local languages, and family participation with ICs for other procedures are recommended to enhance the generalizability and impact of the findings. C onclusion The present study observed that the tracheostomy IC generated by both AI Chatbots was comparable with respect to the accuracy, completeness, and sentiment quotient; however, the readability was better with ChatGPT. The use of AI in the IC process offers great potential to improve accuracy, accessibility, and efficiency, but under direct human supervision. A uthor C ontributions GC, SJ, and PG were involved in the concept, design, definition of intellectual content, literature search, data acquisition, data analysis, statistical analysis, manuscript preparation, manuscript editing, and manuscript review. O rcid Geetanjali T Chilkoti https://orcid.org/0000-0002-2436-0444 Swati Jain https://orcid.org/0000-0002-4660-1712 Prakash G Gondode https://orcid.org/0000-0003-1014-8407 Source of support: Nil Conflict of interest: None R eferences 1. Rahsepar AA Tavakoli N Kim GHJ Hassani C Abtin F Bedayat A How AI responds to common lung cancer questions: ChatGPT vs Google Bard Radiology 2023 307 5 e230922 10.1148/radiol.230922 37310252 2. Gondode PG Singh R Mehta S Singh S Kumar S Nayak SS Artificial intelligence chatbots versus traditional medical resources for patient education on &#8220;Labor Epidurals&#8221;: An evaluation of accuracy, emotional tone, and readability Int J Obstet Anesth 2025 61 104302 10.1016/j.ijoa.2024.104302 39657284 3. Vaira LA Lechien JR Maniaci A Tanda G Abbate V Allevi F et al. Evaluating AI-Generated informed consent documents in oral surgery: A comparative study of ChatGPT-4, Bard Gemini advanced, and human-written consents J Craniomaxillofac Surg 2025 53 1 18 23 10.1016/j.jcms.2024.10.002 39490345 4. Scott Brian 2024 Readability formulas. [online] Available from: https://readabilityformulas.com/ [Last accessed October, 2024] 5. Soper D 2001 Free sentiment analyzer. [online] Available from: https://www.danielsoper.com/sentimentanalysis/default.aspx [Last accessed October, 2024] 6. Gondode PG Mahor V Rani D Ramkumar R Yadav P Debunking palliative care myths: Assessing the performance of artificial intelligence chatbots (ChatGPT vs Google Gemini). Indian J Palliat Care 2024 30 3 284 287 10.25259/IJPC_44_2024 39371498 PMC11450875 7. Gondode PG Sharma P Duggal S Garg N End-of-life care patient information leaflets&#8212;A comparative evaluation of artificial intelligence-generated content for readability, sentiment, accuracy, completeness, and suitability: ChatGPT vs Google Gemini Indian J Crit Care Med 2024 28 6 561 568 10.5005/jp-journals-10071-24725 39130387 PMC11310687 8. Mihalache A Popovic MM Muni RH Performance of an artificial intelligence chatbot in ophthalmic knowledge assessment. JAMA Ophthalmol 2023 1;141 6 589 597 10.1001/jamaophthalmol.2023.1144 37103928 PMC10141269 9. Jacob J ChatGPT: Friend or foe?-Utility in Trauma Triage Indian J Crit Care Med 2023 27 8 563 566 10.5005/jp-journals-10071-24498 37636841 PMC10452764 10. Rahman-Jones I 2025 AI chatbots produce distorted summaries with significant issues, study finds. [online] Available from: https://www.bbc.com/news/articles/c0m17d8827ko [Last accessed March, 2025] 11. Cohen IG Slottje A Artificial intelligence and the law of informed consent. Solaiman B Cohen IG Research Handbook on Health, AI and the Law. Cheltenham, UK Edward Elgar Publishing Ltd 2024 Jul 16 Chapter 10. 40245217 40245217"
}